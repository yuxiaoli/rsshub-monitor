<?xml version="1.0" encoding="UTF-8"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>DeepSeek 新闻</title><link>https://api-docs.deepseek.com/zh-cn</link><atom:link href="http://rsshub.rssforever.com/deepseek/news" rel="self" type="application/rss+xml"></atom:link><description>DeepSeek 新闻 - Powered by RSSHub</description><generator>RSSHub</generator><webMaster>contact@rsshub.app (RSSHub)</webMaster><language>en</language><lastBuildDate>Tue, 25 Mar 2025 00:29:10 GMT</lastBuildDate><ttl>5</ttl><item><title>DeepSeek-R1 发布，性能对标 OpenAI o1 正式版</title><description>&lt;p&gt;今天，我们正式发布 DeepSeek-R1，并同步开源模型权重。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DeepSeek-R1 遵循 MIT License，允许用户通过蒸馏技术借助 R1 训练其他模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DeepSeek-R1 上线 API，对用户开放思维链输出，通过设置 &lt;code&gt;model=&#39;deepseek-reasoner&#39;&lt;/code&gt; 即可调用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DeepSeek 官网与 App 即日起同步更新上线。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;性能对齐-openai-o1-正式版&quot;&gt;性能对齐 OpenAI-o1 正式版&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news250120#%E6%80%A7%E8%83%BD%E5%AF%B9%E9%BD%90-openai-o1-%E6%AD%A3%E5%BC%8F%E7%89%88&quot; class=&quot;hash-link&quot; aria-label=&quot;性能对齐 OpenAI-o1 正式版的直接链接&quot; title=&quot;性能对齐 OpenAI-o1 正式版的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_r1_benchmark.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;p&gt;在此，我们将 DeepSeek-R1 训练技术全部公开，以期促进技术社区的充分交流与创新协作。&lt;/p&gt;
&lt;p&gt;论文链接：
&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf&lt;/a&gt;&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;蒸馏小模型超越-openai-o1-mini&quot;&gt;蒸馏小模型超越 OpenAI o1-mini&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news250120#%E8%92%B8%E9%A6%8F%E5%B0%8F%E6%A8%A1%E5%9E%8B%E8%B6%85%E8%B6%8A-openai-o1-mini&quot; class=&quot;hash-link&quot; aria-label=&quot;蒸馏小模型超越 OpenAI o1-mini的直接链接&quot; title=&quot;蒸馏小模型超越 OpenAI o1-mini的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;我们在开源 DeepSeek-R1-Zero 和 DeepSeek-R1 两个 660B 模型的同时，通过 DeepSeek-R1 的输出，蒸馏了 6 个小模型开源给社区，其中 32B 和 70B 模型在多项能力上实现了对标 OpenAI o1-mini 的效果。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_r1_benchmark_table.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;p&gt;HuggingFace 链接：
&lt;a href=&quot;https://huggingface.co/deepseek-ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://huggingface.co/deepseek-ai&lt;/a&gt;&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_r1_hf.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;h3 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;开放的许可证和用户协议&quot;&gt;开放的许可证和用户协议&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news250120#%E5%BC%80%E6%94%BE%E7%9A%84%E8%AE%B8%E5%8F%AF%E8%AF%81%E5%92%8C%E7%94%A8%E6%88%B7%E5%8D%8F%E8%AE%AE&quot; class=&quot;hash-link&quot; aria-label=&quot;开放的许可证和用户协议的直接链接&quot; title=&quot;开放的许可证和用户协议的直接链接&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;为了推动和鼓励开源社区以及行业生态的发展，在发布并开源 R1 的同时，我们同步在协议授权层面也进行了如下调整：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;模型开源 License 统一使用 MIT。我们曾针对大模型开源的特点，参考当前行业的通行实践，特别引入 DeepSeek License 为开源社区提供授权，但实践表明非标准的开源 License 可能反而增加了开发者的理解成本。为此，此次我们的开源仓库（包括模型权重）统一采用标准化、宽松的 MIT License，完全开源，不限制商用，无需申请。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品协议明确可“模型蒸馏”。为了进一步促进技术的开源和共享，我们决定支持用户进行“模型蒸馏”。我们已更新线上产品的用户协议，明确允许用户利用模型输出、通过模型蒸馏等方式训练其他模型。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;app与网页端&quot;&gt;App与网页端&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news250120#app%E4%B8%8E%E7%BD%91%E9%A1%B5%E7%AB%AF&quot; class=&quot;hash-link&quot; aria-label=&quot;App与网页端的直接链接&quot; title=&quot;App与网页端的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;登录DeepSeek官网或官方App，打开“深度思考”模式，即可调用最新版 DeepSeek-R1 完成各类推理任务。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_r1_example.gif&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;api-及定价&quot;&gt;API 及定价&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news250120#api-%E5%8F%8A%E5%AE%9A%E4%BB%B7&quot; class=&quot;hash-link&quot; aria-label=&quot;API 及定价的直接链接&quot; title=&quot;API 及定�价的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;DeepSeek-R1 API 服务定价为每百万输入 tokens 1 元（缓存命中）/ 4 元（缓存未命中），每百万输出 tokens 16 元。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_r1_price.jpeg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_r1_price_compare.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;p&gt;详细的 API 调用指南请参考官方文档：&amp;nbsp;
&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/guides/reasoning_model&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://api-docs.deepseek.com/zh-cn/guides/reasoning_model&lt;/a&gt;&lt;/p&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news250120</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news250120</guid><pubDate>Sun, 19 Jan 2025 16:00:00 GMT</pubDate></item><item><title>DeepSeek APP</title><description>&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_app_cn.jpg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news250115</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news250115</guid><pubDate>Tue, 14 Jan 2025 16:00:00 GMT</pubDate></item><item><title>DeepSeek-V3 正式发布</title><description>&lt;p&gt;今天，我们全新系列模型 DeepSeek-V3 首个版本上线并同步开源。&lt;/p&gt;
&lt;p&gt;登录官网 &lt;a href=&quot;https://chat.deepseek.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;chat.deepseek.com&lt;/a&gt; 即可与最新版 V3 模型对话。API 服务已同步更新，接口配置无需改动。当前版本的 DeepSeek-V3 暂不支持多模态输入输出。&lt;/p&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;性能对齐海外领军闭源模型&quot;&gt;性能对齐海外领军闭源模型&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1226#%E6%80%A7%E8%83%BD%E5%AF%B9%E9%BD%90%E6%B5%B7%E5%A4%96%E9%A2%86%E5%86%9B%E9%97%AD%E6%BA%90%E6%A8%A1%E5%9E%8B&quot; class=&quot;hash-link&quot; aria-label=&quot;性能对齐海外领军闭源模型的直接链接&quot; title=&quot;性能对齐海外领军闭源模型的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;DeepSeek-V3 为自研 MoE 模型，671B 参数，激活 37B，在 14.8T token 上进行了预训练。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;论文链接：&lt;/strong&gt;&lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/ds_v3_benchmark_hist_zh.jpeg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;百科知识：&lt;/strong&gt; DeepSeek-V3 在知识类任务（MMLU, MMLU-Pro, GPQA, SimpleQA）上的水平相比前代 DeepSeek-V2.5 显著提升，接近当前表现最好的模型 Claude-3.5-Sonnet-1022。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;长文本：&lt;/strong&gt; 在长文本测评中，DROP、FRAMES 和 LongBench v2 上，DeepSeek-V3 平均表现超越其他模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码：&lt;/strong&gt; DeepSeek-V3 在算法类代码场景（Codeforces），远远领先于市面上已有的全部非 o1 类模型；并在工程类代码场景（SWE-Bench Verified）逼近 Claude-3.5-Sonnet-1022。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数学：&lt;/strong&gt; 在美国数学竞赛（AIME 2024, MATH）和全国高中数学联赛（CNMO 2024）上，DeepSeek-V3 大幅超过了所有开源闭源模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;中文能力：&lt;/strong&gt; DeepSeek-V3 与 Qwen2.5-72B 在教育类测评 C-Eval 和代词消歧等评测集上表现相近，但在事实知识 C-SimpleQA 上更为领先。&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/ds_v3_benchmark_table_zh.jpeg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;生成速度提升至-3-倍&quot;&gt;生成速度提升至 3 倍&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1226#%E7%94%9F%E6%88%90%E9%80%9F%E5%BA%A6%E6%8F%90%E5%8D%87%E8%87%B3-3-%E5%80%8D&quot; class=&quot;hash-link&quot; aria-label=&quot;生成速度提升至 3 倍的直接链接&quot; title=&quot;生成速度提升至 3 倍的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;通过算法和工程上的创新，DeepSeek-V3 的生成吐字速度从 20 TPS 大幅提高至 60 TPS，相比 V2.5 模型实现了 3 倍的提升，为用户带来更加迅速流畅的使用体验。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/ds_v3_tps_zh.gif&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;api-服务价格调整&quot;&gt;API 服务价格调整&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1226#api-%E6%9C%8D%E5%8A%A1%E4%BB%B7%E6%A0%BC%E8%B0%83%E6%95%B4&quot; class=&quot;hash-link&quot; aria-label=&quot;API 服务价格调整的直接链接&quot; title=&quot;API 服务价格调整的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;随着性能更强、速度更快的 DeepSeek-V3 更新上线，我们的模型 API 服务定价也将调整为&lt;strong&gt;每百万输入 tokens 0.5 元（缓存命中）/ 2 元（缓存未命中），每百万输出 tokens 8 元&lt;/strong&gt;，以期能够持续地为大家提供更好的模型服务。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/ds_v3_price_zh.jpeg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;p&gt;与此同时，我们决定为全新模型设置长达 &lt;strong&gt;45 天&lt;/strong&gt;的优惠价格体验期：即日起至 &lt;strong&gt;2025 年 2 月 8 日&lt;/strong&gt;，DeepSeek-V3 的 API 服务价格仍然会是大家熟悉的&lt;strong&gt;每百万输入 tokens 0.1 元（缓存命中）/ 1 元（缓存未命中），每百万输出 tokens 2 元&lt;/strong&gt;，已经注册的老用户和在此期间内注册的新用户均可享受以上优惠价格。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/ds_v3_price_2_zh.jpeg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;开源权重和本地部署&quot;&gt;开源权重和本地部署&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1226#%E5%BC%80%E6%BA%90%E6%9D%83%E9%87%8D%E5%92%8C%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2&quot; class=&quot;hash-link&quot; aria-label=&quot;开源权重和本地部署的直接链接&quot; title=&quot;开源权重和本地部署的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;DeepSeek-V3 采用 FP8 训练，并开源了原生 FP8 权重。&lt;/p&gt;
&lt;p&gt;得益于开源社区的支持，&lt;strong&gt;SGLang&lt;/strong&gt; 和 &lt;strong&gt;LMDeploy&lt;/strong&gt;  第一时间支持了 V3 模型的原生 FP8 推理，同时 &lt;strong&gt;TensorRT-LLM&lt;/strong&gt; 和 &lt;strong&gt;MindIE&lt;/strong&gt; 则实现了 BF16 推理。此外，为方便社区适配和拓展应用场景，我们提供了从 FP8 到 BF16 的转换脚本。&lt;/p&gt;
&lt;p&gt;模型权重下载和更多本地部署信息请参考： &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V3-Base&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://huggingface.co/deepseek-ai/DeepSeek-V3-Base&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;“以开源精神和长期主义追求普惠 AGI”&lt;/strong&gt; 是 DeepSeek 一直以来的坚定信念。我们非常兴奋能与社区分享在模型预训练方面的阶段性进展，也十分欣喜地看到开源模型和闭源模型的能力差距正在进一步缩小。&lt;/p&gt;
&lt;p&gt;这是一个全新的开始，未来我们会在 DeepSeek-V3 基座模型上继续打造深度思考、多模态等更加丰富的功能，并将持续与社区分享我们最新的探索成果。&lt;/p&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news1226</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news1226</guid><pubDate>Wed, 25 Dec 2024 16:00:00 GMT</pubDate></item><item><title>DeepSeek V2 系列收官，联网搜索上线官网</title><description>&lt;p&gt;今天，我们发布 DeepSeek V2.5 的最终版微调模型 DeepSeek-V2.5-1210。本版模型将是我们开启下一个全新基座模型系列前对 V2 系列的最后一次更新。&lt;/p&gt;
&lt;p&gt;与之前版本相比，本次更新通过 Post-Training 全面提升了模型各方面能力表现，包括数学、代码、写作、角色扮演等；同时，新版模型优化了文件上传功能，并且全新支持了联网搜索，展现出更加强大的全方位服务于各类工作生活场景的能力。&lt;/p&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;模型通用能力提升&quot;&gt;模型通用能力提升&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1210#%E6%A8%A1%E5%9E%8B%E9%80%9A%E7%94%A8%E8%83%BD%E5%8A%9B%E6%8F%90%E5%8D%87&quot; class=&quot;hash-link&quot; aria-label=&quot;模型通用能力提升的直接链接&quot; title=&quot;模型通用能力提升的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;DeepSeek-V2.5-1210 版本通过 Post-Training 阶段的迭代，全面提升了模型在各个领域的能力：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_v2_5_benchmark_zh.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;p&gt;遵循我们一贯的开源精神，新版模型权重已经开源在 Huggingface：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210&lt;/a&gt;&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_v2_5_hf.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;联网搜索功能&quot;&gt;联网搜索功能&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1210#%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD&quot; class=&quot;hash-link&quot; aria-label=&quot;联网搜索功能的直接链接&quot; title=&quot;联网搜索功能的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;DeepSeek-V2.5-1210 版本支持了&lt;strong&gt;联网搜索&lt;/strong&gt;功能，并已上线网页端。登陆 &lt;a href=&quot;https://chat.deepseek.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://chat.deepseek.com/&lt;/a&gt;，在输入框中打开 &lt;strong&gt;“联网搜索”&lt;/strong&gt; 即可体验。目前，API 暂不支持搜索功能。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_v2_5_search_zh.gif&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;p&gt;在“联网搜索”模式下，模型将深入阅读海量网页，为用户生成全面、准确、满足个性化需求的回答。面对用户的复杂问题，模型将自动提取多个关键词并行搜索，在更短时间内提供更加多样的搜索结果。&lt;/p&gt;
&lt;p&gt;以下是搜索效果示例：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_v2_5_search_example_zh.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;v25-的最后版本&quot;&gt;V2.5 的最后版本&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1210#v25-%E7%9A%84%E6%9C%80%E5%90%8E%E7%89%88%E6%9C%AC&quot; class=&quot;hash-link&quot; aria-label=&quot;V2.5 的最后版本的直接链接&quot; title=&quot;V2.5 的最后版本的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/deepseek_v2_5_timeline.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;p&gt;DeepSeek-V2.5-1210 将会是 DeepSeek V2.5 模型的最后一个版本。随着本次模型的发布，我们 DeepSeek V2系列模型的迭代更新也将告一段落。&lt;/p&gt;
&lt;p&gt;DeepSeek V2 系列模型自今年 5 月发布开源以来，已经陪伴大家走过了半年的时间，期间历经 5 次迭代，而广大用户朋友们的支持与肯定，正是我们一直以来坚持不断更新进步的动力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;“有善始者实繁，能克终者盖寡。”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;终版模型是暂时的收束，更是全新的起点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DeepSeek正在打造更加强大的下一代基座模型 DeepSeek V3，敬请期待！&lt;/strong&gt;&lt;/p&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news1210</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news1210</guid><pubDate>Mon, 09 Dec 2024 16:00:00 GMT</pubDate></item><item><title>DeepSeek推理模型预览版上线，解密o1推理过程</title><description>&lt;p&gt;今天，DeepSeek 全新研发的推理模型 DeepSeek-R1-Lite 预览版正式上线。&lt;/p&gt;
&lt;p&gt;所有用户均可登录官方网页（&lt;a href=&quot;https://chat.deepseek.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;chat.deepseek.com&lt;/a&gt;），一键开启与 R1-Lite 预览版模型的超强推理对话体验。&lt;/p&gt;
&lt;p&gt;DeepSeek R1 系列模型使用强化学习训练，推理过程包含大量反思和验证，思维链长度可达数万字。&lt;/p&gt;
&lt;p&gt;该系列模型在数学、代码以及各种复杂逻辑推理任务上，取得了媲美 o1-preview 的推理效果，并为用户展现了 o1 没有公开的完整思考过程。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h3 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;全面提升的推理性能&quot;&gt;全面提升的推理性能&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1120#%E5%85%A8%E9%9D%A2%E6%8F%90%E5%8D%87%E7%9A%84%E6%8E%A8%E7%90%86%E6%80%A7%E8%83%BD&quot; class=&quot;hash-link&quot; aria-label=&quot;全面提升的推理性能的直接链接&quot; title=&quot;全面提升的推理性能的直接链接&quot;&gt;&lt;/a&gt;&lt;/h3&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;DeepSeek-R1-Lite 预览版模型在美国数学竞赛（AMC）中难度等级最高的 AIME 以及全球顶级编程竞赛（codeforces）等权威评测中，均取得了卓越的成绩，大幅超越了 GPT-4o 等知名模型。&lt;/li&gt;
&lt;li&gt;下表为 DeepSeek-R1-Lite 在各项相关评测中的得分结果：&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/r1_benchmark_zh.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;深度思考的效果与潜力&quot;&gt;深度思考的效果与潜力&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1120#%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%E7%9A%84%E6%95%88%E6%9E%9C%E4%B8%8E%E6%BD%9C%E5%8A%9B&quot; class=&quot;hash-link&quot; aria-label=&quot;深度思考的效果与潜力的直接链接&quot; title=&quot;深度思考的效果与潜力的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;DeepSeek-R1-Lite 的推理过程长，并且包含了大量的反思和验证。下图展示了模型在数学竞赛上的得分与测试所允许思考的长度紧密相关。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/r1_scaling_law_zh.jpg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;红色实线展示了模型所能达到的准确率与所给定的推理长度呈正相关；&lt;/li&gt;
&lt;li&gt;相比传统的多次采样+投票（Majority Voting），模型思维链长度增加展现出了更高的效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;全面上线尝鲜体验&quot;&gt;全面上线，尝鲜体验&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1120#%E5%85%A8%E9%9D%A2%E4%B8%8A%E7%BA%BF%E5%B0%9D%E9%B2%9C%E4%BD%93%E9%AA%8C&quot; class=&quot;hash-link&quot; aria-label=&quot;全面上线，尝鲜体验的直接链接&quot; title=&quot;全面上线，尝鲜体验的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;登录 chat.deepseek.com，在输入框中选择“深度思考”模式，即可开启与 DeepSeek-R1-Lite 预览版的对话。&lt;/p&gt;
&lt;p&gt;“深度思考” 模式专门针对数学、代码等各类复杂逻辑推理问题而设计，相比于普通的简单问题，能够提供更加全面、清晰、思路严谨的优质解答，充分展现出较长思维链的更多优势。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对话开启示例：&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/r1_demo_zh.gif&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;适用场景与效果示例：&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/r1_example_1_zh.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/r1_example_2_zh.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;新的开始敬请期待&quot;&gt;新的开始，敬请期待&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news1120#%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B%E6%95%AC%E8%AF%B7%E6%9C%9F%E5%BE%85&quot; class=&quot;hash-link&quot; aria-label=&quot;新的开始，敬请期待的直接链接&quot; title=&quot;新的开始，敬请期待的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;&lt;/div&gt;
&lt;p&gt;DeepSeek-R1-Lite 目前仍处于迭代开发阶段，仅支持网页使用，暂不支持 API 调用。DeepSeek-R1-Lite 所使用的也是一个较小的基座模型，无法完全释放长思维链的潜力。&lt;/p&gt;
&lt;p&gt;当前，我们正在持续迭代推理系列模型。之后，正式版 DeepSeek-R1 模型将完全开源，我们将公开技术报告，并部署 API 服务。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://cdn.deepseek.com/api-docs/chat_deepseek_com_qr_code.png&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;p&gt;&lt;strong&gt;扫码与 DeepSeek 开启对话&lt;/strong&gt;&lt;/p&gt;&lt;/div&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news1120</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news1120</guid><pubDate>Tue, 19 Nov 2024 16:00:00 GMT</pubDate></item><item><title>DeepSeek-V2.5：融合通用与代码能力的全新开源模型</title><description>&lt;p&gt;今天，我们完成了 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2 两个模型的合并，正式发布 &lt;strong&gt;DeepSeek-V2.5&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;DeepSeek-V2.5 不仅保留了原有 Chat 模型的通用对话能力和 Coder 模型的强大代码处理能力，还更好地对齐了人类偏好。此外，DeepSeek-V2.5 在写作任务、指令跟随等多个方面也实现了大幅提升。&lt;/p&gt;
&lt;p&gt;DeepSeek-V2.5 现已在网页端及 API 全面上线，API 接口向前兼容，用户通过deepseek-coder或deepseek-chat均可以访问新的模型。同时，Function Calling、FIM 补全、Json Output 等功能保持不变。&lt;/p&gt;
&lt;p&gt;All-in-One 的 DeepSeek-V2.5 将为用户带来更简洁、智能、高效的使用体验。&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;升级历史&quot;&gt;升级历史&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0905#%E5%8D%87%E7%BA%A7%E5%8E%86%E5%8F%B2&quot; class=&quot;hash-link&quot; aria-label=&quot;升级历史的直接链接&quot; title=&quot;升级历史的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;DeepSeek 一直专注于模型的改进和优化。在 6 月份，我们对 DeepSeek-V2-Chat 进行了重大升级，用 Coder V2 的 Base 模型替换原有的 Chat 的 Base 模型，显著提升了其代码生成和推理能力，并发布了 DeepSeek-V2-Chat-0628 版本。紧接着，DeepSeek-Coder-V2 在原有 Base 模型的基础上，通过对齐优化，大大提升通用能力后推出了 DeepSeek-Coder-V2 0724 版本。最终，我们成功将 Chat 和 Coder 两个模型合并，推出了全新的DeepSeek-V2.5 版本。&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/version_history.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;&lt;strong&gt;由于本次模型版本变动较大，如出现某些场景效果变差，建议重新调整 System Prompt 和 Temperature，以获得最佳性能。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;通用能力&quot;&gt;通用能力&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0905#%E9%80%9A%E7%94%A8%E8%83%BD%E5%8A%9B&quot; class=&quot;hash-link&quot; aria-label=&quot;通用能力的直接链接&quot; title=&quot;通用能力的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;通用能力评测&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/benchmark_1.jpeg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;首先，我们使用业界通用的测试集对 DeepSeek-V2.5 的能力进行测评，在中文和英文四个测试集上，DeepSeek-V2.5 均优于之前的 DeepSeek-V2-0628 以及 DeepSeek-Coder-V2-0724。&lt;/p&gt;
&lt;p&gt;在我们内部的中文评测中，和 GPT-4o mini、ChatGPT-4o-latest 的对战胜率（裁判为 GPT-4o）相较于 DeepSeek-V2-0628 均有明显提升。此测评中涵盖创作、问答等通用能力，用户使用体验将得到提升：&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/benchmark_2.jpg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;ul&gt;
&lt;li&gt;安全能力评测&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Safety 和 Helpful 之间的权衡是我们在迭代开发中一直重点关注的问题。在 DeepSeek-V2.5 版本中，我们对于模型安全问题的边界做了更加清晰的划分，在强化模型对于各种越狱攻击的安全性的同时，减少了安全策略过度泛化到正常问题中去的倾向。&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;安全综合得分（越高越好）*&lt;/th&gt;&lt;th&gt;安全外溢比例（越低越好）**&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;DeepSeek-V2-0628&lt;/td&gt;&lt;td&gt;74.4%&lt;/td&gt;&lt;td&gt;11.3%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DeepSeek-V2.5&lt;/td&gt;&lt;td&gt;82.6%&lt;/td&gt;&lt;td&gt;4.6%&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;* 基于内部测试集合的得分，分数越高代表模型的整体安全性越高&lt;/p&gt;
&lt;p&gt;** 基于内部测试集合的得分，比例越低代表模型的安全策略对于正常问题的影响越小&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;代码能力&quot;&gt;代码能力&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0905#%E4%BB%A3%E7%A0%81%E8%83%BD%E5%8A%9B&quot; class=&quot;hash-link&quot; aria-label=&quot;代码能力的直接链接&quot; title=&quot;代码能力的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;在代码方面，DeepSeek-V2.5 保留了 DeepSeek-Coder-V2-0724 强大的代码能力。在 HumanEval Python 和LiveCodeBench（2024 年 1 月 - 2024 年 9 月）测试中，DeepSeek-V2.5 显示了较为显著的改进。在 HumanEval Multilingual 和 Aider 测试中，DeepSeek-Coder-V2-0724 略胜一筹。在 SWE-verified 测试中，两个版本的表现都较低，表明在此方面仍需进一步优化。另外，在FIM补全任务上，内部评测集DS-FIM-Eval的评分提升了 5.1%，可以带来更好的插件补全体验。&lt;/p&gt;
&lt;p&gt;另外，DeepSeek-V2.5对代码常见场景进行了优化，以提升实际使用的表现。在内部的主观评测 DS-Arena-Code 中，DeepSeek-V2.5 对战竞品的胜率（GPT-4o 为裁判）取得了显著提升。&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/benchmark_3.png&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/benchmark_4.jpg&quot; width=&quot;768&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;模型开源&quot;&gt;模型开源&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0905#%E6%A8%A1%E5%9E%8B%E5%BC%80%E6%BA%90&quot; class=&quot;hash-link&quot; aria-label=&quot;模型开源的直接链接&quot; title=&quot;模型开源的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;一如既往，秉持着持久开源的精神，DeepSeek-V2.5 现已开源到了 HuggingFace：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V2.5&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://huggingface.co/deepseek-ai/DeepSeek-V2.5&lt;/a&gt;&lt;/p&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news0905</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news0905</guid><pubDate>Wed, 04 Sep 2024 16:00:00 GMT</pubDate></item><item><title>DeepSeek API 创新采用硬盘缓存，价格再降一个数量级</title><description>&lt;p&gt;在大模型 API 的使用场景中，用户的输入有相当比例是重复的。举例说，用户的 prompt 往往有一些重复引用的部分；再举例说，多轮对话中，每一轮都要将前几轮的内容重复输入。&lt;/p&gt;
&lt;p&gt;为此，DeepSeek 启用上下文硬盘缓存技术，把预计未来会重复使用的内容，缓存在分布式的硬盘阵列中。如果输入存在重复，则重复的部分只需要从缓存读取，无需计算。该技术不仅降低服务的延迟，还大幅削减最终的使用成本。&lt;/p&gt;
&lt;p&gt;缓存命中的部分，DeepSeek 收费 0.1元 每百万 tokens。至此，大模型的价格再降低一个数量级&lt;sup&gt;1&lt;/sup&gt;。&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/kv_cache_price.JPEG&quot; width=&quot;512&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;&lt;small&gt;注 1: DeepSeek-V3 API 价格已做调整，最新价格请参考&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/quick_start/pricing&quot;&gt;模型 &amp;amp; 价格&lt;/a&gt;页面。&lt;/small&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;如何使用-deepseek-api-的缓存服务&quot;&gt;如何使用 DeepSeek API 的缓存服务&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0802#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-deepseek-api-%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%8D%E5%8A%A1&quot; class=&quot;hash-link&quot; aria-label=&quot;如何使用 DeepSeek API 的缓存服务的直接链接&quot; title=&quot;如何使用 DeepSeek API 的缓存服务的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;硬盘缓存服务已经全面上线，用户无需修改代码，无需更换接口，硬盘缓存服务将自动运行，系统自动按照实际命中情况计费。&lt;/p&gt;
&lt;p&gt;注意，只有当两个请求的前缀内容相同时（从第 0 个 token 开始相同），才算重复。中间开始的重复不能被缓存命中。&lt;/p&gt;
&lt;p&gt;以下为两个经典场景的缓存举例：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 多轮对话场景，下一轮对话会命中上一轮对话生成的上下文缓存&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/kv_cache_example_1.JPEG&quot; width=&quot;512&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;&lt;strong&gt;2. 数据分析场景，后续具有相同前缀的请求会命中上下文缓存&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/kv_cache_example_2.JPEG&quot; width=&quot;512&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;多种应用能从上下文硬盘缓存中受益：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;具有长预设提示词的问答助手类应用&lt;/li&gt;
&lt;li&gt;具有长角色设定与多轮对话的角色扮演类应用&lt;/li&gt;
&lt;li&gt;针对固定文本集合进行频繁询问的数据分析类应用&lt;/li&gt;
&lt;li&gt;代码仓库级别的代码分析与排障工具&lt;/li&gt;
&lt;li&gt;通过 Few-shot 提升模型输出效果&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更详细的使用方法，请参考指南&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/guides/kv_cache&quot;&gt;使用硬盘缓存&lt;/a&gt;&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;如何查询缓存命中情况&quot;&gt;如何查询缓存命中情况&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0802#%E5%A6%82%E4%BD%95%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98%E5%91%BD%E4%B8%AD%E6%83%85%E5%86%B5&quot; class=&quot;hash-link&quot; aria-label=&quot;如何查询缓存命中情况的直接链接&quot; title=&quot;如何查询缓存命中情况的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;在 API 返回的 usage 中，增加了两个字段，帮助用户实时监测缓存的命中情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;prompt_cache_hit_tokens&lt;/code&gt;：本次请求的输入中，缓存命中的 tokens 数（0.1 元 / 百万 tokens）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;prompt_cache_miss_tokens&lt;/code&gt;：本次请求的输入中，缓存未命中的 tokens 数（1 元 / 百万 tokens）&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;降低服务延迟&quot;&gt;降低服务延迟&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0802#%E9%99%8D%E4%BD%8E%E6%9C%8D%E5%8A%A1%E5%BB%B6%E8%BF%9F&quot; class=&quot;hash-link&quot; aria-label=&quot;降低服务延迟的直接链接&quot; title=&quot;降低服务延迟的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;输入长、重复内容多的请求，API 服务的首 token 延迟将大幅降低。&lt;/p&gt;
&lt;p&gt;举个极端的例子，对 128K 输入且大部分重复的请求，实测首 token 延迟从 13 秒降低到 500 毫秒。&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;降低整体费用&quot;&gt;降低整体费用&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0802#%E9%99%8D%E4%BD%8E%E6%95%B4%E4%BD%93%E8%B4%B9%E7%94%A8&quot; class=&quot;hash-link&quot; aria-label=&quot;降低整体费用的直接链接&quot; title=&quot;降低整体费用的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;最高可以节省 90% 的费用（需要针对缓存特性进行优化）。&lt;/p&gt;
&lt;p&gt;即使不做任何优化，按历史使用情况，用户整体节省的费用也超过 50%。&lt;/p&gt;
&lt;p&gt;缓存没有其它额外的费用，只有0.1 元每百万 tokens。缓存占用存储无需付费。&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;缓存的安全性问题&quot;&gt;缓存的安全性问题&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0802#%E7%BC%93%E5%AD%98%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7%E9%97%AE%E9%A2%98&quot; class=&quot;hash-link&quot; aria-label=&quot;缓存的安全性问题的直接链接&quot; title=&quot;缓存的安全性问题的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;本缓存系统在设计的时候已充分考虑了各种潜在的安全问题。&lt;/p&gt;
&lt;p&gt;每个用户的缓存是独立的，逻辑上相互不可见，从底层确保用户数据的安全和隐私。&lt;/p&gt;
&lt;p&gt;长时间不用的缓存会自动清空，不会长期保留，且不会用于其他用途。&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;为何-deepseek-api-能率先采用硬盘缓存&quot;&gt;为何 DeepSeek API 能率先采用硬盘缓存&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0802#%E4%B8%BA%E4%BD%95-deepseek-api-%E8%83%BD%E7%8E%87%E5%85%88%E9%87%87%E7%94%A8%E7%A1%AC%E7%9B%98%E7%BC%93%E5%AD%98&quot; class=&quot;hash-link&quot; aria-label=&quot;为何 DeepSeek API 能率先采用硬盘缓存的直接链接&quot; title=&quot;为何 DeepSeek API 能率先采用硬盘缓存的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;根据公开的信息，DeepSeek 可能是全球第一家在 API 服务中大范围采用硬盘缓存的大模型厂商。&lt;/p&gt;
&lt;p&gt;这得益于 DeepSeek V2 提出的 MLA 结构，在提高模型效果的同时，大大压缩了上下文 KV Cache 的大小，使得存储所需要的传输带宽和存储容量均大幅减少，因此可以缓存到低成本的硬盘上。&lt;/p&gt;
&lt;h2 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;deepseek-api-的并发和限流&quot;&gt;DeepSeek API 的并发和限流&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0802#deepseek-api-%E7%9A%84%E5%B9%B6%E5%8F%91%E5%92%8C%E9%99%90%E6%B5%81&quot; class=&quot;hash-link&quot; aria-label=&quot;DeepSeek API 的并发和限流的直接链接&quot; title=&quot;DeepSeek API 的并发和限流的直接链接&quot;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;DeepSeek API 服务按照每天 1 万亿的容量进行设计。对所有用户均不限流、不限并发、同时保证服务质量。请放心加大并发使用。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;small&gt;注1. 缓存系统以 64 tokens 为一个存储单元，不足 64 tokens 的内容不会被缓存&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;注2. 缓存系统是“尽力而为”，不保证 100% 缓存命中&lt;/small&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;注3. 缓存不再使用后会自动被清空，时间一般为几个小时到几天&lt;/small&gt;&lt;/p&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news0802</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news0802</guid><pubDate>Thu, 01 Aug 2024 16:00:00 GMT</pubDate></item><item><title>DeepSeek API 升级，支持续写、FIM、Function Calling、JSON Output</title><description>&lt;p&gt;今天，DeepSeek API 迎来更新，装备了新的接口功能，来释放模型的更多潜力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;更新接口 &lt;code&gt;/chat/completions&lt;/code&gt;&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;JSON Output&lt;/li&gt;
&lt;li&gt;Function Calling&lt;/li&gt;
&lt;li&gt;对话前缀续写（Beta）&lt;/li&gt;
&lt;li&gt;8K 最长输出（Beta）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;新增接口 &lt;code&gt;/completions&lt;/code&gt;&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;FIM 补全（Beta）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有新功能，均可使用 &lt;code&gt;deepseek-chat&lt;/code&gt; 和 &lt;code&gt;deepseek-coder&lt;/code&gt; 模型调用。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;一更新接口-chatcompletions&quot;&gt;一、更新接口 &lt;code&gt;/chat/completions&lt;/code&gt;&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#%E4%B8%80%E6%9B%B4%E6%96%B0%E6%8E%A5%E5%8F%A3-chatcompletions&quot; class=&quot;hash-link&quot; aria-label=&quot;一更新接口-chatcompletions的直接链接&quot; title=&quot;一更新接口-chatcompletions的直接链接&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;h4 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;1-json-output增强内容格式化&quot;&gt;1. JSON Output，增强内容格式化&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#1-json-output%E5%A2%9E%E5%BC%BA%E5%86%85%E5%AE%B9%E6%A0%BC%E5%BC%8F%E5%8C%96&quot; class=&quot;hash-link&quot; aria-label=&quot;1. JSON Output，增强内容格式化的直接链接&quot; title=&quot;1. JSON Output，增强内容格式化的直接链接&quot;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;DeepSeek API 新增 JSON Output 功能，兼容 OpenAI API，能够强制模型输出 JSON 格式的字符串。&lt;/p&gt;
&lt;p&gt;在进行数据处理等任务时，该功能可以让模型按预定格式返回 JSON，方便后续对模型输出内容进行解析，提高程序流程的自动化能力。&lt;/p&gt;
&lt;p&gt;要使用 JSON Output 功能，需要：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设置 &lt;code&gt;response_format&lt;/code&gt; 参数为 &lt;code&gt;{&#39;type&#39;: &#39;json_object&#39;}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;用户需要在提示词中，指导模型输出 JSON 的格式，来确保输出格式符合预期&lt;/li&gt;
&lt;li&gt;合理设置 &lt;code&gt;max_tokens&lt;/code&gt;，防止 JSON 字符串被中途截断&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以下为一个 JSON Output 功能的使用样例。在这个样例中，用户给出一段文本，模型对文本中的问题&amp;amp;答案进行格式化输出。&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/json_mode.jpg&quot; width=&quot;512&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;详细使用方法，请参考 &lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/guides/json_mode&quot;&gt;JSON Output 指南&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h4 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;2-function连接物理世界&quot;&gt;2. Function，连接物理世界&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#2-function%E8%BF%9E%E6%8E%A5%E7%89%A9%E7%90%86%E4%B8%96%E7%95%8C&quot; class=&quot;hash-link&quot; aria-label=&quot;2. Function，连接物理世界的直接链接&quot; title=&quot;2. Function，连接物理世界的直接链接&quot;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;DeepSeek API 新增 Function Calling 功能，兼容 OpenAI API，通过调用外部工具，来增强模型与物理世界交互的能力。&lt;/p&gt;
&lt;p&gt;Function Calling 功能支持传入多个 Function（最多 128 个），支持并行 Function 调用。&lt;/p&gt;
&lt;p&gt;下图展示了将 &lt;code&gt;deepseek-coder&lt;/code&gt; 整合到开源大模型前端 &lt;a href=&quot;https://github.com/lobehub/lobe-chat&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;LobeChat&lt;/a&gt; 的效果。在这个例子中，我们开启了“网站爬虫”插件，来实现对网站的爬取和总结。&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/fc_demo.gif&quot; width=&quot;512&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;下图展示了使用 Function Calling 功能的交互过程：&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/fc_demo_2.jpeg&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;详细使用方法，请参考 &lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/guides/function_calling&quot;&gt;Function Calling 指南&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h4 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;3-对话前缀续写beta更灵活的输出控制&quot;&gt;3. 对话前缀续写（Beta），更灵活的输出控制&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#3-%E5%AF%B9%E8%AF%9D%E5%89%8D%E7%BC%80%E7%BB%AD%E5%86%99beta%E6%9B%B4%E7%81%B5%E6%B4%BB%E7%9A%84%E8%BE%93%E5%87%BA%E6%8E%A7%E5%88%B6&quot; class=&quot;hash-link&quot; aria-label=&quot;3. 对话前缀续写（Beta），更灵活的输出控制的直接链接&quot; title=&quot;3. 对话前缀续写（Beta），更灵活的输出控制的直接链接&quot;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;对话前缀续写沿用了&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/api/create-chat-completion&quot;&gt;对话补全&lt;/a&gt;的 API 格式，允许用户指定最后一条 &lt;code&gt;assistant&lt;/code&gt; 消息的前缀，来让模型按照该前缀进行补全。该功能也可用于输出长度达到 &lt;code&gt;max_tokens&lt;/code&gt; 被截断后，将被截断的消息进行拼接，重新发送请求对被截断内容进行续写。&lt;/p&gt;
&lt;p&gt;要使用对话前缀续写功能，需要：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设置 &lt;code&gt;base_url&lt;/code&gt; 为 &lt;code&gt;https://api.deepseek.com/beta&lt;/code&gt; 来开启 Beta 功能&lt;/li&gt;
&lt;li&gt;确保 messages 列表里最后一条消息的 &lt;code&gt;role&lt;/code&gt; 为 &lt;code&gt;assistant&lt;/code&gt;，并设置最后一条消息的 &lt;code&gt;prefix&lt;/code&gt; 参数为 &lt;code&gt;True&lt;/code&gt;，如：&lt;code&gt;{&quot;role&quot;: &quot;assistant&quot;: &quot;content&quot;: &quot;在很久很久以前，&quot;, &quot;prefix&quot;: True}&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以下为对话前缀续写功能的使用样例。在这个例子里，设置了 assistant 消息开头为&lt;code&gt;&#39;```python\n&#39;&lt;/code&gt;，以强制其以代码块开始，并设置 stop 参数为 &lt;code&gt;&#39;```&#39;&lt;/code&gt;，让模型不输出多余的内容。&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/chat_prefix_completion.jpeg&quot; width=&quot;512&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;详细使用方法，请参考 &lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/guides/chat_prefix_completion&quot;&gt;对话前缀续写指南&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h4 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;4-8k-最长输出beta释放更长可能&quot;&gt;4. 8K 最长输出（Beta），释放更长可能&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#4-8k-%E6%9C%80%E9%95%BF%E8%BE%93%E5%87%BAbeta%E9%87%8A%E6%94%BE%E6%9B%B4%E9%95%BF%E5%8F%AF%E8%83%BD&quot; class=&quot;hash-link&quot; aria-label=&quot;4. 8K 最长输出（Beta），释放更长可能的直接链接&quot; title=&quot;4. 8K 最长输出（Beta），释放更长可能的直接链接&quot;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;为了满足更长文本输出的场景，我们在 Beta 版 API 中，将 &lt;code&gt;max_tokens&lt;/code&gt; 参数的上限调整为 8K。&lt;/p&gt;
&lt;p&gt;要提高到 8K 最长输出，需要：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设置 &lt;code&gt;base_url&lt;/code&gt; 为 &lt;code&gt;https://api.deepseek.com/beta&lt;/code&gt; 来开启 Beta 功能&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_tokens&lt;/code&gt; 默认为 4096。开启 Beta 功能后，&lt;code&gt;max_tokens&lt;/code&gt; 最大可设置为 8192&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;二新增接口-completions&quot;&gt;二、新增接口 &lt;code&gt;/completions&lt;/code&gt;&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#%E4%BA%8C%E6%96%B0%E5%A2%9E%E6%8E%A5%E5%8F%A3-completions&quot; class=&quot;hash-link&quot; aria-label=&quot;二新增接口-completions的直接链接&quot; title=&quot;二新增接��口-completions的直接链接&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;h4 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;1-fim-补全beta使能续写场景&quot;&gt;1. FIM 补全（Beta），使能续写场景&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#1-fim-%E8%A1%A5%E5%85%A8beta%E4%BD%BF%E8%83%BD%E7%BB%AD%E5%86%99%E5%9C%BA%E6%99%AF&quot; class=&quot;hash-link&quot; aria-label=&quot;1. FIM 补全（Beta），使能续写场景的直接链接&quot; title=&quot;1. FIM 补全（Beta），使能续写场景的直接链接&quot;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;DeepSeek API 新增 FIM (Fill-In-the-Middle) 补全接口，兼容 OpenAI 的 FIM 补全 API，允许用户提供自定义的前缀/后缀（可选），让模型进行内容补全。该功能常用于故事续写、代码补全等场景。FIM 补全接口收费与对话补全相同。&lt;/p&gt;
&lt;p&gt;要使用 FIM 补全接口，需要设置 &lt;code&gt;base_url&lt;/code&gt; 为 &lt;code&gt;https://api.deepseek.com/beta&lt;/code&gt; 来开启 Beta 功能。&lt;/p&gt;
&lt;p&gt;以下为 FIM 补全接口的使用样例。在这个例子中，用户提供斐波那契数列函数的开头和结尾，模型对中间内容进行补全。&lt;/p&gt;
&lt;img src=&quot;https://cdn.deepseek.com/api-docs/fim_completion.jpeg&quot; width=&quot;512&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;p&gt;详细使用方法，请参考 &lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/guides/fim_completion&quot;&gt;FIM 补全指南&lt;/a&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class=&quot;anchor anchorWithStickyNavbar_YAqC&quot; id=&quot;更新说明&quot;&gt;更新说明&lt;a href=&quot;https://api-docs.deepseek.com/zh-cn/news/news0725#%E6%9B%B4%E6%96%B0%E8%AF%B4%E6%98%8E&quot; class=&quot;hash-link&quot; aria-label=&quot;更新说明的直接链接&quot; title=&quot;更新说明的直接链接&quot;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Beta 接口已开放给所有用户使用，用户需要设置 &lt;code&gt;base_url&lt;/code&gt; 为 &lt;code&gt;https://api.deepseek.com/beta&lt;/code&gt; 来开启 Beta 功能。&lt;/p&gt;
&lt;p&gt;Beta 接口属于不稳定接口，后续测试、发布计划会灵活变动，敬请谅解。&lt;/p&gt;
&lt;p&gt;相关模型版本，在功能稳定后会发布到开源社区，敬请期待。&lt;/p&gt;</description><link>https://api-docs.deepseek.com/zh-cn/news/news0725</link><guid isPermaLink="false">https://api-docs.deepseek.com/zh-cn/news/news0725</guid><pubDate>Wed, 24 Jul 2024 16:00:00 GMT</pubDate></item></channel></rss>