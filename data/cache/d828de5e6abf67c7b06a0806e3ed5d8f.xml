<?xml version="1.0" encoding="UTF-8"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>DuckDB News</title><link>https://duckdb.org/news/</link><atom:link href="http://rsshub.pseudoyu.com/duckdb/news" rel="self" type="application/rss+xml"></atom:link><description>DuckDB News - Powered by RSSHub</description><generator>RSSHub</generator><webMaster>contact@rsshub.app (RSSHub)</webMaster><language>en</language><lastBuildDate>Tue, 25 Mar 2025 00:30:06 GMT</lastBuildDate><ttl>5</ttl><item><title>Maximizing Your Delta Scan Performance</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We released a new version of the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension&lt;/a&gt;, which includes several new features and performance improvements. In this blog post, we’ll put the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension through its paces with some benchmarks and take a deep dive into some of the new performance-related features.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;overview&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#overview&quot;&gt;Overview&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In our &lt;a href=&quot;https://duckdb.org/2024/06/10/delta.html&quot;&gt;previous&lt;/a&gt; post, we talked about what the Delta Lake table format is all about, and how DuckDB’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension leverages the &lt;a href=&quot;https://github.com/delta-io/delta-kernel-rs&quot;&gt;Delta Kernel&lt;/a&gt; library to offer native support. In this blog post, we will focus on how to get the most performance out of reading Delta tables from DuckDB. We’ll start with a small recap of Delta, then demonstrate the performance gains that were made over the past few releases. Finally, we demonstrate three key features available in the latest Delta release that will ensure you get the most out of your Delta reading performance: metadata caching, file skipping and partition information pushdown.&lt;/p&gt;
      &lt;h2 id=&quot;the-delta-open-table-format&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#the-delta-open-table-format&quot;&gt;The Delta Open Table Format&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let’s start off with a small recap of Delta to get back up to speed. &lt;a href=&quot;https://delta.io/&quot;&gt;Delta Lake&lt;/a&gt; is an &lt;a href=&quot;https://delta.io/blog/open-table-formats/&quot;&gt;Open Table Format&lt;/a&gt; similar to &lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Apache Iceberg&lt;/a&gt; and &lt;a href=&quot;https://hudi.apache.org/&quot;&gt;Apache Hudi&lt;/a&gt;. Open Table Formats are best understood as “a collection of data and metadata files” that aim to provide the flexibility of data lakes while providing some of the consistency guarantees of traditional data warehouses. In the case of Delta, the format consists of Parquet files for data and a mix of Parquet, JSON and binary files for metadata. Besides providing an improved level of consistency, the additional metadata provided by Open Table Formats allows various types of performance optimizations through things like column statistics and file skipping. For a more in-depth explanation, we refer to the &lt;a href=&quot;https://duckdb.org/2024/06/10/delta.html&quot;&gt;previous Delta blog post&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;the-delta-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#the-delta-extension&quot;&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB natively supports reading Delta Tables through the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension&lt;/a&gt;. This extension is one of the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/core_extensions.html&quot;&gt;core DuckDB extensions&lt;/a&gt; with &amp;gt;70k weekly downloads. Using this extension to read from a Delta Table is really simple. Since DuckDB v1.2.0, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension will be automatically installed upon first use and loaded when invoking the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;So for example, to read a local Delta table, simply open any DuckDB client and run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;./&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;path_to_your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is your Delta table on someone else’s machine, perhaps in AWS? DuckDB can also query straight from S3! To have DuckDB automatically load your AWS credentials and query a remote Delta table, run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PROVIDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;credential_chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For other cloud providers such as Azure or Google Cloud, check the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta.html#usage&quot;&gt;extension’s documentation page&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;performance-improvements-between-delta-v010-and-030&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#performance-improvements-between-delta-v010-and-030&quot;&gt;Performance Improvements between &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; v0.1.0 and 0.3.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;While the first release (v0.1.0) of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension already came with various performance-related features such as projection pushdown and constant filter pushdown, the features added since then have massively improved the performance of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;. To illustrate this, our first benchmark will use the industry standard &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/tpcds.html&quot;&gt;TPC-DS&lt;/a&gt; benchmark with the scale factor 1 data set (SF1).&lt;/p&gt;
      &lt;h3 id=&quot;benchmark-setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#benchmark-setup&quot;&gt;Benchmark Setup&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For this benchmark, we started up an &lt;a href=&quot;https://instances.vantage.sh/aws/ec2/c6id.4xlarge&quot;&gt;AWS c6id.4xlarge instance&lt;/a&gt; (16 vCPUs, 32 GB RAM) and wrote the TPC-DS SF1 dataset to an S3 bucket in the same region (eu-west-1) using &lt;a href=&quot;https://github.com/duckdb/duckdb-delta/blob/026345b9cf9092e3dd5ae42cc501ec8ed45ca09b/scripts/data_generator/generate_test_data.py&quot;&gt;PySpark&lt;/a&gt;.
Each benchmark is run a total of 6 times with the result being the median runtime of the last 5 runs with the first being considered a cold run. The aggregated results are shown in the following table.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Result&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Total runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Min runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Max runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Median runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Queries timed out&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt;&amp;nbsp;extension&amp;nbsp;v0.1.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;444.76&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.48&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.31&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.63&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt;&amp;nbsp;extension&amp;nbsp;v0.3.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;151.06&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.46&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.22&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The detailed results of the benchmark are shown in the foldout:&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt;
    Detailed TPC-DS SF1 benchmark results, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension v0.1.0 vs. v0.3.0
&lt;/summary&gt;

  &lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/delta-performance-fig1.svg&quot;&gt;&lt;img src=&quot;https://duckdb.org/images/blog/delta-performance-fig1.svg&quot; alt=&quot;Detailed TPC-DS SF1 benchmark results, `delta` extension v0.1.0 vs. v0.3.0&quot; width=&quot;900&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;div align=&quot;center&quot;&gt;&lt;/div&gt;
&lt;/details&gt;
      &lt;h3 id=&quot;analysis&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#analysis&quot;&gt;Analysis&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We can see from the results that there has been a significant performance improvement all around. In v0.1.0, 4 out of 99 queries hit the benchmark timeout of 30 sec and were excluded from the results. In v0.3.0, all 99 queries completed well within the timeout. Comparing total runtimes (excluding the queries that timed out for v0.1.0) we find a speedup of more than 3×!&lt;/p&gt;

&lt;p&gt;Now, without going into too much detail, an important part of the speedup here can be attributed to the &lt;strong&gt;cardinality information propagation&lt;/strong&gt; that was added in &lt;a href=&quot;https://github.com/duckdb/duckdb-delta/pull/77&quot;&gt;PR #77&lt;/a&gt;. Having accurate cardinality estimation is essential for DuckDB’s &lt;a href=&quot;https://duckdb.org/2024/11/14/optimizers.html&quot;&gt;query optimizer&lt;/a&gt; to work well and produce efficient query plans. Specifically, DuckDB’s Join Optimizer uses the cardinality estimates to change the order in which joins are performed. The join order can massively impact the cardinality of the intermediate tuples, which has a big impact on query performance. Especially in workloads like the TPC-DS benchmark, which has many queries that contain a lot of joins, the Join Order Optimizer plays a crucial role. For (a lot) more details, check out &lt;a href=&quot;https://blobs.duckdb.org/papers/tom-ebergen-msc-thesis-join-order-optimization-with-almost-no-statistics.pdf&quot;&gt;this thesis&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;further-optimizations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#further-optimizations&quot;&gt;Further Optimizations&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;attaching-delta-tables&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#attaching-delta-tables&quot;&gt;Attaching Delta Tables&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Besides the general performance improvements like cardinality information propagation, several performance-related features have been added to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension as well. One of those is the ability to attach Delta tables. Using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; to query a Delta table has multiple advantages. For starters, by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt;, your queries can look a little cleaner when querying the same table multiple times since you don’t have to repeat the full Delta table path every time it is queried. More importantly, though, using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; will allow DuckDB to cache/reuse certain parts of the Delta metadata, which can improve query performance. To attach the local Delta table, run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;./&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;path_to_your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;your_table&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After attaching the Delta table, you can query the table just by using the alias:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;your_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By default, DuckDB will automatically cache Delta metadata within the same transaction. That means if a Delta table is scanned multiple times in that transaction, DuckDB can reuse parts of the Delta metadata between the different scans. For example, the following query will only read the Delta metadata once:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For even more performance improvements, DuckDB also supports &lt;strong&gt;persisting this cached Delta metadata &lt;em&gt;between&lt;/em&gt; different queries&lt;/strong&gt;. To do this, the Delta table can be attached using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIN_SNAPSHOT&lt;/code&gt; option. With this option enabled, subsequent queries can reuse the metadata such as in the following code block:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PIN_SNAPSHOT&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- First scan (metadata not yet cached)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Second scan (metadata is now cached)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Metadata caching can have a significant performance impact, especially in situations where the data is relatively small and the latency high. To illustrate this, we will rerun our TPC-DS experiment to compare three different ways of scanning the Delta table: using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;, using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt;, and using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH ... (PIN_SNAPSHOT)&lt;/code&gt;. The rest of the benchmark setup is identical to the one in the previous section.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;result&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;total runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;min runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;max runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;median runtime&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;151.06&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.46&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.22&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;134.26&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.43&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.28&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIN_SNAPSHOT&lt;/code&gt;)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;102.80&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.36&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.87&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The detailed results of the benchmark are shown in the foldout:&lt;/p&gt;
&lt;details&gt;
  &lt;summary&gt;
    Detailed TPC-DS SF1 benchmark results with different configurations
&lt;/summary&gt;

  &lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/delta-performance-fig2.svg&quot;&gt;&lt;img src=&quot;https://duckdb.org/images/blog/delta-performance-fig2.svg&quot; alt=&quot;Detailed TPC-DS SF1 benchmark results with different configurations&quot; width=&quot;900&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;div align=&quot;center&quot;&gt;&lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;The results show that for many TPC-DS queries, using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; can already slightly improve performance for several queries, with overall runtime seeing a 1.13× speedup. When the metadata is fully in cache due to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIN_SNAPSHOT&lt;/code&gt;, we see an even greater speedup of 1.47×. This, however, comes at the tradeoff of missing any updates to the table that occur after the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; statement.&lt;/p&gt;

&lt;p&gt;A keen eye looking at the full results will also spot a few cases where the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; results are actually slightly worse than the results with raw &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;. This is something we will explain in the &lt;a href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#a-note-on-pushdown--attach-performance-interplay&quot;&gt;section on the pushdown / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; interplay&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;file-skipping&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#file-skipping&quot;&gt;File Skipping&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Another key performance feature of scanning Delta tables is file skipping. As explained in the introduction, Delta tables contain metadata that contains all sorts of statistics of the data files of the table. These statistics can be used by engines like DuckDB to decide which Parquet files need to be scanned and which ones can be skipped altogether. File skipping is something that is done automatically by DuckDB. File skipping will work for both constant filters and dynamic filters (filters that are calculated during query execution):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- constant filter&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;...&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;some_value&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- dynamic filter&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;...&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other_tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the previous benchmarks, file skipping has only a very limited effect. The overall data is simply not big enough and many queries actually touch large parts of the data anyway.  However, when only a relatively small part of the data is touched in a query, file skipping can have a huge impact on performance. To demonstrate this, we will first generate some test data. We’ll use the same &lt;a href=&quot;https://github.com/duckdb/duckdb-delta/blob/026345b9cf9092e3dd5ae42cc501ec8ed45ca09b/scripts/data_generator/generate_test_data.py&quot;&gt;PySpark-based&lt;/a&gt; test data generation script as before.&lt;/p&gt;

&lt;p&gt;The table has 100 million rows and has a very basic schema with an incrementing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt; column of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt; type and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value&lt;/code&gt; column of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; type. If we query the data using DuckDB we will see something like:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────┬──────────────┐
│    id    │    value     │
│  int64   │   varchar    │
├──────────┼──────────────┤
│ 49950000 │ val-49950000 │
│ 49950001 │ val-49950001 │
│ 49950002 │ val-49950002 │
│ 49950003 │ val-49950003 │
│      ·   │     ·        │
│      ·   │     ·        │
│      ·   │     ·        │
│    49996 │ val-49996    │
│    49997 │ val-49997    │
│    49998 │ val-49998    │
│    49999 │ val-49999    │
├──────────┴──────────────┤
│     100000000 rows      │
│        (8 shown)        │
└─────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, let’s say we are only interested in a specific range of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt;s: maybe we only want &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt;s below 100. We will now construct two queries.&lt;/p&gt;

&lt;p&gt;For the first query, we will directly read all the parquet files stored in the table using a &lt;a href=&quot;https://duckdb.org/docs/stable/data/multiple_files/overview.html#multi-file-reads-and-globs&quot;&gt;glob pattern&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parquet_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/*.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;We are doing this for illustrative purposes to show us the benefits of file skipping, scanning the raw Parquet files in a Delta table like this only works here because we have no updates, deletes or checkpoints in this table.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For the second query, we directly scan the table using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; table function, selecting only the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt;s we are interested in using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clause:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now when running these queries from a c6id.4xlarge AWS instance on the S3 bucket in the same region, we can see that they perform wildly differently. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; only requires ≈0.5 seconds to complete, whereas the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_scan&lt;/code&gt; takes ≈17 seconds. So what’s going on here exactly?&lt;/p&gt;

&lt;p&gt;We can use DuckDB’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt; statement to get more details here. Let’s start by analyzing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_scan&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;EXPLAIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ANALYZE&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parquet_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/*.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────────────────────┐
│┌──────────────────────────────────────────────┐│
││              Total Time: 17.08s              ││
│└──────────────────────────────────────────────┘│
└────────────────────────────────────────────────┘
             ...
┌─────────────┴─────────────┐
│         TABLE_SCAN        │
│    ────────────────────   │
│         Function:         │
│        PARQUET_SCAN       │
│                           │
│        Projections:       │
│             id            │
│           value           │
│                           │
│      Filters: id&amp;lt;100      │
│                           │
│          100 Rows         │
│         (262.39s)         │
└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt; output that our filter was properly pushed down, and the scan correctly only produced 100 rows. This all seems fine, right? Well, let’s compare it with the output of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt; for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;EXPLAIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ANALYZE&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────────────────────┐
│┌──────────────────────────────────────────────┐│
││              Total Time: 0.615s              ││
│└──────────────────────────────────────────────┘│
└────────────────────────────────────────────────┘
             ...
┌─────────────┴─────────────┐
│         TABLE_SCAN        │
│    ────────────────────   │
│        Projections:       │
│             id            │
│           value           │
│                           │
│      Filters: id&amp;lt;100      │
│    File Filters: id&amp;lt;100   │
│                           │
│      Scanning Files:      │
│           1/2000          │
│                           │
│          100 Rows         │
│          (0.06s)          │
└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; function’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt; output, we can see two new fields: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;File Filters&lt;/code&gt;  and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Scanning Files&lt;/code&gt;. This shows us clearly what’s going on. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&amp;lt;100&lt;/code&gt; predicate is now used for two things: it’s pushed down into the scans on the individual Parquet files, just like the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_scan&lt;/code&gt;, but it also shows up as a file filter, which is used to reduce the list of files to be scanned altogether! This leads to a &lt;strong&gt;2,000× reduction&lt;/strong&gt; of the amount of Parquet metadata to be read, which results in a huge performance boost.&lt;/p&gt;
      &lt;h3 id=&quot;partition-information-pushdown&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#partition-information-pushdown&quot;&gt;Partition Information Pushdown&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The final DuckDB Delta performance feature is partition information pushdown. Partition information pushdown and the partition-aware aggregation operator are relatively &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14329&quot;&gt;new&lt;/a&gt; features introduced in DuckDB v1.2.0. In the v0.3.0 release of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension this feature was also added, which means that DuckDB can now use the partitioning information to create query plans that can utilize the fact that the data scanned is already partitioned.
To show the performance benefit of partition information, we will, &lt;em&gt;surprise,&lt;/em&gt; run another benchmark! This time, we chose the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/tpch.html&quot;&gt;TPC-H dataset&lt;/a&gt; at scale factor 10 and ran the experiment on a 32 GB MacBook Pro M1 Max. We partitioned the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; table by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_returnflag&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_linestatus&lt;/code&gt; columns. We then run &lt;a href=&quot;https://github.com/duckdb/duckdb/blob/v1.2.1/extension/tpch/dbgen/queries/q01.sql&quot;&gt;Q1&lt;/a&gt; which looks roughly like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that the query contains a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; statement, which lists the exact columns by which our dataset is already partitioned. Making DuckDB use partitioning-aware operators is done all automatically, so in this case simply running:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;./&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;path_to_partitioned_directory&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/lineitem_sf10&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;delta&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tpch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;will fire off the TPC-H Q1 on the partitioned Delta dataset. To inspect what’s happening we will again use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────────────────────┐
│┌──────────────────────────────────────────────┐│
││              Total Time: 0.477s              ││
│└──────────────────────────────────────────────┘│
└────────────────────────────────────────────────┘
             ...
┌─────────────┴─────────────┐
│   PARTITIONED_AGGREGATE   │
│    ────────────────────   │
│          Groups:          │
│             #0            │
│             #1            │
│                           │
│        Aggregates:        │
│          sum(#2)          │
│          sum(#3)          │
│          sum(#4)          │
│          sum(#5)          │
│          avg(#6)          │
│          avg(#7)          │
│          avg(#8)          │
│        count_star()       │
│                           │
│           4 Rows          │
│          (0.65s)          │
└─────────────┬─────────────┘
             ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see that DuckDB has detected the partitioning information correctly and is using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PARTITIONED_AGGREGATE&lt;/code&gt; operator to do the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; efficiently.&lt;/p&gt;

&lt;p&gt;Now, as a baseline, we will rerun the same query, but now with partition information pushdown disabled:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;./&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;path_to_partitioned_directory&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/lineitem_sf10&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PUSHDOWN_PARTITION_INFO&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tpch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Again, using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt;, we can see that DuckDB will now use a regular &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HASH_GROUP_BY&lt;/code&gt; operator, since the partition information from Delta was not available during query planning.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────────────────────┐
│┌──────────────────────────────────────────────┐│
││              Total Time: 0.552s              ││
│└──────────────────────────────────────────────┘│
└────────────────────────────────────────────────┘
             ...
┌─────────────┴─────────────┐
│       HASH_GROUP_BY       │
│    ────────────────────   │
│          Groups:          │
│             #0            │
│             #1            │
│                           │
│        Aggregates:        │
│          sum(#2)          │
│          sum(#3)          │
│          sum(#4)          │
│          sum(#5)          │
│          avg(#6)          │
│          avg(#7)          │
│          avg(#8)          │
│        count_star()       │
│                           │
│           4 Rows          │
│          (1.37s)          │
└─────────────┬─────────────┘
             ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now looking at the performance differences between these two queries, we can see that the overall speedup is only a modest 1.16×, however the aggregation operation itself was sped up by 2.11×! This means that when queries that regularly do heavy group by operations, partitioning the data by these columns can definitely be a very useful tool to have in your performance tuning toolbox.&lt;/p&gt;
      &lt;h3 id=&quot;a-note-on-pushdown--attach-performance-interplay&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#a-note-on-pushdown--attach-performance-interplay&quot;&gt;A Note on Pushdown / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; Performance Interplay&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;While features such as filter pushdown and partition information pushdown will improve performance for many workloads, it is useful to be aware that there is a somewhat intricate interplay between the metadata caching mechanism from using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt;, and the pushdown of filters and partition information. At the end of the section on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; feature, we already saw that for some queries, using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; is actually slightly slower than using the raw &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;. Without diving into too much detail, pushing down filters and partitioning information can negatively affect the effectiveness of metadata caching for some queries. This means that on some queries, you may, somewhat counterintuitively, benefit from partially disabling filter pushdown when using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;./&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_delta_table_directory&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;PIN_SNAPSHOT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;PUSHDOWN_PARTITION_INFO&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;PUSHDOWN_FILTERS&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;none&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This should be considered an advanced use case, though, and only relevant when optimizing for specific queries. The default settings of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; should provide the best overall performance and are recommended for most cases. Furthermore, there is ongoing work in the &lt;a href=&quot;https://github.com/delta-io/delta-kernel-rs&quot;&gt;underlying &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-kernel-rs&lt;/code&gt; library used by DuckDB Delta&lt;/a&gt; that aims to reduce this effect by exposing mechanisms to cleverly refresh metadata objects held by DuckDB. As soon as these mechanisms are available, we will add them to the DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension, likely making these flags obsolete for anything but testing.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we’ve taken a look at the latest version of the DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension and put it to the test with some benchmarks. We’ve run queries from the industry standard TPC benchmarks to demonstrate the large performance improvements that were made over the past releases of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension.&lt;/p&gt;

&lt;p&gt;Furthermore, we’ve taken a look at three specific techniques that can be used while working with Delta tables to improve performance even further:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Using metadata caching with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Using filters and data layout to reduce the number of files that need to be scanned&lt;/li&gt;
  &lt;li&gt;Utilizing partitioning information to speed up aggregations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All in all, we think with the v0.3.0 release of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension, DuckDB can read Delta tables with excellent performance for many different workloads and highly encourage everyone to give the latest version a shot!&lt;/p&gt;

</description><link>https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html</link><guid isPermaLink="false">https://duckdb.org/2025/03/21/maximizing-your-delta-scan-performance.html</guid><pubDate>Fri, 21 Mar 2025 00:00:00 GMT</pubDate><author>Sam Ansmink</author></item><item><title>Preview: Amazon S3 Tables in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We are happy to announce a new preview feature that adds support for Apache Iceberg REST Catalogs, enabling DuckDB users to connect to Amazon S3 Tables and Amazon SageMaker Lakehouse with ease.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
  &lt;p&gt;The AWS Storage Blog also published a post on this feature, see &lt;a href=&quot;https://aws.amazon.com/blogs/storage/streamlining-access-to-tabular-datasets-stored-in-amazon-s3-tables-with-duckdb/&quot;&gt;Streamlining access to tabular datasets stored in Amazon S3 Tables with DuckDB&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;iceberg-ahead&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#iceberg-ahead&quot;&gt;Iceberg Ahead!&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In recent years, the &lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Iceberg open table format&lt;/a&gt; has become increasingly popular. Major data warehouse platforms such as
&lt;a href=&quot;https://www.databricks.com/company/newsroom/press-releases/databricks-agrees-acquire-tabular-company-founded-original-creators&quot;&gt;Databricks&lt;/a&gt;,
&lt;a href=&quot;https://docs.snowflake.com/en/release-notes/2024/other/2024-10-18-snowflake-open-catalog-ga&quot;&gt;Snowflake&lt;/a&gt;,
&lt;a href=&quot;https://cloud.google.com/blog/products/data-analytics/biglake-support-for-building-apache-iceberg-lakehouses-is-now-ga&quot;&gt;Google BigQuery&lt;/a&gt;
and
&lt;a href=&quot;https://aws.amazon.com/blogs/big-data/read-and-write-s3-iceberg-table-using-aws-glue-iceberg-rest-catalog-from-open-source-apache-spark/&quot;&gt;AWS&lt;/a&gt;
have all announced or already implemented support for Iceberg tables. These platforms also support Iceberg &lt;a href=&quot;https://iceberg.apache.org/terms/#catalog&quot;&gt;catalogs&lt;/a&gt;, which are responsible for tracking current metadata for a collection of Iceberg tables grouped by namespaces.&lt;/p&gt;

&lt;p&gt;DuckDB has supported reading Iceberg tables &lt;a href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html&quot;&gt;since September 2023&lt;/a&gt; via the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/iceberg/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iceberg&lt;/code&gt; extension&lt;/a&gt;. Today, we are happy to introduce a new preview feature in this extension, which allows attaching to &lt;a href=&quot;https://www.tabular.io/apache-iceberg-cookbook/getting-started-catalog-background/&quot;&gt;Iceberg REST catalogs&lt;/a&gt;. This preview release coincides with two AWS announcements yesterday: &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-s3-tables-apache-iceberg-rest-catalog-apis/&quot;&gt;support for Iceberg tables in Amazon S3 Tables&lt;/a&gt; and the &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-sagemaker-lakehouse-integration-s3-tables-generally-available/&quot;&gt;GA release of the integration between S3 Tables and SageMaker Lakehouse (AWS Glue Data Catalog)&lt;/a&gt;. In practice, these developments mean that DuckDB now provides an end-to-end solution for reading Iceberg tables in &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/iceberg/amazon_s3_tables.html&quot;&gt;S3 Tables&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/iceberg/amazon_sagemaker_lakehouse.html&quot;&gt;SageMaker Lakehouse&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;DuckDB&#39;s support for Iceberg REST Catalog endpoints in Amazon S3 Tables is the result of a collaboration between AWS and DuckDB Labs.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;using-apache-iceberg-rest-catalogs-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#using-apache-iceberg-rest-catalogs-in-duckdb&quot;&gt;Using Apache Iceberg REST Catalogs in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;steps-for-installing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#steps-for-installing&quot;&gt;Steps for Installing&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To connect to Apache Iceberg REST Catalogs in DuckDB,
make sure you are running the &lt;strong&gt;latest stable&lt;/strong&gt; DuckDB release (version 1.2.1).
For our example steps, we&#39;ll use the DuckDB &lt;a href=&quot;https://duckdb.org/docs/stable/clients/overview.html&quot;&gt;CLI client&lt;/a&gt;.
You can obtain this client from the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation page&lt;/a&gt; and start it with:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we need to install the “bleeding edge” versions of the required extensions from the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/installing_extensions.html#extension-repositories&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;core_nightly&lt;/code&gt; repository&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FORCE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; aws &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;core_nightly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FORCE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; httpfs &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;core_nightly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FORCE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; iceberg &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;core_nightly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;For more information on using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;core_nightly&lt;/code&gt; repository, please see the &lt;a href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#footnotes&quot;&gt;notes&lt;/a&gt; at the end of the post.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;With these extensions installed, your DuckDB is now capable of using Apache Iceberg REST Catalogs.
Let&#39;s find some data.&lt;/p&gt;
      &lt;h3 id=&quot;setting-up-an-amazon-s3-table-bucket&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#setting-up-an-amazon-s3-table-bucket&quot;&gt;Setting up an Amazon S3 Table Bucket&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;(If you already have Iceberg tables in Amazon S3 Tables, you can skip to the &lt;a href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#reading-amazon-s3-tables-with-duckdb&quot;&gt;“Reading Iceberg Catalogs with DuckDB” section&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;In this post, we demonstrate how to read data from Amazon S3 Tables.
To follow along, make sure that your account has &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-setting-up.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s3tables&lt;/code&gt; permissions&lt;/a&gt;
and create a new &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-buckets.html&quot;&gt;S3 table bucket&lt;/a&gt;.
Note that Amazon S3 Tables is currently only supported in &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-regions-quotas.html&quot;&gt;selected AWS regions&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;populating-an-amazon-s3-table-bucket&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#populating-an-amazon-s3-table-bucket&quot;&gt;Populating an Amazon S3 Table Bucket&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If you don&#39;t have an S3 table bucket with tables already, we found the easiest way to get going is to create a table using Amazon Athena.
See their &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-getting-started.html#s2-tables-tutorial-EMR-cluster&quot;&gt;instructions&lt;/a&gt;.
For our example, we created a simple table with three columns using the Athena query editor:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duck_species&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;english_name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;STRING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;latin_name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;STRING&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TBLPROPERTIES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;table_type&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;ICEBERG&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&#39;s insert some data to the table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duck_species&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Anas nivis&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Snow duck&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;reading-amazon-s3-tables-with-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#reading-amazon-s3-tables-with-duckdb&quot;&gt;Reading Amazon S3 Tables with DuckDB&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Querying S3 Tables with DuckDB is really easy.
The first step is to get your AWS credentials into DuckDB.
You can achieve this in two ways.
First, you can let DuckDB detect your AWS credentials and configuration based on the default profile in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.aws&lt;/code&gt; directory by creating the following secret using the &lt;a href=&quot;https://duckdb.org/docs/stable/configuration/secrets_manager.html&quot;&gt;Secrets Manager&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PROVIDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;credential_chain&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, you can set the AWS key, secret, and region values manually. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;AKIAIOSFODNN7EXAMPLE&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;REGION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;us-east-1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tip To see the secrets in your session, run &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duckdb_secrets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Next, point DuckDB to your S3 table bucket.
You can do so by copy-pasting the S3 Tables ARN value directly from the AWS Management Console and using it in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;arn:aws:s3tables:&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;us-east-1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;111122223333&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;:bucket/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;bucket_name&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3_tables_db&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;iceberg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ENDPOINT_TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3_tables&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And that&#39;s all! Now, DuckDB is connected to Amazon S3 Tables. 
To show the available tables, run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SHOW&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────┬─────────┬───────────────┬──────────────┬──────────────┬───────────┐
│   database   │ schema  │     name      │ column_names │ column_types │ temporary │
│   varchar    │ varchar │    varchar    │  varchar[]   │  varchar[]   │  boolean  │
├──────────────┼─────────┼───────────────┼──────────────┼──────────────┼───────────┤
│ s3_tables_db │ ducks   │ duck_species  │ [__]         │ [INTEGER]    │ false     │
└──────────────┴─────────┴───────────────┴──────────────┴──────────────┴───────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can query tables as if they were ordinary DuckDB tables:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3_tables_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ducks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duck_species&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────┬──────────────┬────────────┐
│  id   │ english_name │ latin_name │
│ int32 │   varchar    │  varchar   │
├───────┼──────────────┼────────────┤
│   0   │ Anas nivis   │ Snow duck  │
└───────┴──────────────┴────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You also have an alternative option to connect to S3 Tables using the Amazon SageMaker Lakehouse (AWS Glue Data Catalog) Iceberg REST Catalog endpoint.
To do so, run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;account_id&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;:s3tablescatalog/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;namespace_name&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;iceberg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ENDPOINT_TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;glue&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tip If you need basic read access to tabular data in a single S3 table bucket, use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s3_tables&lt;/code&gt; endpoint type.
If you want a unified view across all of your tabular data in AWS, use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;glue&lt;/code&gt; endpoint type.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h3 id=&quot;schema-evolution&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#schema-evolution&quot;&gt;Schema Evolution&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;A key feature of the Iceberg format is &lt;a href=&quot;https://iceberg.apache.org/docs/1.7.1/evolution/&quot;&gt;schema evolution&lt;/a&gt;,
i.e., the ability to follow changes in the table&#39;s schema.
To demonstrate this, we go back to the Athena query editor and add a new column to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duck_species&lt;/code&gt; table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duck_species&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ADD&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conservation_status&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;STRING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, we insert a few more duck species:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duck_species&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Anas eatoni&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Eaton&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;s pintail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Vulnerable&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Histrionicus histrionicus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Harlequin duck&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Least concern&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&#39;s run the query again from DuckDB:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s3_tables_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ducks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duck_species&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The query now returns a table with the additional fourth column, which has a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; value in the row inserted before the change in the schema
– as expected.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────┬───────────────────────────┬─────────────────┬─────────────────────┐
│  id   │       english_name        │   latin_name    │ conservation_status │
│ int32 │          varchar          │     varchar     │       varchar       │
├───────┼───────────────────────────┼─────────────────┼─────────────────────┤
│     1 │ Anas eatoni               │ Eaton&#39;s pintail │ Vulnerable          │
│     2 │ Histrionicus histrionicus │ Harlequin duck  │ Least concern       │
│     0 │ Anas nivis                │ Snow duck       │ NULL                │
└───────┴───────────────────────────┴─────────────────┴─────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The latest preview release of the DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iceberg&lt;/code&gt; extension enables directly reading tables using Iceberg REST endpoints.
This allows you to query Amazon S3 Tables and Amazon SageMaker Lakehouse (AWS Glue Data Catalog) with ease.
As of today, the extension is in an experimental state and is under active development.
We will publish a stable release later this year.&lt;/p&gt;
      &lt;h2 id=&quot;footnotes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#footnotes&quot;&gt;Footnotes&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;cleaning-up&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#cleaning-up&quot;&gt;Cleaning Up&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If you created a new S3 table bucket to follow the examples,
don&#39;t forget to clean up by &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-buckets-delete.html&quot;&gt;deleting your S3 table bucket&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;using-the-core_nightly-repository&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html#using-the-core_nightly-repository&quot;&gt;Using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;core_nightly&lt;/code&gt; Repository&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The extensions used in this blog post are currently experimental, and hence they are distributed through the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/installing_extensions.html#extension-repositories&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;core_nightly&lt;/code&gt; repository&lt;/a&gt;. If you want to switch back to using extensions from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;core&lt;/code&gt; repository, follow the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/installing_extensions.html#force-installing-to-upgrade-extensions&quot;&gt;extension documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Note that DuckDB does not support reloading extensions. Therefore, if you experience any issues, try restarting DuckDB after updating the extensions.&lt;/p&gt;

</description><link>https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html</link><guid isPermaLink="false">https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html</guid><pubDate>Fri, 14 Mar 2025 00:00:00 GMT</pubDate><author>Sam Ansmink, Tom Ebergen, Gabor Szarnyas</author></item><item><title>The DuckDB Local UI</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The DuckDB team and MotherDuck are excited to announce the release of a local UI for DuckDB shipped as part of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ui&lt;/code&gt; extension.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;The DuckDB project was built to make it &lt;a href=&quot;https://duckdb.org/why_duckdb.html#simple&quot;&gt;simple&lt;/a&gt; to leverage &lt;a href=&quot;https://duckdb.org/why_duckdb.html#feature-rich&quot;&gt;modern database technology&lt;/a&gt;.
DuckDB can be used from &lt;a href=&quot;https://duckdb.org/docs/stable/clients/overview.html&quot;&gt;many popular languages&lt;/a&gt; and runs on a &lt;a href=&quot;https://duckdb.org/why_duckdb.html#portable&quot;&gt;wide variety of platforms&lt;/a&gt;.
The included &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;Command Line Interface (CLI)&lt;/a&gt; provides a convenient way to interactively run SQL queries from a terminal window,
and several &lt;a href=&quot;https://github.com/davidgasquez/awesome-duckdb?tab=readme-ov-file#sql-clients-and-ide-that-support-duckdb&quot;&gt;third-party tools&lt;/a&gt; offer more sophisticated UIs.&lt;/p&gt;

&lt;p&gt;The DuckDB CLI provides advanced features like interactive multi-line editing, auto-complete, and progress indicators.
However, it can be cumbersome for working with lengthy SQL queries, and its data exploration tools are limited.
Many of the available third party UIs are great, but selecting, installing, and configuring one is not straightforward.
Using DuckDB through a UI should be as simple as using the CLI.
And now it is!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The DuckDB UI is the result of a &lt;a href=&quot;https://duckdb.org/faq.html#how-are-duckdb-the-duckdb-foundation-duckdb-labs-and-motherduck-related&quot;&gt;collaboration&lt;/a&gt; between &lt;a href=&quot;https://duckdblabs.com/&quot;&gt;DuckDB Labs&lt;/a&gt; and &lt;a href=&quot;https://motherduck.com/&quot;&gt;MotherDuck&lt;/a&gt; and is shipped as part of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ui&lt;/code&gt; extension.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;video muted=&quot;&quot; controls=&quot;&quot; loop=&quot;&quot; width=&quot;700&quot;&gt;
  &lt;source src=&quot;https://blobs.duckdb.org/videos/duckdb-ui.mp4&quot; type=&quot;video/mp4&quot;&gt;
&lt;/video&gt;
      &lt;h2 id=&quot;introducing-the-duckdb-ui&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#introducing-the-duckdb-ui&quot;&gt;Introducing the DuckDB UI&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Starting with &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v1.2.1&quot;&gt;DuckDB v1.2.1&lt;/a&gt;, a full-featured local web user interface is available out-of-the-box!
You can start it from the terminal by launching the DuckDB CLI client with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-ui&lt;/code&gt; argument:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-ui&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can also run the following SQL command from a &lt;a href=&quot;https://duckdb.org/docs/stable/clients/overview.html&quot;&gt;DuckDB client&lt;/a&gt; (e.g., CLI, Python, Java, etc.):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;start_ui&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Both of these approaches install the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ui&lt;/code&gt; extension (if it isn&#39;t installed yet),
then open the DuckDB UI in your browser:&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;margin:10px&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/ui/basics.png&quot;&gt;
        &lt;img src=&quot;https://duckdb.org/images/blog/ui/basics.png&quot; alt=&quot;DuckDB UI basics screenshot&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;The DuckDB UI uses interactive notebooks to define SQL scripts and show the results of queries.
However, its capabilities go far beyond this.
Let’s go over its main features.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The DuckDB UI runs all your queries locally: your queries and data never leave your computer.
If you would like to use &lt;a href=&quot;https://motherduck.com/&quot;&gt;MotherDuck&lt;/a&gt; through the UI, you have to &lt;a href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#motherduck-integration&quot;&gt;opt-in explicitly&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#features&quot;&gt;Features&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;databases&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#databases&quot;&gt;Databases&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Your attached databases are shown on the left.
This list includes in-memory databases plus any files and URLs you’ve loaded.
You can explore tables and views by expanding databases and schemas.&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;margin:10px&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/ui/attached_dbs.png&quot;&gt;
        &lt;img src=&quot;https://duckdb.org/images/blog/ui/attached_dbs.png&quot; alt=&quot;Attached databases screenshot&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;
      &lt;h3 id=&quot;table-summary&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#table-summary&quot;&gt;Table Summary&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Click on a table or view to show a summary below.
The UI shows the number of rows, the name and type of each column, and a profile of the data in each column.&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;margin:10px&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/ui/preview_data.png&quot;&gt;
        &lt;img src=&quot;https://duckdb.org/images/blog/ui/preview_data.png&quot; alt=&quot;Table summary screenshot&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Select a column to see a more detailed summary of its data.
You can use the &lt;em&gt;“Preview data”&lt;/em&gt; button near the top right to inspect the first 100 rows.
You can also find the SQL definition of the table or view here.&lt;/p&gt;
      &lt;h3 id=&quot;notebooks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#notebooks&quot;&gt;Notebooks&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;You can organize your work into named notebooks.
Each cell of the notebook can execute one or more SQL statements.
The UI supports syntax highlighting and autocomplete to assist with writing your queries.&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;margin:10px&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/ui/autocomplete.png&quot;&gt;
        &lt;img src=&quot;https://duckdb.org/images/blog/ui/autocomplete.png&quot; alt=&quot;Autocomplete screenshot&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;You can run the whole cell, or just a selection,
then sort, filter, or further transform the results using the provided controls.&lt;/p&gt;
      &lt;h3 id=&quot;column-explorer&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#column-explorer&quot;&gt;Column Explorer&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The right panel contains the &lt;a href=&quot;https://motherduck.com/blog/introducing-column-explorer/&quot;&gt;Column Explorer&lt;/a&gt;, which shows a summary of your results.
You can dive into each column to gain insights.&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;margin:10px&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/ui/column_explorer.png&quot;&gt;
        &lt;img src=&quot;https://duckdb.org/images/blog/ui/column_explorer.png&quot; alt=&quot;Column Explorer screenshot&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;
      &lt;h3 id=&quot;motherduck-integration&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#motherduck-integration&quot;&gt;MotherDuck Integration&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If you would like to connect to &lt;a href=&quot;https://motherduck.com/&quot;&gt;MotherDuck&lt;/a&gt;, you can sign into MotherDuck to persist files and tables to a &lt;a href=&quot;https://motherduck.com/docs/getting-started/&quot;&gt;cloud data warehouse&lt;/a&gt; crafted for using DuckDB at scale and sharing data with your team.&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;margin:10px&quot;&gt;
    &lt;a href=&quot;https://duckdb.org/images/blog/ui/sign_in_to_motherduck.png&quot;&gt;
        &lt;img src=&quot;https://duckdb.org/images/blog/ui/sign_in_to_motherduck.png&quot; alt=&quot;Sign in to MotherDuck screenshot&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;/a&gt;
&lt;/div&gt;
      &lt;h3 id=&quot;and-more&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#and-more&quot;&gt;…And More!&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The DuckDB UI is under active development. Expect additions and improvements!&lt;/p&gt;
      &lt;h2 id=&quot;footprint&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#footprint&quot;&gt;Footprint&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Like the DuckDB CLI, the DuckDB UI creates some files in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.duckdb&lt;/code&gt; directory in your home directory.
The UI puts its files in a sub-directory, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;extension_data/ui&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Your notebooks and some other state are stored in a DuckDB database, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ui.db&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;When you export data to the clipboard or a file (using the controls below the results), some tiny intermediate files (e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ui_export.csv&lt;/code&gt;) are generated.
Your data is cleared from these files after the export is completed, but some near-empty files remain, one per file type.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;internals&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#internals&quot;&gt;Internals&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Support for the UI is implemented in a &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/overview.html&quot;&gt;DuckDB extension&lt;/a&gt;.
The extension embeds a localhost HTTP server, which serves the UI browser application, and also exposes an API for communication with DuckDB.
In this way, the UI leverages the native DuckDB instance from which it was started, enabling full access to your local memory, compute, and file system.&lt;/p&gt;

&lt;p&gt;Results are returned in an efficient binary form closely matching DuckDB’s in-memory representation (&lt;a href=&quot;https://github.com/duckdb/duckdb/blob/v1.2.1/src/include/duckdb/common/types/data_chunk.hpp&quot;&gt;DataChunk&lt;/a&gt;).
&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events&quot;&gt;Server-sent events&lt;/a&gt; enable prompt notification of updates such as attaching databases.
These techniques and others make for a low-latency experience that keeps you in your flow.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/ui.html&quot;&gt;UI extension documentation&lt;/a&gt; for more details.&lt;/p&gt;
      &lt;h2 id=&quot;summary&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#summary&quot;&gt;Summary&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we presented the new DuckDB UI, a powerful web interface for DuckDB.&lt;/p&gt;

&lt;p&gt;The DuckDB UI shares many of its design principles with the DuckDB database.
It’s simple, fast, feature-rich, and portable, and runs locally on your computer.
The DuckDB UI extension is also open source: visit the &lt;a href=&quot;https://github.com/duckdb/duckdb-ui&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb/duckdb-ui&lt;/code&gt; repository&lt;/a&gt; if you want to dive in deeper into the extension&#39;s code.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The repository does not contain the source code for the frontend, which is currently not available as open-source.
Releasing it as open-source is under consideration.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For help or to share feedback, please &lt;a href=&quot;https://github.com/duckdb/duckdb-ui/issues/new&quot;&gt;file an issue&lt;/a&gt;, join the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#ui&lt;/code&gt; channel in either the &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;DuckDB Discord&lt;/a&gt; or the &lt;a href=&quot;https://slack.motherduck.com/&quot;&gt;MotherDuck Community Slack&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Happy quacking!&lt;/p&gt;
      &lt;h2 id=&quot;update-2025-03-20&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/12/duckdb-ui.html#update-2025-03-20&quot;&gt;Update (2025-03-20)&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We are very happy to see the overwhelmingly positive response to the announcement of the DuckDB Local UI. In this short update, we’d like to address some of the questions raised by the community:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Regarding the &lt;strong&gt;licensing of the frontend code&lt;/strong&gt; (HTML, JavaScript, etc.), MotherDuck is currently reviewing licensing options for the UI code and assets and will clarify shortly.&lt;/li&gt;
  &lt;li&gt;Regarding &lt;strong&gt;offline (“air-gapped”) operations,&lt;/strong&gt; we are working towards supporting offline usage in a future version, and are currently exploring how to provide version notifications as upgrades become available.&lt;/li&gt;
  &lt;li&gt;Regarding the &lt;strong&gt;client-server protocol for the UI,&lt;/strong&gt; we’re going to work on opening up the client-server protocol so that other user interfaces can use the “back-end” part of the UI extension to run queries in DuckDB.&lt;/li&gt;
&lt;/ul&gt;

</description><link>https://duckdb.org/2025/03/12/duckdb-ui.html</link><guid isPermaLink="false">https://duckdb.org/2025/03/12/duckdb-ui.html</guid><pubDate>Wed, 12 Mar 2025 00:00:00 GMT</pubDate><author>Jeff Raymakers and Gabor Szarnyas</author></item><item><title>Parquet Bloom Filters in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB now supports reading and writing Parquet Bloom filters.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;One of the key features of the Parquet file format is the ability for readers to &lt;em&gt;selectively&lt;/em&gt; read only the data that is relevant to a particular query. To support this, Parquet files contain column &lt;em&gt;statistics&lt;/em&gt;, most notably the minimum and maximum value for each column in each row group. If a query is filtering with a particular value, and the data is – as it is often – somewhat sorted, a reader can “prove” that a particular row group cannot contain values relevant to the query. DuckDB heavily leverages this, and is able to – even when querying remote endpoints – selectively only read the parts of a Parquet file relevant to a query. For details on how this works, see our by now ancient blog post &lt;a href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html&quot;&gt;“Querying Parquet with precision using DuckDB”&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;However, there are some limitation to this approach. What if a column&#39;s data is randomly shuffled? In that case, all values occur in all row groups and the minimum and maximum statistics are less useful because we can only exclude values that are outside the minimum and maximum &lt;em&gt;of the entire column&lt;/em&gt;. Parquet will use &lt;a href=&quot;https://parquet.apache.org/docs/file-format/data-pages/encodings/&quot;&gt;dictionary encoding&lt;/a&gt; if there are not too many distinct values in the column. In theory, that dictionary could be used to eliminate row groups but there are two problems with this approach: Parquet (inexplicably) allows &lt;em&gt;switching&lt;/em&gt; from dictionary to plain encoding &lt;em&gt;halfway through a row group&lt;/em&gt;. If the dictionary alone were used to eliminate the row group, but the plain part contained the queried value, this would lead to incorrect results. Furthermore, the dictionary is part of the actual column data. If we&#39;re reading the column data just to look at the dictionary we have already incurred most of the cost of reading the column in the first place.&lt;/p&gt;

&lt;p&gt;Obscure sidenote: Again, in theory the column metadata contains the list of encodings that occur in that column. &lt;em&gt;If&lt;/em&gt; that list is correct and does &lt;em&gt;not&lt;/em&gt; include the plain encoding the dictionary &lt;em&gt;could&lt;/em&gt; – again, in theory – be used for slightly earlier row group elimination. But the usefulness of this approach is more than dubious.&lt;/p&gt;
      &lt;h2 id=&quot;parquet-bloom-filters&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html#parquet-bloom-filters&quot;&gt;Parquet Bloom Filters&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The good people over at the &lt;a href=&quot;https://projects.apache.org/committee.html?parquet&quot;&gt;Parquet PMC&lt;/a&gt; have recognized that there is room for improvement here and added &lt;a href=&quot;https://github.com/apache/parquet-format/blob/master/BloomFilter.md&quot;&gt;Bloom filters&lt;/a&gt; for Parquet back in 2018. In a nutshell, &lt;a href=&quot;https://en.wikipedia.org/wiki/Bloom_filter&quot;&gt;Bloom filters&lt;/a&gt; are compact but approximate index structures for a set of values. For a given value, they can either say with certainty that a value is &lt;em&gt;not&lt;/em&gt; in the set or that it &lt;em&gt;may be&lt;/em&gt; in the set, with a false positive ratio depending on the size of the Bloom filter and the amount of distinct values added to it. For now, we can just treat a Bloom filter like an opaque series of bytes with magic properties.&lt;/p&gt;

&lt;p&gt;When used, Parquet files can contain a Bloom filter for each column in each row group. Each Bloom filter can be at an arbitrary location in the file (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bloom_filter_offset&lt;/code&gt;). At the offset in the file, we find another Thrift-encoded structure, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BloomFilterHeader&lt;/code&gt;. This structure has a field for the length of the filter, and some algorithmic settings which are currently redundant because there is only one valid setting for all of them. But decode the header you must to find out where the header ends and where the filter bytes begin. Finally, we have arrived at the precious magic bytes of the Bloom filter. We can now test the filter against any query predicates and see if we can skip the row group entirely.&lt;/p&gt;

&lt;p&gt;More obscure sidenotes: while the column metadata &lt;em&gt;does&lt;/em&gt; contain a field to store the size of the filter (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bloom_filter_length&lt;/code&gt;) it is also optional and some writers (looking at you, Spark) annoyingly only set the offset, not the length. Also, the specification describes two possible filter locations. By also not requiring a length in the metadata, this makes it difficult slash impossible to read all Bloom filters for a Parquet file in a single range request. It is also not clear why the Bloom filters needed to &lt;em&gt;each&lt;/em&gt; be prefixed with a Thrift metadata blob, when this information could also be contained in the ColumnMetaData. Or perhaps, god forbid, the filters could have become part of the main Parquet metadata itself. In the end we end up with a lot of additional reads to find and read the Bloom filter bytes, in principle requiring a careful trade-off between reading the filters and “just” reading the column brute-force.&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-bloom-filters&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html#duckdb-bloom-filters&quot;&gt;DuckDB Bloom Filters&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;As of the last feature release (1.2.0), DuckDB supports &lt;em&gt;both reading and writing&lt;/em&gt; of Parquet Bloom filters. This happens completely transparently to users, no additional action or configuration is required.&lt;/p&gt;
      &lt;h3 id=&quot;writing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html#writing&quot;&gt;Writing&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Currently, Bloom filters are supported for the following types:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Integer types (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TINYINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UTINYINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SMALLINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;USMALLINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UINTEGER&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UBIGINT&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Floating point types (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;String types (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BLOB&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nested types (lists, structs, arrays) are currently &lt;em&gt;not&lt;/em&gt; supported, but they might be added in a future release. In general, Bloom filters will be written if DuckDB decides to use dictionary encoding for a particular column (chunk) within the row group. There is a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; parameter that controls the maximum dictionary size (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DICTIONARY_SIZE_LIMIT&lt;/code&gt;), but this parameter is by default set to 10% of the row group size (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROW_GROUP_SIZE&lt;/code&gt;), which is 122,880 rows by default. Those values have been found to be reasonable first approximations for most use cases but users are of course encouraged to experiment with both parameters if they encounter performance issues. As the number of distinct values in a Bloom filter grows, its size needs to be improved to maintain a certain false positive ratio. By default, filters size is chosen using an 
“acceptable” false positive ratio of 1% or 0.01. The new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BLOOM_FILTER_FALSE_POSITIVE_RATIO&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; parameter controls the acceptable ratio. In general, false positive hurt more the slower the read path is.&lt;/p&gt;
      &lt;h3 id=&quot;reading&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html#reading&quot;&gt;Reading&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;During reading, DuckDB will automatically use constant-comparison filter predicates in the query (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE a = 42&lt;/code&gt;) to probe the Bloom filter (if present) and skip row groups where the Bloom filter can guarantee there are no matching rows in the group. Again, this happens transparently to users and there is no configuration that needs to be set.&lt;/p&gt;

&lt;p&gt;Users can find out if a given Parquet file contains Bloom filters: the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_metadata&lt;/code&gt; function was extended with two new columns, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bloom_filter_offset&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bloom_filter_length&lt;/code&gt;. Furthermore, to actually find out which row groups would be eliminated by Bloom filters for a given file and column, we have added the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_bloom_probe&lt;/code&gt; function. For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_bloom_probe(&#39;file.parquet&#39;, &#39;col1&#39;, 42)&lt;/code&gt; returns a table for each row group in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;file.parquet&lt;/code&gt; that indicates whether the value &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;42&lt;/code&gt; can guaranteed not to be in each row group or not for column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;col1&lt;/code&gt;. Most users will not need to use these functions however, they just help with debugging (and testing).&lt;/p&gt;
      &lt;h2 id=&quot;example-use-case&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html#example-use-case&quot;&gt;Example Use Case&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let&#39;s showcase the Parquet Bloom filters in DuckDB with an example. First, we create a example file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter.parquet&lt;/code&gt; that &lt;em&gt;will&lt;/em&gt; contain Bloom filters:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;r2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;filter.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROW_GROUP_SIZE&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;filter.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The file contains 10 distinct values &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(0, 100, 200 ... 900)&lt;/code&gt;, each repeated ten million times. So in total, 100 million rows. The resulting Parquet file weighs in at 88 MB.&lt;/p&gt;

&lt;p&gt;We will also create an equivalent file but &lt;em&gt;without&lt;/em&gt; Bloom filters. We achieve this by setting the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DICTIONARY_SIZE_LIMIT&lt;/code&gt; to 1:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;filter.parquet&#39;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;nofilter.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DICTIONARY_SIZE_LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROW_GROUP_SIZE&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The contents of both files will be equivalent, but &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nofilter.parquet&lt;/code&gt; will not use dictionary encoding and thus not use Bloom filters. As a result, the file is also larger, weighing in at 181 MB. However, there is a much larger difference when querying for non-existing values, in our example &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;501&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;filter.parquet&#39;&lt;/span&gt;   &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;501&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;nofilter.parquet&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;501&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first query completes in ca. than 0.002 s, where the second query takes 0.1 s. This large difference can be explained by Bloom filters! Since &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;501&lt;/code&gt; does not actually occur in the query, DuckDB can automatically exclude all row groups and not actually read any data besides the Bloom filters. We can explore this further using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_metadata&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parquet_metadata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;filter.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_group_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bloom_filter_offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom_filter_length&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_group_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;row_group_id&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;stats_min&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;stats_max&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;bloom_filter_offset&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;bloom_filter_length&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;900&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;92543967&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;47&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;900&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;92544390&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;47&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that there are ten row groups, and that there is a quite compact Bloom filter for reach row group with a length of 47 bytes each. That&#39;s ca. 500 bytes added to fairly large file, so rather irrelevant for file size.&lt;/p&gt;

&lt;p&gt;If we run the query on the other file, we can see the lack of Bloom filters:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parquet_metadata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;nofilter.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_group_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;bloom_filter_offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom_filter_length&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_group_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;row_group_id&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;stats_min&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;stats_max&lt;/th&gt;
      &lt;th&gt;bloom_filter_offset&lt;/th&gt;
      &lt;th&gt;bloom_filter_length&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;900&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can further explore the Bloom filters in the file using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_bloom_probe&lt;/code&gt; function. For example, for the value of 500 (which exists in the data), the function shows the following:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parquet_bloom_probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;filter.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;file_name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;row_group_id&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;bloom_filter_excludes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;filter.parquet&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;filter.parquet&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;false&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So the Bloom filter cannot exclude any row group because the value &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;500&lt;/code&gt; is contained in all row groups. But if we try a &lt;em&gt;non-existent&lt;/em&gt; value, the Bloom filter strikes:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parquet_bloom_probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;filter.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;501&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;file_name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;row_group_id&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;bloom_filter_excludes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;filter.parquet&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;true&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;filter.parquet&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;true&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here, we can confidently skip all row groups because the Bloom filter guarantees that there can be no matching values in those row groups. All that with 47 bytes per row group.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s new Bloom filter support for Parquet files can greatly reduce the amount of data to be read in certain scenarios, greatly improving query performance. This is particularly useful if files are read over a slow network connection or if row groups are particularly large with few distinct yet non-clustered values.&lt;/p&gt;

</description><link>https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html</link><guid isPermaLink="false">https://duckdb.org/2025/03/07/parquet-bloom-filters-in-duckdb.html</guid><pubDate>Fri, 07 Mar 2025 00:00:00 GMT</pubDate><author>Hannes Mühleisen</author></item><item><title>Gems of DuckDB 1.2</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We highlight a few exciting features that were introduced in DuckDB 1.2.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;We published the DuckDB 1.2.1 bugfix release yesterday. As usual, please consult the &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v1.2.1&quot;&gt;release notes&lt;/a&gt; for the full list of changes and the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation page&lt;/a&gt; for instructions on installing or upgrading. In this post, we&#39;ll highlight a few features that were recently added to DuckDB and improvements that have been made in its ecosystem.&lt;/p&gt;
      &lt;h2 id=&quot;new-clients-page&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#new-clients-page&quot;&gt;New Clients Page&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s client APIs (or “drivers”) are distributed through several centralized repositories, such as &lt;a href=&quot;https://cran.r-project.org/web/packages/duckdb/index.html&quot;&gt;CRAN&lt;/a&gt; for R and &lt;a href=&quot;https://central.sonatype.com/artifact/org.duckdb/duckdb_jdbc&quot;&gt;Maven&lt;/a&gt; for Java. To help users keep track of the rollout of a new DuckDB release, we reworked our &lt;a href=&quot;https://duckdb.org/docs/stable/clients/overview.html&quot;&gt;“Clients” page&lt;/a&gt; to show the latest version for each client. The page also clarifies the support tiers that apply to clients.&lt;/p&gt;
      &lt;h2 id=&quot;simpler-installation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#simpler-installation&quot;&gt;Simpler Installation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In line with DuckDB&#39;s “low friction” principle, we made sure that you can install the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;DuckDB command line client&lt;/a&gt; more easily.&lt;/p&gt;
      &lt;h3 id=&quot;installation-script-on-linux-and-macos&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#installation-script-on-linux-and-macos&quot;&gt;Installation Script on Linux and macOS&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB can now be installed on UNIX-like systems with an installation script:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;curl &lt;/span&gt;https://install.duckdb.org | &lt;span class=&quot;nb&quot;&gt;sh&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The script determines your operating system and architecture, fetches the tag of latest release, and if not present downloads the latest available DuckDB binary to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.duckdb/cli&lt;/code&gt; (the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.duckdb&lt;/code&gt; folder is already used to store extensions).&lt;/p&gt;

&lt;p&gt;Running the script does not require root (sudo) privileges, and it only uses the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zcat&lt;/code&gt; tools, which are widely available. You can inspect the shell script by visiting &lt;a href=&quot;https://install.duckdb.org/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;install.duckdb.org&lt;/code&gt;&lt;/a&gt; in your browser.&lt;/p&gt;
      &lt;h3 id=&quot;signed-binaries-on-windows&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#signed-binaries-on-windows&quot;&gt;Signed Binaries on Windows&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Starting with v1.2.1, we ship digitally signed binaries for the DuckDB Windows command line client. This means that you can run DuckDB in environments where signed binaries are a requirement.&lt;/p&gt;
      &lt;h2 id=&quot;unsung-duckdb-12-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#unsung-duckdb-12-features&quot;&gt;Unsung DuckDB 1.2 Features&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Further to the &lt;a href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#whats-new-in-120&quot;&gt;“What&#39;s New in 1.2.0” section of the announcement blog post&lt;/a&gt;, we collected five new features that were introduced in v1.2.0.&lt;/p&gt;
      &lt;h3 id=&quot;or--in-filter-pushdown&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#or--in-filter-pushdown&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OR&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; Filter Pushdown&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Starting with version 1.2.0, DuckDB &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14313&quot;&gt;supports &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OR&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; expressions for filter pushdown&lt;/a&gt;.
This optimization comes especially handy when querying remote Parquet files or DuckDB databases.&lt;/p&gt;
      &lt;h3 id=&quot;-f-command-line-flag&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#-f-command-line-flag&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-f&lt;/code&gt; Command Line Flag&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The DuckDB CLI client now &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15050&quot;&gt;supports the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-f&lt;/code&gt; flag&lt;/a&gt; to execute SQL script files:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; script.sql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is equivalent to:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.read script.sql&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This feature is documented in the &lt;a href=&quot;https://tldr.inbrowser.app/pages/common/duckdb&quot;&gt;DuckDB tldr page&lt;/a&gt;. If you have &lt;a href=&quot;https://tldr.sh/&quot;&gt;tldr&lt;/a&gt; installed, you can get this page in the CLI via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tldr duckdb&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;allowed_directories--allowed_paths-options&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#allowed_directories--allowed_paths-options&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allowed_directories&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allowed_paths&lt;/code&gt; Options&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We continue to improve support for &lt;a href=&quot;https://duckdb.org/docs/stable/operations_manual/securing_duckdb/overview.html&quot;&gt;operating DuckDB in secure environments&lt;/a&gt;. The &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14568&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allowed_directories&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allowed_paths&lt;/code&gt; options&lt;/a&gt; allow restricting DuckDB&#39;s access to certain directories or files (resp.).
These options allows fine-grained access control for the file system.
For example, you can set DuckDB to only use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/tmp&lt;/code&gt; directory.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;allowed_directories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;/tmp&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;  
&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;enable_external_access&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;  
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;test.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With the setting applied, DuckDB will refuse to read files in the current working directory:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Permission Error:
Cannot access file &quot;test.csv&quot; - file system operations are disabled by configuration  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;sumboolean&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#sumboolean&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum(BOOLEAN)&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;You can now directly &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15042&quot;&gt;compute the sum of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOLEAN&lt;/code&gt; expressions&lt;/a&gt; without wrapping them into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CASE&lt;/code&gt; expression:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is equivalent to:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;excel-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#excel-extension&quot;&gt;Excel Extension&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Prior to DuckDB 1.2, Excel files were only supported by the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spatial&lt;/code&gt; extension&lt;/a&gt;, which is a heavyweight extension with several dependencies.
Starting with 1.2, the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/excel.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;excel&lt;/code&gt; extension&lt;/a&gt; – which was previously limited to computing a few formulas – can read and write Excel sheets. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_xlsx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;test.xlsx&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;header&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you would like to work with &lt;em&gt;Google Sheets&lt;/em&gt; sheets, take a look at the &lt;a href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gsheets&lt;/code&gt; community extension&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;on-the-interweb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#on-the-interweb&quot;&gt;On the Interweb&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are several repositories and pieces of information on DuckDB on the internet.
We highlight two important ones:&lt;/p&gt;
      &lt;h3 id=&quot;awesome-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#awesome-duckdb&quot;&gt;Awesome DuckDB&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The ecosystem around DuckDB keeps growing: many projects are built both with DuckDB and within DuckDB. The community-driven &lt;a href=&quot;https://github.com/davidgasquez/awesome-duckdb&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awesome-duckdb&lt;/code&gt; repository&lt;/a&gt;, maintained by &lt;a href=&quot;https://github.com/davidgasquez&quot;&gt;David Gasquez&lt;/a&gt;, lists these and has recently surpassed 200 entries.&lt;/p&gt;
      &lt;h3 id=&quot;duckdb-file-signature&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#duckdb-file-signature&quot;&gt;DuckDB File Signature&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/internals/storage.html#storage-header&quot;&gt;file signature&lt;/a&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DUCK&lt;/code&gt; (hex: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;44 55 43 4B&lt;/code&gt;), is now listed on &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_file_signatures&quot;&gt;Wikipedia&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;parquet-information-sheet&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html#parquet-information-sheet&quot;&gt;Parquet Information Sheet&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We added DuckDB to the &lt;a href=&quot;https://parquet.apache.org/docs/file-format/implementationstatus/&quot;&gt;“Implementation status” page of the Parquet documentation&lt;/a&gt;.
In the process, we also improved DuckDB&#39;s Parquet support, e.g., by adding the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/16395&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT16&lt;/code&gt; logical type&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html</link><guid isPermaLink="false">https://duckdb.org/2025/03/06/gems-of-duckdb-1-2.html</guid><pubDate>Thu, 06 Mar 2025 00:00:00 GMT</pubDate><author>The DuckDB team</author></item><item><title>Reading and Writing Google Sheets in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Securely read from and write to Google Sheets directly in DuckDB using the GSheets community extension! For ad hoc querying, authentication is as easy as logging into Google from a browser. Scheduled workflows can use persistent DuckDB Secrets. SQL-on-Sheets has arrived!&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;video muted=&quot;&quot; controls=&quot;&quot; autoplay=&quot;&quot; loop=&quot;&quot; width=&quot;900&quot;&gt;
  &lt;source src=&quot;https://blobs.duckdb.org/videos/gsheets-demo.mp4&quot; type=&quot;video/mp4&quot;&gt;
&lt;/video&gt;
      &lt;h2 id=&quot;spreadsheets-are-everywhere&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#spreadsheets-are-everywhere&quot;&gt;Spreadsheets Are Everywhere&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Is anything more polarizing for data folks than spreadsheets?
Wait, don&#39;t answer that, we don&#39;t have time to talk about leading and trailing commas again…&lt;/p&gt;

&lt;p&gt;The fact is that spreadsheets are everywhere.
It is estimated that there are over &lt;a href=&quot;https://thenewstack.io/microsoft-excel-becomes-a-programming-language/&quot;&gt;750 million spreadsheet users&lt;/a&gt;, compared to just &lt;a href=&quot;https://www.jetbrains.com/lp/devecosystem-data-playground/#global_population&quot;&gt;20&lt;/a&gt; to &lt;a href=&quot;https://www.statista.com/statistics/627312/worldwide-developer-population/&quot;&gt;30 million programmers&lt;/a&gt;. 
That includes all languages put together!&lt;/p&gt;

&lt;p&gt;There are a number of ways that using a spreadsheet can improve a data workflow.
Blasphemy you say!
Well, imagine if your database could actually read and write those spreadsheets.
Spreadsheets are often the best place to manually edit data and they also provide highly customizable pivoting for self-serve analytics.&lt;/p&gt;

&lt;p&gt;Now, you can use DuckDB to seamlessly bridge the gap between data-y folks and business-y folks!
With a simple in-browser authentication flow, or an automateable private key file flow, you can both query from and load into Google Sheets.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/evidence-dev/duckdb_gsheets&quot;&gt;GSheets extension&lt;/a&gt; was originally authored by Archie from the team at &lt;a href=&quot;https://evidence.dev/&quot;&gt;Evidence&lt;/a&gt;, but has since had significant contributions from Alex and &lt;a href=&quot;https://www.linkedin.com/in/mharrisb1/&quot;&gt;Michael&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;getting-started-with-the-gsheets-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#getting-started-with-the-gsheets-extension&quot;&gt;Getting Started with the GSheets Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The first few steps are to install the &lt;a href=&quot;https://duckdb.org/community_extensions/extensions/gsheets.html&quot;&gt;gsheets community extension&lt;/a&gt; and authenticate with Google.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; gsheets &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;community&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; gsheets&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Authenticate with a Google Account in the browser (default)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsheet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As a part of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE SECRET&lt;/code&gt; command, a browser window will open and allow for a login and copying a temporary token to then paste back into DuckDB.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/gsheets_oauth_browser_screenshot.png&quot; alt=&quot;In-browser OAuth flow to generate token.&quot; width=&quot;680&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;examples-of-reading-from-sheets&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#examples-of-reading-from-sheets&quot;&gt;Examples of Reading from Sheets&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that you are authenticated, DuckDB can query any Sheet that your Google account has access to.
This includes any publicly available sheets like the one below, so give it a run!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://docs.google.com/spreadsheets/d/1B4RFuOnZ4ITZ-nR9givZ7vWVOTVddC3VTKuSqgifiyE/edit?gid=0#gid=0&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Gotham Wisdom&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;You either die a hero&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;or live long enough to query from spreadsheets&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Copy the URL of the Sheet to query when viewing the sheet of interest within the workbook.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gid&lt;/code&gt; query string parameter is the id of that specific sheet.&lt;/p&gt;

&lt;p&gt;There are two ways to pass in additional parameters:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Add them to the end of the URL as query string parameters or&lt;/li&gt;
  &lt;li&gt;Use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_gsheet&lt;/code&gt; table function and specify them as separate SQL parameters.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/evidence-dev/duckdb_gsheets/blob/main/docs/pages/index.md&quot;&gt;repository README&lt;/a&gt; has a variety of examples and some are included below!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Query string parameters must be placed after a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;?&lt;/code&gt;.
Each parameter is formatted as a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;key=value&lt;/code&gt; pair, and multiple are separated with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;amp;&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h3 id=&quot;reading-a-specific-sheet-and-range&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#reading-a-specific-sheet-and-range&quot;&gt;Reading a Specific Sheet and Range&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;By default, the GSheets extension will read all data on the first sheet in the workbook.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sheet&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;range&lt;/code&gt; parameters (or their query string equivalents) allow for targeted reads.&lt;/p&gt;

&lt;p&gt;For example, to read only the first 3 cells on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;We &amp;lt;3 Ducks&lt;/code&gt; sheet, these two statements are equivalent:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- The sheet with the gid of 0 is named &#39;We &amp;lt;3 Ducks&#39; (because of course it is!)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_gsheet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;https://docs.google.com/spreadsheets/d/1B4RFuOnZ4ITZ-nR9givZ7vWVOTVddC3VTKuSqgifiyE/edit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;We &amp;lt;3 Ducks&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;A1:A3&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://docs.google.com/spreadsheets/d/1B4RFuOnZ4ITZ-nR9givZ7vWVOTVddC3VTKuSqgifiyE/edit?gid=0#gid=0&amp;amp;range=A1:A3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The Google Sheets API helpfully skips empty rows at the end of a dataset or empty columns to the right.
Feel free to specify a slightly bigger &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;range&lt;/code&gt; if your data may grow!
Additionally, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;range&lt;/code&gt; can be specified as a set of columns (e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;D:X&lt;/code&gt;) to be friendlier to a variable number of rows.&lt;/p&gt;
      &lt;h3 id=&quot;data-types&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#data-types&quot;&gt;Data Types&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The extension will sample the first row of data in the sheet to attempt to determine the data types of the columns.
(We have plans to improve this sampling and are open to contributions!)
To skip this step and define the data types within SQL, set the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;all_varchar&lt;/code&gt; parameter to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt;.
The example below also demonstrates that the full URL is not needed – only the Google Workbook identifier.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_gsheet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;1B4RFuOnZ4ITZ-nR9givZ7vWVOTVddC3VTKuSqgifiyE&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;We &amp;lt;3 Ducks&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;A:A&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;all_varchar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is also possible to query data without a header row by setting the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;header&lt;/code&gt; parameter to false.
Columns will be given default names and can be renamed in SQL.&lt;/p&gt;
      &lt;h2 id=&quot;examples-of-writing-to-a-gsheet&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#examples-of-writing-to-a-gsheet&quot;&gt;Examples of Writing to a GSheet&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another key capability of the GSheets extension is to write the results of any DuckDB query to a Google Sheet!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;By default, the entire Sheet will be replaced with the output of the query (including a header row for column names), starting in cell A1 of the first sheet.
See below for examples that adjust this behavior!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Here you will need to specify your own Sheet to experiment with!&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- (We can&#39;t predict what folks would write to a public Sheet...&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Probably just memes, but there is always that one person, you know?)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://docs.google.com/spreadsheets/d/...&#39;&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsheet&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;writing-to-a-specific-sheet-and-range&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#writing-to-a-specific-sheet-and-range&quot;&gt;Writing to a Specific Sheet and Range&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As with reading, both query string parameters and SQL parameters can be used to write to a specific &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sheet&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;range&lt;/code&gt;.
Similarly, the SQL parameters take precedence. These examples are equivalent:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://docs.google.com/spreadsheets/d/...?&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsheet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sheet&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;The sheet name!&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;A2:Z10000&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://docs.google.com/spreadsheets/d/...?gid=123#gid=123&amp;amp;range=A2:Z10000&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsheet&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;header&lt;/code&gt; boolean parameter can also be used to determine whether the column names should be written out or not.&lt;/p&gt;
      &lt;h3 id=&quot;overwriting-or-appending&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#overwriting-or-appending&quot;&gt;Overwriting or Appending&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;At times, it is helpful to avoid clearing out other data in a Sheet before copying.
This is especially handy when writing to specific ranges.
Perhaps columns C and D can come from DuckDB and the remainder can be spreadsheet formulas.
It would be great to just clear out columns C and D!&lt;/p&gt;

&lt;p&gt;To adjust this behavior, pass in these boolean parameters to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; function.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVERWRITE_SHEET&lt;/code&gt; is the default where the entire sheet is cleared out prior to copying.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVERWRITE_RANGE&lt;/code&gt; will only clear out the specified range.&lt;/p&gt;

&lt;p&gt;If both are set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt;, then data will be appended without any other cells being cleared out.
Typically, when appending it is not desirable to include the column headers in the output.
Helpfully, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;header&lt;/code&gt; parameter defaults to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt; in the append case, but it can be adjusted if needed.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- To append, set both flags to false.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://docs.google.com/spreadsheets/d/...?gid=123#gid=123&amp;amp;range=A2:Z10000&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsheet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;OVERWRITE_SHEET&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;OVERWRITE_RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- HEADER false is the default in this case!&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;automated-workflows&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#automated-workflows&quot;&gt;Automated Workflows&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Working with spreadsheets is great for ad hoc work, but it can also be powerful when ingrained in automated processes.
If you want to schedule an interaction with Google Sheets, a key file containing a private key will be needed instead of the in-browser authentication method.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
    The process to acquire this key file has a number of steps, outlined below. Luckily they only need to be done once! This is also available in the &lt;a href=&quot;https://github.com/evidence-dev/duckdb_gsheets/blob/main/docs/pages/index.md&quot;&gt;repo README&lt;/a&gt;.
&lt;/summary&gt;

  &lt;p&gt;To connect DuckDB to Google Sheets via an access token, you’ll need to create a Service Account through the Google API Console.
The GSheets extension will use it to generate an access token periodically.&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;Navigate to the &lt;a href=&quot;https://console.developers.google.com/apis/library&quot;&gt;Google API Console&lt;/a&gt;.&lt;/li&gt;
    &lt;li&gt;Create a new project.&lt;/li&gt;
    &lt;li&gt;Search for the Google Sheets API and enable it.&lt;/li&gt;
    &lt;li&gt;In the left-hand navigation, go to the &lt;strong&gt;Credentials&lt;/strong&gt; tab.&lt;/li&gt;
    &lt;li&gt;Click &lt;strong&gt;+ Create Credentials&lt;/strong&gt; and select &lt;strong&gt;Service Account&lt;/strong&gt;.&lt;/li&gt;
    &lt;li&gt;Name the Service Account and assign it the &lt;strong&gt;Owner&lt;/strong&gt; role for your project. Click &lt;strong&gt;Done&lt;/strong&gt; to save.&lt;/li&gt;
    &lt;li&gt;From the &lt;strong&gt;Service Accounts&lt;/strong&gt; page, click on the Service Account you just created.&lt;/li&gt;
    &lt;li&gt;Go to the &lt;strong&gt;Keys&lt;/strong&gt; tab, then click &lt;strong&gt;Add Key&lt;/strong&gt; &amp;gt; &lt;strong&gt;Create New Key&lt;/strong&gt;.&lt;/li&gt;
    &lt;li&gt;Choose &lt;strong&gt;JSON&lt;/strong&gt;, then click &lt;strong&gt;Create&lt;/strong&gt;. The JSON file will download automatically.&lt;/li&gt;
    &lt;li&gt;Open your Google Sheet and share it with the Service Account email.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

&lt;p&gt;After aquiring this key file, the persistent private key must be converted to a temporary token once every 30 minutes.
That process is now automated with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;key_file&lt;/code&gt; secret provider.
Create the &lt;a href=&quot;https://duckdb.org/docs/stable/configuration/secrets_manager.html&quot;&gt;secret&lt;/a&gt; with a command like below, pointing to the JSON file exported from Google.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PERSISTENT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_secret&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gsheet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PROVIDER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FILEPATH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;credentials.json&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As the secret is created, the private key is stored in DuckDB and a temporary token is created.
The secret can be stored in memory or optionally persisted to disk (unencrypted) using the &lt;a href=&quot;https://duckdb.org/docs/stable/configuration/secrets_manager.html#persistent-secrets&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PERSISTENT&lt;/code&gt; keyword&lt;/a&gt;.
The temporary token is cached within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SECRET&lt;/code&gt; as well and is recreated if it is over 30 minutes old.&lt;/p&gt;

&lt;p&gt;This unlocks the use of the GSheets extension within pipelines, like GitHub Actions (GHA) or other orchestrators like dbt.
The best practice is to store the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;credentials.json&lt;/code&gt; file as a secret within your orchestrator and write it out to a temporary file.
An &lt;a href=&quot;https://github.com/Alex-Monahan/duckdb-gsheets/blob/main/.github/workflows/python-app.yml&quot;&gt;example GHA workflow is here&lt;/a&gt;, which uses &lt;a href=&quot;https://github.com/Alex-Monahan/duckdb-gsheets/blob/main/ci_scripts/set_env_vars_for_tests.py&quot;&gt;this Python script to query a Sheet&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;developing-the-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#developing-the-extension&quot;&gt;Developing the Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The Google Sheets extension is a good example of how DuckDB&#39;s extension GitHub template and CI/CD workflows can let even non-C++ experts contribute to the community!
Several of the folks who have contributed thus far (thank you!!), including the authors of this post, are not traditional C++ programmers.
The combination of a great template, examples from other extensions, and a little help from some LLM-powered “junior devs” made it possible.
We encourage you to give your extension idea a shot and reach out on Discord if you need some help!&lt;/p&gt;
      &lt;h2 id=&quot;roadmap&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#roadmap&quot;&gt;Roadmap&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are a few more fun features we are thinking about for the extension – we are open to PRs and collaborators!&lt;/p&gt;

&lt;p&gt;We would like to use a better heuristic for detecting data types when reading from a Sheet.
The DuckDB type system is more advanced than Sheets, so it would be beneficial to be more precise.&lt;/p&gt;

&lt;p&gt;Enabling the GSheets extension to work in &lt;a href=&quot;https://duckdb.org/docs/stable/clients/wasm/overview.html&quot;&gt;DuckDB-Wasm&lt;/a&gt; would allow in-browser applications to query Sheets directly – no server needed!
Several &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http&lt;/code&gt; functions need some modification to work in a browser environment.&lt;/p&gt;

&lt;p&gt;The OAuth flow that powers the browser-based login may be useful for authenticating to other APIs.
We are wondering if maybe it would be possible to have a generic OAuth community extension.
There are no concrete plans for this at the moment, but if anyone is interested, please reach out!&lt;/p&gt;
      &lt;h2 id=&quot;closing-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/26/google-sheets-community-extension.html#closing-thoughts&quot;&gt;Closing Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;At MotherDuck (where Alex works), we have this extension running in production for several internal data pipelines!
We have automated exports of forecasts from our warehouse into Sheets and continually load manually collected customer support data into our (MotherDuck-powered) data warehouse.
As a result, our KPI dashboards include context from folks talking directly to customers!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/in/mharrisb1/&quot;&gt;Michael Harris&lt;/a&gt; has also contributed to the extension (thank you!), and &lt;a href=&quot;https://www.definite.app/&quot;&gt;Definite&lt;/a&gt; has deployed GSheets scheduled jobs into production for multiple customers!&lt;/p&gt;

&lt;p&gt;How do you use Google Sheets in your data analysis workflow and how can DuckDB help?
We would love to hear your ideas on &lt;a href=&quot;https://bsky.app/profile/duckdb.org&quot;&gt;BlueSky&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/company/duckdb/&quot;&gt;LinkedIn&lt;/a&gt;, or &lt;a href=&quot;https://x.com/duckdb&quot;&gt;X / Twitter&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Now go automate that Sheet with some SQL!&lt;/p&gt;

</description><link>https://duckdb.org/2025/02/26/google-sheets-community-extension.html</link><guid isPermaLink="false">https://duckdb.org/2025/02/26/google-sheets-community-extension.html</guid><pubDate>Wed, 26 Feb 2025 00:00:00 GMT</pubDate><author>Alex Monahan and Archie Wood</author></item><item><title>Prefix Aliases in SQL</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: You can now put your aliases first in DuckDB&#39;s SQL dialect with a colon, e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT a: 42;&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;syntax&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/25/prefix-aliases-in-sql.html#syntax&quot;&gt;Syntax&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;i&gt;“Perhaps we &lt;a href=&quot;https://www.youtube.com/watch?v=TBAf5l1RmcA&quot;&gt;should just leave nature alone&lt;/a&gt;, to its simple one-assed schematics.”&lt;/i&gt;&lt;br&gt;
   — Dr. Alphonse Mephesto, South Park Episode #5&lt;/p&gt;

&lt;p&gt;There is often more than one way to do things in our beloved SQL. For example, you can define join conditions &lt;em&gt;implicitly&lt;/em&gt; (and dangerously) in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clause or use the (better) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JOIN ... ON ...&lt;/code&gt; syntax. Generally, having “more than one way to do things” can be confusing and even outright &lt;a href=&quot;https://www.youtube.com/watch?v=noQcWra6sbU&quot;&gt;dangerous sometimes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Having said that we here at DuckDB &lt;a href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html&quot;&gt;pride&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html&quot;&gt;ourselves&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;in&lt;/a&gt; &lt;em&gt;friendlier&lt;/em&gt; SQL. There are just too many people typing this stuff by hand, especially in the more ad-hoc world of analytics.&lt;/p&gt;

&lt;p&gt;If there is a &lt;em&gt;good&lt;/em&gt; reason to expand the SQL syntax with something useful we are at least considering it. Others seem to be watching closely. For example, our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY ALL&lt;/code&gt; syntax has by now been picked up by &lt;a href=&quot;https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax&quot;&gt;almost&lt;/a&gt; &lt;a href=&quot;https://docs.snowflake.com/en/sql-reference/constructs/group-by#label-group-by-all-columns&quot;&gt;every&lt;/a&gt; &lt;a href=&quot;https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-syntax-qry-select-groupby&quot;&gt;SQL&lt;/a&gt; &lt;a href=&quot;https://learn.microsoft.com/en-us/sql/t-sql/queries/select-group-by-transact-sql?view=sql-server-ver16#group-by-all-column-expression--n-&quot;&gt;system&lt;/a&gt; out there (and their little brothers).&lt;/p&gt;
      &lt;h2 id=&quot;aliases&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/25/prefix-aliases-in-sql.html#aliases&quot;&gt;Aliases&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In SQL, a user can define &lt;em&gt;aliases&lt;/em&gt; for lots of things like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; expressions, table names, subqueries, etc. This is sometimes just nice to have readable column names in the result and sometimes required to refer back to a complex expression in for example the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause without just repeating it and praying for the optimizer. Aliases are defined &lt;em&gt;after&lt;/em&gt; the thing they alias using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AS&lt;/code&gt; but actually typing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AS&lt;/code&gt; term is optional. For example, those two statements are equivalent:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fortytwo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fortytwo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see the alias follows the expression (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;42&lt;/code&gt;) and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AS&lt;/code&gt; is optional. Having the alias &lt;em&gt;behind&lt;/em&gt; the thing it describes is actually somewhat rare in programming, it is much more typical to define the alias first and then provide the expression. For example, in C:&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fortytwo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems to be a good idea to first state the alias, after all, this is what we are going to refer to this thing later on. Forcing it the other way around like SQL just increases the mental load. In addition, having the aliases last can make them quite hard to find if there are several complex expressions in a query. For example, here are the first few lines of the infamous TPC-H Query 1:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_base_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_disc_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_tax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_charge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_order&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It&#39;s hard to spot all the aliases here, and this is not even a complex example. What if you could put the aliases first in SQL? Well, wait no more.&lt;/p&gt;
      &lt;h2 id=&quot;prefix-aliases-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/25/prefix-aliases-in-sql.html#prefix-aliases-in-duckdb&quot;&gt;Prefix Aliases in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In the latest DuckDB release, &lt;a href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html&quot;&gt;1.2.0&lt;/a&gt;, we have quietly shipped yet another useful (we think) &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14436&quot;&gt;syntax extension&lt;/a&gt; to allow the alias to come before the thing it names using the colon (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:&lt;/code&gt;) syntax. This turned out to be less difficult than we thought, “all” it took was some modification to the Bison parser we inherited from Postgres (&lt;a href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html&quot;&gt;but are in the process of replacing&lt;/a&gt;). Here is the example from before again:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fortytwo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Prefix aliases also work for table names, e.g.:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;some_other_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Aliases can be quoted if neccessary using &lt;em&gt;double&lt;/em&gt; quotes:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;forty two&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Prefix aliases can be used to name just about everything, for example expressions, function calls and subqueries in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;asdf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;They can also apply to function calls and subqueries in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM clause&lt;/code&gt;, e.g.:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VALUES&lt;/code&gt; clause and the subquery with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; need additional parentheses to work here, this was required to pacify the evil Bison parser generator. Let&#39;s look at the Q1 example from earlier, but this time with prefix aliases:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum_base_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum_disc_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum_charge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_tax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;      &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;       &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;count_order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is no semantic difference between using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AS&lt;/code&gt;, they lead to the same query constructs.&lt;/p&gt;
      &lt;h2 id=&quot;credits&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/25/prefix-aliases-in-sql.html#credits&quot;&gt;Credits&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Credit for this idea goes to Looker veteran &lt;a href=&quot;https://www.linkedin.com/in/michael-toy-27b3407/&quot;&gt;Michael Toy&lt;/a&gt;.
We&#39;re grateful for his suggestion.
We also would like to thank the legendary &lt;a href=&quot;https://www.linkedin.com/in/lloydtabb/&quot;&gt;Lloyd Tabb&lt;/a&gt; for recommending Michael&#39;s idea to us.
Also check out Mark Needham&#39;s &lt;a href=&quot;https://youtu.be/rwIiw7HZa1M?si=yRzsHfpd62d0pp7u&amp;amp;t=215&quot;&gt;video on DuckDB&#39;s prefix aliases&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2025/02/25/prefix-aliases-in-sql.html</link><guid isPermaLink="false">https://duckdb.org/2025/02/25/prefix-aliases-in-sql.html</guid><pubDate>Tue, 25 Feb 2025 00:00:00 GMT</pubDate><author>Hannes Mühleisen</author></item><item><title>Planning AsOf Joins</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: AsOf Joins are a great example of how DuckDB can choose different implementations for an expensive operation.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;“I love it when a plan comes together.”&lt;br&gt;
  — Hannibal Smith, &lt;cite&gt;The A-Team&lt;/cite&gt;&lt;/p&gt;
      &lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;AsOf joins are a very useful kind of operation for temporal analytics.
As the name suggests, they are a kind of lookup for when you have a
table of values that change over time, and you want to look up the most recent value
at another set of times.
Put another way, they let you ask &lt;em&gt;“What was the value of the property &lt;strong&gt;as of this time&lt;/strong&gt;?”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;DuckDB &lt;a href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html&quot;&gt;added AsOf joins about 18 months ago&lt;/a&gt;
and you can read that post to learn about their semantics.&lt;/p&gt;
      &lt;h2 id=&quot;whats-the-plan&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#whats-the-plan&quot;&gt;What&#39;s the Plan?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In that &lt;a href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html&quot;&gt;earlier post&lt;/a&gt;, I explained why we have a custom operator and syntax for AsOf joins
when you can implement them in traditional SQL.
The superpower of SQL is that it is &lt;em&gt;declarative:&lt;/em&gt;
you tell us &lt;em&gt;what&lt;/em&gt; you want and we figure out an efficient &lt;em&gt;how.&lt;/em&gt;
By allowing you to say you want an AsOf join, we can think about how to get you results faster!&lt;/p&gt;

&lt;p&gt;Still, the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#as-of-joins&quot;&gt;AsOf operator&lt;/a&gt; has to do a lot of work.
Namely:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Read all the data in the right side (lookup) table&lt;/li&gt;
  &lt;li&gt;Partition it on any equality conditions&lt;/li&gt;
  &lt;li&gt;Sort it on the inequality condition&lt;/li&gt;
  &lt;li&gt;Repeat the process for the left side (probe) table&lt;/li&gt;
  &lt;li&gt;Do a merge join on the two tables that only returns the “most recent” value&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That&#39;s a lot of data movement!
Plus, if any of the tables are large, we may end up exceeding memory and spilling to disk,
slowing the operation down even further.
Still, as we will see, it is much faster than the plain SQL implementation.&lt;/p&gt;

&lt;p&gt;This is such a burden, that many databases that support AsOf joins
require the right side table to be partitioned and ordered on any keys you might want to join on.
That doesn&#39;t fit well with DuckDB&#39;s “friendly SQL” approach,
so (for now) we have to do it every time.&lt;/p&gt;
      &lt;h3 id=&quot;lets-get-small&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#lets-get-small&quot;&gt;Let&#39;s Get Small&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;It turns out there is a very common case for AsOf where the left table is small.
Suppose you have a year&#39;s worth of price data, recorded at high granularity
(e.g., fractions of a second),
but you only want to look up a small number (say 20) values that are the times you actually bought or sold?&lt;/p&gt;

&lt;p&gt;The price table could run to hundreds of millions, if not billions of rows,
and just sorting that will take a lot of time and memory.
Given how expensive that is, one might wonder if there is a way to avoid all that sorting?
Happily the answer is &lt;em&gt;yes!&lt;/em&gt;&lt;/p&gt;
      &lt;h3 id=&quot;simple-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#simple-joins&quot;&gt;Simple Joins&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Suppose we were to swap the sides of the join, build the old left side as a small right side table,
and stream the huge table through the left side of the join.
We could use the AsOf conditions for the join, and hopefully find a way to throw out the older matches
(we only want to keep the latest match).
This would use very little memory, and the streaming could be highly parallelized.&lt;/p&gt;

&lt;p&gt;There are two streaming physical join operators we could use for this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Nested Loop Join&lt;/em&gt; – Literally what it sounds like: loop over each left block and the right side table, checking for matches;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Piecewise Merge Join&lt;/em&gt; – A tricky join for one inequality condition that sorts the right side and each left block before merging to find matches;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can try both of these once we have a way to eliminate the duplicates.
One thing to be aware of, though, is that they are both &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N^2&lt;/code&gt; algorithms,
so there will be a limit on how big “small” can be.&lt;/p&gt;
      &lt;h3 id=&quot;grouping&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#grouping&quot;&gt;Grouping&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If you have been around databases long enough,
you know that the phrase “eliminate the duplicates” means &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt;!
So to eliminate the duplicates, we want to add an aggregation operator onto the output.
The tricky part is that we want to keep only the matched values that have the “largest” times.
Fortunately, DuckDB has a pair of aggregate functions that do just that:
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#arg_maxarg-val&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_max&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#arg_minarg-val&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_min&lt;/code&gt;&lt;/a&gt;
(also called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_by&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;That takes care of the fields from the lookup table, but what about the fields from the small table?
Well, those values will all be the same, so we can just use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first&lt;/code&gt; aggregate function for them.&lt;/p&gt;
      &lt;h3 id=&quot;streaming-window&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#streaming-window&quot;&gt;Streaming Window&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;But what should we group on?
One might be tempted to group on the times that are being looked up,
but that could be problematic if there are duplicate lookup times
(only one of the rows would be returned!).
Instead, we need to have a unique identifier for each row being looked up.
The simplest way to do this is to use the
&lt;a href=&quot;https://duckdb.org/2025/02/14/window-flying.html&quot;&gt;&lt;em&gt;streaming window operator&lt;/em&gt;&lt;/a&gt;
with the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html#row_numberorder-by-ordering&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row_number()&lt;/code&gt; window function&lt;/a&gt;.
We then group on this row number.&lt;/p&gt;
      &lt;h2 id=&quot;coming-together&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#coming-together&quot;&gt;Coming Together&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This all sounds good, but how does it work in practice?
How big can “small” get?
To answer that I ran a number of benchmarks joining small tables against large ones.
The tables are called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prices&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;times&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prices_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&#39;2021-01-01T00:00:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECOND&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prices_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;times_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&#39;2021-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECONDS&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;times_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I then ran a benchmark query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;times_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prices_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;for a matrix of the following values:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Prices – 100K to 1B rows in steps of 10x;&lt;/li&gt;
  &lt;li&gt;Time – 1 to 2048 rows in steps of 2x (until it got too slow);&lt;/li&gt;
  &lt;li&gt;Threads – 36, 18 and 9;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here are the results:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/asof/asof-plans.png&quot; alt=&quot;AsOf Plan Matrix&quot; title=&quot;AsOf Plan Matrix&quot; style=&quot;max-width:100%;width:100%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, the quadratic nature of the joins means that “small” means “&amp;lt;= 64”.
That is pretty small, but the table in the original user issue had only 21 values.&lt;/p&gt;

&lt;p&gt;We can also see that the sorting provided by piecewise merge join does not seem to help much,
so plain old Nested Loop Join is the best choice.&lt;/p&gt;

&lt;p&gt;It is clear that the performance of the standard operator is stable at each size,
but decreases slowly as the number of threads increases.
This makes sense because sorting is compute-intensive and the fewer cores we can assign,
the longer it will take.&lt;/p&gt;

&lt;p&gt;If you want to play with the data more, you can find
the &lt;a href=&quot;https://public.tableau.com/app/profile/duckdb.labs/viz/AsOfLoopJoin/Tuning&quot;&gt;interactive vizualization&lt;/a&gt;
on our &lt;a href=&quot;https://public.tableau.com/app/profile/duckdb.labs/vizzes&quot;&gt;Tableau Public site&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;memory&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#memory&quot;&gt;Memory&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The Loop Join plan is clearly faster at small sizes,
but how much memory do the two plans use?
These are the rough amounts of memory needed before excessive paging or allocation failures occur:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Price Rows&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;AsOf Memory&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Loop Join Memory&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1B&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;48 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100M&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10M&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;256 MB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1M&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;32 MB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100K&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;32 MB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In other words, the Loop Join plan only needs enough memory to page in the lookup table!
So if the table is large and you have limited memory, the Loop Join plan is the best option,
even if it is painfully slow.
Just remember that the Loop Join plan has to compete with the speed of the standard operator
under paging, and that may still be faster past a certain point.&lt;/p&gt;
      &lt;h3 id=&quot;backup-plans&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#backup-plans&quot;&gt;Backup Plans&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As part of the experiment, I also measured how the old SQL implementation would perform,
and it did not fare well.
At the 1B row level I had to cut it off after one run to avoid wasting time:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/asof/asof-debug.png&quot; alt=&quot;AsOf SQL Implementation&quot; title=&quot;AsOf SQL Implementation&quot; style=&quot;max-width:100%;width:100%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Note that the Y-axis is a log scale here!&lt;/p&gt;
      &lt;h3 id=&quot;setting&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#setting&quot;&gt;Setting&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;While it is nice that we provide a default value for making plan choices like this, your mileage may vary as they say.
If you have more time than memory, it might be worth it to you to bump up the Loop Join threshold a bit.
The threshold is a new setting called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;asof_loop_join_threshold&lt;/code&gt; with a default value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;64&lt;/code&gt;,
and you can change it using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRAGMA&lt;/code&gt; statement:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;asof_loop_join_threshold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Remember, though, this is a quadratic operation, and pushing it up too high might take a Very Long Time
(especially if you express it in &lt;a href=&quot;https://tolkiengateway.net/wiki/Entish&quot;&gt;Old Entish&lt;/a&gt;!).&lt;/p&gt;

&lt;p&gt;If you wish to disable the feature, you can just set it to zero:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;asof_loop_join_threshold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;roll-your-own&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#roll-your-own&quot;&gt;Roll Your Own&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This Loop Join plan optimization will not ship until v1.3, but if you are having problems today,
you can always write your own version like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;arg_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pk&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pk&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you know the probe times are unique, you can simplify this to:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;arg_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#future-work&quot;&gt;Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The new AsOf Loop Join plan feature only covers a common but very specific situation,
and the standard operator could be made a lot more efficient if it knew that the data was already sorted.
This is often the case, but we do not yet have the ability to track partitioning and ordering between operators.
Tracking that kind of metadata would be very useful for speeding up a large number of operations,
including sorting (!), partitioned aggregation, windowing, AsOf joins and merge joins.
This is work we are very interested in, so stay tuned!&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;With apologies to &lt;a href=&quot;https://en.wikipedia.org/wiki/Guido_van_Rossum&quot;&gt;Guido van Rossum&lt;/a&gt;, there is usually more than one way to do something,
but each way may have radically different performance characteristics.
One of the jobs of a relational database with a declarative query language like SQL
is to make intelligent choices between the options so you the user can focus on the result.
Here at DuckDB we look forward to finding more ways to plan your queries so you can focus on what you do best!&lt;/p&gt;
      &lt;h2 id=&quot;notes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/19/asof-plans.html#notes&quot;&gt;Notes&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;ul&gt;
  &lt;li&gt;The tests were all run on an iMac Pro with a 2.3 GHz 18-core Intel Xeon W CPU and 128 GB of RAM.&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://public.tableau.com/views/AsOfLoopJoin/Tuning?:language=en-US&amp;amp;:sid=&amp;amp;:redirect=auth&amp;amp;:display_count=n&amp;amp;:origin=viz_share_link&quot;&gt;raw test data and visualizations&lt;/a&gt; are available on our &lt;a href=&quot;https://public.tableau.com/app/profile/duckdb.labs/vizzes&quot;&gt;Tableau Public repository&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The script to generate the data is in my &lt;a href=&quot;https://github.com/hawkfish/feathers/blob/main/joins/asof-plans.py&quot;&gt;public DuckDB tools repository&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

</description><link>https://duckdb.org/2025/02/19/asof-plans.html</link><guid isPermaLink="false">https://duckdb.org/2025/02/19/asof-plans.html</guid><pubDate>Wed, 19 Feb 2025 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>Flying Through Windows</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Dive into the details of recent DuckDB windowing performance improvements.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In the previous post I went into some new windowing functionality in DuckDB available through SQL.
But there are other changes that improve our use of resources (such as memory) without adding new functionality.
So let&#39;s get “under the feathers” and look at these changes.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We previously &lt;a href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html&quot;&gt;benchmarked ourselves on a window function-heavy workload&lt;/a&gt;, which showed great performance improvements over time.
The optimizations presented in this blog post push the performance of DuckDB&#39;s window operator even further.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;segment-tree-vectorization&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#segment-tree-vectorization&quot;&gt;Segment Tree Vectorization&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;One important improvement that was made in the summer of 2023 was converting the segment tree evaluation code
to vectorized evaluation from single-value evaluation.
You might wonder why it wasn&#39;t that way to begin with in a “vectorized relational database” (!),
but the answer is lost in the mists of time.
My best guess is either that the published algorithm was written for values
or that the aggregation API had not been nailed down yet (or both).&lt;/p&gt;

&lt;p&gt;In the old version, we used the aggregate&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;update&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;combine&lt;/code&gt; APIs,
but with only the values and tree states for a single row.
To vectorize the segment tree aggregation, we accumulate &lt;em&gt;vectors&lt;/em&gt; of leaf values and tree states
and flush them into each output row&#39;s state when we reach the vector capacity of 2048 rows.
Some care needed to be taken to handle order-sensitive aggregates by accumulating values in the correct order.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FILTER&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; clauses also provided some entertainment, but the segment trees are now fully vectorized.
The performance gains here were about a factor of four (from “Baseline” to “Fan Out”).&lt;/p&gt;

&lt;p&gt;The chart below shows the speedups achieved by the vectorization improvements:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://duckdb.org/images/blog/windowing/vectorization-improvements.png&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/windowing/vectorization-improvements.png&quot; alt=&quot;Vectorization Improvements&quot; title=&quot;Vectorization Improvements&quot; style=&quot;width: 950px&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Once segment trees were vectorized,
we could use the same approach when implementing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt; aggregates with merge sort trees.
It may be worth updating the custom window API to handle vectorization at some point,
because although most custom window aggregates are quite slow (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mad&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt;),
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count(*)&lt;/code&gt; is also implemented as a custom aggregate and would likely benefit from a vectorized implementation.&lt;/p&gt;
      &lt;h2 id=&quot;constant-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#constant-aggregation&quot;&gt;Constant Aggregation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A lot of window computations are aggregates over frames,
and a common analytic task with these results is to compare a partial aggregate
to the same aggregate over &lt;em&gt;the entire partition&lt;/em&gt;.
Computing this value repeatedly is expensive and potentially wasteful of memory
(e.g, the old implementation would construct a segment tree even though only one value was needed.)&lt;/p&gt;

&lt;p&gt;The previous performance workaround for this was
to compute the aggregate in a subquery and join it in on the partition keys, but that was, well, unfriendly.
Instead, we have added an optimization that checks for &lt;em&gt;partition-wide aggregates&lt;/em&gt;
and computes that value once per partition.
This not only reduces memory and compute time for the aggregate itself,
but we can often return a constant vector that shares the values across all rows in a chunk,
reducing copy costs and potentially even downstream evaluation costs.&lt;/p&gt;

&lt;p&gt;Returning a constant vector can yield surprisingly large memory and performance benefits.
In the issue that drove this improvement, the user was constructing a constant 100k element list (!)
and then computing the median with a list aggregation lambda.
By returning a single constant list, we build and reduce that list only once
instead of once per row!&lt;/p&gt;
      &lt;h2 id=&quot;streaming-windows&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#streaming-windows&quot;&gt;Streaming Windows&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Computing window functions is usually quite expensive!
The entire relation has to be materialized,
broken up into partitions, and each partition needs to be sorted.&lt;/p&gt;

&lt;p&gt;But what if there is no partitioning or ordering?
This just means that the window function is computed over the entire relation, in the “natural order”,
using a frame that starts with the first row and continues to the current row.
Examples might be assigning row numbers or computing a running sum.
This is simple enough that we can &lt;em&gt;stream&lt;/em&gt; the evaluation of the function on a single thread.&lt;/p&gt;

&lt;p&gt;First, let&#39;s step back a bit and talk about the window &lt;em&gt;operator&lt;/em&gt;.
During parsing and optimization of a query, all the window functions are attached to a single &lt;em&gt;logical&lt;/em&gt; window operator.
When it comes time to plan the query, we group the functions that have common partitions and “compatible” orderings
(see Cao et al.,
&lt;a href=&quot;https://www.vldb.org/pvldb/vol5/p1244_yucao_vldb2012.pdf&quot;&gt;&lt;em&gt;Optimization of Analytic Window Functions&lt;/em&gt;&lt;/a&gt;
for more information)
and hand each group off to a separate &lt;em&gt;physical&lt;/em&gt; window operator that handles that partitioning and ordering.
In order to use the “natural order” we have to group those functions that can be streamed and execute them first
(or the order will have been destroyed!) and hand them off to the &lt;em&gt;streaming&lt;/em&gt; physical window operator.&lt;/p&gt;

&lt;p&gt;So which &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html&quot;&gt;window functions&lt;/a&gt; can we stream?
It turns out there are quite a few:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Aggregates &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW&lt;/code&gt; (we just update the aggregate)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first_value&lt;/code&gt; – it&#39;s always the same&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;percent rank&lt;/code&gt; – it&#39;s always 0&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rank&lt;/code&gt; – it&#39;s always 0&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dense_rank&lt;/code&gt; – it&#39;s always 0&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row_number&lt;/code&gt; – we just count the rows&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lead&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lag&lt;/code&gt; – we just keep a buffer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are a few more restrictions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IGNORE NULLS&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; arguments are not allowed&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lead&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lag&lt;/code&gt; distances are restricted to a constant within ±2048 (one vector). this is not really a big deal because the distance is usually 1.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The improvements for streaming &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LEAD&lt;/code&gt; were quite dramatic:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;setseed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8675309&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The chart below shows the performance improvements.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Baseline – Where we started&lt;/li&gt;
  &lt;li&gt;Shift – Copying blocks of rows inside the non-streaming implementation, instead of one at a time&lt;/li&gt;
  &lt;li&gt;Streaming – First implementation of streaming &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LEAD&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Partials – Avoid copying when the entire chunk can just be referenced&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the &lt;em&gt;x&lt;/em&gt; axis shows the speedups compared to the baseline (1×) and the absolute runtimes (in seconds) are shown as labels.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://duckdb.org/images/blog/windowing/streaming-lead.png&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/windowing/streaming-lead.png&quot; alt=&quot;Streaming Lead Performance&quot; title=&quot;Streaming Lead Performance&quot; style=&quot;width: 800px&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;In the future we may be able to relax the end of the frame to a constant distance from the current row
that fits inside the buffer length (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING&lt;/code&gt;)
but that hasn&#39;t been investigated yet.&lt;/p&gt;
      &lt;h2 id=&quot;partition-major-evaluation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#partition-major-evaluation&quot;&gt;Partition Major Evaluation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Window partitions are completely independent, so evaluating them separately is attractive.
Our first implementation took advantage of this and evaluated each partition on a separate thread.
This works well if you have more partitions than threads, and they are all roughly the same size,
but if the partition sizes are skewed or if there is only one partition (a common situation),
then most of the cores will be idle, reducing throughput.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://duckdb.org/images/blog/windowing/parallel-partitions.png&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/windowing/parallel-partitions.png&quot; alt=&quot;Thread Partition Evaluation&quot; title=&quot;Thread Partition Evaluation&quot; style=&quot;width: 400px;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;To improve the CPU utilization, we changed the execution model for v1.1 to evaluate partitions in parallel.
The partitions are evaluated from largest to smallest and
we then distribute each partition across as many cores as we can, while synchronizing access to shared data structures.
This was a lot more challenging than independent single-threaded evaluation of partitions,
and we had some synchronization issues (hopefully all sorted now!) that were dealt with in the v1.1.x releases.
But we now have much better core utilization, especially for unpartitioned data.
As a side benefit, we were able to reduce the memory footprint because fewer partitions were in memory at a time.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://duckdb.org/images/blog/windowing/partition-major.png&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/windowing/partition-major.png&quot; alt=&quot;Partition Major Evaluation&quot; title=&quot;Partition Major Evaluation&quot; style=&quot;width: 400px;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;One remaining issue is the coarseness of the sub-partitions.
At the moment to avoid copying they use the blocks produced by the sorting code,
which are often larger than we would like.
Reducing the size of these chunks is future work,
but hopefully we will get to it as part of some proposed changes to the sorting code.&lt;/p&gt;
      &lt;h2 id=&quot;out-of-memory-operation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#out-of-memory-operation&quot;&gt;Out of Memory Operation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Because windowing materializes the entire relation, it was very easy to blow out the memory budget of a query.
For v1.2 we have switched from materializing active partitions in memory to using a pageable collection.
So now not only do we have fewer active partitions (due to partition major evaluation above),
but those partitions themselves can now spool to disk.
This further reduces memory pressure during evaluation of large partitions.&lt;/p&gt;

&lt;p&gt;Windowing is so complex, however, that there are still some remaining large data structures.
The &lt;a href=&quot;https://www.vldb.org/pvldb/vol8/p1058-leis.pdf&quot;&gt;segment trees&lt;/a&gt;
and &lt;a href=&quot;https://dl.acm.org/doi/10.1145/3514221.3526184&quot;&gt;merge sort trees&lt;/a&gt;
used for accelerating aggregation are still in memory,
especially the intermediate aggregate states in the middle of the trees.
Solving this completely, will require a general method of serializing aggregate states to disk,
which we do not yet have.
Still, most aggregates can be serialized as binary data without special handling,
so in the short term we can probably cover a lot of cases with the current aggregation infrastructure,
just as we do for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;shared-expressions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#shared-expressions&quot;&gt;Shared Expressions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Window expressions are evaluated independently, but they often share expressions.
Some of those expressions can be expensive to evaluate and others need to be materialized
over the entire partition.
As an example of the latter, aggregate functions can reference values anywhere in the partition.
This could result in computing and materializing the same values multiple times:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Compute the moving average and range of x over a large window&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WINDOW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1_000_000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1_000_000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Paging the data for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; reduces the memory footprint, but the segment trees used to evaluate the three aggregates
will contain duplicate copies of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; – along with the with operator itself (which has to return &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;).
With v1.2 we have added a mechanism for sharing evaluation of expressions like these between functions.
This not only reduces memory, but in this example we will also reduce disk paging
because all three functions will be accessing the same values.&lt;/p&gt;

&lt;p&gt;There are a number of places where we are sharing expressions, including &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; arguments,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;range&lt;/code&gt; expressions and “value” functions like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lead&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lag&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nth_value&lt;/code&gt;,
and we are always on the lookout for more (such as frame boundaries – or even segment trees).&lt;/p&gt;
      &lt;h2 id=&quot;future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#future-work&quot;&gt;Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;While I have mentioned a number of things we would like to get to in the future,
one that doesn&#39;t fit nicely into any of the topics so far is query rewriting.
It turns out that some window functions can be evaluated using other techniques
such as &lt;a href=&quot;https://www.vldb.org/pvldb/vol17/p2162-baca.pdf&quot;&gt;self-joins&lt;/a&gt;
and some of our smarter aggregates (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_max&lt;/code&gt;).
Generating these alternate query plans can have large performance benefits
and we plan to investigate them.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/14/window-flying.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;As you can see, windowing is a big hairy beast!
There is also not a lot of published research on effective algorithms (I&#39;ve linked to pretty much all of it),
so we are often stuck making it up ourselves or falling back to extremely simple and slow approaches.
But I hope that many of you will find something new and exciting in what we have been up to for the past 2-3 years -
and I will try to be more timely in blogging about future window improvements.&lt;/p&gt;

</description><link>https://duckdb.org/2025/02/14/window-flying.html</link><guid isPermaLink="false">https://duckdb.org/2025/02/14/window-flying.html</guid><pubDate>Fri, 14 Feb 2025 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>Catching up with Windowing</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB implements a number of modern windowing features, some of which are extensions to the SQL standard. This posts presents a few of these features, including GROUPS framing, QUALIFY and aggregate/function modifiers.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;background&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/10/window-catchup.html#background&quot;&gt;Background&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In the beginning, the relational data processing model was all about sets.
This was &lt;a href=&quot;https://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf&quot;&gt;Codd&#39;s great insight&lt;/a&gt;
and for many years, relational processing took little notice of data ordering.&lt;/p&gt;

&lt;p&gt;But it turns out that there are a lot of analytic operations that are related to ordering.
For example, smoothing out noise in time series is very difficult to do in traditional SQL queries
– it involves self-joins with inequality conditions!
So in the late 1990s database vendors started adding &lt;em&gt;windowing&lt;/em&gt; operations.
By making the user&#39;s intent clear, the operations could be implemented much more efficiently,
and these operations were eventually
&lt;a href=&quot;https://en.wikipedia.org/wiki/Window_function_(SQL)&quot;&gt;added to the SQL:2003 standard&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;DuckDB has had support for window functions since the early days,
but if they are new to you, you might want to start with my earlier blog posts
on &lt;a href=&quot;https://duckdb.org/2021/10/13/windowing.html&quot;&gt;Windowing in DuckDB&lt;/a&gt;
and &lt;a href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html&quot;&gt;Fast Moving Holistic Aggregates&lt;/a&gt;,
or just the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html&quot;&gt;window function documentation&lt;/a&gt;.
In this post, I will start by introducing the more recent functionality additions.
In a follow-up post, I will spelunk into the internals to talk about some performance and scaling improvements.&lt;/p&gt;

&lt;p&gt;For the examples in this post, I will mostly stick to using a table of athletic &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;results&lt;/code&gt;:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Field&lt;/th&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;event&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The name of the event (e.g., 200 meter butterfly).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;athlete&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The name of the competitor (e.g., Michael Phelps).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;date&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The start time of the event.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DECIMAL(18, 3)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The athlete&#39;s time in that event (in seconds).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;groups-framing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/10/window-catchup.html#groups-framing&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUPS&lt;/code&gt; Framing&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In addition to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROWS&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RANGE&lt;/code&gt; frame boundary types (which we have supported for a while now),
the standard also defines &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUPS&lt;/code&gt; as a boundary type.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROWS&lt;/code&gt; is pretty simple: it just counts the number of rows.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RANGE&lt;/code&gt; is trickier: it treats its counts as distances from
the value of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; expression at the current row.
This means that there can only be one such expression
and you have to be able to do arithmetic on it.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUPS&lt;/code&gt; is somewhere in between.
A “group” in the standard&#39;s language is all the “peers” of a row,
which are all the rows with the same
value of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; expression at the current row.
In the original windowing code, this was not easy to implement,
but after several years of work, the infrastructure has evolved,
and as of v1.2.0 we now support this last type of framing.&lt;/p&gt;
      &lt;h2 id=&quot;frame-exclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/10/window-catchup.html#frame-exclusion&quot;&gt;Frame Exclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another missing piece of the 2003 specification was the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; clause.
Thanks to work by a community member, we have supported this since v0.10.0,
but we somehow never got around to mentioning it in a blog post!&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; is an optional modifier to the frame clause for excluding rows around the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CURRENT ROW&lt;/code&gt;.
This is useful when you want to compute some aggregate value of nearby rows
to see how the current row compares to it.
In this example, we want to know how an athlete&#39;s time in an event compares to
the average of all the times recorded for their event within ±10 days:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WINDOW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are four options for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; that specify how to treat the current row:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CURRENT ROW&lt;/code&gt; – exclude just the current row&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP&lt;/code&gt; – exclude the current row and all its “peers” (rows that have the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; value)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIES&lt;/code&gt; – exclude all peer rows, but &lt;em&gt;not&lt;/em&gt; the current row (this makes a hole on either side)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NO OTHERS&lt;/code&gt; – don&#39;t exclude anything (the default)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Exclusion is implemented for both windowed aggregates and for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;last&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nth_value&lt;/code&gt; functions.&lt;/p&gt;
      &lt;h2 id=&quot;qualify-clause&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/10/window-catchup.html#qualify-clause&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; Clause&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;It may not be immediately obvious, but the SQL language
has rules for the order in which various expressions are computed.
For example, aggregates (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt;) are computed after row-level expressions (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+&lt;/code&gt;).
This is why SQL has two filtering clauses: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HAVING&lt;/code&gt;:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; is for row-level computations and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HAVING&lt;/code&gt; is applied after &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When windowing was introduced, it added another layer of computation:
window functions are computed &lt;em&gt;after&lt;/em&gt; aggregates.
That is great, but then how do you filter the results of an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; function?
Originally, you had to put the query in a Common Table Expression (or CTE)
which is defined by a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH&lt;/code&gt; clause:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Find the third fastest times in each event&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;windowed&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WINDOW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;windowed&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This was kind of clunky, so eventually the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; clause was proposed for filtering window functions.
DuckDB supports this, making it easier to filter the results of window functions:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Find the third fastest times in each event&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WINDOW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;QUALIFY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;aggregate-modifiers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/10/window-catchup.html#aggregate-modifiers&quot;&gt;Aggregate Modifiers&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are several modifiers for ordinary aggregate functions (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FILTER&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; as an argument)
that are not part of the SQL:2003 standard for windowing, but which are also useful in a windowing context.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FILTER&lt;/code&gt; is pretty straightforward (and DuckDB has supported it for a while)
but the others are not easy to implement efficiently.&lt;/p&gt;

&lt;p&gt;They can of course be implemented naïvely (academic-speak for “slow”!) by just computing each row independently:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;re-read all the values,&lt;/li&gt;
  &lt;li&gt;filter out the ones we don&#39;t want,&lt;/li&gt;
  &lt;li&gt;stick them into a hash table to remove duplicates,&lt;/li&gt;
  &lt;li&gt;sort the results,&lt;/li&gt;
  &lt;li&gt;send them off to the aggregate function to get the result.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We have an implementation that does this (which you can access by turning off the optimizer)
and we use it to check fancier implementations, but it is horribly slow.&lt;/p&gt;

&lt;p&gt;Fortunately, these last two modifiers have been the subject of
&lt;a href=&quot;https://www.vldb.org/pvldb/vol9/p1221-wesley.pdf&quot;&gt;research&lt;/a&gt;
&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3514221.3526184&quot;&gt;published&lt;/a&gt;
in the last 10 years,
and we have now added those algorithms to the windowing aggregates.
We can then use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt; modifier to exclude duplicates in the frame:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Count the number of distinct athletes at a given point in time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Concatenate those distinct athletes into a list&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can also use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; modifier with order-sensitive aggregates to get sorted results:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Return an alphabetized list of athletes who made or beat a time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I should mention that the research on these extensions is ongoing,
and combining them will often force us to use the naïve implementation.
So for example, if we wished to exclude the athlete who made the time in the previous example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Return an alphabetized list athletes who beat the each time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB will still compute this for you, but it may be very slow.&lt;/p&gt;
      &lt;h2 id=&quot;function-modifiers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/10/window-catchup.html#function-modifiers&quot;&gt;Function Modifiers&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; modifier also makes sense for some non-aggregate window functions,
especially if we let them use framing with it:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Compute the current world record holder over time for each event&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;first_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;first_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;athlete&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record_holder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WINDOW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UNBOUNDED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All of the non-aggregate window functions (except &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dense_rank&lt;/code&gt;) now support ordering arguments
and will use the frame instead of the entire partition when an ordering argument is supplied.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tip If you wish to use the entire frame with an ordering argument, then you will need to be explicit and use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note If you wish to use the frame ordering &lt;em&gt;and&lt;/em&gt; the frame boundaries with a non-aggregate function, you will need to specify the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; &lt;em&gt;twice&lt;/em&gt; (once in the frame specification and once in the argument list). This has not yet been optimized, but it will be in the v1.3.0 release.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/10/window-catchup.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Windowing is a very natural way to think about order-dependent analysis,
but it is at odds with traditional unordered query processing.
Nevertheless, since 2003 the SQL language has provided syntax for expressing a wide range of such queries.
In recent years, the community has also considered further extensions to the language
(such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; and argument modifiers like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt;) to improve expressivity.
Here at DuckDB we love providing this kind of expressiveness as part of our &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;“friendly SQL”&lt;/a&gt; work.
What may  be less obvious is that when we enable users to express their problem more naturally,
it helps us provide more performant solutions!
In my next post, I will go deeper into recent improvements in windowing&#39;s performance and resource utilization.&lt;/p&gt;

</description><link>https://duckdb.org/2025/02/10/window-catchup.html</link><guid isPermaLink="false">https://duckdb.org/2025/02/10/window-catchup.html</guid><pubDate>Mon, 10 Feb 2025 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>Announcing DuckDB 1.2.0</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The DuckDB team is happy to announce that today we&#39;re releasing DuckDB version 1.2.0, codenamed “Histrionicus”.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;.
For the release notes, see the &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v1.2.0&quot;&gt;release page&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Some packages (Go, R, Java) take a few extra days to release due to the reviews required in the release pipelines.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We are proud to release DuckDB 1.2.0. This release is codenamed “Histrionicus” after the good-looking &lt;a href=&quot;https://en.wikipedia.org/wiki/Harlequin_duck&quot;&gt;Harlequin duck (Histrionicus histrionicus)&lt;/a&gt;, that inhabits “cold fast moving streams in North America, Greenland, Iceland and eastern Russia”.&lt;/p&gt;
      &lt;h2 id=&quot;whats-new-in-120&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#whats-new-in-120&quot;&gt;What&#39;s New in 1.2.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There have been far too many changes to discuss them each in detail, but we would like to highlight several particularly important and exciting features!
Below is a summary of those new features with examples.&lt;/p&gt;
      &lt;h3 id=&quot;breaking-changes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#breaking-changes&quot;&gt;Breaking Changes&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/13920&quot;&gt;&lt;strong&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random&lt;/code&gt; function now uses a larger state.&lt;/strong&gt;&lt;/a&gt;
This means that it&#39;s &lt;em&gt;even more random&lt;/em&gt;™ now. Due to this change fixed seeds will now produce different values than in the previous versions of DuckDB.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14175&quot;&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map[&#39;entry&#39;]&lt;/code&gt; now returns a value, instead of a &lt;em&gt;list&lt;/em&gt; of entries.&lt;/strong&gt;&lt;/a&gt;
For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map([&#39;k&#39;], [&#39;v&#39;])[&#39;k&#39;]&lt;/code&gt; now returns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;v&#39;&lt;/code&gt;, while previously it returned &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[&#39;v&#39;]&lt;/code&gt;. We also introduced the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map_extract_value&lt;/code&gt; function, which is now the alias for the bracket operator &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[]&lt;/code&gt;.
If you would like to return a list, use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/map.html#map_extractmap-key&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map_extract&lt;/code&gt; function&lt;/a&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map_extract(map([&#39;k&#39;], [&#39;v&#39;]), &#39;k&#39;) = [&#39;v&#39;]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15614&quot;&gt;&lt;strong&gt;The indexing of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt; is fixed.&lt;/strong&gt;&lt;/a&gt; When indexing is applied in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;, the index points to the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#reduce&quot;&gt;last parameter of the lambda function&lt;/a&gt; and indexing starts from 1. Therefore, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce([&#39;a&#39;, &#39;b&#39;], (x, y, i) -&amp;gt; x || y || i)&lt;/code&gt; returns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ab2&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;explicit-storage-versions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#explicit-storage-versions&quot;&gt;Explicit Storage Versions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB v1.2.0 ships new compression methods but &lt;em&gt;they are not yet enabled by default&lt;/em&gt; to ensure that older DuckDB versions can read files produced by DuckDB v1.2.0.&lt;/p&gt;

&lt;p&gt;In practice, this means that DuckDB v1.2.0 can read database files written by past stable DuckDB versions such as v1.0.0.
When using DuckDB v1.2.0 with default settings, older versions can read files written by DuckDB v1.2.0.&lt;/p&gt;

&lt;p&gt;You can &lt;em&gt;opt-in to newer forwards-incompatible features&lt;/em&gt; using the following syntax:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;file.db&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;STORAGE_VERSION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;v1.2.0&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This setting specifies the minimum DuckDB version that should be able to read the database file. When database files are written with this option, the resulting files cannot be opened by older DuckDB released versions than the specified version. They can be read by the specified version and all newer versions of DuckDB.&lt;/p&gt;

&lt;p&gt;If you attach to DuckDB databases, you can query the storage versions using the following command:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;database_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tags&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duckdb_databases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This shows the storage versions:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────┬───────────────────────────────────┐
│ database_name │               tags                │
│    varchar    │       map(varchar, varchar)       │
├───────────────┼───────────────────────────────────┤
│ file1         │ {storage_version=v1.2.0}          │
│ file2         │ {storage_version=v1.0.0 - v1.1.3} │
│ ...           │ ...                               │
└───────────────┴───────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This means that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;file2&lt;/code&gt; can be opened by past DuckDB versions while &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;file1&lt;/code&gt; is compatible only with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v1.2.0&lt;/code&gt; (or future versions).&lt;/p&gt;

&lt;p&gt;To convert from the new format to the old format for compatibility, use the following sequence in DuckDB v1.2.0:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;file1.db&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;converted_file.db&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;STORAGE_VERSION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;v1.0.0&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;converted_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;indexing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#indexing&quot;&gt;Indexing&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14419&quot;&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALTER TABLE ... ADD PRIMARY KEY&lt;/code&gt;.&lt;/strong&gt;&lt;/a&gt;
After a long while, DuckDB is finally able to add a primary key to an existing table 🎉. So it is now possible to run this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ADD&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15092&quot;&gt;&lt;strong&gt;Over-eager constraint checking addressed.&lt;/strong&gt;&lt;/a&gt;
We also resolved a long-standing issue with &lt;a href=&quot;https://duckdb.org/docs/1.1/sql/indexes.html#over-eager-unique-constraint-checking&quot;&gt;over-eager unique constraint checking&lt;/a&gt;. For example, the following sequence of commands used to throw an error but now works:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;students&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;students&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;John Doe&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- start transaction&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;students&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;students&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Jane Doe&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;csv-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#csv-features&quot;&gt;CSV Features&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14560&quot;&gt;&lt;strong&gt;Latin-1 and UTF-16 encodings.&lt;/strong&gt;&lt;/a&gt;
Previously, DuckDB&#39;s CSV reader was limited to UTF-8 files. It can now read Latin-1 and UTF-16 files. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;cities-latin-1.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;encoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;latin-1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14670&quot;&gt;&lt;strong&gt;Multi-byte delimiters.&lt;/strong&gt;&lt;/a&gt;
DuckDB now supports delimiters of up to 4 bytes. This means that you can finally use the &lt;a href=&quot;https://emojipedia.org/duck&quot;&gt;duck emoji&lt;/a&gt; as a column delimiter. For example:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a🦆b
hello🦆world
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;example.dsv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;🦆&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14464&quot;&gt;&lt;strong&gt;Strict CSV parsing.&lt;/strong&gt;&lt;/a&gt;
The &lt;a href=&quot;https://www.ietf.org/rfc/rfc4180.txt&quot;&gt;RFC 4180 specification&lt;/a&gt; defines requirements for well-formed CSV files, e.g., having a single line delimiter.
By default, DuckDB now parses CSVs in so-called strict mode (`strict_mode = true). For example, the following CSV file gets rejected because of mixed newline characters:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;a,b&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;hello,42&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;world,84&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; rfc_4180-defiant.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;rfc_4180-defiant.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Invalid Input Error:
Error when sniffing file &quot;rfc_4180-defiant.csv&quot;.
It was not possible to automatically detect the CSV Parsing dialect/types
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But it&#39;s parsed with the more lenient option &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strict_mode = false&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;rfc_4180-defiant.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;strict_mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────┬───────┐
│    a    │   b   │
│ varchar │ int64 │
├─────────┼───────┤
│ hello   │    42 │
│ world   │    84 │
└─────────┴───────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14260&quot;&gt;&lt;strong&gt;Performance improvements.&lt;/strong&gt;&lt;/a&gt;
The CSV parser in the new release uses a new algorithm to find a new line on parallel execution. This leads to speedups of around 15%.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14512&quot;&gt;&lt;strong&gt;Unlimited row length.&lt;/strong&gt;&lt;/a&gt;
Previously, DuckDB was limited to CSV files with rows of up to 8 MB. The new version lifts this restriction, and lines can be of arbitrary length.&lt;/p&gt;
      &lt;h3 id=&quot;parquet-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#parquet-features&quot;&gt;Parquet Features&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14597&quot;&gt;&lt;strong&gt;Parquet dictionary and Bloom filter support.&lt;/strong&gt;&lt;/a&gt;
DuckDB now supports writing many more types using dictionary encoding. This should reduce file size in some cases. DuckDB is now also able to read and write Parquet Bloom filters. Bloom filters are small indexing data structures that can be used to exclude row groups if a filter is set. This is particularly useful for often-repeated but unordered data (e.g., categorical values). A separate blog post will follow.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14257&quot;&gt;&lt;strong&gt;Delta binary packed compression for Parquet.&lt;/strong&gt;&lt;/a&gt;
DuckDB now supports the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELTA_BINARY_PACKED&lt;/code&gt; compression as well as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELTA_LENGTH_BYTE_ARRAY&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BYTE_STREAM_SPLIT&lt;/code&gt; option for Parquet files. A few weeks ago, we elaborated on these in a &lt;a href=&quot;https://duckdb.org/2025/01/22/parquet-encodings.html&quot;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;cli-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#cli-improvements&quot;&gt;CLI Improvements&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14509&quot;&gt;&lt;strong&gt;Safe mode.&lt;/strong&gt;&lt;/a&gt;
The DuckDB command line client now supports &lt;em&gt;safe mode&lt;/em&gt;, which can be activated with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-safe&lt;/code&gt; flag or the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.safe_mode&lt;/code&gt; &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/dot_commands.html&quot;&gt;dot command&lt;/a&gt;. In this mode, the CLI client is prevented from accessing external files other than the database file that it was initially connected to and prevented from interacting with the host file system. For more information, see the &lt;a href=&quot;https://duckdb.org/docs/stable/operations_manual/securing_duckdb/overview.html&quot;&gt;Securing DuckDB page in the Operations Manual&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15003&quot;&gt;&lt;strong&gt;Better autocomplete.&lt;/strong&gt;&lt;/a&gt;
The autocomplete in CLI now uses a &lt;a href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html&quot;&gt;Parsing Expression Grammar (PEG)&lt;/a&gt; for better autocomplete, as well as improved error messages and suggestions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15031&quot;&gt;&lt;strong&gt;Pretty-printing large numbers.&lt;/strong&gt;&lt;/a&gt;
The CLI provides a summary of the number printed if the client is only rendering only a single row.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100_000_000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1e9&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────┬───────────────────┐
│        x         │         y         │
│      int32       │      double       │
├──────────────────┼───────────────────┤
│    100000000     │ 3141592653.589793 │
│ (100.00 million) │  (3.14 billion)   │
└──────────────────┴───────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;friendly-sql&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#friendly-sql&quot;&gt;Friendly SQL&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14436&quot;&gt;&lt;strong&gt;Prefix aliases.&lt;/strong&gt;&lt;/a&gt;
SQL Expression and table aliases can now be specified before the thing they are referring to (instead of using the well-known syntax of using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AS&lt;/code&gt;s). This can improve readability in some cases, for example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;some_long_and_winding_expression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_column_name&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;some_long_table_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Credit for this idea goes to &lt;a href=&quot;https://www.linkedin.com/in/michael-toy-27b3407/&quot;&gt;Michael Toy&lt;/a&gt;.
A separate blog post will follow soon.
&lt;strong&gt;Update:&lt;/strong&gt; the &lt;a href=&quot;https://duckdb.org/2025/02/25/prefix-aliases-in-sql.html&quot;&gt;blog post on prefix aliases&lt;/a&gt; is out.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14650&quot;&gt;&lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RENAME&lt;/code&gt; clause&lt;/strong&gt;.&lt;/a&gt;
DuckDB now supports the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RENAME&lt;/code&gt; clause in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;. This allows renaming fields emitted by the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt; expression&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RENAME&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14662&quot;&gt;&lt;strong&gt;Star &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt;&lt;/strong&gt;.&lt;/a&gt; The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SIMILAR TO&lt;/code&gt; clauses can now be used on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt; expressions as a short-hand for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; syntax.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key_val&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key_val&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;v&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;val%&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────┬───────┐
│ val1  │ val2  │
│ int32 │ int32 │
├───────┼───────┤
│  42   │  84   │
└───────┴───────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;optimizations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#optimizations&quot;&gt;Optimizations&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We have spent
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14864&quot;&gt;a&lt;/a&gt;
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14313&quot;&gt;lot&lt;/a&gt;
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14329&quot;&gt;of&lt;/a&gt;
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14424&quot;&gt;time&lt;/a&gt;
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15020&quot;&gt;on&lt;/a&gt;
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15692&quot;&gt;DuckDB&#39;s&lt;/a&gt;
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/14750&quot;&gt;optimizer&lt;/a&gt;.
It is hard to quantify optimizer improvements, but as a result of these optimizations, DuckDB for example achieves a &lt;strong&gt;13% improvement&lt;/strong&gt; on the total runtime of TPC-H SF100 queries when run on a MacBook Pro over the previous release.&lt;/p&gt;
      &lt;h3 id=&quot;c-api-for-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#c-api-for-extensions&quot;&gt;C API for Extensions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Currently, DuckDB extensions use DuckDB’s internal C++ structures. This – along with some fun linking issues – requires a lock-step development of extensions with mainline DuckDB and constant updates. Starting with this release, we expose a new C-style API for extensions in &lt;a href=&quot;https://github.com/duckdb/duckdb/blob/v1.2.0/src/include/duckdb_extension.h&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb_extension.h&lt;/code&gt;&lt;/a&gt;. This API can be used to create for example scalar, aggregate or table functions in DuckDB. There are two main advantages of using this API: first, many programming languages (e.g., Go, Rust and even Java) have direct bindings to C APIs, making it rather easy to integrate. Secondly, the C Extension API is stable and backwards-compatible, meaning that extensions that target this API will keep working for new DuckDB versions. We will follow up with a new extension template.&lt;/p&gt;
      &lt;h3 id=&quot;musl-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#musl-extensions&quot;&gt;musl Extensions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/15607&quot;&gt;&lt;strong&gt;Distributing extensions for musl.&lt;/strong&gt;&lt;/a&gt;
The &lt;a href=&quot;https://musl.libc.org/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;musl&lt;/code&gt; C library&lt;/a&gt; is often used in lightweight setups such as Docker setups running Alpine Linux. Starting with this release, we officially support musl and we distribute extensions for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;linux_amd64_musl&lt;/code&gt; platform (but not yet for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;linux_arm64_musl&lt;/code&gt;). Note that DuckDB binaries (e.g., the CLI client) are not yet distributed for musl platforms, so you have to &lt;a href=&quot;https://duckdb.org/docs/stable/dev/building/linux.html&quot;&gt;build them from source&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;final-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/02/05/announcing-duckdb-120.html#final-thoughts&quot;&gt;Final Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;These were a few highlights – but there are many more features and improvements in this release.  There have been &lt;strong&gt;over 5 000 commits&lt;/strong&gt; by over 70 contributors since we released 1.1.3. The full – very long – release notes can be &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v1.2.0&quot;&gt;found on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We would like to thank again our amazing community for using DuckDB, building cool projects on DuckDB and improving DuckDB by providing us feedback. Your contributions truly mean a lot!&lt;/p&gt;

</description><link>https://duckdb.org/2025/02/05/announcing-duckdb-120.html</link><guid isPermaLink="false">https://duckdb.org/2025/02/05/announcing-duckdb-120.html</guid><pubDate>Wed, 05 Feb 2025 00:00:00 GMT</pubDate><author>The DuckDB team</author></item><item><title>Query Engines: Gatekeepers of the Parquet File Format</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Mainstream query engines do not support reading newer Parquet encodings, forcing systems like DuckDB to default to writing older encodings, thereby sacrificing compression.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;the-apache-parquet-format&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/22/parquet-encodings.html#the-apache-parquet-format&quot;&gt;The Apache® Parquet™ Format&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Apache Parquet is a popular, free, open-source, column-oriented data storage format.
Whereas database systems typically load data from formats such as CSV and JSON into database tables before analyzing them, Parquet is designed to be efficiently queried directly.
Parquet considers that users often only want to read some of the data, not all of it.
To accommodate this, Parquet is designed to read individual columns instead of always having to read all of them.
Furthermore, statistics can be used to filter out parts of files without fully reading them (this is also referred to as &lt;a href=&quot;https://www.vldb.org/conf/1998/p476.pdf&quot;&gt;zone maps&lt;/a&gt;).
Furthermore, storing data in Parquet typically results in a much smaller file than CSV or JSON due to a combination of &lt;a href=&quot;https://ir.cwi.nl/pub/15564/15564B.pdf&quot;&gt;lightweight columnar compression&lt;/a&gt; and general-purpose compression.&lt;/p&gt;

&lt;p&gt;Many query engines implement reading and writing Parquet files.
Therefore, it is also useful as a &lt;em&gt;data interchange&lt;/em&gt; format.
For example, Parquet files written by Spark in a large distributed data pipeline can later be analyzed using DuckDB.
Because so many systems can read and write Parquet, it is the data format of choice for data lake solutions like &lt;a href=&quot;https://delta.io/&quot;&gt;Delta Lake™&lt;/a&gt; and &lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Iceberg™&lt;/a&gt;.
While Parquet certainly has flaws, which &lt;a href=&quot;https://github.com/cwida/FastLanes&quot;&gt;researchers&lt;/a&gt; and &lt;a href=&quot;https://github.com/facebookincubator/nimble&quot;&gt;companies&lt;/a&gt; are trying to address with new data formats, like it or not, it seems like Parquet is here to stay, at least for a while.&lt;/p&gt;

&lt;p&gt;So, while we&#39;re here, we might try to make the best of it, right?
SQL also has its flaws, and while researchers have certainly tried to create &lt;a href=&quot;https://en.wikipedia.org/wiki/QUEL_query_languages&quot;&gt;different query languages&lt;/a&gt;, we&#39;re still stuck with SQL.
DuckDB embraces this and tries to &lt;a href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html&quot;&gt;make&lt;/a&gt; the &lt;a href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html&quot;&gt;best&lt;/a&gt; of &lt;a href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html&quot;&gt;it&lt;/a&gt;.
The Parquet developers are doing the same for their format by updating it occasionally, bringing &lt;a href=&quot;https://github.com/apache/parquet-format/blob/master/CHANGES.md&quot;&gt;new features&lt;/a&gt; that make the format better.&lt;/p&gt;
      &lt;h2 id=&quot;updates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/22/parquet-encodings.html#updates&quot;&gt;Updates&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;If DuckDB adds a new compression method to its internal file format in a release, all subsequent releases must be able to read it.
Otherwise, you couldn&#39;t read a database file created by DuckDB 1.1.0 after updating it to 1.2.0.
This is called &lt;em&gt;backward compatibility&lt;/em&gt;, and it can be challenging for developers.
It sometimes requires holding onto legacy code and creating conversions from old to new.
It is important to keep supporting older formats because updating DuckDB is much easier than rewriting entire database files.&lt;/p&gt;

&lt;p&gt;Backward compatibility is also valuable for Parquet: it should be possible to read a Parquet file written years ago today.
Luckily, most mainstream query engines can still read files in the Parquet 1.0 format, which was released in 2013, over ten years ago.
Updates to the format do not threaten backward compatibility, as query engines simply need to continue being able to read the old files.
However, it is also important that query engines add support for &lt;em&gt;reading&lt;/em&gt; newer files alongside the older ones so that we can start &lt;em&gt;writing&lt;/em&gt; new and improved Parquet files as well.&lt;/p&gt;

&lt;p&gt;Here&#39;s where it gets tricky.
We cannot expect query engines to be able to read the bleeding-edge Parquet format &lt;em&gt;tomorrow&lt;/em&gt; if Parquet developers roll out an update &lt;em&gt;today&lt;/em&gt;.
We cannot start writing the new format for some time because many query engines will not be able to read it.
The &lt;a href=&quot;https://en.wikipedia.org/wiki/Robustness_principle&quot;&gt;robustness principle&lt;/a&gt; states, “Be conservative in what you send, be liberal in what you accept.”
If we apply this to Parquet files, query engines should strive to read new Parquet files but not write them yet, at least by default.&lt;/p&gt;
      &lt;h2 id=&quot;encodings&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/22/parquet-encodings.html#encodings&quot;&gt;Encodings&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB really likes &lt;a href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html&quot;&gt;lightweight compression&lt;/a&gt;.
So, for the upcoming DuckDB 1.2.0 version, we&#39;re excited to have implemented the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELTA_BINARY_PACKED&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELTA_LENGTH_BYTE_ARRAY&lt;/code&gt; (added in Parquet 2.2.0 in 2015), and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BYTE_STREAM_SPLIT&lt;/code&gt; (added in Parquet 2.8.0 in 2019) encodings in our Parquet writer.
DuckDB, initially created in 2018, has been able to read Parquet since &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/556&quot;&gt;2020&lt;/a&gt;, and has been able to read the encodings &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELTA_BINARY_PACKED&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELTA_LENGTH_BYTE_ARRAY&lt;/code&gt; since &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5457&quot;&gt;2022&lt;/a&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BYTE_STREAM_SPLIT&lt;/code&gt; since &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9240&quot;&gt;2023&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;However, despite these new encodings being available in 1.2.0, DuckDB will not write them by default.
If DuckDB did this, many of our users would have a frustrating experience because some mainstream query engines still do not support reading these encodings.
Having a good compression ratio does not help users if their downstream application cannot read the file.
Therefore, we had to disable writing these encodings by default.
They are only used when setting &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PARQUET_VERSION v2&lt;/code&gt; in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; command.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;DuckDB versions as old as 0.9.1 (released in late 2023) can already read files serialized with the setting &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PARQUET_VERSION v2&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Compressing data is almost always a trade-off between file size and the time it takes to write.
Let&#39;s take a look at the following example (ran on a MacBook Pro with an M1 Max):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Generate TPC-H scale factor 1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; tpch&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; tpch&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dbgen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Export to Parquet using Snappy compression&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;snappy_v1.parquet&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COMPRESSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;snappy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 244 MB, ~0.46s&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;snappy_v2.parquet&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COMPRESSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;snappy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 170 MB, ~0.39s&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Export to Parquet using zstd compression&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;zstd_v1.parquet&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COMPRESSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;zstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 152 MB, ~0.58s&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;zstd_v2.parquet&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COMPRESSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;zstd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 135 MB, ~0.44s&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When using &lt;a href=&quot;https://github.com/google/snappy&quot;&gt;Snappy&lt;/a&gt;, DuckDB&#39;s default page compression algorithm for Parquet, which focuses mostly on speed, not compression ratio, the file is ~30% smaller and writing is ~15% faster with the encodings enabled.
When using &lt;a href=&quot;https://github.com/facebook/zstd&quot;&gt;zstd&lt;/a&gt;, which focuses more on compression ratio than speed, the file is ~11% smaller, and writing is ~24% faster with the encodings enabled.&lt;/p&gt;

&lt;p&gt;The compression ratio highly depends on how well data can be compressed.
Here are some more extreme examples:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1e9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;v1.parquet&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 3.7 GB, ~2.96s&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;v2.parquet&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 1.3 MB, ~1.68s&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The integer sequence 0, 1, 2, … compresses extremely well with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELTA_BINARY_PACKED&lt;/code&gt;.
In this case, the file is ~99% smaller, and writing is almost twice as fast.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/cwida/ALP&quot;&gt;Compressing floating points is much more difficult&lt;/a&gt;.
Nonetheless, if there is a pattern, the data will compress quite well:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1e9&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1e9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;v1.parquet&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 6.3 GB, ~3.83s&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;v2.parquet&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARQUET_VERSION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- 610 MB, ~2.63s&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This sequence compresses really well with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BYTE_STREAM_SPLIT&lt;/code&gt;.
It is ~90% smaller and writes ~31% faster.
Real-world data often does not have such extremely compressible patterns.
Still, there are patterns, nonetheless, which will be exploited by these encodings.&lt;/p&gt;

&lt;p&gt;If the query engines you&#39;re using support reading them, you can start using these encodings once DuckDB 1.2.0 is released!&lt;/p&gt;
      &lt;h2 id=&quot;wasted-bits&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/22/parquet-encodings.html#wasted-bits&quot;&gt;Wasted Bits&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Although it&#39;s difficult to get exact numbers, it&#39;s safe to assume that many TBs of data are written in Parquet each day.
A large chunk of the bits written are wasted because query engines haven&#39;t implemented these newer encodings.
The solution to this is surprisingly easy.
There&#39;s no need to invent anything new to stop wasting all that space.
Just &lt;a href=&quot;https://parquet.apache.org/docs/file-format/data-pages/encodings/&quot;&gt;read the specification on Parquet encodings&lt;/a&gt;, and implement them.
Some of these “newer” encodings are almost 10 years old by now!&lt;/p&gt;

&lt;p&gt;By reducing the size of Parquet files, we can reduce the amount of data we store in data centers.
Reducing the amount of data we store even a little bit can have a big impact, as it can eventually reduce the need to build new data centers.
This is not to say that data centers are evil; we will certainly need more of them in the future.
However, making the most out of the data centers that we already have wouldn&#39;t hurt anyone.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/22/parquet-encodings.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Parquet is currently the industry standard tabular data format.
Because it is also used as a data interchange format, the effectiveness of Parquet&#39;s features depends on the query engines that use it.
If &lt;em&gt;some&lt;/em&gt; of the mainstream query engines (you know who you are) refuse to implement these features, we &lt;em&gt;all&lt;/em&gt; lose.
This is not to say that all query engines must be on Parquet&#39;s bleeding edge, and DuckDB certainly isn&#39;t.
However, query engine developers have a shared responsibility to make Parquet more useful.&lt;/p&gt;

&lt;p&gt;We hope that more query engines will implement these newer encodings.
Then, more query engines can write them by default and stop wasting so many bits.&lt;/p&gt;

</description><link>https://duckdb.org/2025/01/22/parquet-encodings.html</link><guid isPermaLink="false">https://duckdb.org/2025/01/22/parquet-encodings.html</guid><pubDate>Wed, 22 Jan 2025 00:00:00 GMT</pubDate><author>Laurens Kuiper</author></item><item><title>TPC-H SF300 on a Raspberry Pi</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB can run all TPC-H SF300 queries on a Raspberry Pi board.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The Raspberry Pi is an initiative to provide affordable and easy-to-program microcomputer boards.
The initial model in 2012 had a single CPU core running at 0.7 GHz, 256 MB RAM and an SD card slot, making it a great educational platform.
Over time the Raspberry Pi Foundation introduced more and more powerful models.
The latest model, the &lt;a href=&quot;https://www.raspberrypi.com/products/raspberry-pi-5/&quot;&gt;Raspberry Pi 5&lt;/a&gt;, has a 2.4 GHz quad-core CPU and – with extra connectors – can even make use of NVMe SSDs for storage.&lt;/p&gt;

&lt;p&gt;Last week, the &lt;a href=&quot;https://www.raspberrypi.com/news/16gb-raspberry-pi-5-on-sale-now-at-120/&quot;&gt;Pi 5 got another upgrade&lt;/a&gt;:
it can now be purchased with 16 GB RAM.
The DuckDB team likes to experiment with DuckDB in unusual setups such as &lt;a href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html&quot;&gt;smartphones dipped into dry ice&lt;/a&gt;, so we were eager to get our hands on a new Raspberry Pi 5.
After all, 16 GB or memory is equivalent to the amount found in the median gaming machine as reported in the &lt;a href=&quot;https://store.steampowered.com/hwsurvey/Steam-Hardware-Software-Survey-Welcome-to-Steam&quot;&gt;2024 December Steam survey&lt;/a&gt;.
So, surely, the Pi must be able to handle a few dozen GBs of data, right?
We ventured to find out.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Do you have a cool DuckDB setup?
We would like to hear about it!
Please post about it on social media or email it to &lt;a href=&quot;https://duckdb.org/cdn-cgi/l/email-protection#f19690939e83b19584929a95939d909382df929e9c&quot;&gt;&lt;span class=&quot;__cf_email__&quot; data-cfemail=&quot;bfd8deddd0cdffdbcadcd4dbddd3deddcc91dcd0d2&quot;&gt;[email&amp;nbsp;protected]&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html#setup&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Our setup consisted of the following components, priced at a total of $300:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Component&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Price (USD)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.raspberrypi.com/products/raspberry-pi-5/&quot;&gt;Raspberry Pi 5 with 16 GB RAM&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;120.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.raspberrypi.com/products/27w-power-supply/&quot;&gt;Raspberry Pi 27 W USB-C power supply&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13.60&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.raspberrypi.com/products/sd-cards/&quot;&gt;Raspberry Pi microSD card (128 GB)&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;33.40&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.amazon.com/Technology-Intelligent-Turbowrite-MZ-V8V1T0B-AM/dp/B08V83JZH4&quot;&gt;Samsung 980 NVMe SSD (1 TB)&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;84.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://argon40.com/products/argon-one-v3-m-2-nvme-case&quot;&gt;Argon ONE V3 Case&lt;/a&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;49.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Total&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;$300.00&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We installed the heat sinks, popped the SSD into place, and assembled the house.
Here is a photo of our machine:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/raspberry-pi-5-duckdb.jpg&quot; alt=&quot;Raspberry 5 in an Argon ONE v3 case&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
      &lt;h2 id=&quot;experiments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html#experiments&quot;&gt;Experiments&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;So what is this little box capable of? We used the &lt;a href=&quot;https://www.tpc.org/tpch/&quot;&gt;TPC-H workload&lt;/a&gt; to find out.&lt;/p&gt;

&lt;p&gt;We first updated the Raspberry Pi OS (a fork of Debian Linux) to its latest version, 2024-11-19.
We then compiled DuckDB &lt;a href=&quot;https://github.com/duckdb/duckdb/commit/0024e5d4be&quot;&gt;version &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0024e5d4be&lt;/code&gt;&lt;/a&gt; using the &lt;a href=&quot;https://duckdb.org/docs/stable/dev/building/raspberry_pi.html&quot;&gt;Raspberry Pi build instruction&lt;/a&gt;.
To make the queries easy to run, we also included the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/tpch.html&quot;&gt;TPC-H extension&lt;/a&gt; in the build:&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;GEN&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ninja &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CORE_EXTENSIONS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;tpch&quot;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;make&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We then downloaded DuckDB database files containing the TPC-H datasets at different scale factors (SF):&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;wget &lt;/span&gt;https://blobs.duckdb.org/data/tpch-sf100.db
&lt;span class=&quot;nb&quot;&gt;wget &lt;/span&gt;https://blobs.duckdb.org/data/tpch-sf300.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We used two different storage options for both scale factors.
For the first run, we stored the database files on the microSD card, which is the storage that most Raspberry Pi setups have.
This card works fine for serving the OS and programs,
and it can also store DuckDB databases but it&#39;s rather slow, especially for write-intensive operations, which include spilling to disk.
Therefore, for the second run, we placed the database files on the 1 TB NVMe SSD disk.&lt;/p&gt;

&lt;p&gt;For the measurements, we used our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tpch-queries.sql&lt;/code&gt; script, which performs a cold run of all TPC-H queries, from &lt;a href=&quot;https://github.com/duckdb/duckdb/blob/v1.1.3/extension/tpch/dbgen/queries/q01.sql&quot;&gt;Q1&lt;/a&gt; to &lt;a href=&quot;https://github.com/duckdb/duckdb/blob/v1.1.3/extension/tpch/dbgen/queries/q22.sql&quot;&gt;Q22&lt;/a&gt;.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tpch-queries.sql&lt;/code&gt;
&lt;/summary&gt;
  &lt;pre&gt;PRAGMA version;
SET enable_progress_bar = false;
LOAD tpch;
.timer on
PRAGMA tpch(1);
PRAGMA tpch(2);
PRAGMA tpch(3);
PRAGMA tpch(4);
PRAGMA tpch(5);
PRAGMA tpch(6);
PRAGMA tpch(7);
PRAGMA tpch(8);
PRAGMA tpch(9);
PRAGMA tpch(10);
PRAGMA tpch(11);
PRAGMA tpch(12);
PRAGMA tpch(13);
PRAGMA tpch(14);
PRAGMA tpch(15);
PRAGMA tpch(16);
PRAGMA tpch(17);
PRAGMA tpch(18);
PRAGMA tpch(19);
PRAGMA tpch(20);
PRAGMA tpch(21);
PRAGMA tpch(22);
&lt;/pre&gt;
&lt;/details&gt;

&lt;p&gt;We ran the script as follows:&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb &lt;/span&gt;tpch-sf&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SF&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;.db &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;.read tpch-queries.sql&#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We did not encounter any crashes, errors or incorrect results.
The following table contains the aggregated runtimes:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Scale factor&lt;/th&gt;
      &lt;th&gt;Storage&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Geometric mean runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Total runtime&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;SF100&lt;/td&gt;
      &lt;td&gt;microSD card&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23.8 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;769.9 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;SF100&lt;/td&gt;
      &lt;td&gt;NVMe SSD&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.7 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;372.3 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;SF300&lt;/td&gt;
      &lt;td&gt;microSD card&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;171.9 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4,866.5 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;SF300&lt;/td&gt;
      &lt;td&gt;NVMe SSD&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;55.2 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1,561.8 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;aggregated-runtimes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html#aggregated-runtimes&quot;&gt;Aggregated Runtimes&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For the SF100 dataset, the geometric mean runtimes were 23.8 seconds with the microSD card and 11.7 seconds with the NVMe disk.
The latter isn&#39;t that far off from the 7.5 seconds we achieved with the &lt;a href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html&quot;&gt;Samsung S24 Ultra&lt;/a&gt;, which has 8 CPU cores, most of which run at a higher frequency than the Raspberry Pi&#39;s cores.&lt;/p&gt;

&lt;p&gt;For the SF300 dataset, DuckDB had to spill more to disk due to the limited system memory.
This resulted in relatively slow queries for the microSD card setup with a geometric mean of 171.9 seconds.
However, switching to the NVMe disk gave a 3× improvement, bringing the geometric mean down to 55.2 seconds.&lt;/p&gt;
      &lt;h3 id=&quot;individual-query-runtimes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html#individual-query-runtimes&quot;&gt;Individual Query Runtimes&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If you are interested in the individual query runtimes, you can find them below.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;i&gt;Query runtimes (in seconds)&lt;/i&gt;
&lt;/summary&gt;
  &lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Query&lt;/th&gt;&lt;th&gt;SF100 / microSD&lt;/th&gt;&lt;th&gt;SF100 / NVMe&lt;/th&gt;&lt;th&gt;SF300 / microSD&lt;/th&gt;&lt;th&gt;SF300 / NVMe&lt;/th&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;81.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;15.6&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;242.0&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;55.1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;7.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;2.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;27.8&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;7.9&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q3&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;31.5&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;11.8&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;218.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;52.7&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;40.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;11.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;157.5&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;40.9&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q5&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;32.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;12.3&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;215.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;54.1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q6&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;1.6&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;1.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;155.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;32.7&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;12.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;12.3&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;255.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;69.6&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q8&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;25.0&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;19.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;298.0&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;77.8&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;74.0&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;50.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;337.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;147.7&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q10&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;54.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;24.3&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;234.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;82.6&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q11&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;7.8&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;2.3&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;34.0&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;14.9&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q12&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;43.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;13.6&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;202.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;50.5&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q13&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;59.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;51.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;207.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;177.2&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q14&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;33.0&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;9.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;269.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;59.0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q15&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;11.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;7.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;157.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;39.6&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q16&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;8.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;8.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;33.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;27.1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q17&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;8.3&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;7.6&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;249.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;66.2&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q18&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;73.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;40.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;374.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;177.1&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q19&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;66.0&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;17.8&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;317.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;73.8&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q20&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;22.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;8.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;273.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;56.0&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q21&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;66.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;35.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;569.5&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;172.5&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Q22&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;9.2&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;8.4&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;34.1&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;26.7&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;b&gt;Geomean&lt;/b&gt;&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;23.8&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;11.7&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;171.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;55.2&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;&lt;b&gt;Total&lt;/b&gt;&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;769.9&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;372.3&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;4,866.5&lt;/td&gt;&lt;td align=&quot;right&quot;&gt;1,561.8&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/details&gt;
      &lt;h3 id=&quot;perspective&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html#perspective&quot;&gt;Perspective&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To put our results into context, we looked at &lt;a href=&quot;https://www.tpc.org/tpch/results/tpch_results5.asp?version=2&quot;&gt;historical TPC-H results&lt;/a&gt;, and found that several enterprise solutions from 20 years ago had similar query performance, often reporting more than 60 seconds as the geometric mean of their query runtimes.
Back then, these systems – with their software license and maintenance costs factored in – were priced &lt;em&gt;around $300,000!&lt;/em&gt;
This means that – if you ignore the maintenance aspects –, the “bang for your buck” metric (a.k.a. price–performance ratio) for TPC read queries has increased by around 1,000× over the last 20 years.
This is a great demonstration of what the continuous innovation in hardware and software enables in modern systems.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Disclaimer: The results presented here are not official TPC-H results and only include the read queries of TPC-H.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;summary&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html#summary&quot;&gt;Summary&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We showed that you can use DuckDB in a Raspberry Pi setup that costs less than $300 and
runs all queries on the TPC-H SF300 dataset in less than 30 minutes.&lt;/p&gt;

&lt;p&gt;We hope you enjoyed this blog post. If you have an interesting DuckDB setup, don&#39;t forget to share it with us!&lt;/p&gt;

</description><link>https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html</link><guid isPermaLink="false">https://duckdb.org/2025/01/17/raspberryi-pi-tpch.html</guid><pubDate>Fri, 17 Jan 2025 00:00:00 GMT</pubDate><author>Gábor Szárnyas</author></item><item><title>Vertical Stacking as the Relational Model Intended: UNION ALL BY NAME</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB allows vertical stacking of datasets by column name rather than position. This allows DuckDB to read files with schemas that evolve over time and finally aligns SQL with Codd&#39;s relational model.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;overview&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#overview&quot;&gt;Overview&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Ever heard of SQL&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CORRESPONDING&lt;/code&gt; keyword?
Yeah, me neither!
Well, it has been in the &lt;a href=&quot;https://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt&quot;&gt;SQL standard since at least 1992&lt;/a&gt;, and almost nobody implemented it!
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CORRESPONDING&lt;/code&gt; was an attempt to fix a flaw in SQL – but it failed.
It&#39;s time for SQL to get back to the relational model&#39;s roots when stacking data.
Let&#39;s wind the clocks back to 1969…&lt;/p&gt;

&lt;p&gt;You just picked up your own &lt;a href=&quot;https://en.wikipedia.org/wiki/Boss_302_Mustang&quot;&gt;Ford Mustang Boss 302&lt;/a&gt;, drifting around the corner at every street to make it to the library to read the latest &lt;a href=&quot;https://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf&quot;&gt;research report out of IBM by Edgar Codd&lt;/a&gt;.
(Do we need a Neflix special about databases?)
Reading that report, wearing plenty of plaid, you gain a critical insight: data should be treated as unordered sets!
(Technically &lt;a href=&quot;https://en.wikipedia.org/wiki/Multiset&quot;&gt;multisets&lt;/a&gt; – duplicates are everywhere…)
Rows should be treated as unordered and so should columns.
The relational model is &lt;em&gt;the way&lt;/em&gt;.
Any language built atop the relational model should absolutely follow those core principles.&lt;/p&gt;

&lt;p&gt;A few years later, you learn about SQL, and it looks like a pretty cool idea.
Declarative, relational – none of this maintaining order business.
You don&#39;t want to be tied down by an ordering, after all.
What if you change your mind about how to query your data?
Sets are the best way to think about these things.&lt;/p&gt;

&lt;p&gt;More time passes, and then, you have the need to stack some data in SQL.
Should be easy enough – I can just take two tables and stack them, and the corresponding attributes will map together.
No need to worry about ordering, and certainly no need to make sure that the relations are exactly the same width.&lt;/p&gt;

&lt;p&gt;Wait.
This can&#39;t be right.&lt;/p&gt;

&lt;p&gt;I have to get the order of my columns exactly right?
And I have to have the exact same number of columns in both relations?
Did these SQL folks forget about Codd??&lt;/p&gt;

&lt;p&gt;Fast forward just a couple of decades, and DuckDB is making stacking in SQL totally groovy again.&lt;/p&gt;
      &lt;h2 id=&quot;making-vertical-stacking-groovy-again&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#making-vertical-stacking-groovy-again&quot;&gt;Making Vertical Stacking Groovy Again&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In addition to the traditional &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/setops.html#union&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/setops.html#union-all-bag-semantics&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL&lt;/code&gt;&lt;/a&gt; operators, DuckDB adds both &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/setops.html#union-all-by-name&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION BY NAME&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt;&lt;/a&gt;.
These will vertically stack multiple relations (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statements) by matching on the names of columns independent of their order.
As an example, we provide columns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt; out of order, and even introduce the entirely new column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c&lt;/code&gt; and stacking will still succeed:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;woot&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;woot2&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;9001&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;more wooting&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;a&lt;/th&gt;
      &lt;th&gt;b&lt;/th&gt;
      &lt;th&gt;c&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;42&lt;/td&gt;
      &lt;td&gt;woot&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9001&lt;/td&gt;
      &lt;td&gt;woot2&lt;/td&gt;
      &lt;td&gt;more wooting&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;Any column that is not present in all relations is filled in with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; in the places where it is missing.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This capability unlocks a variety of useful patterns that can add flexibility and save time.
Some examples include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stacking datasets that have different column orders&lt;/li&gt;
  &lt;li&gt;Adding new columns to an analysis, but only for a portion of the rows&lt;/li&gt;
  &lt;li&gt;Combining completely unrelated datasets into a single resultset
    &lt;ul&gt;
      &lt;li&gt;This can be useful if your IDE, BI tool, or API can only return a single resultset at a time, but you need to view multiple datasets&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;DuckDB has had this capability since August of 2022, but the performance and scalability of this feature has recently been greatly improved!
See the end of the post for some micro-benchmarks.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h3 id=&quot;union-vs-union-all&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#union-vs-union-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; vs. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If only using the keyword &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt;, duplicates are removed when stacking.
With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL&lt;/code&gt;, duplicates are permitted and the stacking occurs without additional processing.&lt;/p&gt;

&lt;p&gt;Unfortunately we have Codd to thank for this confusing bit!
If only &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL&lt;/code&gt; were the default…
Typically, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL&lt;/code&gt; (and its new counterpart &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt;!) are the desired behavior as they faithfully reproduce the input relations, just stacked together.
This is higher performance as well, since the deduplication that occurs with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; can be quite time intensive with large datasets.
And finally, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL&lt;/code&gt; &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/order_preservation.html&quot;&gt;preserves the original row order&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;reading-multiple-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#reading-multiple-files&quot;&gt;Reading Multiple Files&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;This column matching functionality becomes particularly useful when querying data from multiple files with different schemas.
DuckDB provides a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt; boolean parameter in the table functions used to pull external flat files:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html#parameters&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/data/json/loading_json.html#parameters&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html#parameters&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To read multiple files, DuckDB can use glob patterns within the file path parameter (or a list of files, or a list of glob patterns!).
If those files could have different schemas, adding &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name=True&lt;/code&gt; will allow them to be read and stacked!
Any columns that do not appear in a particular file will be filled with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values.
For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Star&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;star.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Wars&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;wars.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;star.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;wars.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;union_by_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;col1&lt;/th&gt;
      &lt;th&gt;col2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Star&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;Wars&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;If your files have different schemas and you did not expect it, DuckDB&#39;s friendly error messages will suggest the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt; parameter!
There is no need for memorization:&lt;/p&gt;

  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;If you are trying to read files with different schemas, try setting union_by_name=True&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h3 id=&quot;data-lakes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#data-lakes&quot;&gt;Data Lakes&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;It is very common to have schema changes over time in data lakes, so this unlocks many additional uses for DuckDB in those environments.
The secondary effect of this feature is that you may now feel free to change your data lake schemas freely!
Now it is painless to add more attributes to your data lake over time – DuckDB will be ready to handle the analysis!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;DuckDB&#39;s extensions to read lakehouse table formats like &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta.html&quot;&gt;Delta&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/iceberg/overview.html&quot;&gt;Iceberg&lt;/a&gt; handle schema evolution within the formats&#39; own metadata, so &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt; is not needed.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;inserting-data-by-name&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#inserting-data-by-name&quot;&gt;Inserting Data by Name&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another use case for vertically stacking data is when inserting into an existing table.
The DuckDB syntax of &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/insert.html#insert-into--by-name&quot;&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;my_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt;&lt;/code&gt;&lt;/a&gt; offers the same flexibility of referring to columns by name rather than by position.
This allows you to provide the data to insert with any column order and even including only a subset of columns.
For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year_info&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year_info&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;s1&quot;&gt;&#39;The planet made it through&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;2024&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year_info&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;mi&quot;&gt;2025&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;year&lt;/th&gt;
      &lt;th&gt;status&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2024&lt;/td&gt;
      &lt;td&gt;The planet made it through&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2025&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The pre-existing alternative approach was to provide an additional clause that specified the list of columns to be added in the same order as the dataset.
However, this requires the ordering and number of columns to be known up front rather than determined dynamically.
In many cases it also requires specifying columns in two locations: the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT&lt;/code&gt; statement and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement producing the data.
Ignoring the sage advice of &lt;a href=&quot;https://en.wikipedia.org/wiki/Don%27t_repeat_yourself&quot;&gt;“Don&#39;t Repeat Yourself”&lt;/a&gt; has led to more than a few unintended consequences in my own code…
It is always nicer to have a single location to edit rather than having to keep things in sync!&lt;/p&gt;
      &lt;h2 id=&quot;the-inspirations-for-union-all-by-name&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#the-inspirations-for-union-all-by-name&quot;&gt;The Inspirations for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Other systems and communities have tackled the challenges of stacking messy data for many years.
DuckDB takes inspiration from them and brings their improvements back into SQL!&lt;/p&gt;

&lt;p&gt;The most direct inspiration is the &lt;a href=&quot;https://pandas.pydata.org/docs/reference/api/pandas.concat.html&quot;&gt;Pandas &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;concat&lt;/code&gt; function&lt;/a&gt;.
It was &lt;a href=&quot;https://github.com/pandas-dev/pandas/commit/35f3322ac5599c83e29fe0d61a606a7f6845b9fa&quot;&gt;added in January of 2012&lt;/a&gt;, and from the very beginning it supported the addition of new columns.
Pandas is incredibly widely used and is a significant contributor to the popularity of Python today.
Bringing this capability to SQL can broaden its impact beyond Python and into the other languages that DuckDB supports (Java, Node.js, Go, Rust, etc.).
Databases should learn from dataframes!&lt;/p&gt;

&lt;p&gt;PySpark added the function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unionByName&lt;/code&gt; in 2018 and added the abilty to handle the addition of new columns in version 3.1 in March of 2021.
This is another option for Pythonistas, but carries with it the requirement for a Spark cluster and its overhead.&lt;/p&gt;

&lt;p&gt;SQL&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; clause had the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CORRESPONDING&lt;/code&gt; keyword since 1992 (!) at the latest, but critically it lacks the ability to handle new or missing columns.
As a result, it is useless for handling schema evolution.&lt;/p&gt;

&lt;p&gt;It is our hope that we inspire other SQL engines to become “friendlier” and allow for this flexibility!&lt;/p&gt;
      &lt;h2 id=&quot;improved-performance-in-duckdb-11&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#improved-performance-in-duckdb-11&quot;&gt;Improved Performance in DuckDB 1.1&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB has supported &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt; since 2022, but &lt;a href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html&quot;&gt;version 1.1&lt;/a&gt; brought some significant scalability and performance improvements.
This feature used to be an “if you have to” approach, but can now be used more broadly!&lt;/p&gt;

&lt;p&gt;The first change &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12730&quot;&gt;reduced memory usage when reading multiple files over the network using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt;&lt;/a&gt;.
This provides scalability benefits when querying from cloud object storage like S3, especially when the files are large relative to available memory.&lt;/p&gt;

&lt;p&gt;The second change was to &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12957&quot;&gt;parallelize reads across files when using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt;&lt;/a&gt;.
This expectedly provides a dramatic performance improvement (~6× in the microbenchmark in the PR).&lt;/p&gt;
      &lt;h3 id=&quot;micro-benchmark&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#micro-benchmark&quot;&gt;Micro-Benchmark&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;This micro-benchmark is a reproduction of the work done by &lt;a href=&quot;https://dataengineeringcentral.substack.com/about&quot;&gt;Daniel Beach&lt;/a&gt; (&lt;a href=&quot;https://x.com/dataenggdude&quot;&gt;@DataEngDude&lt;/a&gt;) in &lt;a href=&quot;https://dataengineeringcentral.substack.com/p/duckdb-vs-polars-thunderdome&quot;&gt;this post&lt;/a&gt;.
Thanks to Daniel for his permission to reuse his benchmark for this post!&lt;/p&gt;

&lt;p&gt;The benchmark requires reading 16 GB of CSV files stored on S3 that have changing schemas on a cloud instance with 4 GB of memory.
The intent behind it is to process large datasets on small commodity hardware (which is a use case where we want to see DuckDB be helpful!).
The original post uses Linode, but for this post we selected the most similar AWS instance having the same amount of memory (&lt;a href=&quot;https://instances.vantage.sh/aws/ec2/c5d.large&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c5d.large&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We use two quarters&#39; of CSV files from the &lt;a href=&quot;https://www.backblaze.com/cloud-storage/resources/hard-drive-test-data#downloadingTheRawTestData&quot;&gt;Backblaze dataset&lt;/a&gt; (&lt;a href=&quot;https://blobs.duckdb.org/data/backblaze-data-2023-Q2.zip&quot;&gt;2023 Q2&lt;/a&gt; and &lt;a href=&quot;https://blobs.duckdb.org/data/backblaze-data-2023-Q3.zip&quot;&gt;2023 Q3&lt;/a&gt;), which are placed in an S3 bucket.&lt;/p&gt;

&lt;p&gt;I modified the query &lt;a href=&quot;https://dataengineeringcentral.substack.com/i/141997113/duckdb-reading-gb-from-s-on-a-gb-machine&quot;&gt;from here&lt;/a&gt; very slightly to remove the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ignore_errors = true&lt;/code&gt; option.
The benchmark continued to use Python, but I&#39;m just showing the SQL here for better syntax highlighting:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VIEW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failures&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv_auto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/*.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;union_by_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/results/results.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When using a 4 GB instance and an older version of DuckDB (1.0.0), I am able to replicate the out of memory errors that Daniel encountered.
If I upgrade to DuckDB 1.1.3, the queries run successfully! However, they required about 5.8 minutes to complete.&lt;/p&gt;

&lt;p&gt;As I dug more deeply into the dataset, I discovered that the columns selected in the benchmark query are present in each file.
In prior versions of DuckDB, just having files with different sets of columns would require the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name = True&lt;/code&gt; flag, even if the inconsistent or new columns were not used in the query.
However, between the original post and version 1.1.3, DuckDB added the capability to do projection pushdown into CSV files!
This means that only the columns used in the query are actually read from the CSV, not all columns.
As a result, we can actually remove the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name = true&lt;/code&gt; for the benchmark query and run successfully.
This requires less overhead (since we do not need to invest time checking if all schemas match – we can rely on the first schema that is read).
The simplified query runs in only 4 minutes, but it fails to exercise the capability we discussed – handling schema evolution!&lt;/p&gt;

&lt;p&gt;To exercise the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY NAME&lt;/code&gt; capability, we add a column to the SQL query that is present only in some of the files.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VIEW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datacenter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datacenters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failures&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv_auto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/*.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;union_by_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/results/results.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query runs in approximately the same amount of time as the original (5.6 minutes), so it is a good proxy for the original while showcasing how DuckDB handles schema evolution!&lt;/p&gt;

&lt;p&gt;I then made a few tweaks to improve the performance.
The first change is to skip the creation of a view and complete the operations all in one step.
The reason this improves performance is that DuckDB will try to ensure that a view is correctly defined by binding it when it is created.
Normally, this has negligible overhead (views are a great abstraction!), however when reading from cloud object storage and using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt;, this triggers a check of the schema of each file, which can take time.
In this case, around 2 minutes!
The updated SQL statement looks like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datacenter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datacenters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failures&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv_auto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/*.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;union_by_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/results/results.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Performance improves to about 4.1 minutes with this change and also reduces the test down to a single query.&lt;/p&gt;

&lt;p&gt;We can quantify the overhead of the flexibility that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt; provides if we keep the improved subquery syntax, but once again remove the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;datacenter&lt;/code&gt; column and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt; flag.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failures&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv_auto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/*.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;s3_path&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/results/results.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query runs in 3.7 minutes, so the overhead of handling schema evolution is only about 10%!
That is a small price to pay for flexibilty and ease of use.&lt;/p&gt;

&lt;p&gt;However, we can improve performance further still.
The next change was to increase the number of threads that DuckDB uses.
By default, DuckDB will use a single thread per core.
However, this is a very I/O intensive query (due to the network hops reading from then writing to S3) and less of a CPU intensive one.
DuckDB uses synchronous I/O, so with the default thread count, if a thread is doing I/O, that CPU core is idle.
As a result, using more threads might be more likely to fully utilize network resources, which is the bottleneck in this test.
Here I just made an educated guess that this would help, but monitoring CPU utilization is a better approach.&lt;/p&gt;

&lt;p&gt;With 4 threads, instead of the default of 2, performance improves to 3 minutes!&lt;/p&gt;

&lt;p&gt;Adding more threads did not meaningfully improve performance any further.
Additional threads do use more memory, but with the improvements in 1.1, this is no longer a significant issue (I tested up to 16 threads with only 2.2 GB of memory used).&lt;/p&gt;

&lt;p&gt;The table below summarizes the results achieved on a &lt;a href=&quot;https://instances.vantage.sh/aws/ec2/c5d.large&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c5d.large&lt;/code&gt;&lt;/a&gt; instance, which has 2 vCPUs and 4 GB RAM. We report the total runtime and the maximum memory usage for each query.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Query syntax&lt;/th&gt;
      &lt;th&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; type&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Threads&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Runtime&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Memory&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;create view, copy&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY NAME&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.8 min&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.47 GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;create view, copy&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY POSITION&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.0 min&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.47 GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;create view, copy, new column&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY NAME&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.6 min&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.47 GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;copy subquery, new column&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY NAME&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.1 min&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.47 GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;copy subquery&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY POSITION&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.7 min&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.49 GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;copy subquery, new column&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY NAME&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.0 min&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.77 GB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;closing-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2025/01/10/union-by-name.html#closing-thoughts&quot;&gt;Closing Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When stacking data, DuckDB brings the spirit of the relational model back to SQL!
After all, stacking data should not require column orders to match…
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY NAME&lt;/code&gt; keywords can simplify common operations like combining relations with different orders or sets of columns, inserting the results of a query into a table, or querying a data lake with a changing schema.
As of DuckDB version 1.1, this is now a performant and scalable approach!&lt;/p&gt;

&lt;p&gt;Happy analyzing!&lt;/p&gt;

</description><link>https://duckdb.org/2025/01/10/union-by-name.html</link><guid isPermaLink="false">https://duckdb.org/2025/01/10/union-by-name.html</guid><pubDate>Fri, 10 Jan 2025 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>DuckDB Node Neo Client</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The new DuckDB Node client, “Neo”, provides a powerful and friendly way to use your favorite database&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Meet the newest DuckDB client API: &lt;a href=&quot;https://duckdb.org/docs/stable/clients/node_neo/overview.html&quot;&gt;DuckDB Node “Neo”&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;You may be familiar with DuckDB’s &lt;a href=&quot;https://duckdb.org/docs/stable/clients/nodejs/overview.html&quot;&gt;old Node client&lt;/a&gt;. While it has served the community well over the years, “Neo” aims to learn from and improve upon its predecessor. It presents a friendlier API, supports more features, and uses a more robust and maintainable architecture. It provides both high-level conveniences and low-level access. Let’s take a tour!&lt;/p&gt;
      &lt;h2 id=&quot;what-does-it-offer&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#what-does-it-offer&quot;&gt;What Does It Offer?&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;friendly-modern-api&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#friendly-modern-api&quot;&gt;Friendly, Modern API&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The old Node client’s API is based on &lt;a href=&quot;https://www.npmjs.com/package/sqlite3&quot;&gt;SQLite’s&lt;/a&gt;. While familiar to many, it uses an awkward, dated callback-based style. Neo uses &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise&quot;&gt;Promises&lt;/a&gt; natively.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`SELECT &#39;Hello, Neo!&#39;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Additionally, Neo is built from the ground up in &lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;TypeScript&lt;/a&gt;. Carefully chosen names and types minimize the need to check documentation.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnNames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;columnNames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnTypes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;columnTypes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Neo also provides convenient helpers to read only as many rows as needed and return them in either column-major or row-major format.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;runAndReadUtil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;FROM range(5000)&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;rows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getRows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// OR: const columns = reader.getColumns();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;full-data-type-support&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#full-data-type-support&quot;&gt;Full Data Type Support&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB supports a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/overview.html&quot;&gt;rich variety of data types&lt;/a&gt;. Neo supports every built-in type as well as custom types such as &lt;a href=&quot;https://duckdb.org/docs/stable/data/json/json_type.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JSON&lt;/code&gt;&lt;/a&gt;. For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;typeId&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DuckDBTypeId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ARRAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrayValueType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;valueType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrayLength&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DECIMAL&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;typeId&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DuckDBTypeId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decimalWidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;decimalScale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JSON&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;alias&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;json&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;columnValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Type-specific utilities ease common conversions such as producing human-readable strings from &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/timestamp.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;&lt;/a&gt;s or &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/numeric.html#fixed-point-decimals&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DECIMAL&lt;/code&gt;&lt;/a&gt;s, while preserving access to the raw values for lossless processing.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;columnType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;typeId&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DuckDBTypeId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;timestampMicros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;micros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// bigint&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;timestampString&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;day&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;hour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;micros&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;columnValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;toParts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;advanced-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#advanced-features&quot;&gt;Advanced Features&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Need to bind specific types of values to &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/prepared_statements.html&quot;&gt;prepared statements&lt;/a&gt;, or precisely &lt;a href=&quot;https://duckdb.org/docs/stable/clients/c/api.html#pending-result-interface&quot;&gt;control SQL execution&lt;/a&gt;? Perhaps you want to leverage DuckDB’s parser to &lt;a href=&quot;https://duckdb.org/docs/stable/clients/c/api.html#extract-statements&quot;&gt;extract statements&lt;/a&gt;, or efficiently &lt;a href=&quot;https://duckdb.org/docs/stable/clients/c/appender.html&quot;&gt;append data to a table&lt;/a&gt;. Neo has you covered, providing full access to these powerful features of DuckDB.&lt;/p&gt;
      &lt;h4 id=&quot;binding-values-to-prepared-statements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#binding-values-to-prepared-statements&quot;&gt;Binding Values to Prepared Statements&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;When binding values to parameters of &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/prepared_statements.html&quot;&gt;prepared statements&lt;/a&gt;, you can select the SQL data type. This is useful for types that don’t have a natural equivalent in JavaScript.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;prepare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;SELECT $1, $2&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bindTimestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DuckDBTimestampValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;micros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bindDecimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DuckDBDecimalValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;controlling-task-execution&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#controlling-task-execution&quot;&gt;Controlling Task Execution&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Using &lt;a href=&quot;https://duckdb.org/docs/stable/clients/c/api.html#pending-result-interface&quot;&gt;pending results&lt;/a&gt; allows pausing or stopping SQL execution at any point, even before the result is ready.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DuckDBPendingResultState&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/node-api&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Placeholder to demonstrate doing other work between tasks.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;setTimeout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;resolve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;prepare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;FROM range(10_000_000)&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;pending&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Run tasks until the result is ready.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// This allows execution to be paused and resumed as needed.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Other work can be done between tasks.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;pending&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;runTask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!==&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;DuckDBPendingResultState&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;RESULT_READY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;not ready&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;ready&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;pending&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getResult&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;extracting-statements-and-running-them-with-parameters&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#extracting-statements-and-running-them-with-parameters&quot;&gt;Extracting Statements and Running Them with Parameters&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;You can run multi-statement SQL containing parameters using the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/c/api.html#extract-statements&quot;&gt;extract statements API&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Parse this multi-statement input into separate statements.&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;extractedStatements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;extractStatements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`
  CREATE OR REPLACE TABLE numbers AS FROM range(?);
  FROM numbers WHERE range &amp;lt; ?;
  DROP TABLE numbers;
`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;parameterValues&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmtCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;extractedStatements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Run each statement, binding values as needed.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmtIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmtIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmtCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmtIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;extractedStatements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;prepare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stmtIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;paramCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parameterCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;paramIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;paramIndex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;paramCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;paramIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bindInteger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;paramIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;parameterValues&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;shift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;prepared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// ...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;appending-data-to-a-table&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#appending-data-to-a-table&quot;&gt;Appending Data to a Table&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/clients/c/appender.html&quot;&gt;appender API&lt;/a&gt; is the most efficient way to bulk insert data into a table.&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;s2&quot;&gt;`CREATE OR REPLACE TABLE target_table(i INTEGER, v VARCHAR)`&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createAppender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;target_table&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendInteger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendVarchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;walk&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endRow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendInteger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendVarchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;swim&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endRow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendInteger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendVarchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;fly&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endRow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;appender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;how-is-it-built&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#how-is-it-built&quot;&gt;How Is It Built?&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;dependencies&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#dependencies&quot;&gt;Dependencies&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Neo uses a different implementation approach from most other DuckDB client APIs, including the old Node client. It binds to DuckDB’s &lt;a href=&quot;https://duckdb.org/docs/stable/clients/c/overview.html&quot;&gt;C API&lt;/a&gt; instead of the C++ API.&lt;/p&gt;

&lt;p&gt;Why should you care? Using DuckDB’s C++ API means building all of DuckDB from scratch. Each client API using this approach ships with a slightly different build of DuckDB. This can create headaches for both library maintainers and consumers.&lt;/p&gt;

&lt;p&gt;Maintainers need to pull in the entire DuckDB source code. This increases the cost and complexity of the build, and thus the cost of code changes and especially DuckDB version updates. These costs often lead to significant delays in fixing bugs or supporting new versions.&lt;/p&gt;

&lt;p&gt;Consumers are impacted by these delays. There’s also the possibility of subtle behavioral differences between the builds in each client, perhaps introduced by different compile-time configuration.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Some client APIs reside in the &lt;a href=&quot;https://github.com/duckdb/duckdb/tree/main/tools&quot;&gt;main DuckDB repository&lt;/a&gt;. This addresses some of the problems above, but increases the cost and complexity of maintaining DuckDB itself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To use DuckDB’s C API, on the other hand, one only needs to depend on &lt;a href=&quot;https://github.com/duckdb/duckdb/releases&quot;&gt;released binaries&lt;/a&gt;. This significantly simplifies the maintenance required, speeds up builds, and minimizes the cost of updates. It removes the uncertainty and risk of rebuilding DuckDB.&lt;/p&gt;
      &lt;h3 id=&quot;packages&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#packages&quot;&gt;Packages&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB requires different binaries for each platform. Distributing platform-specific binaries in Node packages is notoriously challenging. It can often lead to inscrutable errors when installing, when the package manager attempts to rebuild some component from source, using whatever build and configuration tools happen to be around.&lt;/p&gt;

&lt;p&gt;Neo uses a package design aimed to avoid these problems. Inspired by &lt;a href=&quot;https://github.com/evanw/esbuild/pull/1621&quot;&gt;ESBuild&lt;/a&gt;, Neo packages pre-built binaries for each supported platform in a separate package. Each of these packages declares the particular platform (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;os&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cpu&lt;/code&gt;) it supports. Then, the main package depends on all these platform-specific packages using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;optionalDependencies&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When the main package is installed, the package manager will only install optionalDependencies for supported platforms. So you only get exactly the binaries you need, no more. If installed on an unsupported platform, no binaries will be installed. At no point will an attempt to build from source occur during install.&lt;/p&gt;
      &lt;h3 id=&quot;layers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#layers&quot;&gt;Layers&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The DuckDB Node Neo client has multiple layers. Most people will want to use Neo’s main “api” package, &lt;a href=&quot;https://www.npmjs.com/package/@duckdb/node-api&quot;&gt;@duckdb/node-api&lt;/a&gt;. This contains the friendly API with convenient helpers. But, for advanced use cases, Neo also exposes the lower-level “bindings” package, &lt;a href=&quot;https://www.npmjs.com/package/@duckdb/node-bindings&quot;&gt;@duckdb/node-bindings&lt;/a&gt;, which implements a more direct translation of DuckDB’s C API into Node.&lt;/p&gt;

&lt;p&gt;This API has TypeScript definitions, but, as it follows the conventions of C, it can be awkward to use from Node. However, it provides a relatively unopinionated way to access DuckDB, which supports building special-purpose applications or alternate higher-level APIs.&lt;/p&gt;
      &lt;h2 id=&quot;where-is-it-headed&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#where-is-it-headed&quot;&gt;Where Is It Headed?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Neo is currently marked “alpha”. This is an indication of completeness and maturity, not robustness. Most of the functionality of DuckDB’s C API is exposed, and what is exposed has extensive tests. But it’s relatively new, so it may contain undiscovered bugs.&lt;/p&gt;

&lt;p&gt;Additionally, some areas of functionality are not yet complete:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Appending and binding advanced data types. These require additional functions in DuckDB’s C API. The goal is to add these for the next release of DuckDB 1.2, &lt;a href=&quot;https://duckdb.org/docs/stable/dev/release_calendar.html&quot;&gt;currently planned for January 2025&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Writing to data chunk &lt;a href=&quot;https://duckdb.org/docs/stable/internals/vector.html&quot;&gt;vectors&lt;/a&gt;. Modifying binary buffers in a way that can be seen by a native layer presents special challenges in the Node environment. This is a high priority to work on in the near future.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;User-defined types &amp;amp; functions. The necessary functions and types were added to the DuckDB C API relatively recently, in v1.1.0. This is on the near-term roadmap.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Profiling info. This was added in v1.1.0. It’s on the roadmap.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Table descriptions. This was also added in v1.1.0. It’s on the roadmap.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;New versions of DuckDB will include additions to the C API. Since Neo aims to cover all the functionality of the C API, these additions will be added to the roadmap as they are released.&lt;/p&gt;

&lt;p&gt;If you have a feature request, or other feedback, &lt;a href=&quot;https://github.com/duckdb/duckdb-node-neo/issues&quot;&gt;let us know&lt;/a&gt;! &lt;a href=&quot;https://github.com/duckdb/duckdb-node-neo/pulls&quot;&gt;Pull requests&lt;/a&gt; are also welcome.&lt;/p&gt;
      &lt;h2 id=&quot;what-now&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/18/duckdb-node-neo-client.html#what-now&quot;&gt;What Now?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB Node Neo provides a friendly and powerful way to use DuckDB with Node. By leveraging DuckDB’s C API, it exemplifies a new, more maintainable way to build on DuckDB, providing benefits to maintainers and consumers alike. It’s still young, but growing up fast. &lt;a href=&quot;https://www.npmjs.com/package/@duckdb/node-api&quot;&gt;Try it yourself&lt;/a&gt;!&lt;/p&gt;

</description><link>https://duckdb.org/2024/12/18/duckdb-node-neo-client.html</link><guid isPermaLink="false">https://duckdb.org/2024/12/18/duckdb-node-neo-client.html</guid><pubDate>Wed, 18 Dec 2024 00:00:00 GMT</pubDate><author>Jeff Raymakers</author></item><item><title>25 000 Stars on GitHub</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We have recently reached 25 000 stars on GitHub. We would like to use this occasion to stop and reflect about DuckDB&#39;s recent year and our future plans.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Our &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;GitHub repository&lt;/a&gt; has just passed 25,000 stars. This is great news and since it is also the end of the year it is a good moment to reflect on DuckDB’s trajectory. There has been a lot of new and exciting adoption of DuckDB across the industry.&lt;/p&gt;

&lt;p&gt;We would like to highlight two main events that have happened this year:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We &lt;a href=&quot;https://duckdb.org/2024/06/03/announcing-duckdb-100.html&quot;&gt;released DuckDB 1.0.0&lt;/a&gt;. This version introduced a stable storage format which guarantees &lt;a href=&quot;https://duckdb.org/docs/stable/internals/storage.html#compatibility&quot;&gt;backwards compatibility and limited forward compatibility&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;We started the &lt;a href=&quot;https://duckdb.org/2024/07/05/community-extensions.html&quot;&gt;DuckDB Community Extensions project&lt;/a&gt;. Community extensions allow developers to contribute packages to DuckDB and users to easily install these extensions using the simple command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSTALL xyz FROM community&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Besides the GitHub stars we have also observed a lot of growth in various metrics.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Each month, our website handles over 1.5 million unique visitors. In addition, we see over 300 TB in traffic from ca. 30 million extension downloads. Thanks again to Cloudflare for &lt;a href=&quot;https://duckdb.org/foundation/#technical-sponsors&quot;&gt;sponsoring the project&lt;/a&gt; with free content delivery services!&lt;/li&gt;
  &lt;li&gt;In one year, we rose in the &lt;a href=&quot;https://db-engines.com/en/ranking&quot;&gt;DB Engines ranking&lt;/a&gt; from position 91 to 55 on the general board and from position 47 to 33 in the &lt;a href=&quot;https://db-engines.com/en/ranking/relational+dbms&quot;&gt;relational board&lt;/a&gt;, which makes DuckDB the fastest growing relational system in the top-50.&lt;/li&gt;
  &lt;li&gt;We count &lt;a href=&quot;https://pypistats.org/packages/duckdb&quot;&gt;7.5M+ monthly downloads in PyPI&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Maven Central downloads for the JDBC driver have also shot up, we now see over 500k+ downloads per month.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We should note that we’re not glorifying those numbers and they are not a target per se for our much-beloved optimization in accordance with &lt;a href=&quot;https://en.wikipedia.org/wiki/Goodhart%27s_law&quot;&gt;Goodhart’s law&lt;/a&gt;. Still, they are just motivating to see grow.&lt;/p&gt;

&lt;p&gt;As an aside, we have recently opened a &lt;a href=&quot;https://bsky.app/profile/duckdb.org&quot;&gt;Bluesky account&lt;/a&gt; and are seeing great discussions happening over there. The account has already exceeded 4 thousand followers!&lt;/p&gt;

&lt;p&gt;Following our ancient two-year tradition, we hosted two DuckCon events, one in &lt;a href=&quot;https://duckdb.org/events/2023/10/06/duckcon4/&quot;&gt;Amsterdam&lt;/a&gt; and another in &lt;a href=&quot;https://duckdb.org/events/2024/08/15/duckcon5/&quot;&gt;Seattle&lt;/a&gt;. We also organized the first &lt;a href=&quot;https://duckdb.org/events/2024/10/17/duckdb-amsterdam-meetup-1/&quot;&gt;DuckDB Amsterdam Meetup&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Early next year, we are going to host &lt;a href=&quot;https://duckdb.org/events/2025/01/31/duckcon6/&quot;&gt;DuckCon in Amsterdam&lt;/a&gt;, which is going to be the first event that we live stream in order to be more accessible to the growing DuckDB users in, e.g., Asia.
But for now, let’s sit around the syntax tree and be merry thinking about what’s to come.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/duckdb-syntax-tree.jpg&quot; alt=&quot;Christmas tree with SQL syntax decorations&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;

</description><link>https://duckdb.org/2024/12/16/github-25k-stars.html</link><guid isPermaLink="false">https://duckdb.org/2024/12/16/github-25k-stars.html</guid><pubDate>Mon, 16 Dec 2024 00:00:00 GMT</pubDate><author>The DuckDB team</author></item><item><title>The DuckDB Avro Extension</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB now supports reading Avro files through the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avro&lt;/code&gt; community extension.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;the-apache-avro-format&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#the-apache-avro-format&quot;&gt;The Apache™ Avro™ Format&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://avro.apache.org/&quot;&gt;Avro&lt;/a&gt; is a binary format for record data. Like many innovations in the data space, Avro was &lt;a href=&quot;https://vimeo.com/7362534&quot;&gt;developed&lt;/a&gt; by &lt;a href=&quot;https://en.wikipedia.org/wiki/Doug_Cutting&quot;&gt;Doug Cutting&lt;/a&gt; as part of the Apache Hadoop project &lt;a href=&quot;https://github.com/apache/hadoop/commit/8296413d4988c08343014c6808a30e9d5e441bfc&quot;&gt;in around 2009&lt;/a&gt;. Avro gets its name – somewhat obscurely – from a defunct &lt;a href=&quot;https://en.wikipedia.org/wiki/Avro&quot;&gt;British aircraft manufacturer&lt;/a&gt;. The company famously built over 7,000 &lt;a href=&quot;https://en.wikipedia.org/wiki/Avro_Lancaster&quot;&gt;Avro Lancaster heavy bombers&lt;/a&gt; under the challenging conditions of World War 2. But we digress.&lt;/p&gt;

&lt;p&gt;The Avro format is yet another attempt to solve the dimensionality reduction problem that occurs when transforming a complex &lt;em&gt;multi-dimensional data structure&lt;/em&gt; like tables (possibly with nested types) to a &lt;em&gt;single-dimensional storage layout&lt;/em&gt; like a flat file, which is just a sequence of bytes. The most fundamental question that arises here is whether to use a columnar or a row-major layout. Avro uses a row-major layout, which differentiates it from its famous cousin, the &lt;a href=&quot;https://parquet.apache.org/&quot;&gt;Apache™ Parquet™&lt;/a&gt; format. There are valid use cases for a row-major format: for example, appending a few rows to a Parquet file is difficult and inefficient because of Parquet&#39;s columnar layout and due to the fact the Parquet metadata is stored &lt;em&gt;at the back&lt;/em&gt; of the file. In a row-major format like Avro with the metadata &lt;em&gt;up top&lt;/em&gt;, we can “just” add those rows to the end of the files and we&#39;re done. This enables Avro to handle appends of a few rows somewhat efficiently.&lt;/p&gt;

&lt;p&gt;Avro-encoded data can appear in several ways, e.g., in &lt;a href=&quot;https://en.wikipedia.org/wiki/Remote_procedure_call&quot;&gt;RPC messages&lt;/a&gt; but also in files. In the following, we focus on files since those survive long-term.&lt;/p&gt;
      &lt;h3 id=&quot;header-block&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#header-block&quot;&gt;Header Block&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Avro “object container” files are encoded using a comparatively simple binary &lt;a href=&quot;https://avro.apache.org/docs/++version++/specification/#object-container-files&quot;&gt;format&lt;/a&gt;: each file starts with a &lt;strong&gt;header block&lt;/strong&gt; that first has the &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_file_signatures&quot;&gt;magic bytes&lt;/a&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Obj1&lt;/code&gt;. Then, a metadata “map” (a list of string-bytearray key-value pairs) follows. The map is only strictly required to contain a single entry for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avro.schema&lt;/code&gt; key. This key contains the Avro file schema encoded as JSON. Here is an example for such a schema:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;namespace&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;example.avro&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;record&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;User&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;fields&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;favorite_number&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;int&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;null&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;favorite_color&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;null&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The Avro schema defines a record structure. Records can contain scalar data fields (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;double&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;string&lt;/code&gt;, etc.) but also more complex types like records (similar to &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/struct.html&quot;&gt;DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt;s&lt;/a&gt;), unions and lists. As a sidenote, it is quite strange that a data format for the definition of record structures would fall back to another format like JSON to describe itself, but such are the oddities of Avro.&lt;/p&gt;
      &lt;h3 id=&quot;data-blocks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#data-blocks&quot;&gt;Data Blocks&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The header concludes with 16 randomly chosen bytes as a “sync marker”. The header is followed by an arbitrary amount of &lt;strong&gt;data blocks&lt;/strong&gt;: each data block starts with a record count, followed by a size and a byte array containing the actual records. Optionally, the bytes can be compressed with deflate (gzip), which will be known from the header metadata.&lt;/p&gt;

&lt;p&gt;The data bytes can only be decoded using the schema. The &lt;a href=&quot;https://avro.apache.org/docs/++version++/specification/#object-container-files&quot;&gt;object file specification&lt;/a&gt; contains the details on how each type is encoded. For example, in the example schema we know each value is a record of three fields. The root-level record will encode its entries in the order they are declared. There are no actual bytes required for this. First we will be reading the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;name&lt;/code&gt; field. Strings consist of a length followed by the string bytes. Like other formats (e.g., Thrift), Avro uses &lt;a href=&quot;https://en.wikipedia.org/wiki/Variable-length_quantity#Zigzag_encoding&quot;&gt;variable-length integers with zigzag encoding&lt;/a&gt; to store lengths and counts and the like. After reading the string, we can proceed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;favorite_number&lt;/code&gt;. This field is a union type (encoded with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[]&lt;/code&gt; syntax). This union can have values of two types, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null&lt;/code&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null&lt;/code&gt; type is a bit odd, it can only be used to encode the fact that a value is missing. To decode the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;favorite_number&lt;/code&gt; fields, we first read an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int&lt;/code&gt; that encodes which choice of the union was used. Afterward, we use the “normal” decoders to read the values (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null&lt;/code&gt;). The same can be done for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;favorite_color&lt;/code&gt;. Each data block again ends with the sync marker. The sync marker can be used to verify that the block was fully written and that there is no garbage in the file.&lt;/p&gt;
      &lt;h2 id=&quot;the-duckdb-avro-community-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#the-duckdb-avro-community-extension&quot;&gt;The DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avro&lt;/code&gt; Community Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We have developed a DuckDB community extension that enables DuckDB to &lt;em&gt;read&lt;/em&gt; &lt;a href=&quot;https://avro.apache.org/&quot;&gt;Apache Avro™&lt;/a&gt; files.&lt;/p&gt;

&lt;p&gt;The extension does not contain Avro &lt;em&gt;write&lt;/em&gt; functionality. This is on purpose, by not providing a writer we hope to decrease the amount of Avro files in the world over time.&lt;/p&gt;
      &lt;h3 id=&quot;installation--loading&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#installation--loading&quot;&gt;Installation &amp;amp; Loading&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Installation is simple through the DuckDB community extension repository, just type&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; avro &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;community&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; avro&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;in a DuckDB instance near you. There is currently no build for Wasm because of dependencies (sigh).&lt;/p&gt;
      &lt;h3 id=&quot;the-read_avro-function&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#the-read_avro-function&quot;&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_avro&lt;/code&gt; Function&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The extension adds a single DuckDB function, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_avro&lt;/code&gt;. This function can be used like so:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_avro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;some_example_file.avro&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This function will expose the contents of the Avro file as a DuckDB table. You can then use any arbitrary SQL constructs to further transform this table.&lt;/p&gt;
      &lt;h3 id=&quot;file-io&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#file-io&quot;&gt;File IO&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_avro&lt;/code&gt; function is integrated into DuckDB&#39;s file system abstraction, meaning you can read Avro files directly from e.g., HTTP or S3 sources. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_avro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;http://blobs.duckdb.org/data/userdata1.avro&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_avro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://my-example-bucket/some_example_file.avro&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;should “just” work.&lt;/p&gt;

&lt;p&gt;You can also &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/pattern_matching.html#globbing&quot;&gt;&lt;em&gt;glob&lt;/em&gt; multiple files&lt;/a&gt; in a single read call or pass a list of files to the functions:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_avro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;some_example_file_*.avro&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_avro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;some_example_file_1.avro&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;some_example_file_2.avro&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If the filenames somehow contain valuable information (as is unfortunately all-too-common), you can pass the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filename&lt;/code&gt; argument to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_avro&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_avro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;some_example_file_*.avro&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will result in an additional column in the result set that contains the actual filename of the Avro file.&lt;/p&gt;
      &lt;h3 id=&quot;schema-conversion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#schema-conversion&quot;&gt;Schema Conversion&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;This extension automatically translates the Avro Schema to the DuckDB schema. &lt;em&gt;All&lt;/em&gt; Avro types can be translated, except for &lt;em&gt;recursive type definitions&lt;/em&gt;, which DuckDB does not support.&lt;/p&gt;

&lt;p&gt;The type mapping is very straightforward except for Avro&#39;s “unique” way of handling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;. Unlike other systems, Avro does not treat &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; as a possible value in a range of e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt; but instead represents &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; as a union of the actual type with a special &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; type. This is different to DuckDB, where any value can be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;. Of course DuckDB also supports &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; types, but this would be quite cumbersome to work with.&lt;/p&gt;

&lt;p&gt;This extension &lt;em&gt;simplifies&lt;/em&gt; the Avro schema where possible: an Avro union of any type and the special null type is simplified to just the non-null type. For example, an Avro record of the union type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[&quot;int&quot;, &quot;null&quot;]&lt;/code&gt; (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;favorite_number&lt;/code&gt; in the &lt;a href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#header-block&quot;&gt;example&lt;/a&gt;) becomes a DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt;, which just happens to be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; sometimes. Similarly, an Avro union that contains only a single type is converted to the type it contains. For example, an Avro record of the union type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[&quot;int&quot;]&lt;/code&gt; also becomes a DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The extension also “flattens” the Avro schema. Avro defines tables as root-level “record” fields, which are the same as DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; fields. For more convenient handling, this extension turns the entries of a single top-level record into top-level columns.&lt;/p&gt;
      &lt;h3 id=&quot;implementation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#implementation&quot;&gt;Implementation&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Internally, this extension uses the “official” &lt;a href=&quot;https://avro.apache.org/docs/++version++/api/c/&quot;&gt;Apache Avro C API&lt;/a&gt;, albeit with some minor patching to allow reading Avro files from memory.&lt;/p&gt;
      &lt;h3 id=&quot;limitations--next-steps&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#limitations--next-steps&quot;&gt;Limitations &amp;amp; Next Steps&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In the following, we disclose the limitations of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avro&lt;/code&gt; DuckDB extension along with our plans to mitigate them in the future:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The extension currently does not make use of &lt;strong&gt;parallelism&lt;/strong&gt; when reading either a single (large) Avro file or when reading a list of files. Adding support for parallelism in the latter case is on the roadmap.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is currently no support for projection or filter &lt;strong&gt;pushdown&lt;/strong&gt;, but this is also planned at a later stage.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is currently no support for the Wasm or the Windows-MinGW builds of DuckDB due to issues with the Avro library dependency (sigh again). We plan to fix this eventually.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As mentioned above, DuckDB cannot express recursive type definitions that Avro has. This is unlikely to ever change.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is no support to allow users to provide a separate Avro schema file. This is unlikely to change, all Avro files we have seen so far had their schema embedded.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There is currently no support for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt; flag that other readers in DuckDB support. This is planned for the future.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/09/duckdb-avro-extension.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avro&lt;/code&gt; community extension for DuckDB enables DuckDB to read Avro files directly as if they were tables. If you have a bunch of Avro files, go ahead and try it out! We&#39;d love to &lt;a href=&quot;https://github.com/hannes/duckdb_avro/issues&quot;&gt;hear from you&lt;/a&gt; if you run into any issues.&lt;/p&gt;

</description><link>https://duckdb.org/2024/12/09/duckdb-avro-extension.html</link><guid isPermaLink="false">https://duckdb.org/2024/12/09/duckdb-avro-extension.html</guid><pubDate>Mon, 09 Dec 2024 00:00:00 GMT</pubDate><author>Hannes Mühleisen</author></item><item><title>DuckDB: Running TPC-H SF100 on Mobile Phones</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB runs on mobile platforms such as iOS and Android, and completes the TPC-H benchmark faster than state-of-the-art research systems on big iron machines 20 years ago.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;A few weeks ago, we set out to perform a series of experiments to answer two simple questions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Can DuckDB complete the TPC-H queries on the SF100 data set when running on a new smartphone?&lt;/li&gt;
  &lt;li&gt;If so, can DuckDB complete a run in less than 400 seconds, i.e., faster than the system in the research paper that originally introduced vectorized query processing?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These questions took us on an interesting quest.
Along the way, we had a lot of fun and learned the difference between a cold run and a &lt;em&gt;really cold&lt;/em&gt; run.
Read on to find out more.&lt;/p&gt;
      &lt;h2 id=&quot;a-song-of-dry-ice-and-fire&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html#a-song-of-dry-ice-and-fire&quot;&gt;A Song of Dry Ice and Fire&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Our first attempt was to use an iPhone, namely an &lt;a href=&quot;https://www.gsmarena.com/apple_iphone_16_pro-13315.php&quot;&gt;iPhone 16 Pro&lt;/a&gt;.
This phone has 8 GB memory and a 6-core CPU with 2 performance cores (running at 4.05 GHz) and 4 efficiency cores (running at 2.42 GHz).&lt;/p&gt;

&lt;p&gt;We implemented the application using the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/swift.html&quot;&gt;DuckDB Swift client&lt;/a&gt; and loaded the benchmark on the phone, all 30 GB of it.
We quickly found that the iPhone can indeed run the workload without any problems – except that it heated up during the workload. This prompted the phone to perform thermal throttling, slowing down the CPU to reduce heat production. Due to this, DuckDB took 615.1 seconds. Not bad but not enough to reach our goal.&lt;/p&gt;

&lt;p&gt;The results got us thinking: what if we improve the cooling of the phone? To this end, we purchased a box of dry ice, which has a temperature below -50 degrees Celsius, and put the phone in the box for the duration of the experiments.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/tpch-mobile/ice-cooled-iphone-1.jpg&quot; alt=&quot;iPhone in a box of dry ice, running TPC-H&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;iPhone in a box of dry ice, running TPC-H. Don&#39;t try this at home.&lt;/div&gt;

&lt;p&gt;This helped a lot: DuckDB completed in 478.2 seconds. This is a more than 20% improvement – but we still didn&#39;t manage to be under 400 seconds.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/tpch-mobile/ice-cooled-iphone-2.jpg&quot; alt=&quot;The phone with icing on it, a few minutes after finishing the benchmark&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;The phone a few minutes after finishing the benchmark. It no longer booted because the battery was too cold!&lt;/div&gt;
      &lt;h2 id=&quot;do-androids-dream-of-electric-ducks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html#do-androids-dream-of-electric-ducks&quot;&gt;Do Androids Dream of Electric Ducks?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In our next experiment, we picked up a &lt;a href=&quot;https://www.gsmarena.com/samsung_galaxy_s24_ultra-12771.php&quot;&gt;Samsung Galaxy S24 Ultra phone&lt;/a&gt;, which runs Android 14. This phone is full of interesting hardware. First, it has an 8-core CPU with 4 different core types (1×3.39 GHz, 3×3.10 GHz, 2×2.90 GHz and 2×2.20 GHz). Second, it has a huge amount of RAM – 12 GB to be precise. Finally, its cooling system includes a &lt;a href=&quot;https://www.sammobile.com/news/galaxy-s24-sustain-performance-bigger-vapor-chamber/&quot;&gt;vapor chamber&lt;/a&gt; for improved heat dissipation.&lt;/p&gt;

&lt;p&gt;We ran DuckDB in the &lt;a href=&quot;https://termux.dev/en/&quot;&gt;Termux terminal emulator&lt;/a&gt;. We compiled DuckDB &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;CLI client&lt;/a&gt; from source following the &lt;a href=&quot;https://duckdb.org/docs/stable/dev/building/android.html&quot;&gt;Android build instructions&lt;/a&gt; and ran the experiments from the command line.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/tpch-mobile/duckdb-termux-android-emulator.png&quot; alt=&quot;Screenshot of DuckDB in Termux, running in the Android emulator&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;DuckDB in Termux, running in the Android emulator&lt;/div&gt;

&lt;p&gt;In the end, it wasn&#39;t even close. The Android phone completed the benchmark in 235.0 seconds, outperforming our baseline by around 40%.&lt;/p&gt;
      &lt;h2 id=&quot;never-was-a-cloudy-day&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html#never-was-a-cloudy-day&quot;&gt;Never Was a Cloudy Day&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The results got us thinking: how do the results stack up among cloud servers? We picked two x86-based cloud instances in AWS EC2 with instance-attached NVMe storage.&lt;/p&gt;

&lt;p&gt;The details of these benchmarks are far less interesting than those of the previous ones. We booted up the instances with Ubuntu 24.04 and ran DuckDB in the command line. We found that an &lt;a href=&quot;https://instances.vantage.sh/aws/ec2/r6id.large&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;r6id.large&lt;/code&gt; instance&lt;/a&gt; (2 vCPUs with 16 GB RAM) completes the queries in 570.8 seconds, which is roughly on-par with an air-cooled iPhone. However, an &lt;a href=&quot;https://instances.vantage.sh/aws/ec2/r6id.xlarge&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;r6id.xlarge&lt;/code&gt;&lt;/a&gt; (4 vCPUs with 32 GB RAM) completes the benchmark in 166.2 seconds, faster than any result we achieved on phones.&lt;/p&gt;
      &lt;h2 id=&quot;summary-of-duckdb-results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html#summary-of-duckdb-results&quot;&gt;Summary of DuckDB Results&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The table contains a summary of the DuckDB benchmark results.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Setup&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;CPU cores&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Memory&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Runtime&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;iPhone 16 Pro (air-cooled)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;615.1 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;iPhone 16 Pro (dry ice-cooled)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;478.2 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Samsung Galaxy S24 Ultra&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;235.0 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AWS EC2 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;r6id.large&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;570.8 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AWS EC2 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;r6id.xlarge&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;32 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;166.2 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;historical-context&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html#historical-context&quot;&gt;Historical Context&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;So why did we set out to run these experiments in the first place?&lt;/p&gt;

&lt;p&gt;Just a few weeks ago, &lt;a href=&quot;https://cwi.nl/&quot;&gt;CWI&lt;/a&gt;, the birthplace of DuckDB, held a ceremony for the &lt;a href=&quot;https://www.cwi.nl/en/events/dijkstra-awards/cwi-lectures-dijkstra-fellowship/&quot;&gt;Dijkstra Fellowship&lt;/a&gt;.
The fellowship was awarded to Marcin Żukowski for his pioneering role in the development of database management systems and his successful entrepreneurial career that resulted in systems such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Actian_Vector&quot;&gt;VectorWise&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Snowflake_Inc.&quot;&gt;Snowflake&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A lot of ideas that originate in Marcin&#39;s research are used in DuckDB. Most importantly, &lt;em&gt;vectorized query processing&lt;/em&gt; allows DuckDB to be both fast and portable at the same time.
With his co-authors Peter Boncz and Niels Nes, he first described this paradigm in the CIDR 2005 paper &lt;a href=&quot;https://www.cidrdb.org/cidr2005/papers/P19.pdf&quot;&gt;“MonetDB/X100: Hyper-Pipelining Query Execution”&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The terms &lt;em&gt;vectorization,&lt;/em&gt; &lt;em&gt;hyper-pipelining,&lt;/em&gt; and &lt;em&gt;superscalar&lt;/em&gt; refer to the same idea: processing data in slices, which turns out to be a good compromise between row-at-a-time or column-at-a-time. DuckDB&#39;s query engine uses the same principle.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This paper was published in January 2005, so it&#39;s safe to assume that it was finalized in late 2004 – almost exactly 20 years ago!&lt;/p&gt;

&lt;p&gt;If we read the paper, we learn that the experiments were carried out on an HP workstation equipped with 12 GB of memory (the same amount as the Samsung phone has today!).
It also had an Itanium CPU and looked like this:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/tpch-mobile/hp-itanium-workstation.jpg&quot; alt=&quot;The Itanium2 workstation used in original the experiments&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;The Itanium2 workstation used in original the experiments (source: &lt;a href=&quot;https://commons.wikimedia.org/wiki/File:HP-HP9000-ZX6000-Itanium2-Workstation_11.jpg&quot;&gt;Wikimedia&lt;/a&gt;)&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Upon its release in 2001, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Itanium&quot;&gt;Itanium&lt;/a&gt; was aimed at the high-end market with the goal of eventually replacing the then-dominant x86 architecture with a new instruction set that focused heavily on &lt;a href=&quot;https://en.wikipedia.org/wiki/Single_instruction,_multiple_data&quot;&gt;SIMD (single instruction, multiple data)&lt;/a&gt;. While this ambition did not work out, the Itanium was the state-of-the-art architecture of its day. Due to the focus on the server market, the Itanium CPUs had a large amount of cache: the &lt;a href=&quot;https://www.intel.com/content/www/us/en/products/sku/27982/intel-itanium-processor-1-30-ghz-3m-cache-400-mhz-fsb/specifications.html&quot;&gt;1.3 GHz Itanium2 model used in the experiments&lt;/a&gt; had 3 MB of L2 cache, while Pentium 4 CPUs released around that time only had 0.5–1 MB.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The paper provides a detailed breakdown of the runtimes:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/tpch-mobile/cidr2005-monetdb-x100-results.png&quot; alt=&quot;Benchmark results from the CIDR 2005 paper “MonetDB/X100: Hyper-Pipelining Query Execution”&quot; width=&quot;450&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;Benchmark results from the paper “MonetDB/X100: Hyper-Pipelining Query Execution”&lt;/div&gt;

&lt;p&gt;The total runtime of the TPC-H SF100 queries was 407.9 seconds – hence our baseline for the experiments.
Here is a video of Hannes presenting the results at the event:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/H1N2Jr34jwU?si=7wYychjmxpRWPqcm&amp;amp;start=1617&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&quot; referrerpolicy=&quot;no-referrer&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;And here are all results visualized on a plot:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/tpch-mobile/tpch-mobile-experiment-runtimes.svg&quot; alt=&quot;Plot with the TPC-H SF100 experiment results for MonetDB/X100 and DuckDB&quot; width=&quot;750&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;TPC-H SF100 total query runtimes for MonetDB/X100 and DuckDB&lt;/div&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;It was a long journey from the original vectorized execution paper to running an analytical database on a phone.
Many key innovations happened that allowed these results, and the big improvement in hardware is just one of them.
Another crucial component is that compiler optimizations became a lot more sophisticated.
Thanks to this, while the MonetDB/X100 system needed to use explicit SIMD, DuckDB can rely on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Automatic_vectorization&quot;&gt;auto-vectorization&lt;/a&gt; of our (carefully constructed) loops.&lt;/p&gt;

&lt;p&gt;All that&#39;s left is to answer questions that we posed at the beginning of our journey.
Yes, DuckDB can run TPC-H SF100 on a mobile phone.
And yes, in some cases it can even outperform a research prototype running on a high-end machine of 2004 – on a modern smartphone that fits in your pocket.&lt;/p&gt;

&lt;p&gt;And with newer hardware, smarter compilers and yet-to-be-discovered database optimizations, future versions are only going to be faster.&lt;/p&gt;

</description><link>https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html</link><guid isPermaLink="false">https://duckdb.org/2024/12/06/duckdb-tpch-sf100-on-mobile.html</guid><pubDate>Fri, 06 Dec 2024 00:00:00 GMT</pubDate><author>Gabor Szarnyas, Laurens Kuiper, Hannes Mühleisen</author></item><item><title>CSV Files: Dethroning Parquet as the Ultimate Storage File Format — or Not?</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Data analytics primarily uses two types of storage format files: human-readable text files like CSV and performance-driven binary files like Parquet. This blog post compares these two formats in an ultimate showdown of performance and flexibility, where there can be only one winner.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;file-formats&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#file-formats&quot;&gt;File Formats&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;csv-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#csv-files&quot;&gt;CSV Files&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Data is most &lt;a href=&quot;https://www.vldb.org/pvldb/vol17/p3694-saxena.pdf&quot;&gt;commonly stored&lt;/a&gt; in human-readable file formats, like JSON or CSV files. These file formats are easy to operate on, since anyone with a text editor can simply open, alter, and understand them.&lt;/p&gt;

&lt;p&gt;For many years, CSV files have had a bad reputation for being slow and cumbersome to work with. In practice, if you want to operate on a CSV file using your favorite database system, you must follow this recipe:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Manually discover its schema by opening the file in a text editor.&lt;/li&gt;
  &lt;li&gt;Create a table with the given schema.&lt;/li&gt;
  &lt;li&gt;Manually figure out the dialect of the file (e.g., which character is used for a quote?)&lt;/li&gt;
  &lt;li&gt;Load the file into the table using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; statement and with the dialect set.&lt;/li&gt;
  &lt;li&gt;Start querying it.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Not only is this process tedious, but parallelizing a CSV file reader is &lt;a href=&quot;https://www.microsoft.com/en-us/research/uploads/prod/2019/04/chunker-sigmod19.pdf&quot;&gt;far from trivial&lt;/a&gt;. This means most systems either process it single-threaded or use a two-pass approach.&lt;/p&gt;

&lt;p&gt;Additionally, &lt;a href=&quot;https://youtu.be/YrqSp8m7fmk?si=v5rmFWGJtpiU5_PX&amp;amp;t=624&quot;&gt;CSV files are wild&lt;/a&gt;: although &lt;a href=&quot;https://www.ietf.org/rfc/rfc4180.txt&quot;&gt;RFC-4180&lt;/a&gt; exists as a CSV standard, it is &lt;a href=&quot;https://aic.ai.wu.ac.at/~polleres/publications/mitl-etal-2016OBD.pdf&quot;&gt;commonly ignored&lt;/a&gt;. Systems must therefore be sufficiently robust to handle these files as if they come straight from the wild west.&lt;/p&gt;

&lt;p&gt;Last but not least, CSV files are wasteful: data is always laid out as strings. For example, numeric values like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1000000000&lt;/code&gt; take 10 bytes instead of 4 bytes if stored as an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int32&lt;/code&gt;. Additionally, since the data layout is row-wise, opportunities to apply &lt;a href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html&quot;&gt;lightweight columnar compression&lt;/a&gt; are lost.&lt;/p&gt;
      &lt;h3 id=&quot;parquet-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#parquet-files&quot;&gt;Parquet Files&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Due to these shortcomings, performance-driven file formats like Parquet have gained significant popularity in recent years. Parquet files cannot be opened by general text editors, cannot be easily edited, and have a rigid schema. However, they store data in columns, apply various compression techniques, partition the data into row groups, maintain statistics about these row groups, and define their schema directly in the file.&lt;/p&gt;

&lt;p&gt;These features make Parquet a monolith of a file format — highly inflexible but efficient and fast. It is easy to read data from a Parquet file since the schema is well-defined. Parallelizing a scanner is straightforward, as each thread can independently process a row group. Filter pushdown is also simple to implement, as each row group contains statistical metadata, and the file sizes are very small.&lt;/p&gt;

&lt;p&gt;The conclusion should be simple: if you have small files and need flexibility, CSV files are fine. However, for data analysis, one should pivot to Parquet files, right? Well, this pivot may not be a hard requirement anymore – read on to find out why!&lt;/p&gt;
      &lt;h2 id=&quot;reading-csv-files-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#reading-csv-files-in-duckdb&quot;&gt;Reading CSV Files in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;For the past few releases, DuckDB has doubled down on delivering not only an easy-to-use CSV scanner but also an extremely performant one. This scanner features its own custom &lt;a href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html&quot;&gt;CSV sniffer&lt;/a&gt;, parallelization algorithm, buffer manager, casting mechanisms, and state machine-based parser.&lt;/p&gt;

&lt;p&gt;For usability, the previous paradigm of manual schema discovery and table creation has been changed. Instead, DuckDB now utilizes a CSV Sniffer, similar to those found in dataframe libraries like Pandas.
This allows for querying CSV files as easily as:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;path/to/file.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Or tables to be created from CSV files, without any prior schema definition with:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;path/to/file.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Furthermore, the reader became one of the fastest CSV readers in analytical systems, as can be seen by the load times of the &lt;a href=&quot;https://github.com/ClickHouse/ClickBench/commit/0aba4247ce227b3058d22846ca39826d27262fe0&quot;&gt;latest iteration&lt;/a&gt; of &lt;a href=&quot;https://benchmark.clickhouse.com/#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&quot;&gt;ClickBench&lt;/a&gt;. In this benchmark, the data is loaded from an &lt;a href=&quot;https://datasets.clickhouse.com/hits_compatible/hits.csv.gz&quot;&gt;82 GB uncompressed CSV file&lt;/a&gt; into a database table.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/csv-vs-parquet-clickbench.png&quot; alt=&quot;Image showing the ClickBench result 2024-12-05&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;ClickBench CSV loading times (2024-12-05)&lt;/div&gt;
      &lt;h2 id=&quot;comparing-csv-and-parquet&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#comparing-csv-and-parquet&quot;&gt;Comparing CSV and Parquet&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;With the large boost in usability and performance for the CSV reader, one might ask: what is the actual difference in performance when loading a CSV file compared to a Parquet file into a table? Additionally, how do these formats differ when running queries directly on them?&lt;/p&gt;

&lt;p&gt;To find out, we will run a few examples using both CSV and Parquet files containing TPC-H data to shed light on their differences. All scripts used to generate the benchmarks of this blogpost can be found in a &lt;a href=&quot;https://github.com/pdet/csv_vs_parquet&quot;&gt;repository&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;usability&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#usability&quot;&gt;Usability&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In terms of usability, scanning CSV files and Parquet files can differ significantly.&lt;/p&gt;

&lt;p&gt;In simple cases, where all options are correctly detected by DuckDB, running queries on either CSV or Parquet files can be done directly.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;path/to/file.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;path/to/file.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Things can differ drastically for wild, rule-breaking &lt;a href=&quot;https://reddead.fandom.com/wiki/Arthur_Morgan&quot;&gt;Arthur Morgan&lt;/a&gt;-like CSV files. This is evident from the number of parameters that can be set for each scanner. The &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;Parquet&lt;/a&gt; scanner has a total of six parameters that can alter how the file is read. For the majority of cases, the user will never need to manually adjust any of them.&lt;/p&gt;

&lt;p&gt;The CSV reader, on the other hand, depends on the sniffer being able to automatically detect many different configuration options. For example: What is the delimiter? How many rows should it skip from the top of the file? Are there any comments? And so on. This results in over &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html&quot;&gt;30 configuration options&lt;/a&gt; that the user might have to manually adjust to properly parse their CSV file. Again, this number of options is necessary due to the lack of a widely adopted standard. However, in most scenarios, users can rely on the sniffer or, at most, change one or two options.&lt;/p&gt;

&lt;p&gt;The CSV reader also has an extensive error-handling system and will always provide suggestions for options to review if something goes wrong.&lt;/p&gt;

&lt;p&gt;To give you an example of how the DuckDB error-reporting system works, consider the following CSV file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;Clint Eastwood;94
Samuel L. Jackson
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this file, the second line is missing the value for the second column.&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Invalid Input Error: CSV Error on Line: 2
Original Line: Samuel L. Jackson
Expected Number of Columns: 2 Found: 1
Possible fixes:
* Enable null padding (null_padding=true) to replace missing values with NULL
* Enable ignore errors (ignore_errors=true) to skip this row

  file = western_actors.csv
  delimiter = , (Auto-Detected)
  quote = &quot; (Auto-Detected)
  escape = &quot; (Auto-Detected)
  new_line = \n (Auto-Detected)
  header = false (Auto-Detected)
  skip_rows = 0 (Auto-Detected)
  comment = \0 (Auto-Detected)
  date_format =  (Auto-Detected)
  timestamp_format =  (Auto-Detected)
  null_padding = 0
  sample_size = 20480
  ignore_errors = false
  all_varchar = 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB provides detailed information about any errors encountered. It highlights the line of the CSV file where the issue occurred, presents the original line, and suggests possible fixes for the error, such as ignoring the problematic line or filling missing values with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;. It also displays the full configuration used to scan the file and indicates whether the options were auto-detected or manually set.&lt;/p&gt;

&lt;p&gt;The bottom line here is that, even with the advancements in CSV usage, the strictness of Parquet files make them much easier to operate on.&lt;/p&gt;

&lt;p&gt;Of course, if you need to open your file in a text editor or Excel, you will need to have your data in CSV format. Note that Parquet files do have some visualizers, like &lt;a href=&quot;https://www.tadviewer.com/&quot;&gt;TAD&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;performance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#performance&quot;&gt;Performance&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;There are primarily two ways to operate on files using DuckDB:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;The user creates a DuckDB table from the file and uses the table in future queries. This is a loading process, commonly used if you want to store your data as DuckDB tables or if you will run many queries on them. Also, note that these are the only possible scenarios for most database systems (e.g., Oracle, SQL Server, PostgreSQL, SQLite, …).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;One might run a query directly on the file scanner without creating a table. This is useful for scenarios where the user has limitations on memory and disk space, or if queries on these files are only executed once. Note that this scenario is typically not supported by database systems but is common for dataframe libraries (e.g., Pandas).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To fairly compare the scanners, we provide the table schemas upfront, ensuring that the scanners produce the exact same data types. We also set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;preserve_insertion_order = false&lt;/code&gt;, as this can impact the parallelization of both scanners, and set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_temp_directory_size = &#39;0GB&#39;&lt;/code&gt; to ensure no data is spilled to disk, with all experiments running fully in memory.&lt;/p&gt;

&lt;p&gt;We use the default writers for both CSV files and Parquet (with the default Snappy compression), and also run a variation of Parquet with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CODEC &#39;zstd&#39;, COMPRESSION_LEVEL 1&lt;/code&gt;, as this can speed up querying/loading times.&lt;/p&gt;

&lt;p&gt;For all experiments, we use an Apple M1 Max, with 64 GB RAM. We use TPC-H scale factor 20 and report the median times from 5 runs.&lt;/p&gt;
      &lt;h4 id=&quot;creating-tables&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#creating-tables&quot;&gt;Creating Tables&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;For creating the table, we focus on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; table.&lt;/p&gt;

&lt;p&gt;After defining the schema, both files can be loaded with a simple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; statement, with no additional parameters set. Note that even with the schema defined, the CSV sniffer will still be executed to determine the dialect (e.g., quote character, delimiter character, etc.) and match types and names.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Size (GB)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CSV&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.76&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15.95&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet Snappy&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.21&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.78&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet ZSTD&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.52&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.22&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that the Parquet files are definitely smaller. About 5× smaller than the CSV file, but the performance difference is not drastic.&lt;/p&gt;

&lt;p&gt;The CSV scanner is only about 2× slower than the Parquet scanner. It&#39;s also important to note that some of the cost associated with these operations (~1-2 seconds) is related to the insertion into the DuckDB table, not the scanner itself.&lt;/p&gt;

&lt;p&gt;However, it is still important to consider this in the comparison. In practice, the raw CSV scanner is about 3× slower than the Parquet scanner, which is a considerable difference but much smaller than one might initially think.&lt;/p&gt;
      &lt;h4 id=&quot;directly-querying-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#directly-querying-files&quot;&gt;Directly Querying Files&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;We will run two different TPC-H queries on our files.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Query 01.&lt;/strong&gt; First, we run TPC-H Q01. This query operates solely on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; table, performing an aggregation and grouping with a filter. It filters on one column and projects 7 out of the 16 columns from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Therefore, this query will stress the filter pushdown, which is &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html#partial-reading&quot;&gt;supported by the Parquet reader&lt;/a&gt; but not the CSV reader, and the projection pushdown, which is supported by both.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_base_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_disc_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_tax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_charge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_order&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;1996-09-02&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CSV&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.72&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet Snappy&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.88&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet ZSTD&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.95&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that running this query directly on our file presents a much larger performance gap of approximately 7x compared to simply loading the data into the table. In the Parquet file, we can directly skip row groups that do not match our filter &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_shipdate &amp;lt;= CAST(&#39;1996-09-02&#39; AS date)&lt;/code&gt;. Note that this filter, eliminates approximately 30% of the data. Not only that, but we can also skip individual rows that do not match the filter. Additionally, since the Parquet format is column-oriented, we can completely skip any computation on columns that are not projected.&lt;/p&gt;

&lt;p&gt;Unfortunately, the CSV reader does not benefit from these filters. Since it lacks partitions, it can&#39;t efficiently skip parts of the data. Theoretically, a CSV scanner could skip the computation of rows that do not match a filter, but this is not currently implemented.&lt;/p&gt;

&lt;p&gt;Furthermore, the CSV projection skips much of the computation on a column (e.g., it does not cast or copy the value), but it still must parse the value to be able to skip it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Query 21.&lt;/strong&gt; Query 21 is a query that not only heavily depends on filter and projection pushdown but also relies significantly on join ordering based on statistics to achieve good performance. In this query, four different files are used and joined together.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numwait&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;supplier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nation&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s_suppkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_orderkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_orderstatus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;F&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_receiptdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_commitdate&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l3&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_receiptdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_commitdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_nationkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_nationkey&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;SAUDI ARABIA&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s_name&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;numwait&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s_name&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CSV&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.95&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet Snappy&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.08&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet ZSTD&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.12&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that this query now has a performance difference of approximately 10×. We observe an effect similar to Query 01, but now we also incur the additional cost of performing join ordering with no statistical information for the CSV file.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There is no doubt that the performance of CSV file scanning has drastically increased over the years. If we were to take a guess at the performance difference in table creation a few years ago, the answer would probably have been at least one order of magnitude.&lt;/p&gt;

&lt;p&gt;This is excellent, as it allows data to be exported from legacy systems that do not support performance-driven file formats.&lt;/p&gt;

&lt;p&gt;But oh boy, don&#39;t let super-convenient and fast CSV readers fool you. Your data is still best kept in self-describing, column-binary compressed formats like Parquet — or the DuckDB file format, of course! They are much smaller and more consistent. Additionally, running queries directly on Parquet files is much more beneficial due to efficient projection/filter pushdown and available statistics.&lt;/p&gt;

&lt;p&gt;One thing to note is that there exists an extensive body of work on &lt;a href=&quot;https://ir.cwi.nl/pub/19931/19931B.pdf&quot;&gt;indexing CSV files&lt;/a&gt; (i.e., building statistics in a way) to speed up future queries and enable filter pushdown. However, DuckDB does not perform these operations yet.&lt;/p&gt;

&lt;p&gt;Bottom line: Parquet is still the undisputed champion for most scenarios, but we will continue working on closing this gap wherever possible.&lt;/p&gt;

</description><link>https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html</link><guid isPermaLink="false">https://duckdb.org/2024/12/05/csv-files-dethroning-parquet-or-not.html</guid><pubDate>Thu, 05 Dec 2024 00:00:00 GMT</pubDate><author>Pedro Holanda</author></item><item><title>DuckDB Tricks – Part 3</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: In this new installment of the DuckDB Tricks series, we present features for convenient handling of tables and performance optimization tips for Parquet and CSV files.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;overview&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#overview&quot;&gt;Overview&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We continue our DuckDB &lt;a href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html&quot;&gt;Tricks&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html&quot;&gt;series&lt;/a&gt; with a third part,
where we showcase &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;friendly SQL features&lt;/a&gt; and performance optimizations.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Operation&lt;/th&gt;
      &lt;th&gt;SQL instructions&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#excluding-columns-from-a-table&quot;&gt;Excluding columns from a table&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt;&lt;/code&gt;/&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...)&lt;/span&gt;&lt;/code&gt;, &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SIMILAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#renaming-columns-with-pattern-matching&quot;&gt;Renaming columns with pattern matching&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#loading-with-globbing&quot;&gt;Loading with globbing&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;*.csv&#39;&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#reordering-parquet-files&quot;&gt;Reordering Parquet files&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#hive-partitioning&quot;&gt;Hive partitioning&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;hive_partitioning&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;dataset&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#dataset&quot;&gt;Dataset&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We&#39;ll use a subset of the &lt;a href=&quot;https://www.rijdendetreinen.nl/en/open-data/train-archive&quot;&gt;Dutch railway services dataset&lt;/a&gt;, which was already featured in a &lt;a href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html&quot;&gt;blog post earlier this year&lt;/a&gt;.
This time, we&#39;ll use the CSV files between January and October 2024: &lt;a href=&quot;https://blobs.duckdb.org/data/services-2024-01-to-10.zip&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services-2024-01-to-10.zip&lt;/code&gt;&lt;/a&gt;.
If you would like to follow the examples, download and decompress the data set before proceeding.&lt;/p&gt;
      &lt;h2 id=&quot;excluding-columns-from-a-table&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#excluding-columns-from-a-table&quot;&gt;Excluding Columns from a Table&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;First, let&#39;s look at the data in the CSV files.
We pick the CSV file for August and inspect it with the &lt;a href=&quot;https://duckdb.org/docs/stable/guides/meta/describe.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESCRIBE&lt;/code&gt; statement&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DESCRIBE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-08.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result is a table with the column names and the column types.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;column_name&lt;/th&gt;
      &lt;th&gt;column_type&lt;/th&gt;
      &lt;th&gt;null&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;default&lt;/th&gt;
      &lt;th&gt;extra&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:RDT-ID&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Date&lt;/td&gt;
      &lt;td&gt;DATE&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Type&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Company&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Train number&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now, let&#39;s use &lt;a href=&quot;https://duckdb.org/docs/stable/guides/meta/summarize.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt;&lt;/a&gt; to inspect some statistics about the columns.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SUMMARIZE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-08.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt;, we get 10 statistics about our data (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;approx_unique&lt;/code&gt;, etc.).
If we want to remove a few of them the result, we can use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#exclude-modifier&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; modifier&lt;/a&gt;.
For example, to exclude &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt; and the quantiles &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q25&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q50&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q75&lt;/code&gt;, we can use issue the following command:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUMMARIZE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-08.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, we can use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#columns&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt;&lt;/a&gt; expression with the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/pattern_matching.html#similar-to&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NOT SIMILAR TO&lt;/code&gt; operator&lt;/a&gt;.
This works with a regular expression:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SIMILAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;min|max|q.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SUMMARIZE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-08.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In both cases, the resulting table will contain the 5 remaining statistical columns:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;column_name&lt;/th&gt;
      &lt;th&gt;column_type&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;approx_unique&lt;/th&gt;
      &lt;th&gt;avg&lt;/th&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;null_percentage&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:RDT-ID&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;259022&lt;/td&gt;
      &lt;td&gt;14200071.03736433&lt;/td&gt;
      &lt;td&gt;59022.836209662266&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1846574&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Date&lt;/td&gt;
      &lt;td&gt;DATE&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;32&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1846574&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Type&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1846574&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Company&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1846574&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service:Train number&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17264&lt;/td&gt;
      &lt;td&gt;57781.81688196628&lt;/td&gt;
      &lt;td&gt;186353.76365744913&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1846574&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;renaming-columns-with-pattern-matching&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#renaming-columns-with-pattern-matching&quot;&gt;Renaming Columns with Pattern Matching&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Upon inspecting the columns, we see that their names contain spaces and semicolons (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:&lt;/code&gt;).
These special characters makes writing queries a bit tedious as they necessitate quoting column names with double quotes.
For example, we have to write &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;Service:Company&quot;&lt;/code&gt; in the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Service:Company&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-08.csv&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&#39;s see how we can rename the columns using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression.
To replace the special characters (up to 2), we can write the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(.*?)_*$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(\w*)\W*(\w*)\W*(\w*)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1_\2_\3&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-08.csv&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESCRIBE&lt;/code&gt; at the beginning of the query and we can see the renamed columns:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;column_name&lt;/th&gt;
      &lt;th&gt;column_type&lt;/th&gt;
      &lt;th&gt;null&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;default&lt;/th&gt;
      &lt;th&gt;extra&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Service_RDT_ID&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service_Date&lt;/td&gt;
      &lt;td&gt;DATE&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service_Type&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service_Company&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Service_Train_number&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Let&#39;s break down the query starting with the first &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(\w*)\W*(\w*)\W*(\w*)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1_\2_\3&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we use regular expression with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(\w*)&lt;/code&gt; groups that capture 0…n word characters (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[0-9A-Za-z_]&lt;/code&gt;).
Meanwhile, the expression &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\W*&lt;/code&gt; captures 0…n non-word characters (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[^0-9A-Za-z_]&lt;/code&gt;).
In the alias part we refer to the capture group &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\i&lt;/code&gt; so &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;\1_\2_\3&quot;&lt;/code&gt; means that we only keep the word characters and separate their groups with underscores (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_&lt;/code&gt;).
However, because some column names contain words separated by a space, while others don&#39;t, after this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement we get column names with a trailing underscore (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_&lt;/code&gt;), 
e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Service_Date_&lt;/code&gt;.
Thus, we need an additional processing step:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(.*?)_*$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we capture the group of characters without the trailing underscore(s) and rename the columns to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\1&lt;/code&gt;, which removes the trailing underscores.&lt;/p&gt;

&lt;p&gt;To make writing queries even more convenient, we can rely on the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/keywords_and_identifiers.html#case-sensitivity-of-identifiers&quot;&gt;case-insensitivity of identifiers&lt;/a&gt; to query the column names in lowercase:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service_company&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(.*?)_*$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(\w*)\W*(\w*)\W*(\w*)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1_\2_\3&quot;&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-08.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service_company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Service_Company&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Arriva&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Blauwnet&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Breng&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Eu Sleeper&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;The returned column name preserves its original cases even though we used lowercase letters in the query.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;loading-with-globbing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#loading-with-globbing&quot;&gt;Loading with Globbing&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we can simplify the column names, let&#39;s ingest all 3 months of data to a table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(.*?)_*$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1&quot;&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;(\w*)\W*(\w*)\W*(\w*)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;\1_\2_\3&quot;&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2024-*.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the inner &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause, we use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/pattern_matching.html#globbing&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt; glob syntax&lt;/a&gt; to match all files.
DuckDB automatically detects that all files have the same schema and unions them together.
We have now a table with all the data from January to October, amounting to almost 20 million rows.&lt;/p&gt;
      &lt;h2 id=&quot;reordering-parquet-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#reordering-parquet-files&quot;&gt;Reordering Parquet Files&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Suppose we want to analyze the average delay of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Intercity_Direct&quot;&gt;Intercity Direct trains&lt;/a&gt; operated by the &lt;a href=&quot;https://en.wikipedia.org/wiki/Nederlandse_Spoorwegen&quot;&gt;Nederlandse Spoorwegen (NS)&lt;/a&gt;, measured at the final destination of the train service.
While we can run this analysis directly on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.csv&lt;/code&gt; files, the lack of metadata (such as schema and min-max indexes) will limit the performance.
Let&#39;s measure this in the CLI client by turning on the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/dot_commands.html&quot;&gt;timer&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Stop:Arrival delay&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-*.csv&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Service:Company&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NS&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Service:Type&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Intercity direct&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Stop:Departure time&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query takes about 1.8 seconds. Now, if we run the same query on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services&lt;/code&gt; table that&#39;s already loaded to DuckDB, the query is much faster:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Stop_Arrival_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Company&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NS&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Intercity direct&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stop_Departure_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The run time is about 35 milliseconds.&lt;/p&gt;

&lt;p&gt;If we would like to use an external binary file format, we can also export the database to a single Parquet file:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;EXPORT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;railway&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can then directly query it as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Stop_Arrival_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;railway/services.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Company&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NS&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Intercity direct&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stop_Departure_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The runtime for this format is about 90 milliseconds – somewhat slower than DuckDB&#39;s own file format but about 20× faster than reading the raw CSV files.&lt;/p&gt;

&lt;p&gt;If we have a priori knowledge of the fields a query filters on, we can reorder the Parquet file to improve query performance.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;railway/services.parquet&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;railway/services.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If we run the query again, it&#39;s noticeably faster, taking only 35 milliseconds.
This is thanks to &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html#partial-reading&quot;&gt;partial reading&lt;/a&gt;, which uses the zonemaps (min-max indexes) to limit the amount of data that has to be scanned.
Reordering the file allows DuckDB to skip more data, leading to faster query times.&lt;/p&gt;
      &lt;h2 id=&quot;hive-partitioning&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#hive-partitioning&quot;&gt;Hive Partitioning&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To speed up queries even further, we can use &lt;a href=&quot;https://duckdb.org/docs/stable/data/partitioning/hive_partitioning.html&quot;&gt;Hive partitioning&lt;/a&gt; to create a directory layout on disk that matches the filtering used in the queries.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-parquet-hive&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARTITION_BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Service_Company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&#39;s peek into the directory from DuckDB&#39;s CLI using the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/dot_commands.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.sh&lt;/code&gt; dot command&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;services-parquet-hive
├── Service_Company=Arriva
│&amp;nbsp;&amp;nbsp; ├── Service_Type=Extra%20trein
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── data_0.parquet
│&amp;nbsp;&amp;nbsp; ├── Service_Type=Nachttrein
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── data_0.parquet
│&amp;nbsp;&amp;nbsp; ├── Service_Type=Snelbus%20ipv%20trein
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── data_0.parquet
│&amp;nbsp;&amp;nbsp; ├── Service_Type=Sneltrein
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── data_0.parquet
│&amp;nbsp;&amp;nbsp; ├── Service_Type=Stopbus%20ipv%20trein
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── data_0.parquet
│&amp;nbsp;&amp;nbsp; ├── Service_Type=Stoptrein
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── data_0.parquet
│&amp;nbsp;&amp;nbsp; └── Service_Type=Taxibus%20ipv%20trein
│&amp;nbsp;&amp;nbsp;     └── data_0.parquet
├── Service_Company=Blauwnet
│&amp;nbsp;&amp;nbsp; ├── Service_Type=Intercity
│&amp;nbsp;&amp;nbsp; │&amp;nbsp;&amp;nbsp; └── data_0.parquet
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can now run the query on the Hive partitioned data set by passing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hive_partitioning = true&lt;/code&gt; flag:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Stop_Arrival_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
         &lt;span class=&quot;s1&quot;&gt;&#39;services-parquet-hive/**/*.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;k&quot;&gt;hive_partitioning&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Company&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NS&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Intercity direct&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stop_Departure_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query now takes about 20 milliseconds as DuckDB can use the directory structure to limit the reads even further.
And the neat thing about Hive partitioning is that it even works with CSV files!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-csv-hive&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARTITION_BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Service_Company&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Stop_Arrival_delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;services-csv-hive/**/*.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;hive_partitioning&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Company&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NS&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Service_Type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Intercity direct&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stop_Departure_time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While the CSV files lack any sort of metadata, DuckDB can rely on the directory structure to limit the scans to the relevant directories,
resulting in execution times around 150 milliseconds, more than 10× faster compared to reading all CSV files.&lt;/p&gt;

&lt;p&gt;If all these formats and results got your head spinning, no worries.
We got your covered with this summary table:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Format&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Query runtime (ms)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB file format&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;35&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CSV (vanilla)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1800&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CSV (Hive-partitioned)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;150&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet (vanilla)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet (reordered)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;35&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet (Hive-partitioned)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Oh, and we forgot to report the result. The average delay of Intercity Direct trains is 3 minutes!&lt;/p&gt;
      &lt;h2 id=&quot;closing-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html#closing-thoughts&quot;&gt;Closing Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;That&#39;s it for part three of DuckDB tricks. If you have a trick that would like to share, please share it with the DuckDB team on our social media sites, or submit it to the &lt;a href=&quot;https://duckdbsnippets.com/&quot;&gt;DuckDB Snippets site&lt;/a&gt; (maintained by our friends at MotherDuck).&lt;/p&gt;

</description><link>https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html</link><guid isPermaLink="false">https://duckdb.org/2024/11/29/duckdb-tricks-part-3.html</guid><pubDate>Fri, 29 Nov 2024 00:00:00 GMT</pubDate><author>Andra Ionescu and Gabor Szarnyas</author></item><item><title>Runtime-Extensible SQL Parsers Using PEG</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Despite their central role in processing queries, parsers have not received any noticeable attention in the data systems space. State-of-the art systems are content with ancient old parser generators. These generators create monolithic, inflexible and unforgiving parsers that hinder innovation in query languages and frustrate users. Instead, parsers should be rewritten using modern abstractions like Parser Expression Grammars (PEG), which allow dynamic changes to the accepted query syntax and better error recovery. In this post, we discuss how parsers could be re-designed using PEG, and validate our recommendations using experiments for both effectiveness and efficiency.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
  &lt;p&gt;This post is a shortened version of our peer-reviewed research paper &quot;Runtime-Extensible Parsers&quot; that was accepted for publication and presentation at the &lt;a href=&quot;https://www.cidrdb.org/cidr2025/index.html&quot;&gt;2025 Conference on Innovative Data Systems Research&lt;/a&gt; (CIDR) that is going to be held in Amsterdam between January 19 and 22, 2025. You can &lt;a href=&quot;https://duckdb.org/pdf/CIDR2025-muehleisen-raasveldt-extensible-parsers.pdf&quot;&gt;read the full paper&lt;/a&gt; if you prefer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The parser is the DBMS component that is responsible for turning a query in string format into an internal representation which is usually tree-shaped. The parser defines which queries are going to be accepted at all. Every single SQL query starts its journey in a parser. Despite its prominent position in the stack, very little research has been published on parsing queries for data management systems. There seems to have been very little movement on the topic in the past decades and their implementations are largely stuck in sixty-year-old abstractions and technologies.&lt;/p&gt;

&lt;p&gt;The constant growth of the SQL specification with niche features (e.g., support for graph queries in SQL/PGQ or XML support) as well as the desire to support alternative query notations like dplyr, &lt;a href=&quot;https://cloud.google.com/blog/products/data-analytics/simplify-your-sql-with-pipe-syntax-in-bigquery-and-cloud-logging&quot;&gt;piped SQL&lt;/a&gt;, &lt;a href=&quot;https://prql-lang.org/&quot;&gt;PRQL&lt;/a&gt; or &lt;a href=&quot;https://www.cidrdb.org/cidr2024/papers/p48-neumann.pdf&quot;&gt;SaneQL&lt;/a&gt; makes monolithic parsers less and less practical: in their traditional design, parser construction is a &lt;em&gt;compile-time&lt;/em&gt; activity where enormous grammar files are translated into state machine transition lookup tables which are then baked in a system binary.  Having those &lt;em&gt;always&lt;/em&gt; be present in the parser might be wasteful especially for size-conscious binary distributions like WebAssembly (Wasm).&lt;/p&gt;

&lt;p&gt;Many if not most SQL systems use a static parser created using a &lt;a href=&quot;http://www.nylxs.com/docs/lexandyacc.pdf&quot;&gt;YACC-style&lt;/a&gt; parser toolkit: we are able to easily confirm this for open-source systems like PostgreSQL and MySQL/MariaDB. From analyzing their binaries&#39; symbol names, we also found indications that Oracle, SQL Server and IBM Db2 use YACC. Internally, YACC and its slightly more recent variant GNU Bison as well as the &quot;Lemon&quot; parser generator used by SQLite all use a &quot;single look-ahead left-to-right rightmost derivation&quot; LALR(1) parser generator. This generator translates a formal context-free set of grammar rules in Extended Backus-Naur Form (EBNF) to a parser state machine. &lt;a href=&quot;https://publications.csail.mit.edu/lcs/pubs/pdf/MIT-LCS-TR-065.pdf&quot;&gt;LALR parsers&lt;/a&gt; are a more space-efficient specialization of LR(k) parsers as first described by &lt;a href=&quot;https://harrymoreno.com/assets/greatPapersInCompSci/2.5_-_On_the_translation_of_languages_from_left_to_right-Donald_E._Knuth.pdf&quot;&gt;Knuth&lt;/a&gt;. But in effect, &lt;strong&gt;the most advanced SQL systems of 2024 use parser technology from the 1960s&lt;/strong&gt;. Given that the rest of data management systems have been greatly overhauled since this should raise the question of why the parser did not receive any serious engineering attention.&lt;/p&gt;

&lt;p&gt;Database systems are moving towards becoming &lt;em&gt;ecosystems&lt;/em&gt; instead of pre-built monoliths. Much of the innovation in the PostgreSQL, SQLite, and DuckDB communities now comes from &lt;a href=&quot;https://www.pdl.cmu.edu/PDL-FTP/Database/CMU-CS-23-144.pdf&quot;&gt;extensions&lt;/a&gt;, which are shared libraries that are loaded into the database system at run-time to extend the database system with features like vector similarity search, geospatial support, file systems, or graph processing. Bundling all those features upfront would be difficult due to additional binary size, external dependencies. In addition, they are often maintained independently by their communities. Thus far, at least in part due to the ubiquity of YACC-style parsers, those community extensions have been restricted from extending syntax. While this is also true in other ecosystems like Python, the design of SQL with its heavy focus on syntax and not function calls makes the extensions second-class citizens that have to somehow work around the restrictions by the original parser, e.g., by embedding custom expressions in strings.&lt;/p&gt;

&lt;p&gt;We propose to &lt;em&gt;re-think data management system parser design&lt;/em&gt; to create modern, &lt;em&gt;extensible&lt;/em&gt; parsers, which allow a dynamic configuration of the accepted syntax &lt;em&gt;at run-time&lt;/em&gt;, for example to allow syntax extensions, new statements, or to add entirely new query languages. This would allow to break up the monolithic grammars currently in use and enable more creativity and flexibility in what syntax a data management system can accept, both for industrial and research use. Extensible parsers allow for new grammar features to be easily integrated and tested, and can also help bridge the gap between different SQL dialects by adding support for the dialect of one system to the parser of another. Conversely, it might also be desirable in some use cases to &lt;em&gt;restrict&lt;/em&gt; the acceptable grammar, e.g., to restrict the complexity of queries, or to enforce strict compliance with the SQL standard.&lt;/p&gt;

&lt;p&gt;Modernizing parser infrastructure also has additional benefits: one of the most-reported support issues with data management systems are unhelpful syntax errors. Some systems go to great lengths to try to provide a meaningful error message, e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;this column does not exist, did you mean ...&lt;/code&gt;, but this is typically limited to resolving identifiers following the actual parsing. YACC-style parsers exhibit &quot;all-or-nothing&quot; behavior, the &lt;em&gt;entire&lt;/em&gt; query or set of queries either is accepted entirely or not at all. This is why queries with actual syntactical errors (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELEXT&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; are usually harshly rejected by a DBMS. MySQL for example is notorious for its unhelpful error messages:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;You have an error in your SQL syntax; check the manual that corresponds
to your MySQL server version for the right syntax to use near &#39;SELEXT&#39;
at line 1.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;parsing-expression-grammar&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html#parsing-expression-grammar&quot;&gt;Parsing Expression Grammar&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Parsing_expression_grammar&quot;&gt;Parsing Expression Grammar&lt;/a&gt; (PEG) parsers represent a more modern approach to parsing. PEG parsers are top-down parsers that effectively generate a recursive-descent style parser from a grammar. Through the &quot;packrat&quot; memoization technique PEG parsers exhibit linear time complexity in parsing at the expense of a grammar-dependent amount of extra memory. The biggest difference from a grammar author perspective is the choice operator where multiple syntax options can be matched. In LALR parsers options with similar syntax can create ambiguity and reduce conflicts. In PEG parsers the &lt;em&gt;first&lt;/em&gt; matching option is always selected. Because of this, PEG parsers cannot be ambiguous by design.&lt;/p&gt;

&lt;p&gt;As their name suggests, parsing expression grammar consists of a set of &lt;em&gt;parsing expressions&lt;/em&gt;. Expressions can contain references to other rules, or literal token references, both as actual strings or character classes similar to regular expressions. Expressions can be combined through sequences, quantifiers, optionals, groupings and both positive and negative look-ahead. Each expression can either match or not, but it is required to consume a part of the input if it matches. Expressions are able to look ahead and consider the remaining input but are not required to consume it. Lexical analysis is typically part of the PEG parser itself, which removes the need for a separate step.&lt;/p&gt;

&lt;p&gt;One big advantage is that PEG parsers &lt;em&gt;do not require a compilation step&lt;/em&gt; where the grammar is converted to for example a finite state automaton based on lookup tables. PEG can be executed directly on the input with minimal grammar transformation, making it feasible to re-create a parser at runtime. PEG parsers are gaining popularity, for example, the Python programming language has &lt;a href=&quot;https://peps.python.org/pep-0617/&quot;&gt;recently switched to a PEG parser&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another big advantage of PEG parsers is &lt;em&gt;error handling&lt;/em&gt;: the paper &lt;a href=&quot;https://arxiv.org/abs/1806.11150&quot;&gt;&quot;Syntax Error Recovery in Parsing Expression Grammars&quot;&lt;/a&gt; describes a practical technique where parser rules are annotated with &quot;recovery&quot; actions, which can (1) show more than a single error and (2) annotate errors with a more meaningful error message.&lt;/p&gt;

&lt;p&gt;A possible disadvantage of memoized packrat parsing is the memory required for memoization: the amount required is &lt;em&gt;proportional to the input size&lt;/em&gt;, not the stack size. Of course, memory limitations have relaxed significantly since the invention of LALR parsers sixty years ago and queries typically are not &quot;Big Data&quot;` themselves.&lt;/p&gt;
      &lt;h2 id=&quot;proof-of-concept-experiments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html#proof-of-concept-experiments&quot;&gt;Proof-of-Concept Experiments&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To perform experiments on parser extensibility, we have implemented an – admittedly simplistic – experimental prototype PEG parser for enough of SQL to parse &lt;em&gt;all&lt;/em&gt; the TPC-H and TPC-DS queries. This grammar is compatible with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cpp-peglib&lt;/code&gt; &lt;a href=&quot;https://github.com/yhirose/cpp-peglib&quot;&gt;single-header C++17 PEG execution engine&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cpp-peglib&lt;/code&gt; uses a slightly different grammar syntax, where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&lt;/code&gt; is used to denote choices. The symbol &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;?&lt;/code&gt; shows an optional element, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt; defines arbitrary repetition. The special rules &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Parens()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;List()&lt;/code&gt; are grammar macros that simplify the grammar for common elements. The special &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%whitespace&lt;/code&gt; rule is used to describe tokenization.&lt;/p&gt;

&lt;p&gt;Below is an abridged version of our experimental SQL grammar, with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Expression&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Identifier&lt;/code&gt; syntax parsing rules omitted for brevity:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Statements &amp;lt;- SingleStmt (&#39;;&#39; SingleStmt )* &#39;;&#39;*
SingleStmt &amp;lt;- SelectStmt
SelectStmt &amp;lt;- SimpleSelect (SetopClause SimpleSelect)*
SetopClause &amp;lt;-
    (&#39;UNION&#39; / &#39;EXCEPT&#39; / &#39;INTERSECT&#39;) &#39;ALL&#39;?
SimpleSelect &amp;lt;- WithClause? SelectClause FromClause?
    WhereClause? GroupByClause? HavingClause?
    OrderByClause? LimitClause?
WithStatement &amp;lt;- Identifier &#39;AS&#39; SubqueryReference
WithClause &amp;lt;- &#39;WITH&#39; List(WithStatement)
SelectClause &amp;lt;- &#39;SELECT&#39; (&#39;*&#39; / List(AliasExpression))
ColumnsAlias &amp;lt;- Parens(List(Identifier))
TableReference &amp;lt;-
    (SubqueryReference &#39;AS&#39;? Identifier ColumnsAlias?) /
    (Identifier (&#39;AS&#39;? Identifier)?)
ExplicitJoin &amp;lt;- (&#39;LEFT&#39; / &#39;FULL&#39;)? &#39;OUTER&#39;?
    &#39;JOIN&#39; TableReference &#39;ON&#39; Expression
FromClause &amp;lt;- &#39;FROM&#39; TableReference
    ((&#39;,&#39; TableReference) / ExplicitJoin)*
WhereClause &amp;lt;- &#39;WHERE&#39; Expression
GroupByClause &amp;lt;- &#39;GROUP&#39; &#39;BY&#39; List(Expression)
HavingClause &amp;lt;- &#39;HAVING&#39; Expression
SubqueryReference &amp;lt;- Parens(SelectStmt)
OrderByExpression &amp;lt;- Expression (&#39;DESC&#39; / &#39;ASC&#39;)?
    (&#39;NULLS&#39; &#39;FIRST&#39; / &#39;LAST&#39;)?
OrderByClause &amp;lt;- &#39;ORDER&#39; &#39;BY&#39; List(OrderByExpression)
LimitClause &amp;lt;- &#39;LIMIT&#39; NumberLiteral
AliasExpression &amp;lt;- Expression (&#39;AS&#39;? Identifier)?
%whitespace &amp;lt;- [ \t\n\r]*
List(D) &amp;lt;- D (&#39;,&#39; D)*
Parens(D) &amp;lt;- &#39;(&#39; D &#39;)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All experiments were run on a 2021 MacBook Pro with the M1 Max CPU and 64 GB of RAM. The experimental grammar and the code for experiments are &lt;a href=&quot;https://github.com/hannes/peg-parser-experiments&quot;&gt;available on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Loading the base grammar from its text representation into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cpp-peglib&lt;/code&gt; grammar dictionary with symbolic rule representations takes 3 ms. In case that delay should become an issue, the library also allows to define rules programmatically instead of as strings. It would be straightforward to pre-compile the grammar file into source code for compilation, YACC-style. While somewhat counter-intuitive, it would reduce the time required to initialize the initial, unmodified parser. This difference matters for some applications of e.g., DuckDB where the database instance only lives for a few short milliseconds.&lt;/p&gt;

&lt;p&gt;For the actual parsing, YACC parses TPC-H Query 1 in ca. 0.03 ms, where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cpp-peglib&lt;/code&gt; takes ca. 0.3 ms, a ca. 10 times increase. To further stress parsing performance, we repeated all TPC-H and TPC-DS queries six times to create a 36,840 line SQL script weighing in at ca. 1 MB. Note that a &lt;a href=&quot;https://www.amazon.science/publications/why-tpc-is-not-enough-an-analysis-of-the-amazon-redshift-fleet&quot;&gt;recent study&lt;/a&gt; has found that the 99-percentile of read queries in the Amazon Redshift cloud data warehouse are smaller than 16.5 kB.&lt;/p&gt;

&lt;p&gt;Postgres takes on average 24 ms to parse this file using YACC. Note that this time includes the execution of grammar actions that create Postgres&#39; parse tree. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cpp-peglib&lt;/code&gt; takes on average 266 ms to parse the test file. However, our experimental parser does not have grammar actions defined yet. When simulating actions by generating default AST actions for every rule, parsing time increases to 339 ms. Note that the AST generation is more expensive than required, because a node is created for each matching rule, even if there is no semantic meaning in the grammar at hand.&lt;/p&gt;

&lt;p&gt;Overall, we can observe a ca. 10 times slowdown in parsing performance when using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cpp-peglib&lt;/code&gt; parser. However, it should be noted that the &lt;em&gt;absolute duration&lt;/em&gt; of those two processes is still tiny; at least for analytical queries, sub-millisecond parsing time is more than acceptable as parsing still only accounts for a tiny fraction of overall query processing time. Furthermore, there are still ample optimization opportunities in the experimental parsers we created using an off-the-shelf PEG library. For example, the library makes heavy use of recursive function calls, which can be optimized e.g., by using a loop abstraction.&lt;/p&gt;

&lt;p&gt;In the following, we present some experiments in extending the prototype parser with support for new statements, entirely new syntax and with improvements in error messages.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is already possible to replace DuckDB&#39;s parser by providing an alternative parser.
Several community extensions such as &lt;a href=&quot;https://duckdb.org/community_extensions/extensions/duckpgq.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckpgq&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/community_extensions/extensions/prql.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prql&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/community_extensions/extensions/psql.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;psql&lt;/code&gt;&lt;/a&gt; use this approach.
When trying to parse a query string, DuckDB first attempts to use the default parser.
If this fails, it switches to the extension parsers as failover.
Therefore, these extensions cannot simply extend the parser with a few extra rules – instead, they implement the complete grammar of their target language.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h3 id=&quot;adding-the-unpivot-statement&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html#adding-the-unpivot-statement&quot;&gt;Adding the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; Statement&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Let&#39;s assume we would want to add a new top-level &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; statement to turn columns into rows to a SQL dialect. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; should work on the same level as e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;, for example to unpivot a table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1&lt;/code&gt; on a specific list of columns or all columns (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt;), we would like to be able to write:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;UNPIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UNPIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is clear that we would have to somehow modify the parser to allow this new syntax. However, when using a YACC parser, this would require modifying the grammar, re-running the parser generator, hoping for the absence of shift-reduce conflicts, and then recompiling the actual database system. However, this is not practical at run-time which is when extensions are loaded, ideally within milliseconds.&lt;/p&gt;

&lt;p&gt;In order to add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt;, we have to define a grammar rule and then modify &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SingleStmt&lt;/code&gt; to allow the statement in a global sequence of SQL statements. This is shown below. We define the new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnpivotStatement&lt;/code&gt; grammar rule by adding it to the dictionary, and we then modify the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SingleStmt&lt;/code&gt; rule entry in the dictionary to also allow the new statement.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;UnpivotStatement &amp;lt;- &#39;UNPIVOT&#39; Identifier
    &#39;ON&#39; Parens(List(Identifier) / &#39;*&#39;)

SingleStmt &amp;lt;- SelectStatement / UnpivotStatement
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that we re-use other machinery from the grammar like the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Identifier&lt;/code&gt; rule as well as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Parens()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;List()&lt;/code&gt; macros to define the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ON&lt;/code&gt; clause. The rest of the grammar dictionary remains unchanged. After modification, the parser can be re-initialized in another 3 ms. Parser execution time was unaffected.&lt;/p&gt;
      &lt;h3 id=&quot;extending-select-with-graph_table&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html#extending-select-with-graph_table&quot;&gt;Extending &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GRAPH_TABLE&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Let&#39;s now assume we would want to modify the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; syntax to add support for &lt;a href=&quot;https://arxiv.org/abs/2112.06217&quot;&gt;SQL/PGQ graph matching patterns&lt;/a&gt;. Below is an example query in SQL/PGQ that finds the university name and year for all students called Bob:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;study&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;study&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;GRAPH_TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;MATCH&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Person&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;firstName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Bob&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;studyAt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;University&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;study&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see that this new syntax adds the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GRAPH_TABLE&lt;/code&gt; clause and the pattern matching domain-specific language (DSL) within. To add support for this syntax to a SQL parser at runtime, we need to modify the grammar for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement itself. This is fairly straightforward when using a PEG. We replace the rule that describes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause to also accept a sub-grammar starting at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GRAPH_TABLE&lt;/code&gt; keyword following by parentheses. Because the parser does not need to generate a state machine, we are immediately able to accept the new syntax.&lt;/p&gt;

&lt;p&gt;Below we show a small set of grammar rules that are sufficient to extend our experimental parser with support for the SQL/PGQ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GRAPH_TABLE&lt;/code&gt; clause and the containing property graph patterns. With this addition, the parser can parse the query above. Parser construction and parser execution timings were unaffected.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Name &amp;lt;- (Identifier? &#39;:&#39; Identifier) / Identifier
Edge &amp;lt;- (&#39;-&#39; / &#39;&amp;lt;-&#39;) &#39;[&#39; Name &#39;]&#39; (&#39;-&amp;gt;&#39; / &#39;-&#39;)
Pattern &amp;lt;- Parens(Name WhereClause?) Edge
   Parens(Name WhereClause?)
PropertyGraphReference &amp;lt;- &#39;GRAPH_TABLE&#39;i &#39;(&#39;
        Identifier &#39;,&#39;
        &#39;MATCH&#39;i List(Pattern)
        &#39;COLUMNS&#39;i Parens(List(ColumnReference))
    &#39;)&#39; Identifier?

TableReference &amp;lt;-
    PropertyGraphReference / ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr&lt;/code&gt;, the &lt;a href=&quot;https://dplyr.tidyverse.org/&quot;&gt;&quot;Grammar of Data Manipulation&quot;&lt;/a&gt;, is the de facto standard data transformation language in the R Environment for Statistical Computing. The language uses function calls and a special chaining operator (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%&amp;gt;%&lt;/code&gt;) to combine operators. Below is an example dplyr query:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;species&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mass&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mass&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For those unfamiliar with dplyr, the query is equivalent to this SQL query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mass&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;species&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mass&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With an extensible parser, it is feasible to add support for completely new query languages like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; to a SQL parser. Below is a simplified grammar snippet that enables our SQL parser to accept the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; example from above.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;DplyrStatement &amp;lt;- Identifier Pipe Verb (Pipe Verb)*
Verb &amp;lt;- VerbName Parens(List(Argument))
VerbName &amp;lt;- &#39;group_by&#39; / &#39;summarise&#39; / &#39;filter&#39;
Argument &amp;lt;- Expression / (Identifier &#39;=&#39; Expression)
Pipe &amp;lt;- &#39;%&amp;gt;%&#39;

SingleStmt &amp;lt;- SelectStatement /
    UnpivotStatement / DplyrStatement
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is important to note that the rest of the experimental SQL parser &lt;em&gt;still works&lt;/em&gt;, i.e., the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; syntax now &lt;em&gt;also&lt;/em&gt; works. Parser construction and parser execution timings were again unaffected.&lt;/p&gt;
      &lt;h3 id=&quot;better-error-messages&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html#better-error-messages&quot;&gt;Better Error Messages&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As mentioned above, PEG parsers are able to generate better error messages elegantly. A common novice SQL user mistake is to mix up the order of keywords in a query, for example, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; must come after the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt;. Assume an inexperienced user types the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By default, both the YACC and the PEG parsers will report a similar error message about an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unexpected &#39;GROUP&#39; keyword&lt;/code&gt; with a byte position. However, with a PEG parser we can define a &quot;recovery&quot; syntax rule that will create a useful error message. We modify the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OrderByClause&lt;/code&gt; from our experimental grammar like so:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;OrderByClause &amp;lt;- &#39;ORDER&#39;i &#39;BY&#39;i List(OrderByExpression)
    %recover(WrongGroupBy)?
WrongGroupBy &amp;lt;- GroupByClause
    { error_message &quot;GROUP BY must precede ORDER BY&quot; }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%recover&lt;/code&gt; construct to match a misplaced &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clause, re-using the original definition, and then trigger a custom error message that advises the user on how to fix their query. And indeed, when we parse the wrong SQL example, the parser will output the custom message.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion-and-future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html#conclusion-and-future-work&quot;&gt;Conclusion and Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this post, we have proposed to modernize the ancient art of SQL parsing using more modern parser generators like PEG. We have shown how by using PEG, a parser can be extended at run-time at minimal cost without re-compilation. In our experiments we have demonstrated how minor grammar adjustments can fundamentally extend and change the accepted syntax.&lt;/p&gt;

&lt;p&gt;An obvious next step is to address the observed performance drawback observed in our prototype. Using more efficient implementation techniques, it should be possible to narrow the gap in parsing performance between YACC-based LALR parsers and a dynamic PEG parser. Another next step is to address some detail questions for implementation: for example, parser extension load order should ideally not influence the final grammar. Furthermore, while parser actions can in principle execute arbitrary code, they may have to be restrictions on return types and input handling.&lt;/p&gt;

&lt;p&gt;We plan to switch DuckDB&#39;s parser, which started as a fork of the Postgres YACC parser, to a PEG parser in the near future. As an initial step, we have performed an experiment where we found that it is possible to interpret the current Postgres YACC grammar with PEG. This should greatly simplify the transitioning process, since it ensures that the same grammar will be accepted in both parsing frameworks.&lt;/p&gt;
      &lt;h2 id=&quot;acknowledgments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/22/runtime-extensible-parsers.html#acknowledgments&quot;&gt;Acknowledgments&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We would like to thank &lt;a href=&quot;https://db.cs.uni-tuebingen.de/team/members/torsten-grust/&quot;&gt;&lt;strong&gt;Torsten Grust&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&quot;https://szarnyasg.org/&quot;&gt;&lt;strong&gt;Gábor Szárnyas&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&quot;https://www.cwi.nl/en/people/daniel-ten-wolde/&quot;&gt;&lt;strong&gt;Daniël ten Wolde&lt;/strong&gt;&lt;/a&gt; for their valuable suggestions. We would also like to thank &lt;a href=&quot;https://github.com/carlopi&quot;&gt;&lt;strong&gt;Carlo Piovesan&lt;/strong&gt;&lt;/a&gt; for his translation of the Postgres YACC grammar to PEG.&lt;/p&gt;

</description><link>https://duckdb.org/2024/11/22/runtime-extensible-parsers.html</link><guid isPermaLink="false">https://duckdb.org/2024/11/22/runtime-extensible-parsers.html</guid><pubDate>Fri, 22 Nov 2024 00:00:00 GMT</pubDate><author>Hannes Mühleisen and Mark Raasveldt</author></item><item><title>Optimizers: The Low-Key MVP</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The query optimizer is an important part of any analytical database system as it provides considerable performance improvements compared to hand-optimized queries, even as the state of your data changes.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Optimizers don&#39;t often give &quot;main character&quot; energy in the database community. Databases are usually popular because of their performance, ease of integration, or reliability. As someone who mostly works on the optimizer in DuckDB, I have been wanting to write a blog post about how important optimizers are and why they merit more recognition. In this blog post we will analyze queries that fall into one of three categories: unoptimized, hand-optimized, and optimized by the DuckDB query optimizer. I will also explain why built-in optimizers are almost always better than any hand optimizations. Hopefully, by the end of this blog post, you will agree that optimizers play a silent, but vital role when using a database. Let&#39;s first start by understanding where in the execution pipeline query optimization happens.&lt;/p&gt;

&lt;p&gt;Before any data is read from the database, the given SQL text must be parsed and validated. If this process finishes successfully, a tree-based query plan is created. The query plan produced by the parser is naïve, and can be extremely inefficient depending on the query. This is where the optimizer comes in, the inefficient query plan is passed to the optimizer for modification and, you guessed it, optimization. The optimizer is made up of many optimization rules. Each rule has the ability to reorder, insert, and delete query operations to create a slightly more efficient query plan that is also logically equivalent. Once all the optimization rules are applied, the optimized plan can be much more efficient than the plan produced by the parser.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In practice an optimization rule can also be called an optimizer. For the rest of this blog post, optimizer rule will be used for a specific optimization, and optimizer will refer to the database optimizer, unless the word optimizer names a specific optimization rule, (i.e., &lt;em&gt;Join Order Optimizer&lt;/em&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;normal-queries-vs-optimized-queries&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#normal-queries-vs-optimized-queries&quot;&gt;Normal Queries vs. Optimized Queries&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To examine the effect of the DuckDB query optimizer, let&#39;s use a subset of the NYC taxi dataset. You can create native DuckDB tables with the following commands (note that &lt;a href=&quot;https://blobs.duckdb.org/data/taxi-data-2019.parquet&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;taxi-data-2019.parquet&lt;/code&gt;&lt;/a&gt; is approximately 1.3 GB):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;taxi_data_2019&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/taxi-data-2019.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone_lookups&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/zone-lookups.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now that we have all 2019 data, let&#39;s look at the unoptimized vs. optimized plans for a simple query. The following SQL query gets us the most common pickup and drop-off pairs in the Manhattan borough.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;disable_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;explain_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;optimized_only&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXPLAIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_trips&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;zone_lookups&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;zone_lookups&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;taxi_data_2019&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LocationID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pickup_location_id&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LocationID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropoff_location_id&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Borough&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Manhattan&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Borough&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Manhattan&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_zone&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_trips&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN&lt;/code&gt; query gives us the following plan.&lt;/p&gt;

&lt;div class=&quot;small_code_block&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│           LIMIT           │
│    ────────────────────   │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│          ORDER_BY         │
│    ────────────────────   │
│        count_star()       │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│    ────────────────────   │
│        Expressions:       │
│             0             │
│             1             │
│         num_trips         │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         AGGREGATE         │
│    ────────────────────   │
│          Groups:          │
│        pickup_zone        │
│        dropoff_zone       │
│                           │
│        Expressions:       │
│        count_star()       │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│           FILTER          │
│    ────────────────────   │
│        Expressions:       │
│       (LocationID =       │
│     pickup_location_id)   │
│       (LocationID =       │
│    dropoff_location_id)   │
│ (Borough = CAST(&#39;Manhattan│
│       &#39; AS VARCHAR))      │
│ (Borough = CAST(&#39;Manhattan│
│       &#39; AS VARCHAR))      │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│       CROSS_PRODUCT       │
│    ────────────────────   ├───────────────────────────────────────────┐
└─────────────┬─────────────┘                                           │
┌─────────────┴─────────────┐                             ┌─────────────┴─────────────┐
│       CROSS_PRODUCT       │                             │          SEQ_SCAN         │
│    ────────────────────   ├──────────────┐              │    ────────────────────   │
│                           │              │              │       taxi_data_2019      │
└─────────────┬─────────────┘              │              └───────────────────────────┘
┌─────────────┴─────────────┐┌─────────────┴─────────────┐
│          SEQ_SCAN         ││          SEQ_SCAN         │
│    ────────────────────   ││    ────────────────────   │
│        zone_lookups       ││        zone_lookups       │
└───────────────────────────┘└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The cross products alone make this query extremely inefficient. The cross-products produce &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;256 * 256 * |taxi_data_2019|&lt;/code&gt; rows of data, which is 5 trillion rows of data. The filter only matches 71 million rows, which is only 0.001% of the data. The aggregate produces 4,373 rows of data, which need to be sorted by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; operation, which runs in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N * log N)&lt;/code&gt;. Producing 5 trillion tuples alone is an enormous amount of data processing, which becomes clear when you try to run the query and notice it doesn&#39;t complete. With the optimizer enabled, the query plan produced is much more efficient because the operations are re-ordered to avoid many trillions of rows of intermediate data. Below is the query plan with the optimizer enabled:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;enable_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXPLAIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;small_code_block&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│           TOP_N           │
│    ────────────────────   │
│          ~5 Rows          │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│    ────────────────────   │
│        Expressions:       │
│             0             │
│             1             │
│         num_trips         │
│                           │
│         ~265 Rows         │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         AGGREGATE         │
│    ────────────────────   │
│          Groups:          │
│        pickup_zone        │
│        dropoff_zone       │
│                           │
│        Expressions:       │
│        count_star()       │
│                           │
│         ~265 Rows         │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│      COMPARISON_JOIN      │
│    ────────────────────   │
│      Join Type: INNER     │
│                           │
│        Conditions:        ├───────────────────────────────────────────┐
│   (pickup_location_id =   │                                           │
│         LocationID)       │                                           │
│                           │                                           │
│       ~1977517 Rows       │                                           │
└─────────────┬─────────────┘                                           │
┌─────────────┴─────────────┐                             ┌─────────────┴─────────────┐
│      COMPARISON_JOIN      │                             │          SEQ_SCAN         │
│    ────────────────────   │                             │    ────────────────────   │
│      Join Type: INNER     │                             │          Filters:         │
│                           │                             │  Borough=&#39;Manhattan&#39; AND  │
│        Conditions:        ├──────────────┐              │     Borough IS NOT NULL   │
│   (dropoff_location_id =  │              │              │                           │
│         LocationID)       │              │              │        zone_lookups       │
│                           │              │              │                           │
│       ~12744000 Rows      │              │              │          ~45 Rows         │
└─────────────┬─────────────┘              │              └───────────────────────────┘
┌─────────────┴─────────────┐┌─────────────┴─────────────┐
│          SEQ_SCAN         ││          SEQ_SCAN         │
│    ────────────────────   ││    ────────────────────   │
│       taxi_data_2019      ││          Filters:         │
│                           ││  Borough=&#39;Manhattan&#39; AND  │
│                           ││     Borough IS NOT NULL   │
│                           ││                           │
│                           ││        zone_lookups       │
│                           ││                           │
│       ~84393604 Rows      ││          ~45 Rows         │
└───────────────────────────┘└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&#39;s first look at the difference in execution times on my MacBook with an M1 Max and 32 GB of memory before talking about the optimizations that have taken place.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&amp;nbsp;&lt;/th&gt;
      &lt;th&gt;Unoptimized&lt;/th&gt;
      &lt;th&gt;Optimized&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Runtime&lt;/td&gt;
      &lt;td&gt;&amp;gt;24 hours&lt;/td&gt;
      &lt;td&gt;0.769 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Hopefully this performance benefit illustrates how powerful the DuckDB Optimizer is. So what optimization rules are responsible for these drastic performance improvements? For the query above, there are three powerful rules that are applied when optimizing the query: &lt;em&gt;Filter Pushdown,&lt;/em&gt; &lt;em&gt;Join Order Optimization,&lt;/em&gt; and &lt;em&gt;TopN Optimization&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;Filter Pushdown Optimizer&lt;/em&gt; is very useful since it reduces the amount of intermediate data being processed. It is an optimization rule that is sometimes easy to miss for humans and will always result in faster execution times if the filter is selective in any way. It takes a filter, like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Borough = &#39;Manhattan&#39;&lt;/code&gt; and pushes it down to the operator that first introduces the filtered column, in this case the table scan. In addition, it will also detect when a filtered column like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;col1&lt;/code&gt; is used in an equality condition (i.e., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE col1 = col2&lt;/code&gt;). In these cases, the filter is duplicated and applied to the other column, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;col2&lt;/code&gt;, further reducing the amount of intermediate data being processed.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;Join Order Optimizer&lt;/em&gt; recognizes that the filters &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pickup.LocationID = data.pickup_location_id&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dropoff.LocationID = data.dropoff_location_id&lt;/code&gt; can be used as join conditions and rearranges the scans and joins accordingly. This optimizer rule does a lot of heavy lifting to reduce the amount of intermediate data being processed since it is responsible for removing the cross products.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;TopN Optimizer&lt;/em&gt; is very useful when aggregate data needs to be sorted. If a query has an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt; operator, a TopN operator can replace these two operators. The TopN operator orders only the highest/lowest &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; values, instead of all values. If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; is 5, then DuckDB only needs to keep 5 rows with the minimum/maximum values in memory and can throw away the rest. So if you are only interested in the top &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; values out of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt;, where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N &amp;lt;&amp;lt; M&lt;/code&gt;, the TopN operator can run in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(M + N * log N)&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(M * log M)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;These are just a few of the optimizations DuckDB has. More optimizations are explained in the section &lt;a href=&quot;https://duckdb.org/2024/11/14/optimizers.html#summary-of-all-optimizers&quot;&gt;Summary of All Optimizers&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;hand-optimized-queries&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#hand-optimized-queries&quot;&gt;Hand-Optimized Queries&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;For the query above, it is possible to achieve almost the same plan by carefully writing the SQL query by hand. To achieve a similar plan as the one generated by DuckDB, you can write the following.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_trips&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;taxi_data_2019&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone_lookups&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Borough&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Manhattan&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LocationID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pickup_location_id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone_lookups&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Borough&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Manhattan&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LocationID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropoff_location_id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_zone&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_trips&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;desc&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Inspecting the runtimes again we get:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&amp;nbsp;&lt;/th&gt;
      &lt;th&gt;Unoptimized&lt;/th&gt;
      &lt;th&gt;Hand-optimized&lt;/th&gt;
      &lt;th&gt;Optimized&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Runtime&lt;/td&gt;
      &lt;td&gt;&amp;gt;24 hours&lt;/td&gt;
      &lt;td&gt;0.926 s&lt;/td&gt;
      &lt;td&gt;0.769 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The SQL above results in a plan similar to the DuckDB optimized plan, but it is wordier and more error-prone to write, which can potentially lead to bugs. In very rare cases, it is possible to hand write a query that produces a more efficient plan than an optimizer. These cases are extreme outliers, and in all other cases the optimizer will produce a better plan. Moreover, a hand-optimized query is optimized for the current state of the data, which can change with many updates over time. Once a sufficient amount of changes are applied to the data, the assumptions of a hand-optimized query may no longer hold, leading to bad performance. Let&#39;s take a look at the following example.&lt;/p&gt;

&lt;p&gt;Suppose an upstart company has an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parts&lt;/code&gt; table and every time some dashboard loads, the most popular ordered parts needs to be calculated. Since the company is still relatively new, they only have a small amount orders, but their catalog of parts is still quite large. A hand-optimized query would look like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parts&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;part_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;part_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ordered_amount&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parts&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Naturally, the number of orders will increase as this company gains customers and grows in popularity. If the query above continues to run without the use of an optimizer, the performance will slowly decline. This is because the execution engine will build the hash table on the orders table, which potentially will have 100 million rows. If the optimizer is enabled, the &lt;a href=&quot;https://duckdb.org/2024/11/14/optimizers.html#join-order-optimizer&quot;&gt;Join Order Optimizer&lt;/a&gt; will be able to inspect the statistics of the table during the optimization process and produce a new plan according to the new state of the data.&lt;/p&gt;

&lt;p&gt;Here is a breakdown of running the queries with and without the optimizer as the orders table increases.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&amp;nbsp;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Unoptimized&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Optimized&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;|orders| = 1K&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.004 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.003 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;|orders| = 10K&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.005 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.005 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;|orders| = 100K&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.013 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.008 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;|orders| = 1M&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.055 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.014 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;|orders| = 10M&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.240 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.044 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;|orders| = 100M&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.266 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.259 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;At first the difference in execution time is not really noticeable, so no one would think a query rewrite would be the solution. But once enough orders are reached, waiting 2 seconds every time the dashboard loads becomes tedious. If the optimizer is enabled, the query performance improves by a factor of 10×. So if you ever think you have identified a scenario where you are smarter than the optimizer, make sure you have also thought about all possible updates to the data and have hand-optimized for those as well.&lt;/p&gt;
      &lt;h2 id=&quot;optimizations-that-are-impossible-by-hand&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#optimizations-that-are-impossible-by-hand&quot;&gt;Optimizations That Are Impossible by Hand&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Some optimization rules are also impossible to write by hand. For example, the TopN optimization can not be optimized by hand.&lt;/p&gt;

&lt;p&gt;Another good example is the Join Filter Pushdown optimization. The Join Filter Pushdown optimization works in scenarios where the build side of a hash join has a subset of the join keys. In its current state the join filter pushdown optimization keeps track of the minimum value key and maximum value key and pushes a table filter into the probe side to filter out keys greater than the maximum join value and smaller than the minimum join value.&lt;/p&gt;

&lt;p&gt;With a small change, we can use the query from above to demonstrate this. Suppose we first filter our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parts&lt;/code&gt; table to only include parts with a specific prefix in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;part_name&lt;/code&gt;. When the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table has 100 million rows and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parts&lt;/code&gt; table only has ~20,000 after filtering, then the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table will be the probe side and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parts&lt;/code&gt; table will be the hash/build side. When the hash table is built, the min and max &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p_id&lt;/code&gt; values in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parts&lt;/code&gt; table are recorded, in this case it could be 20,000 and 80,000. These min and max values get pushed as a filter into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table scan, filtering out all parts with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p_id &amp;gt; 80,000&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pid &amp;lt; 20,000&lt;/code&gt;. 40% of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table has a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pid&lt;/code&gt; greater than 80,000, and less than 20,000 so this optimization does a lot of heavy lifting in join queries.&lt;/p&gt;

&lt;p&gt;Imagine trying to express this logic in your favorite data frame API; it would be extremely difficult and error-prone. The library would need to implement this optimization automatically for all hash joins. The Join Filter Pushdown optimization can improve query performance by 10x, so it should be a key factor when deciding what analytical system to use.&lt;/p&gt;

&lt;p&gt;If you use a data frame library like &lt;a href=&quot;https://github.com/SebKrantz/collapse&quot;&gt;collapse&lt;/a&gt;, &lt;a href=&quot;https://github.com/pandas-dev/pandas&quot;&gt;pandas&lt;/a&gt;, &lt;a href=&quot;https://github.com/Rdatatable/data.table&quot;&gt;data.table&lt;/a&gt;, &lt;a href=&quot;https://github.com/modin-project/modin&quot;&gt;modin&lt;/a&gt;, then you are most likely not enjoying the benefits of query optimization techniques. This means your optimizations need to be applied by hand, which is not sustainable if your data starts changing. Moreover, you are most likely writing imperatively, using a syntax specific to the dataframe library. This means the scripts responsible for analyzing data are not very portable. SQL, on the other hand, can be much more intuitive to write since it is a declarative language, and can be ported to practically any other database system.&lt;/p&gt;
      &lt;h2 id=&quot;summary-of-all-optimizers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#summary-of-all-optimizers&quot;&gt;Summary of All Optimizers&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Below is a non-exhaustive list of all the optimization rules that DuckDB applies.&lt;/p&gt;
      &lt;h3 id=&quot;expression-rewriter&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#expression-rewriter&quot;&gt;Expression Rewriter&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;em&gt;Expression Rewriter&lt;/em&gt; simplifies expressions within each operator. Sometimes queries are written with expressions that are not completely evaluated or they can be rewritten in a way that takes advantage of features within the execution engine. Below is a table of common expression rewrites and the optimization rules that are responsible for them. Many of these rules rewrite expressions to use specialized DuckDB functions so expression evaluation is much faster during execution. If an expression can be evaluated to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt; in the optimizer phase, there is no need to pass the original expression to the execution engine. In addition, the optimized expressions are more likely to allow DuckDB to make further improvements to the query plan. For example, the &quot;Move constants&quot; rule could enable filter pushdown to occur.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Rewriter rule&lt;/th&gt;
      &lt;th&gt;Original expression&lt;/th&gt;
      &lt;th&gt;Optimized expression&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Move constants&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x + 1 = 6&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x = 5&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Constant folding&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2 + 2 = 4&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Conjunction simplification&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(1 = 2 AND b)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Arithmetic simplification&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x * 1&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Case simplification&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CASE WHEN true THEN x ELSE y END&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Equal or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; simplification&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a = b OR (a IS NULL AND b IS NULL)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a IS NOT DISTINCT FROM b&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Distributivity&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(x AND b) OR (x AND c) OR (x AND d)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x AND (b OR c OR d)&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Like optimization&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regexp_matches(c, &#39;^Prefix&#39;)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE &#39;Prefix%&#39;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;filter-pull-up--filter-pushdown&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#filter-pull-up--filter-pushdown&quot;&gt;Filter Pull-Up &amp;amp; Filter Pushdown&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;em&gt;Filter Pushdown&lt;/em&gt; was explained briefly above. &lt;em&gt;Filter Pull-Up&lt;/em&gt; is also important to identify cases where a filter can be applied on columns in other tables. For example, the query below scans column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; from both &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t2&lt;/code&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1.a&lt;/code&gt; has a filter, but in the presence of the equality condition, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t2.a&lt;/code&gt; can have the same filter. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This can be optimized to:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Filter Pull-Up&lt;/em&gt; pulls up the filter &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1.a = 50&lt;/code&gt; above the join, and when the filter is pushed down again, the optimizer rule recognizes the filter can be applied to both columns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1.a&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t2.a&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;in-clause-rewriter&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#in-clause-rewriter&quot;&gt;IN Clause Rewriter&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If there is a filter with an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; clause, sometimes it can be re-written so execution is more efficient. Some examples are below:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Original&lt;/th&gt;
      &lt;th&gt;Optimized&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c1 IN (1)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c1 = 1&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c1 IN (3, 4, 5)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c1 &amp;gt;= 3 AND c1 &amp;lt;= 5&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In addition, the &lt;em&gt;IN Clause Rewriter&lt;/em&gt; will transform expensive &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; expressions into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MARK&lt;/code&gt; joins. If a query has an expression like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c1 IN (x1, ..., xn)&lt;/code&gt; where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; is quite large, it can be expensive to evaluate this expression for every row in the table. The runtime would be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(n * m)&lt;/code&gt; where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; is the number of rows and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt; is the length of the list. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; clause rewriter will transform the expression into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT c1 FROM t1, VALUES (x1, ..., xn) t(c0) WHERE c1 = c0&lt;/code&gt; turning the expression into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HASH&lt;/code&gt; join that can complete in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(n + m)&lt;/code&gt; time!&lt;/p&gt;
      &lt;h3 id=&quot;join-order-optimizer&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#join-order-optimizer&quot;&gt;Join Order Optimizer&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;em&gt;Join Order Optimizer&lt;/em&gt; can provide an enormous performance benefit by limiting the number of intermediate tuples that are processed between joins. By processing fewer intermediate tuples, the query can execute faster.&lt;/p&gt;
      &lt;h3 id=&quot;statistics-propagation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#statistics-propagation&quot;&gt;Statistics Propagation&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;em&gt;Statistics Propagation&lt;/em&gt; is another optimization that works even when the state of the data changes. By traversing the query plan and keeping note of all equality join conditions, the Statistics Propagation optimizer can create new filters by inspecting the statistics of the columns that are eventually joined. For example, suppose &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1.a&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t2.a&lt;/code&gt; will be joined with the equality condition &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1.a = t2.a&lt;/code&gt;.  If our internal statistics tell us &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t1.a&lt;/code&gt; has a maximum value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;50&lt;/code&gt; and a minimum value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;25&lt;/code&gt;, the optimizer can create a new filter when scanning table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t2&lt;/code&gt;. The filter would be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t2.a &amp;gt;= 25 AND t2.a &amp;lt;= 50&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;reorder-filters&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#reorder-filters&quot;&gt;Reorder Filters&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;If there are multiple filters on a column, the order in which these filters are executed also becomes important. It&#39;s best to execute the most efficient filters first, saving execution of expensive filters for later. For example, DuckDB can evaluate equality very quickly. So for a query like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;... WHERE a = 50 AND md5(b) LIKE &#39;%d77%&#39;&lt;/code&gt;, the optimizer will tell DuckDB to evaluate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a = 50&lt;/code&gt; on every column first. If the value in column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; passes the check &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a = 50&lt;/code&gt;, DuckDB will evaluate the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;md5&lt;/code&gt; hash for the values in column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/11/14/optimizers.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A well-written optimizer can provide significant performance improvements when allowed to optimize freely. Not only can the optimizer apply the many optimization rules a human might naturally miss, an optimizer can respond to changes in the data. Some optimizations can result in a performance improvement of 100×, which might be the difference when deciding to use analytical system &lt;em&gt;A&lt;/em&gt; vs. analytical system &lt;em&gt;B&lt;/em&gt;. With DuckDB, all optimization rules are applied automatically to every query, so you can continually enjoy the benefits. Hopefully this blog post has convinced you to consider the optimizer next time you hear about the next database that has everyone&#39;s ears burning.&lt;/p&gt;

</description><link>https://duckdb.org/2024/11/14/optimizers.html</link><guid isPermaLink="false">https://duckdb.org/2024/11/14/optimizers.html</guid><pubDate>Thu, 14 Nov 2024 00:00:00 GMT</pubDate><author>Tom Ebergen</author></item><item><title>Analytics-Optimized Concurrent Transactions</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB employs unique analytics-optimized optimistic multi-version concurrency control techniques. These allow DuckDB to perform large-scale in-place updates efficiently.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
  &lt;p&gt;This is the second post on DuckDB&#39;s ACID support. If you have not read the first post, &lt;a href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html&quot;&gt;Changing Data with Confidence and ACID&lt;/a&gt;, it may be a good idea to start there.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In our &lt;a href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html&quot;&gt;previous post&lt;/a&gt;, we have discussed why changes to data are much saner if the formal “ACID” transaction properties hold. A data system should not allow importing “half” a CSV file into a table because of some unexpected &lt;a href=&quot;https://duckdb.org/2024/10/09/analyzing-open-government-data-with-duckplyr.html&quot;&gt;string in line 431,741&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ensuring the ACID properties of transactions &lt;a href=&quot;https://duckdb.org/docs/stable/connect/concurrency.html&quot;&gt;under concurrency&lt;/a&gt; is very challenging and one of the “holy grails” of databases. DuckDB implements advanced methods for concurrency control and logging. In this post, we describe DuckDB&#39;s Multi-Version Concurrency (MVCC) and Write-Ahead-Logging (WAL) schemes that are specifically designed for efficiently ensuring the transactional guarantees for analytical use cases under concurrent workloads.&lt;/p&gt;
      &lt;h2 id=&quot;concurrency-control&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html#concurrency-control&quot;&gt;Concurrency Control&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;Pessimistic Concurrency Control&lt;/strong&gt;. Traditional database systems use locks to manage concurrency. A transaction obtains locks in order to ensure that (a) no other transaction can see its uncommitted changes, and (b) it does not see uncommitted changes of other transactions. Locks need to be obtained both when &lt;strong&gt;reading&lt;/strong&gt; (shared locks) and when &lt;strong&gt;writing&lt;/strong&gt; (exclusive locks). When a different transaction tries to read data that has been written to by another transaction – it must wait for the other transaction to complete and release its exclusive lock on the data. This type of concurrency control is called &lt;strong&gt;pessimistic&lt;/strong&gt;, because locks are always obtained, even if there are no conflicts between transactions.&lt;/p&gt;

&lt;p&gt;This strategy works well for transactional workloads. These workloads consist of small transactions that read or modify a few rows. A typical transaction only locks a few rows, and keeps those rows locked only for a short period of time. For analytical workloads, on the other hand, this strategy does not work well. These workloads consist of large transactions that read or modify large parts of the table. An analytical transaction executed in a system that uses pessimistic concurrency control will therefore lock many rows, and keep those rows locked for a long period of time, preventing other transactions from executing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Optimistic Concurrency Control&lt;/strong&gt;. DuckDB uses a different approach to manage concurrency conflicts. Transactions do not hold locks – they can always read and write to any row in any table. When a conflict occurs and multiple transactions try to write to the same row at the same time – one of the conflicting transactions is instead aborted. The aborted transaction can then be retried if desired. This type of concurrency control is called &lt;strong&gt;optimistic&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In case there are never any concurrency conflicts – this strategy is very efficient as we have not unnecessarily slowed down transactions by pessimistically grabbing locks. This strategy works well for analytical workloads – as read-only transactions can never conflict with one another, and multiple writers that modify the same rows are rare in these workloads.&lt;/p&gt;
      &lt;h2 id=&quot;multi-version-concurrency-control&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html#multi-version-concurrency-control&quot;&gt;Multi-Version Concurrency Control&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In an optimistic concurrency control model – multiple transactions can read and make changes to the same tables at the same time. We have to ensure these transactions cannot see each others&#39; &lt;em&gt;half-done&lt;/em&gt; changes in order to maintain ACID isolation. A well-known technique to achieve this is &lt;a href=&quot;https://en.wikipedia.org/wiki/Multiversion_concurrency_control&quot;&gt;Multi-Version Concurrency Control (MVCC)&lt;/a&gt;. MVCC works by keeping &lt;strong&gt;multiple versions&lt;/strong&gt; of modified rows. When a transaction modifies a row – we can create a copy of that row and modify that instead. This allows other transactions to keep on reading the original version of the row. This allows for each transaction to see their own, consistent state of the database. Often that state is the &quot;version&quot; that existed when the transaction was started. MVCC is widely used in database systems, for example &lt;a href=&quot;https://www.postgresql.org/docs/current/mvcc-intro.html&quot;&gt;PostgreSQL also uses MVCC&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;DuckDB implements MVCC using a technique inspired by the paper &lt;a href=&quot;https://15721.courses.cs.cmu.edu/spring2019/papers/04-mvcc2/p677-neumann.pdf&quot;&gt;“Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems”&lt;/a&gt; by the one and only &lt;a href=&quot;https://en.wikipedia.org/wiki/Thomas_Neumann&quot;&gt;Thomas Neumann&lt;/a&gt;. This MVCC implementation works by maintaining a list of previous versions to each row in a table. Transactions will update the table data in-place, but will save the previous version of the updated row in the undo buffers. Below is an illustrated example.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- add 5 to Sally&#39;s balance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; Accounts &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Balance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Balance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Sally&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/mvcc/rowbasedmvcc.png&quot; alt=&quot;Row-Based MVCC&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;When reading a row, a transaction will first check if there is version information for that row. If there is none, which is the common case, the transaction can read the original data. If there is version information, the transaction has to compare the transaction number at the transaction&#39;s start time with those in the undo buffers and pick the right version to read.&lt;/p&gt;
      &lt;h2 id=&quot;efficient-mvcc-for-analytics&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html#efficient-mvcc-for-analytics&quot;&gt;Efficient MVCC for Analytics&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The above approach works well for transactional workloads where individual rows are changed frequently. For &lt;em&gt;analytical&lt;/em&gt; use cases, we observe a very different usage pattern: changes are much more “bulky” and they often only affect a subset of columns. For example, we do not usually delete individual rows but instead delete all rows matching a pattern, e.g.:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2010-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We also commonly bulk update columns, e.g., to fix the evergreen annoyance of people using nonsensical in-domain values to express &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; people &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;-99&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If every row has version information, such bulk changes create a &lt;em&gt;huge&lt;/em&gt; amount of entries in the undo buffers, which consume a lot of memory and are inefficient to operate on and read from.&lt;/p&gt;

&lt;p&gt;There is also an added complication – the original approach relies on performing &lt;em&gt;in-place updates&lt;/em&gt;. While we can efficiently perform in-place updates on uncompressed data, this is not possible when data is compressed. As DuckDB &lt;a href=&quot;https://duckdb.org/2022/10/28/lightweight-compression&quot;&gt;keeps data compressed, both on-disk and in-memory&lt;/a&gt;, in-place updates cannot be performed.&lt;/p&gt;

&lt;p&gt;In order to address these issues – DuckDB instead stores &lt;strong&gt;bulk version information&lt;/strong&gt; on a per-column basis. For every batch of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2048&lt;/code&gt; rows, a single version information entry is stored. The version information stores the changes made to the data, instead of the old data, as we cannot modify the original data in-place. Instead, any changes made to the data are flushed to disk during a checkpoint. Below is an illustrated example.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- add 20% interest to all accounts&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; Accounts &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Balance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Balance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Balance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/mvcc/columnbasedmvcc.png&quot; alt=&quot;Column-Based MVCC&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;One beautiful aspect of this undo buffer scheme is that it is largely performance-transparent: if no changes are made, there are no extra computational cost associated with providing support for transactions. To the best of our knowledge, DuckDB is the &lt;em&gt;only transactional data management system that is optimized for bulk changes to data&lt;/em&gt; that are common in analytical use cases. But even with changes present, our transaction scheme is very fast for the kind of transactions that we expect for analytical use cases.&lt;/p&gt;
      &lt;h3 id=&quot;benchmarks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html#benchmarks&quot;&gt;Benchmarks&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Here is a small experiment, comparing DuckDB 1.1.0, &lt;a href=&quot;https://www.tableau.com/products/new-features/hyper&quot;&gt;HyPer&lt;/a&gt; 9.1.0, SQLite 3.43.2, and PosgreSQL 14.13 on a recent MacBook Pro, showing some of the effects that an OLAP-optimized transaction scheme will have. We should note that HyPer implements the MVCC scheme from the Neumann paper mentioned above. SQLite does not actually implement MVCC, it is mostly included as a comparison point.&lt;/p&gt;

&lt;p&gt;We create two tables with either 1 or 100 columns, each with 10 million rows, containing the integer values 1-100 repeating.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvcc_test_1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvcc_test_1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;generate_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;generate_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvcc_test_100&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;j1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j99&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvcc_test_100&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;generate_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;generate_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We then run three transactions on both tables that increment a single column, with an increasing number of affected rows, 1%, 10% and 100%:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; mvcc_test_&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; mvcc_test_&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; mvcc_test_&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For the &lt;strong&gt;single-column case&lt;/strong&gt;, there should not be huge differences between using a row-major or a column-major concurrency control scheme, and indeed the results show this:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;1 Column&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;1%&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;10%&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;100%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.07&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SQLite&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.21&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.25&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.61&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;HyPer&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.66&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.28&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.37&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PostgreSQL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.44&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.48&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.07&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Changing more rows took more time. The rows are small, each row only contain a single value. DuckDB and HyPer, having more modern MVCC scheme based on undo buffers as outlined above, are generally much faster than PostgreSQL.
SQLite is doing well, but of course it does not have any MVCC. Timings increase roughly 10× as the amount of rows changed is increased tenfold. So far so good.&lt;/p&gt;

&lt;p&gt;For the &lt;strong&gt;100 column case&lt;/strong&gt;, results look drastically different:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;100 Columns&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;1%&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;10%&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;100%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.07&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SQLite&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.51&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.79&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12.93&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;HyPer&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.66&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.06&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;61.54&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PostgreSQL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.42&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.45&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;50.05&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Recall that here we are changing a single column out of 100, a common use case in wrangling analytical data sets. Because DuckDB&#39;s MVCC scheme is &lt;em&gt;designed&lt;/em&gt; for those use cases, it shows exactly the same runtime as in the single-column experiment above. In SQLite, there is a clear impact of the larger row size on the time taken to complete the updates even without MVCC. HyPer and PostgreSQL also show much larger, up to 100× (!) slowdowns as the amount of changed rows is increased.&lt;/p&gt;

&lt;p&gt;This neatly brings us to checkpointing.&lt;/p&gt;
      &lt;h2 id=&quot;write-ahead-logging-and-checkpointing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html#write-ahead-logging-and-checkpointing&quot;&gt;Write-Ahead Logging and Checkpointing&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Any data that&#39;s not written to disk but instead still lingers in CPU caches or main memory will be lost in case the operating system crashes or if power is lost. To guarantee durability of changes in the presence of those adverse events, DuckDB needs to &lt;em&gt;ensure that any committed changes are written to persistent storage&lt;/em&gt;. However, changes in a transaction can be scattered all over potentially large tables, and fully writing them to disk can be quite slow, especially if it has to happen before any transaction can commit. Also, we don&#39;t yet know if we actually want to persist a change, we may encounter a failure in the very process of committing.&lt;/p&gt;

&lt;p&gt;The traditional approach of transactional data management systems to balance the requirement of writing changes to persistent storage with the requirement of not taking forever is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Write-ahead_logging&quot;&gt;write-ahead log (WAL)&lt;/a&gt;. The WAL can be thought of as a log file of all changes to the database. On each transaction commit, its changes are written to the WAL. On restart, the database files are re-loaded from disk, the changes in the WAL are re-applied (if present), and things happily continue.
After some amount of changes, the changes in the WAL need to be physically applied to the table, a process known as “checkpointing”. Afterward, the WAL entries can be discarded, a process known as “truncating”. This scheme ensures that changes persist even if a crash occurs or power is lost immediately after a commit.&lt;/p&gt;

&lt;p&gt;DuckDB implements write-ahead logging and you may have seen a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.wal&lt;/code&gt; file appearing here and there. Checkpointing normally happens &lt;em&gt;automatically&lt;/em&gt; whenever the WAL file reached a limit, by default 16 MB but this can be adjusted with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;checkpoint_threshold&lt;/code&gt; setting. Checkpoints also automatically happen at database shutdown. Checkpoints can also be &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/checkpoint.html&quot;&gt;explicitly triggered&lt;/a&gt; with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CHECKPOINT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FORCE CHECKPOINT&lt;/code&gt; commands, the difference being that the latter will abort (rollback) any active transactions to ensure the checkpoing is happening &lt;em&gt;right now&lt;/em&gt; while the former will wait.&lt;/p&gt;

&lt;p&gt;DuckDB explicitly calls the &lt;a href=&quot;https://pubs.opengroup.org/onlinepubs/009695399/functions/fsync.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fsync()&lt;/code&gt; system call&lt;/a&gt; to make sure any WAL entries will be forced to be written to persistent storage, ignoring the many caches on the way. This is &lt;em&gt;necessary&lt;/em&gt; because those caches may also be lost in the event of, e.g., power failure, so it&#39;s no use to only write log entries to the WAL if they end up not being actually written to storage because the operating system or the disk decided that it was better to wait for performance reasons. However, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fsync()&lt;/code&gt; does take some time, and while it&#39;s generally considered bad practice, there are systems out there that don&#39;t do this at all or not by default in order to boast about more transactions per second.&lt;/p&gt;

&lt;p&gt;In DuckDB, even bulk loads such as loading large files into tables (e.g., using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/copy.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; statement&lt;/a&gt;) are fully transactional. This means you can do something like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TRANSACTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;many_people.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; people &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;-99&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1_000_000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ELSE&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;expected 1m rows&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This transaction creates a table, copies a large CSV file into the table, and then updates the table to replace a magic value. Finally, a check is performed to see if there is the expected number of rows in the table. All this is bound together into a &lt;em&gt;single transaction&lt;/em&gt;. If anything goes wrong at any point in the process or the check fails, the transaction will be aborted and zero changes to the database will have happened, the table will not even exist. This is great because it allows implementing all-or-nothing semantics for complex loading tasks, possibly into many tables.&lt;/p&gt;

&lt;p&gt;However, logging large changes is a problem. Imagine the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;many_people.csv&lt;/code&gt; file being large, say ten gigabytes. As discussed, all changes are written to the WAL and eventually checkpointed. The changes in the file are large enough to immediately trigger a checkpoint. So now we&#39;re first writing ten gigabytes to the WAL, and then reading them again, and then writing them again to the database file. Instead of reading ten and writing ten, we have read twenty and written twenty. This is not ideal, but rather than allowing to bypass transactions for bulk loads, DuckDB will instead &lt;em&gt;optimistically write large changes to new blocks in the database file directly&lt;/em&gt;, and merely add a reference to the WAL. On commit, these new blocks are added to the table. On rollback, the blocks are marked as free space. So while this can lead to the database file pointlessly increasing in size if transactions are aborted, the common case will benefit greatly. Again, this means that users experience near-zero-cost transactionality.&lt;/p&gt;
      &lt;h2 id=&quot;more-experiments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html#more-experiments&quot;&gt;More Experiments&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Making concurrency control and write-ahead looking work correctly in the face of failure is very challenging. Software engineers are biased towards the “happy path”, where everything works as intended. The well-known &lt;a href=&quot;https://www.tpc.org/TPC_Documents_Current_Versions/pdf/TPC-H_v3.0.1.pdf&quot;&gt;TPC-H benchmark&lt;/a&gt; actually contains tests that stress concurrency and logging schemes (Section 3.5.4, “Durability Tests”). Our previous blog post also &lt;a href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#acid-tests&quot;&gt;implemented this test and DuckDB passed&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In addition, we also defined our own, even more challenging &lt;a href=&quot;https://github.com/hannes/duckdb-tpch-power-test/blob/main/check-invariant.py&quot;&gt;test for durability&lt;/a&gt;: we run the TPC-H refresh sets one-by-one, in a sub-process. The sub-process reports the last commited refresh. As they are run, after a random (short) time interval, that sub-process is being killed (using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SIGKILL&lt;/code&gt;). Then, DuckDB is restarted, it will likely start recovering from WAL and then continue with the refresh sets. Because of the random time interval, it is likely that DuckDB also gets killed during WAL recovery. This of course should not have any impact on the contents of the database. Finally, we have pre-computed the correct result after running 4000 refresh sets using DuckDB, and after all is set and done we check if there are any differences. There were none, luckily.&lt;/p&gt;

&lt;p&gt;To stress our implementation further, we have repeated this experiment on a special file system, &lt;a href=&quot;https://github.com/dsrhaslab/lazyfs&quot;&gt;LazyFS&lt;/a&gt;. This &lt;a href=&quot;https://en.wikipedia.org/wiki/Filesystem_in_Userspace&quot;&gt;FUSE&lt;/a&gt; file system is &lt;a href=&quot;https://dl.acm.org/doi/10.14778/3681954.3681980&quot;&gt;specifically designed&lt;/a&gt; to help uncover bugs in database systems by – among other things – not properly flushing changes to disk using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fsync()&lt;/code&gt;. In our LazyFS configuration, any change that is written to a file is discarded &lt;em&gt;unless&lt;/em&gt; sync-ed, which also happens if a file is closed. So in our experiment where we kill the database any un-sync-ed entries in the WAL would be lost. We&#39;ve re-run our durability tests described above on LazyFS and are also &lt;strong&gt;happy to report that no issues were found&lt;/strong&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this post, we described DuckDB&#39;s approaches to concurrency control and write-ahead logging. Of course, we are constantly working on improving them. One nasty failure mode that can appear in real-world systems are partial (“torn”) writes to files, where only parts of write requests actually make it to the file. Luckily, LazyFS can be configured to be even more hostile, for example failing read and write system calls entirely, returning partial or wrong data, or only partially writing the data to disk. We plan to expand our experimentation on this, to make sure DuckDB&#39;s transaction handling is as bullet-proof as it can be.&lt;/p&gt;

&lt;p&gt;And who knows, maybe we even dare to unleash the famous &lt;a href=&quot;https://aphyr.com/about&quot;&gt;Kyle&lt;/a&gt; of &lt;a href=&quot;https://jepsen.io/&quot;&gt;Jepsen&lt;/a&gt; on DuckDB at some point.&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/30/analytics-optimized-concurrent-transactions.html</guid><pubDate>Wed, 30 Oct 2024 00:00:00 GMT</pubDate><author>Mark Raasveldt and Hannes Mühleisen</author></item><item><title>Fast Top N Aggregation and Filtering with DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Find the top N values or filter to the latest N rows more quickly and easily with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; parameter in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_by&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; aggregate functions.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;introduction-to-top-n&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#introduction-to-top-n&quot;&gt;Introduction to Top N&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A common pattern when analyzing data is to look for the rows of data that are the highest or lowest in a particular metric.
When interested in the highest or lowest &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; rows in an entire dataset, SQL&#39;s standard &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt; clauses will sort by the metric of interest and only return &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; rows.
For example, using the scale factor 1 (SF1) data set of the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/tpch.html&quot;&gt;TPC-H benchmark&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; tpch&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; tpch&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Generate an example TPC-H dataset&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dbgen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Return the most recent 3 rows by l_shipdate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_orderkey&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_partkey&lt;/th&gt;
      &lt;th&gt;…&lt;/th&gt;
      &lt;th&gt;l_shipmode&lt;/th&gt;
      &lt;th&gt;l_comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;354528&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6116&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;MAIL&lt;/td&gt;
      &lt;td&gt;wake according to the u&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;413956&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16402&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;SHIP&lt;/td&gt;
      &lt;td&gt;usual patterns. carefull&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;484581&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10970&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;TRUCK&lt;/td&gt;
      &lt;td&gt;ccounts maintain. dogged accounts a&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This is useful to quickly get the oldest or newest values in a dataset or to find outliers in a particular metric.&lt;/p&gt;

&lt;p&gt;Another common approach is to query the min/max summary statistics of one or more columns.
This can find outliers, but the row that contains the outlier can be different for each column, so it is answering a different question.
DuckDB&#39;s helpful &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression allows us to calculate the maximum value for all columns.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;The queries in this post make extensive use of DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#from-first-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;-first syntax&lt;/a&gt;.
This allows the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clauses to be swapped, and it even allows omitting the latter entirely.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_orderkey&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_partkey&lt;/th&gt;
      &lt;th&gt;…&lt;/th&gt;
      &lt;th&gt;l_shipmode&lt;/th&gt;
      &lt;th&gt;l_comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;600000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20000&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;TRUCK&lt;/td&gt;
      &lt;td&gt;zzle. slyly&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;However, these two approaches can only answer certain kinds of questions.
There are many scenarios where the goal is to understand the top N values &lt;em&gt;within a group&lt;/em&gt;.
In the first example above, how would we calculate the last 10 shipments from each supplier?
SQL&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt; clause is not able to handle that situation.
Let&#39;s call this type of analysis the top N by group.&lt;/p&gt;

&lt;p&gt;This type of analysis is a common tool for exploring new datasets.
Use cases include pulling the most recent few rows for each group or finding the most extreme few values in a group.
Sticking with our shipment example, we could look at the last 10 shipments of each part number, or find the 5 highest priced orders per customer.&lt;/p&gt;
      &lt;h2 id=&quot;traditional-top-n-by-group&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#traditional-top-n-by-group&quot;&gt;Traditional Top N by Group&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In most databases, the way to filter to the top N within a group is to use a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html&quot;&gt;window function&lt;/a&gt; and a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/with.html&quot;&gt;common table expression (CTE)&lt;/a&gt;.
This approach also works in DuckDB.
For example, this query returns the 3 most recent shipments for each supplier:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked_lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_ranking&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked_lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;my_ranking&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_orderkey&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_partkey&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_suppkey&lt;/th&gt;
      &lt;th&gt;…&lt;/th&gt;
      &lt;th&gt;l_shipmode&lt;/th&gt;
      &lt;th&gt;l_comment&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;my_ranking&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1310688&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;169532&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7081&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;RAIL&lt;/td&gt;
      &lt;td&gt;ully final exc&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;910561&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;194561&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7081&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;SHIP&lt;/td&gt;
      &lt;td&gt;ly bold excuses caj&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4406883&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;179529&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7081&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;RAIL&lt;/td&gt;
      &lt;td&gt;tions. furious&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4792742&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;52095&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7106&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;RAIL&lt;/td&gt;
      &lt;td&gt;onic, ironic courts. final deposits sleep&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4010212&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;122081&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7106&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;MAIL&lt;/td&gt;
      &lt;td&gt;accounts cajole finally ironic instruc&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1220871&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;94596&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7106&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;TRUCK&lt;/td&gt;
      &lt;td&gt;regular requests above t&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In DuckDB, this can be simplified using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/qualify.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; clause&lt;/a&gt;.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; acts like a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clause, but specifically operates on the results of window functions.
By making this adjustment, the CTE can be avoided while returning the same results.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_ranking&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;QUALIFY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;my_ranking&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is certainly a viable approach!
However, what are its weaknesses?
Even though the query is interested in only the 3 most recent shipments, it must sort every shipment just to retrieve those top 3.
Sorting in DuckDB has a complexity of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(kn)&lt;/code&gt; due to DuckDB&#39;s innovative &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html&quot;&gt;Radix sort implementation&lt;/a&gt;, but this is still higher than the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(n)&lt;/code&gt; of &lt;a href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html&quot;&gt;DuckDB&#39;s hash aggregate&lt;/a&gt;, for example.
Sorting is also a memory intensive operation when compared with aggregation.&lt;/p&gt;
      &lt;h2 id=&quot;top-n-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#top-n-in-duckdb&quot;&gt;Top N in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html&quot;&gt;DuckDB 1.1&lt;/a&gt; added a new capability to dramatically simplify and improve performance of top N calculations.
Namely, the functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_by&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; all now accept an optional parameter &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt;.
If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; is greater than 1 (the default), they will return an array of the top values.&lt;/p&gt;

&lt;p&gt;As a simple example, let&#39;s query the most recent (top 3) shipment dates:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_3_shipdates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;top_3_shipdates&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[1998-12-01, 1998-12-01, 1998-12-01]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;top-n-by-column-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#top-n-by-column-in-duckdb&quot;&gt;Top N by Column in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The top N selection can become even more useful thanks to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression once again – we can retrieve the 3 top values in each column.
We can call this a &lt;em&gt;top N by column analysis.&lt;/em&gt;
It is particularly messy to try to do this analysis with ordinary SQL!
You would need a subquery or window function for every single column…
In DuckDB, simply:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;top_3_\0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;top_3_l_orderkey&lt;/th&gt;
      &lt;th&gt;top_3_l_partkey&lt;/th&gt;
      &lt;th&gt;…&lt;/th&gt;
      &lt;th&gt;top_3_l_shipmode&lt;/th&gt;
      &lt;th&gt;top_3_l_comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[600000, 600000, 599975]&lt;/td&gt;
      &lt;td&gt;[20000, 20000, 20000]&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;[TRUCK, TRUCK, TRUCK]&lt;/td&gt;
      &lt;td&gt;[zzle. slyly, zzle. quickly bold a, zzle. pinto beans boost slyly slyly fin]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;top-n-by-group-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#top-n-by-group-in-duckdb&quot;&gt;Top N by Group in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Armed with the new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; parameter, how can we speed up a top N by group analysis?&lt;/p&gt;

&lt;p&gt;Want to cut to the chase and see the final output?
&lt;a href=&quot;https://duckdb.org/2024/10/25/topn.html#the-final-top-n-by-group-query&quot;&gt;Feel free to skip ahead!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We will take advantage of three other DuckDB SQL features to make this possible:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#max_byarg-val-n&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; function&lt;/a&gt; (also known as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_max&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/unnest.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unnest&lt;/code&gt; function&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Automatically packing an entire row into a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/struct.html#creating-structs&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; column&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt; function will return the max (or now the max N!) of a specific column.
In contrast, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; function will find the maximum value in a column, and then retrieve a value from the same row, but a different column.
For example, this query will return the ids of the 3 most recently shipped orders for each supplier:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent_orders&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_suppkey&lt;/th&gt;
      &lt;th&gt;recent_orders&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2992&lt;/td&gt;
      &lt;td&gt;[233573, 3597639, 3060227]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8516&lt;/td&gt;
      &lt;td&gt;[4675968, 5431174, 4626530]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3205&lt;/td&gt;
      &lt;td&gt;[3844610, 4396966, 3405255]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2152&lt;/td&gt;
      &lt;td&gt;[1672000, 4209601, 3831138]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1880&lt;/td&gt;
      &lt;td&gt;[4852999, 2863747, 1650084]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; function is an aggregate function, so it takes advantage of DuckDB&#39;s fast hash aggregation rather than sorting.
Instead of sorting by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_shipdate&lt;/code&gt;, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; function scans through the dataset just once and keeps track of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; highest &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_shipdate&lt;/code&gt; values.
It then returns the order id that corresponds with each of the most recent shipment dates.
The radix sort in DuckDB must scan through the dataset once per byte, so scanning only once provides a significant speedup.
For example, if sorting by a 64-bit integer, the sort algorithm must loop through the dataset 8 times vs. 1 with this approach!
A simple micro-benchmark is included in the &lt;a href=&quot;https://duckdb.org/2024/10/25/topn.html#performance-comparisons&quot;&gt;Performance Comparisons&lt;/a&gt; section.&lt;/p&gt;

&lt;p&gt;However, this SQL query has a few gaps.
The query returns results as a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; rather than as separate rows.
Thankfully the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unnest&lt;/code&gt; function can split a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; into separate rows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;max_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent_orders&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_suppkey&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;recent_orders&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2576&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;930468&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2576&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2248354&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2576&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3640711&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5559&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4022148&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5559&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1675680&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5559&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4976259&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The next gap is that there is no way to easily see the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_shipdate&lt;/code&gt; associated with the returned &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_orderkey&lt;/code&gt; values.
This query only returns a single column, while typically a top N by group analysis will require the entire row.&lt;/p&gt;

&lt;p&gt;Fortunately, DuckDB allows us to refer to the entire contents of a row as if it were just a single column!
By referring to the name of the table itself (here, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt;) instead of the name of a column, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; function can retrieve all columns.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;max_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent_orders&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_suppkey&lt;/th&gt;
      &lt;th&gt;recent_orders&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5411&lt;/td&gt;
      &lt;td&gt;{&#39;l_orderkey&#39;: 2543618, &#39;l_partkey&#39;: 105410, &#39;l_suppkey&#39;: 5411, …&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5411&lt;/td&gt;
      &lt;td&gt;{&#39;l_orderkey&#39;: 580547, &#39;l_partkey&#39;: 130384, &#39;l_suppkey&#39;: 5411, …&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5411&lt;/td&gt;
      &lt;td&gt;{&#39;l_orderkey&#39;: 3908642, &#39;l_partkey&#39;: 132897, &#39;l_suppkey&#39;: 5411, …&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90&lt;/td&gt;
      &lt;td&gt;{&#39;l_orderkey&#39;: 4529697, &#39;l_partkey&#39;: 122553, &#39;l_suppkey&#39;: 90, …&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90&lt;/td&gt;
      &lt;td&gt;{&#39;l_orderkey&#39;: 4473346, &#39;l_partkey&#39;: 160089, &#39;l_suppkey&#39;: 90, …&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Let&#39;s make that a bit friendlier looking by splitting the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; out into separate columns to match our original dataset.&lt;/p&gt;
      &lt;h3 id=&quot;the-final-top-n-by-group-query&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#the-final-top-n-by-group-query&quot;&gt;The Final Top N by Group Query&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Passing in one more argument to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNNEST&lt;/code&gt; will split this out into separate columns by running recursively.
In this case, that means that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNNEST&lt;/code&gt; will run twice: once to convert each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; into separate rows, and then again to convert each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; into separate columns.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_suppkey&lt;/code&gt; column can also be excluded, since it will automatically be included already.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;max_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;recursive&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent_orders&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_orderkey&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_partkey&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;l_suppkey&lt;/th&gt;
      &lt;th&gt;…&lt;/th&gt;
      &lt;th&gt;l_shipinstruct&lt;/th&gt;
      &lt;th&gt;l_shipmode&lt;/th&gt;
      &lt;th&gt;l_comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1234726&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6875&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6876&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;COLLECT COD&lt;/td&gt;
      &lt;td&gt;FOB&lt;/td&gt;
      &lt;td&gt;cajole carefully slyly fin&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2584193&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;51865&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6876&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;TAKE BACK RETURN&lt;/td&gt;
      &lt;td&gt;TRUCK&lt;/td&gt;
      &lt;td&gt;fully regular deposits at the q&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2375524&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;26875&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6876&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;DELIVER IN PERSON&lt;/td&gt;
      &lt;td&gt;AIR&lt;/td&gt;
      &lt;td&gt;nusual ideas. busily bold deposi&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5751559&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;95626&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8136&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;NONE&lt;/td&gt;
      &lt;td&gt;SHIP&lt;/td&gt;
      &lt;td&gt;ers nag fluffily against the spe&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3103457&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;103115&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8136&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;TAKE BACK RETURN&lt;/td&gt;
      &lt;td&gt;FOB&lt;/td&gt;
      &lt;td&gt;y slyly express warthogs– unusual, e&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5759105&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;178135&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8136&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;COLLECT COD&lt;/td&gt;
      &lt;td&gt;TRUCK&lt;/td&gt;
      &lt;td&gt;es. regular pinto beans haggle.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;This approach can also be useful for the common task of de-duplicating by finding the latest value within a group.
One pattern is to find the current state of a dataset by returning the most recent event in an events table.
Simply use an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; of 1!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We now have a way to use an aggregate function to calculate the top N rows per group!
So, how much more efficient is it?&lt;/p&gt;
      &lt;h2 id=&quot;performance-comparisons&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#performance-comparisons&quot;&gt;Performance Comparisons&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We will compare the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; approach with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; approach for solving the top N by group problem.
We have discussed both queries, but for reference they are repeated below.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
    &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; query:
&lt;/summary&gt;

  &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_ranking&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;QUALIFY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;my_ranking&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;
    &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; query:
&lt;/summary&gt;

  &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;max_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;recursive&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_suppkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/details&gt;

&lt;p&gt;While the main query is running, we will also kick off a background thread to periodically measure DuckDB&#39;s memory use.
This uses the built in table function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb_memory()&lt;/code&gt; and includes information about Memory usage as well as temporary disk usage.
The small Python script used for benchmarking is included below the results.
The machine used for benchmarking was an M1 MacBook Pro with 16 GB RAM.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;SF&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_memory&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Metric&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Improvement&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Default&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Total time&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.58 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.24 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.4×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Default&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Total time&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.15 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.26 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.9×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;36 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Total time&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;36.8 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25.4 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.4×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Default&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Memory usage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.7 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.2 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.5×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Default&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Memory usage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.9 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.5 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.3×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;36 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Memory usage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15.7 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.1 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.9×&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that in each of these situations, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; approach is faster, in some cases nearly 5× faster!
However, as the data grows larger, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; approach begins to weaken relative to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In some cases, the memory use is significantly lower with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; also.
However, the memory use of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; approach becomes more significant as scale increases, because the number of distinct &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_suppkey&lt;/code&gt; values increases linearly with the scale factor.
This increased memory use likely explains the performance decrease, as both algorithms approached the maximum amount of RAM on my machine and began to swap to disk.&lt;/p&gt;

&lt;p&gt;In order to reduce the memory pressure, let&#39;s re-run the scale factor 10 (SF10) benchmark using fewer threads (4 threads and 1 thread).
We continue to use a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_memory&lt;/code&gt; setting of 36 GB.
The prior SF10 results with all 10 threads are included for reference.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;SF&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Threads&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Metric&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Improvement&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Total time&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;36.8 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25.4 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.4×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Total time&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;49.0 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.0 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.3×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Total time&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;115.7 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12.7 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9.1×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Memory usage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15.7 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.1 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.9×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Memory usage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15.9 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.3 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.9×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Memory usage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14.5 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.8 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.1×&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; approach is so computationally efficient that even with 1 thread it is dramatically faster than the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; approach that uses all 10 threads!
Reducing the thread count very effectively lowered the memory use as well (a nearly 10× reduction).&lt;/p&gt;

&lt;p&gt;So, when should we use each?
As with all database things, &lt;em&gt;it depends!&lt;/em&gt;
If memory is constrained, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; may also offer benefits, especially when the thread count is tuned to avoid spilling to disk.
However, if there are approximately as many groups as there are rows, consider &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; since we lose some of the memory efficiency of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; approach.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
    Python Benchmarking Script
&lt;/summary&gt;

  &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;threading&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sleep_seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Starting background thread&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;background_con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_temporary_storage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Profile the memory
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;memory_profile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;background_con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
            FROM duckdb_memory()
            SELECT
                tag,
                round(memory_usage_bytes / (1000000), 0)::bigint AS memory_usage_mb,
                round(temporary_storage_bytes / (1000000), 0)::bigint AS temporary_storage_mb;
            &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total_memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;background_con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
            FROM memory_profile
            select
                sum(memory_usage_mb) AS total_memory_usage_mb,
                sum(temporary_storage_mb) AS total_temporary_storage_mb
            &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Current memory:&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Current temporary_storage:&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;max_memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_temporary_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;max_temporary_storage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Maximum memory:&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Maximum temporary_storage:&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_temporary_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep_seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;results_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;max_memory&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_memory&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;results_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;max_temporary_storage&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_temporary_storage&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;background_con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;query_and_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;set max_memory=&#39;36GB&#39;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;results_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;stop_threads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;background_memory_thread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                      &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop_threads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;background_memory_thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Starting query:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;results_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;results_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_time_seconds&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;stop_threads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;background_memory_thread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results_dict&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;./arg_max_check_duckdb_memory_v3.duckdb&#39;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Begin initial tpch load&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;call dbgen(sf=1);&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    FROM lineitem
    SELECT
        UNNEST(
            max_by(lineitem, l_shipdate, 3),
            recursive := 1
        )
    GROUP BY
        l_suppkey
;&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;max_by_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query_and_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    FROM lineitem
    SELECT
        *,
        row_number() OVER
            (PARTITION BY l_suppkey ORDER BY l_shipdate DESC)
            AS my_ranking
    QUALIFY
        my_ranking &amp;lt;= 3
;&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;qualify_results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query_and_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;max_by_results:&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_by_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;qualify_results:&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qualify_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/details&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/25/topn.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB now offers a convenient way to calculate the top N values of both &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt; aggregate functions, as well as their advanced cousins &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_by&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt;.
They are easy to get started with, and also enable more complex analyses like calculating the top N for all columns or the top N by group.
There are also possible performance benefits when compared with a window function approach.&lt;/p&gt;

&lt;p&gt;We would love to hear about the creative ways you are able to use this new feature!&lt;/p&gt;

&lt;p&gt;Happy analyzing!&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/25/topn.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/25/topn.html</guid><pubDate>Fri, 25 Oct 2024 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>What&#39;s New in the Vector Similarity Search Extension?</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB is another step closer to becoming a vector database! In this post, we show the new performance optimizations implemented in the vector search extension.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;In the &lt;a href=&quot;https://duckdb.org/2024/05/03/vector-similarity-search-vss.html&quot;&gt;previous blog post&lt;/a&gt;, we introduced the DuckDB &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/vss.html&quot;&gt;Vector Similarity Search (VSS) extension&lt;/a&gt;. While the extension is still quite experimental, we figured it would be interesting to dive into the details of some of the new features and improvements that we&#39;ve been working on since the initial release.&lt;/p&gt;
      &lt;h2 id=&quot;indexing-speed-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/23/whats-new-in-the-vss-extension.html#indexing-speed-improvements&quot;&gt;Indexing Speed Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;As previously documented, creating an HNSW (Hierarchical Navigable Small Worlds) index over an already populated table is much more efficient than first creating the index and then inserting into the table. This is because it is much easier to predict how large the index will be if the total amount of rows are known up-front, which makes its possible to divide the work into chunks large enough to distribute over multiple threads. However, in the initial release this work distribution was a bit too coarse-grained as we would only schedule an additional worker thread for each &lt;a href=&quot;https://duckdb.org/docs/stable/internals/storage.html#row-groups&quot;&gt;&lt;em&gt;row group&lt;/em&gt;&lt;/a&gt; (about 120,000 rows by default) in the table.&lt;/p&gt;

&lt;p&gt;We&#39;ve now introduced an extra buffer step in the index creation pipeline which enables more fine-grained work distribution, smarter memory allocation and less contention between worker threads. This results in much higher CPU saturation and a significant speedup when building HNSW indexes in environments with many threads available, regardless of how big or small the underlying table is.&lt;/p&gt;

&lt;p&gt;Another bonus of this change is that we can now emit a progress bar when building the index, which is a nice touch when you still need to wait a while for the index creation to finish (despite the now much better use of system resources!).&lt;/p&gt;
      &lt;h2 id=&quot;new-distance-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/23/whats-new-in-the-vss-extension.html#new-distance-functions&quot;&gt;New Distance Functions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In the initial release of VSS we supported three different distance functions:
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/array.html#array_distancearray1-array2&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_distance&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/array.html#array_cosine_similarityarray1-array2&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_similarity&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/array.html#array_inner_productarray1-array2&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_inner_product&lt;/code&gt;&lt;/a&gt;. However, only the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_distance&lt;/code&gt; function is actually a &lt;em&gt;distance&lt;/em&gt; function in that it returns results closer to 0 when the vectors are similar, and close to 1 when they are dissimilar, in contrast to, e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_similarity&lt;/code&gt; that returns 1 when the vectors are identical. Oops!&lt;/p&gt;

&lt;p&gt;To remedy this we&#39;ve introduced two new distances:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_distance&lt;/code&gt;, equivalent to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1 - array_cosine_simililarity&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_negative_inner_product&lt;/code&gt;equivalent to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-array_inner_product&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These will now be accelerated with the use of the HNSW index instead, making the query patterns and ordering consistent for all supported metrics regardless if you make use of the HNSW index or not. Additionally, if you have an HNSW using, e.g., the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cosine&lt;/code&gt; metric and write a top-k style query using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1 - array_cosine_similarity&lt;/code&gt; as the ranking criterium, the optimizer should be able to normalize the expression to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_distance&lt;/code&gt; and use the index for this function as well.&lt;/p&gt;

&lt;p&gt;For completeness we&#39;ve also added the equivalent distance functions for the dynamically-sized &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/list.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; datatype&lt;/a&gt; (prefixed with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_&lt;/code&gt;) and changed the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;=&amp;gt;&lt;/code&gt; binary operator to now be an alias of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_distance&lt;/code&gt;, matching the semantics of the &lt;a href=&quot;https://github.com/pgvector/pgvector&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pgvector&lt;/code&gt; extension&lt;/a&gt; for PostgreSQL.&lt;/p&gt;
      &lt;h2 id=&quot;index-accelerated-top-k-aggregates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/23/whats-new-in-the-vss-extension.html#index-accelerated-top-k-aggregates&quot;&gt;Index Accelerated &quot;Top-K&quot; Aggregates&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another cool thing that&#39;s happened in core DuckDB since last time is that DuckDB now has extra overloads for the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#min_byarg-val-n&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_by&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#max_byarg-val-n&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt;&lt;/a&gt; aggregate functions (and their aliases &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_min&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_max&lt;/code&gt;)
These new overloads take an optional third &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; argument that specifies the number of top-k (or top-&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;) elements to keep and outputs them into a sorted &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; value. Here&#39;s an example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Create a table with some example data&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vecs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Find the top 3 rows with the vector closest to [2, 2, 2]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;arg_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vecs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vecs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[{&#39;id&#39;: 14, &#39;vec&#39;: [2.0, 2.0, 2.0]}, {&#39;id&#39;: 13, &#39;vec&#39;: [2.0, 1.0, 2.0]}, {&#39;id&#39;: 11, &#39;vec&#39;: [1.0, 2.0, 2.0]}]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Of course, the VSS extension now includes optimizer rules to use to the HNSW index to accelerate these top-k aggregates when the ordering input is a distance function that references an indexed vector column, similarly to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT a FROM b ORDER BY array_distance(a.vec, query_vec) LIMIT k&lt;/code&gt; query pattern that we discussed in the previous blog post. These new overloads allow you to express the same query in a more concise and readable way, while still avoiding the need for a full scan and sort of the underlying table (as long as the table has a matching HNSW index).&lt;/p&gt;
      &lt;h2 id=&quot;index-accelerated-lateral-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/23/whats-new-in-the-vss-extension.html#index-accelerated-lateral-joins&quot;&gt;Index Accelerated &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LATERAL&lt;/code&gt; Joins&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;After running some benchmarking on the initial version of VSS, we realized that even though index-lookups on our HNSW index is really fast (thanks to the &lt;a href=&quot;https://github.com/unum-cloud/usearch&quot;&gt;USearch&lt;/a&gt; library that it is based on!), using DuckDB to search for individual vectors at a time has a lot of latency compared to other solutions. The reasons for this are many and nuanced, but we want to be clear that our choice of HNSW implementation, USearch, is not the bottleneck here as profiling revelead only about 2% of the runtime is actually spent inside of usearch.&lt;/p&gt;

&lt;p&gt;Instead, most of the per-query overhead comes from the fact that DuckDB is just not optimized for &lt;em&gt;point queries,&lt;/em&gt; i.e., queries that only really fetch and process a single row. Because DuckDB is based on a vectorized execution engine, the smallest unit of work is not 1 row but 2,048, and because we expect to crunch through a ton of data, we generally favor spending a lot of time up front to optimize the query plan and pre-allocate large buffers and caches so that everything is as efficient as possible once we start executing. But a lot of this work becomes unneccessary when the actual working set is so small. For example, is it really worthwile to inspect and hash every single element of a constant 768-long query vector to attempt to look for common subexpressions if you know there is only going to be a handful of rows in the result?&lt;/p&gt;

&lt;p&gt;While we have some ideas on how to improve this scenario in the future, we decided to take another approach for now and instead try focus not on our weaknesses, but on our strengths. That is, crunching through a ton of data! So instead of trying to optimize the “1:N”, i.e., “given this one embedding, give me the closes N embeddings” query, what if we instead focused on the “N:M”, “given all these N embeddings, pair them up with the closest M embeddings each”. What would that look like? Well, that would be a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#lateral-joins&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LATERAL&lt;/code&gt; join&lt;/a&gt; of course!&lt;/p&gt;

&lt;p&gt;Basically, we are now able to make use of HNSW indexes to accelerate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LATERAL&lt;/code&gt; joins where the “inner” query looks just like the top-k style queries we normally target, for example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But where the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_vec&lt;/code&gt; array is now a reference to an “outer” join table. The only requirement is for the inner table to have an HNSW index on the vector column matching the distance function. Here&#39;s an example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Set the random seed for reproducibility&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;setseed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Create some example tables&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queries&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Collect the 5 closest items to each query embedding&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matches&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LATERAL&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inner_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;array_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Executing this on my Apple M3 Pro-equipped MacBook with 36 GB memory takes about 10 seconds.&lt;/p&gt;

&lt;p&gt;If we &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN&lt;/code&gt; this query plan, we&#39;ll see a lot of advanced operators:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;explain_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;optimized_only&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXPLAIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;details&gt;
  &lt;summary&gt;
Vanilla query plan (operators and expected cardinalities)
&lt;/summary&gt;

  &lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│         PROJECTION        │
│    ────────────────────   │
│       ~5000000 Rows       │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│       HASH_GROUP_BY       │
│    ────────────────────   │
│       ~5000000 Rows       │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│    ────────────────────   │
│       ~10000000 Rows      │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│    ────────────────────   │
│       ~10000000 Rows      │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│      RIGHT_DELIM_JOIN     │
│    ────────────────────   │
│       ~10000000 Rows      ├──────────────┐
└─────────────┬─────────────┘              │
┌─────────────┴─────────────┐┌─────────────┴─────────────┐
│         SEQ_SCAN          ││         HASH_JOIN         │
│    ────────────────────   ││    ────────────────────   │
│        ~10000 Rows        ││       ~10000000 Rows      ├──────────────┐
└───────────────────────────┘└─────────────┬─────────────┘              │
                             ┌─────────────┴─────────────┐┌─────────────┴─────────────┐
                             │         PROJECTION        ││         DUMMY_SCAN        │
                             │    ────────────────────   ││                           │
                             │       ~10000000 Rows      ││                           │
                             └─────────────┬─────────────┘└───────────────────────────┘
                             ┌─────────────┴─────────────┐
                             │           FILTER          │
                             │    ────────────────────   │
                             │       ~10000000 Rows      │
                             └─────────────┬─────────────┘
                             ┌─────────────┴─────────────┐
                             │         PROJECTION        │
                             │    ────────────────────   │
                             │       ~50000000 Rows      │
                             └─────────────┬─────────────┘
                             ┌─────────────┴─────────────┐
                             │           WINDOW          │
                             └─────────────┬─────────────┘
                             ┌─────────────┴─────────────┐
                             │         PROJECTION        │
                             │    ────────────────────   │
                             │       ~50000000 Rows      │
                             └─────────────┬─────────────┘
                             ┌─────────────┴─────────────┐
                             │       CROSS_PRODUCT       ├──────────────┐
                             └─────────────┬─────────────┘              │
                             ┌─────────────┴─────────────┐┌─────────────┴─────────────┐
                             │         SEQ_SCAN          ││         DELIM_SCAN        │
                             │    ────────────────────   ││    ────────────────────   │
                             │        ~10000 Rows        ││         ~5000 Rows        │
                             └───────────────────────────┘└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;While this plan looks very complicated, the most worrysome among these operators is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CROSS_PRODUCT&lt;/code&gt; towards the bottom of the plan, which blows up the expected cardinality and is a sign that we are doing a lot of work that we probably don&#39;t want to do. However, if we create an HNSW index on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;items&lt;/code&gt; table using&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_hnsw_idx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;HNSW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and re-run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN&lt;/code&gt;, we get this plan instead:&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
Query plan with HNSW index (operators and expected cardinalities)
&lt;/summary&gt;

  &lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│         PROJECTION        │
│    ────────────────────   │
│        ~50000 Rows        │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│       HASH_GROUP_BY       │
│    ────────────────────   │
│        ~50000 Rows        │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│    ────────────────────   │
│        ~50000 Rows        │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│    ────────────────────   │
│        ~50000 Rows        │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│    ────────────────────   │
│        ~50000 Rows        │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│      HNSW_INDEX_JOIN      │
│    ────────────────────   │
│        ~50000 Rows        │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         SEQ_SCAN          │
│    ────────────────────   │
│        ~10000 Rows        │
└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;We can see that this plan is drastically simplified, but most importantly, the new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW_INDEX_JOIN&lt;/code&gt; operator replaces the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CROSS_PRODUCT&lt;/code&gt; node that was there before and the estimated cardinality went from 5,000,000 to 50,000! Executing this query now takes about 0.15 seconds. That&#39;s an almost 66× speedup!&lt;/p&gt;

&lt;p&gt;This optimization was just recently added to the VSS extension, so if you&#39;ve already installed &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; for DuckDB v1.1.2, run the following command to get the latest version:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; EXTENSIONS &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/23/whats-new-in-the-vss-extension.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;That&#39;s all for this time folks! We hope you&#39;ve enjoyed this update on the DuckDB Vector Similarity Search extension. While this update has focused a lot on new features and improvements such as faster indexing, additional distance functions and more optimizer rules, we&#39;re still working on improving some of the limitations mentioned in the previous blog post. We hope to have more to share related to custom indexes and index-based optimizations soon! If you have any questions or feedback, feel free to reach out to us on the &lt;a href=&quot;https://github.com/duckdb/duckdb-vss&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb-vss&lt;/code&gt; GitHub repository&lt;/a&gt; or on the &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;DuckDB Discord&lt;/a&gt;. Hope to see you around!&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/23/whats-new-in-the-vss-extension.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/23/whats-new-in-the-vss-extension.html</guid><pubDate>Wed, 23 Oct 2024 00:00:00 GMT</pubDate><author>Max Gabrielsson</author></item><item><title>Driving CSV Performance: Benchmarking DuckDB with the NYC Taxi Dataset</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB&#39;s benchmark suite now includes the NYC Taxi Benchmark. We explain how our CSV reader performs on the Taxi Dataset and provide steps to reproduce the benchmark.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;The &lt;a href=&quot;https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page&quot;&gt;NYC taxi dataset&lt;/a&gt; is a collection of many years of taxi rides that occurred in New York City. It is a very influential dataset, used for &lt;a href=&quot;https://tech.marksblogg.com/benchmarks.html&quot;&gt;database benchmarks&lt;/a&gt;, &lt;a href=&quot;https://www.r-bloggers.com/2018/01/new-york-city-taxi-limousine-commission-tlc-trip-data-analysis-using-sparklyr-and-google-bigquery-2/&quot;&gt;machine learning&lt;/a&gt;, &lt;a href=&quot;https://www.kdnuggets.com/2017/02/data-science-nyc-taxi-trips.html&quot;&gt;data visualization&lt;/a&gt;, and more.&lt;/p&gt;

&lt;p&gt;In 2022, the data provider has decided to distribute the dataset as a series of Parquet files instead of CSV files. Performance-wise, this is a wise choice, as Parquet files are much smaller than CSV files, and their native columnar format allows for fast execution directly on them. However, this change hinders the number of systems that can natively load the files.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&quot;https://tech.marksblogg.com/billion-nyc-taxi-rides-redshift.html&quot;&gt;“Billion Taxi Rides in Redshift”&lt;/a&gt; blog post, a new database benchmark is proposed to evaluate the performance of aggregations over the taxi dataset. The dataset is also joined and denormalized with other datasets that contain information about the weather, cab types, and pickup/dropoff locations. It is then stored as multiple compressed, gzipped CSV files, each containing 20 million rows.&lt;/p&gt;
      &lt;h2 id=&quot;the-taxi-data-set-as-csv-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#the-taxi-data-set-as-csv-files&quot;&gt;The Taxi Data Set as CSV Files&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Since DuckDB is well-known for its &lt;a href=&quot;https://x.com/jmduke/status/1820593783005667459&quot;&gt;CSV reader performance&lt;/a&gt;, we were intrigued to explore whether the loading process of this benchmark could help us identify new performance bottlenecks in our CSV loader. This curiosity led us on a journey to generate these datasets and analyze their performance in DuckDB. According to the recent study conducted on the AWS RedShift fleet, &lt;a href=&quot;https://assets.amazon.science/24/3b/04b31ef64c83acf98fe3fdca9107/why-tpc-is-not-enough-an-analysis-of-the-amazon-redshift-fleet.pdf&quot;&gt;CSV files are the most used external source data type in S3&lt;/a&gt;, and 99% of them are gzipped. Therefore, the fact that the proposed benchmark also used split gzipped files caught my attention.&lt;/p&gt;

&lt;p&gt;In this blog post, we&#39;ll guide you through how to run this benchmark in DuckDB and discuss some lessons learned and future ideas for our CSV Reader. The dataset used in this benchmark is &lt;a href=&quot;https://github.com/pdet/taxi-benchmark/blob/0.1/files.txt&quot;&gt;publicly available&lt;/a&gt;. The dataset is partitioned and distributed as a collection of 65 gzipped CSV files, each containing 20 million rows and totaling up to 1.8 GB per file. The total dataset is 111 GB compressed and 518 GB uncompressed. We also provide more details on how we generated this dataset and highlight the differences between the dataset we distribute and the original one described in the &lt;a href=&quot;https://tech.marksblogg.com/billion-nyc-taxi-rides-redshift.html&quot;&gt;“Billion Taxi Rides in Redshift”&lt;/a&gt; blog post.&lt;/p&gt;
      &lt;h2 id=&quot;reproducing-the-benchmark&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#reproducing-the-benchmark&quot;&gt;Reproducing the Benchmark&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Doing fair benchmarking is a &lt;a href=&quot;https://pdet.github.io/assets/papers/benchmarking.pdf&quot;&gt;difficult problem&lt;/a&gt;, especially when the data, queries, and results used for the benchmark are not easy to access and run. We have made the benchmark discussed in this blog post easy to run by providing scripts available in the &lt;a href=&quot;https://github.com/pdet/taxi-benchmark&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;taxi-benchmark&lt;/code&gt; GitHub repository&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This repository contains three main Python scripts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;generate_prepare_data.py&lt;/code&gt;: Downloads all necessary files and prepares them for the benchmark.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;benchmark.py&lt;/code&gt;: Runs the benchmark and performs result verification.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;analyse.py&lt;/code&gt;: Analyzes the benchmark results and produces some of the insights discussed in this blog post.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The benchmark is not intended to be flawless – no benchmark is. However, we believe that sharing these scripts is a positive step, and we welcome any contributions to make them cleaner and more efficient.&lt;/p&gt;

&lt;p&gt;The repository also includes a README file with detailed instructions on how to use it.
This repository will serve as the foundation for the experiments conducted in this blog post.&lt;/p&gt;
      &lt;h3 id=&quot;preparing-the-dataset&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#preparing-the-dataset&quot;&gt;Preparing the Dataset&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To start, you first need to download and prepare the files by executing &lt;a href=&quot;https://github.com/pdet/taxi-benchmark/blob/0.1/generate_prepare_data.py&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python generate_prepare_data.py&lt;/code&gt;&lt;/a&gt;. This will download all 65 files to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./data&lt;/code&gt; folder. Additionally, the files will be uncompressed and combined into a single large file.&lt;/p&gt;

&lt;p&gt;As a result, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./data&lt;/code&gt; folder will have 65 gzipped CSV files (i.e., from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;trips_xaa.csv.gz&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;trips_xcm.csv.gz&lt;/code&gt;) and a single large uncompressed CSV file containing the full data (i.e., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;decompressed.csv&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Our benchmark then run in two different settings:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Over 65 compressed files.&lt;/li&gt;
  &lt;li&gt;Over a single uncompressed file.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once the files have been prepared, you can run the benchmark by running &lt;a href=&quot;https://github.com/pdet/taxi-benchmark/blob/0.1/benchmark.py&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python benchmark.py&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;loading&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#loading&quot;&gt;Loading&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The loading phase of the benchmark runs six times for each benchmark setting. From the first five runs, we take the median loading time. During the sixth run, we collect resource usage data (e.g., CPU usage and disk reads/writes).&lt;/p&gt;

&lt;p&gt;Loading is performed using an in-memory DuckDB instance, meaning the data is not persisted to DuckDB storage and only exists while the connection is active. This is important to note because, as the dataset does not fit in memory and is spilled into a temporary space on disk. The decision to not persist the data has a substantial impact on performance: it makes loading the dataset significantly faster, while querying it will be somewhat slower as &lt;a href=&quot;https://duckdb.org/docs/stable/guides/performance/how_to_tune_workloads.html#persistent-vs-in-memory-tables&quot;&gt;DuckDB will use an uncompressed representation&lt;/a&gt;. We made this choice for the benchmark since our primary focus is on testing the CSV loader rather than the queries.&lt;/p&gt;

&lt;p&gt;Our table schema is defined in &lt;a href=&quot;https://github.com/pdet/taxi-benchmark/blob/0.1/sql/schema.sql&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schema.sql&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;a href=&quot;https://github.com/pdet/taxi-benchmark/blob/0.1/sql/schema.sql&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schema.sql&lt;/code&gt;&lt;/a&gt;.
&lt;/summary&gt;

  &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trips&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;trip_id&lt;/span&gt;                 &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vendor_id&lt;/span&gt;               &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_datetime&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_datetime&lt;/span&gt;        &lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;store_and_fwd_flag&lt;/span&gt;      &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rate_code_id&lt;/span&gt;            &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_longitude&lt;/span&gt;        &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_latitude&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_longitude&lt;/span&gt;       &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_latitude&lt;/span&gt;        &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;passenger_count&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;           &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fare_amount&lt;/span&gt;             &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;extra&lt;/span&gt;                   &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mta_tax&lt;/span&gt;                 &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tip_amount&lt;/span&gt;              &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tolls_amount&lt;/span&gt;            &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ehail_fee&lt;/span&gt;               &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;improvement_surcharge&lt;/span&gt;   &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total_amount&lt;/span&gt;            &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;payment_type&lt;/span&gt;            &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;trip_type&lt;/span&gt;               &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup&lt;/span&gt;                  &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff&lt;/span&gt;                 &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cab_type&lt;/span&gt;                &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;precipitation&lt;/span&gt;           &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;snow_depth&lt;/span&gt;              &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;snowfall&lt;/span&gt;                &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_temperature&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;min_temperature&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;average_wind_speed&lt;/span&gt;      &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_nyct2010_gid&lt;/span&gt;     &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_ctlabel&lt;/span&gt;          &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_borocode&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_boroname&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_ct2010&lt;/span&gt;           &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_boroct2010&lt;/span&gt;       &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_cdeligibil&lt;/span&gt;       &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_ntacode&lt;/span&gt;          &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_ntaname&lt;/span&gt;          &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickup_puma&lt;/span&gt;             &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_nyct2010_gid&lt;/span&gt;    &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_ctlabel&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_borocode&lt;/span&gt;        &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_boroname&lt;/span&gt;        &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_ct2010&lt;/span&gt;          &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_boroct2010&lt;/span&gt;      &lt;span class=&quot;nb&quot;&gt;BIGINT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_cdeligibil&lt;/span&gt;      &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_ntacode&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_ntaname&lt;/span&gt;         &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dropoff_puma&lt;/span&gt;            &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;The loader for the 65 files uses the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trips&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;data/trips_*.csv.gz&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;HEADER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The loader for the single uncompressed file uses this query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trips&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;data/decompressed.csv&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;HEADER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;querying&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#querying&quot;&gt;Querying&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;After loading, the benchmark script will run each of the &lt;a href=&quot;https://github.com/pdet/taxi-benchmark/tree/0.1/sql/queries&quot;&gt;benchmark queries&lt;/a&gt; five times to measure their execution time. It is also important to note that the results of the queries are validated against their corresponding &lt;a href=&quot;https://github.com/pdet/taxi-benchmark/tree/0.1/sql/answers&quot;&gt;answers&lt;/a&gt;. This allows us to verify the correctness of the benchmark. Additionally, the queries are identical to those used in the original &lt;a href=&quot;https://tech.marksblogg.com/benchmarks.html&quot;&gt;“Billion Taxi Rides”&lt;/a&gt; benchmark.&lt;/p&gt;
      &lt;h2 id=&quot;results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#results&quot;&gt;Results&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;loading-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#loading-time&quot;&gt;Loading Time&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Although we are talking about many rows of a CSV file with 51 columns, DuckDB can ingest them rather fast.&lt;/p&gt;

&lt;p&gt;Note that, by default, DuckDB preserves the insertion order of the data, which negatively impacts performance. In the following results, all datasets have been loaded with this option set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;preserve_insertion_order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All experiments were run on my Apple M1 Max with 64 GB of RAM, and we compare the loading times for a single uncompressed CSV file, and the 65 compressed CSV files.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (min)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Avg deviation of CPU usage from 100%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Single File – Uncompressed&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11:52&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;31.57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Multiple Files – Compressed&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13:52&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;27.13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Unsurprisingly, loading data from multiple compressed files is more CPU-efficient than loading from a single uncompressed file. This is evident from the lower average deviation in CPU usage for multiple compressed files, indicating fewer wasted CPU cycles. There are two main reasons for this: (1) The compressed files are approximately eight times smaller than the uncompressed file, drastically reducing the amount of data that needs to be loaded from disk and, consequently, minimizing CPU stalls while waiting for data to be processed. (2) It is much easier to parallelize the loading of multiple files than a single file, as each thread can handle on a single file.&lt;/p&gt;

&lt;p&gt;The difference in CPU efficiency is also reflected in execution times: reading from a single uncompressed file is 2 minutes faster than reading from multiple compressed files. The reason for this lies in our decompression algorithm, which is admittedly not optimally designed. Reading a compressed file involves three tasks: (1) loading data from disk into a compressed buffer, (2) decompressing that data into a decompressed buffer, and (3) processing the decompressed buffer. In our current implementation, tasks 1 and 2 are combined into a single operation, meaning we cannot continue reading until the current buffer is fully decompressed, resulting in idle cycles.&lt;/p&gt;
      &lt;h3 id=&quot;under-the-hood&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#under-the-hood&quot;&gt;Under the Hood&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We can also see what happens under the hood to verify our conclusion regarding the loading time.&lt;/p&gt;

&lt;p&gt;In the figure below, you can see a snapshot of CPU and disk utilization for the “Single File – Uncompressed” run. We observe that achieving 100% CPU utilization is challenging, and we frequently experience stalls due to data writes to disk, as we are creating a table from a dataset that does not fit into our memory. Another key point is that CPU utilization is closely tied to disk reads, indicating that our threads often wait for data before processing it. Implementing async IO for the CSV Reader/Writer could significantly improve performance for parallel processing, as a single thread could handle most of our disk I/O without negatively affecting CPU utilization.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/images/blog/taxi/utilization_uncompressed_unset.png&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/taxi/utilization_uncompressed_unset.png&quot; alt=&quot;Uncompressed Load Stats&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Below, you can see a similar snapshot for loading the 65 compressed files. We frequently encounter stalls during data writes; however, CPU utilization is significantly better because we wait less time for the data to load (remember, the data is approximately 8 times smaller than in the uncompressed case). In this scenario, parallelization is also much easier. Like in the uncompressed case, these gaps in CPU utilization could be mitigated by async I/O, with the addition of a decomposed decompression algorithm.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/images/blog/taxi/utilization_compressed_unset.png&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/taxi/utilization_compressed_unset.png&quot; alt=&quot;Compressed Load Stats&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/a&gt;&lt;/p&gt;
      &lt;h3 id=&quot;query-times&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#query-times&quot;&gt;Query Times&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For completeness, we also provide the results of the four queries on a MacBook Pro with an M1 Pro CPU. This comparison demonstrates the time differences between querying a database that does not fit in memory using a purely in-memory connection (i.e., without storage) versus one where the data is first loaded and persisted in the database.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time – without storage (s)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time – with storage (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Q 01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.45&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Q 02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.89&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Q 03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.21&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Q 04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.12&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The main difference between these times is that when DuckDB uses a storage file, the data is &lt;a href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html&quot;&gt;highly compressed&lt;/a&gt;, resulting in &lt;a href=&quot;https://duckdb.org/docs/stable/guides/performance/how_to_tune_workloads.html#persistent-vs-in-memory-tables&quot;&gt;much faster access when querying the dataset&lt;/a&gt;.
In contrast, when we do not use persistent storage, our in-memory database temporarily stores data in an uncompressed &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.tmp&lt;/code&gt; file to allow for memory overflow, which increases disk I/O and leads to slower query results. This observation raises a potential area for exploration: determining whether applying compression to temporary data would be beneficial.&lt;/p&gt;
      &lt;h2 id=&quot;how-this-dataset-was-generated&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#how-this-dataset-was-generated&quot;&gt;How This Dataset Was Generated&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The original blog post generated the dataset using CSV files distributed by the NYC Taxi and Limousine Commission. Originally, these files included precise latitude and longitude coordinates for pickups and drop-offs. However, starting in mid-2016, these precise coordinates were anonymized using pickup and drop-off geometry objects to address privacy concerns. (There are even stories of broken marriages resulting from checking the actual destinations of taxis.) Furthermore, in recent years, the TLC decided to redistribute the data as Parquet files and to fully anonymize these data points, including data prior to mid-2016.&lt;/p&gt;

&lt;p&gt;This is a problem, as the dataset from the “Billion Taxi Rides in Redshift” blog post relies on having this detailed information. Let&#39;s take the following snippet of the data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;649084905,VTS,2012-08-31 22:00:00,2012-08-31 22:07:00,0,1,-73.993908,40.741383000000006,-73.989915,40.75273800000001,1,1.32,6.1,0.5,0.5,0,0,0,0,7.1,CSH,0,0101000020E6100000E6CE4C309C7F52C0BA675DA3E55E4440,0101000020E610000078B471C45A7F52C06D3A02B859604440,yellow,0.00,0.0,0.0,91,69,4.70,142,54,1,Manhattan,005400,1005400,I,MN13,Hudson Yards-Chelsea-Flatiron-Union Square,3807,132,109,1,Manhattan,010900,1010900,I,MN17,Midtown-Midtown South,3807
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We see precise longitude and latitude data points: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-73.993908, 40.741383000000006, -73.989915, 40.75273800000001&lt;/code&gt;, along with a PostGIS Geometry hex blob created from this longitude and latitude information: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0101000020E6100000E6CE4C309C7F52C0BA675DA3E55E4440, 0101000020E610000078B471C45A7F52C06D3A02B859604440&lt;/code&gt; (generated as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_SetSRID(ST_Point(longitude, latitude), 4326)&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Since this information is essential to the dataset, producing files as described in the “Billion Taxi Rides in Redshift” blog post is no longer feasible due to the missing detailed location data. However, the internet never forgets. Hence, we located instances of the original dataset distributed by various sources, such as &lt;a href=&quot;https://arrow.apache.org/docs/6.0/r/articles/dataset.html&quot;&gt;[1]&lt;/a&gt;, &lt;a href=&quot;https://catalog.data.gov/dataset/?q=Yellow+Taxi+Trip+Data&amp;amp;sort=views_recent+desc&amp;amp;publisher=data.cityofnewyork.us&amp;amp;organization=city-of-new-york&amp;amp;ext_location=&amp;amp;ext_bbox=&amp;amp;ext_prev_extent=&quot;&gt;[2]&lt;/a&gt;, and &lt;a href=&quot;https://datasets.clickhouse.com/trips_mergetree/partitions/trips_mergetree.tar&quot;&gt;[3]&lt;/a&gt;. Using these sources, we combined the original CSV files with weather information from the &lt;a href=&quot;https://github.com/toddwschneider/nyc-taxi-data&quot;&gt;scripts&lt;/a&gt; referenced in the “Billion Taxi Rides in Redshift” blog post.&lt;/p&gt;
      &lt;h3 id=&quot;how-does-this-dataset-differ-from-the-original-one&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#how-does-this-dataset-differ-from-the-original-one&quot;&gt;How Does This Dataset Differ from the Original One?&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;There are two significant differences between the dataset we distribute and the one from the “Billion Taxi Rides in Redshift” blog post:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Our dataset includes data up to the last date that longitude and latitude information was available (June 30, 2016), whereas the original post only included data up to the end of 2015 (understandable, as the post was written in February 2016).&lt;/li&gt;
  &lt;li&gt;We also included Uber trips, which were excluded from the original post.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you wish to run the benchmark with a dataset as close to the original as possible, you can generate a new table by filtering out the additional data. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trips_og&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trips&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_datetime&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2016-01-01&#39;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cab_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;uber&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we discussed how to run the taxi benchmark on DuckDB, and we&#39;ve made all scripts available so you can benchmark your preferred system as well. We also demonstrated how this highly relevant benchmark can be used to evaluate our operators and gain insights into areas for further improvement.&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/16/driving-csv-performance-benchmarking-duckdb-with-the-nyc-taxi-dataset.html</guid><pubDate>Wed, 16 Oct 2024 00:00:00 GMT</pubDate><author>Pedro Holanda</author></item><item><title>DuckDB Tricks – Part 2</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We continue our “DuckDB tricks” series, focusing on queries that clean, transform and summarize data.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;overview&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#overview&quot;&gt;Overview&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This post is the latest installment of the &lt;a href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html&quot;&gt;DuckDB Tricks series&lt;/a&gt;, where we show you nifty SQL tricks in DuckDB.
Here’s a summary of what we’re going to cover:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Operation&lt;/th&gt;
      &lt;th&gt;SQL instructions&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#fixing-timestamps-in-csv-files&quot;&gt;Fixing timestamps in CSV files&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;nf&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt; and &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;nf&quot;&gt;strptime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#filling-in-missing-values&quot;&gt;Filling in missing values&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt;&lt;/code&gt;, &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt;&lt;/code&gt; and &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;nf&quot;&gt;coalesce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#repeated-data-transformation-steps&quot;&gt;Repeated transformation steps&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#computing-checksums-for-columns&quot;&gt;Computing checksums for columns&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;nf&quot;&gt;bit_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;md5_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#creating-a-macro-for-the-checksum-query&quot;&gt;Creating a macro for checksum&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;checksum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;dataset&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#dataset&quot;&gt;Dataset&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;For our example dataset, we’ll use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule.csv&lt;/code&gt;, a hand-written CSV file that encodes a conference schedule. The schedule contains the timeslots, the locations and the events scheduled.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;timeslot,location,event
2024-10-10 9am,room Mallard,Keynote
2024-10-10 10.30am,room Mallard,Customer stories
2024-10-10 10.30am,room Fusca,Deep dive 1
2024-10-10 12.30pm,main hall,Lunch
2024-10-10 2pm,room Fusca,Deep dive 2
&lt;/code&gt;&lt;/pre&gt;
      &lt;h2 id=&quot;fixing-timestamps-in-csv-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#fixing-timestamps-in-csv-files&quot;&gt;Fixing Timestamps in CSV Files&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;As usual in real use case, the input CSV is messy with irregular timestamps such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2024-10-10 9am&lt;/code&gt;.
Therefore, if we load the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule.csv&lt;/code&gt; file using DuckDB’s CSV reader, the CSV sniffer will detect the first column as a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; field:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_raw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://duckdb.org/data/schedule.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────┬──────────────┬──────────────────┐
│      timeslot      │   location   │      event       │
│      varchar       │   varchar    │     varchar      │
├────────────────────┼──────────────┼──────────────────┤
│ 2024-10-10 9am     │ room Mallard │ Keynote          │
│ 2024-10-10 10.30am │ room Mallard │ Customer stories │
│ 2024-10-10 10.30am │ room Fusca   │ Deep dive 1      │
│ 2024-10-10 12.30pm │ main hall    │ Lunch            │
│ 2024-10-10 2pm     │ room Fusca   │ Deep dive 2      │
└────────────────────┴──────────────┴──────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ideally, we would like the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timeslot&lt;/code&gt; column to have the type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt; so we can treat it as a timestamp in the queries later. To achieve this, we can use the table we just loaded and fix the problematic entities by using a regular expression-based search and replace operation, which unifies the format to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hours.minutes&lt;/code&gt; followed by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;am&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pm&lt;/code&gt;. Then, we convert the string to timestamps using &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/dateformat.html#strptime-examples&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strptime&lt;/code&gt;&lt;/a&gt; with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%p&lt;/code&gt; format specifier capturing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;am&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pm&lt;/code&gt; part of the string.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_cleaned&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39; (\d+)(am|pm)$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39; \1.00\2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strptime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;%Y-%m-%d %H.%M%p&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that we use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/overview.html#function-chaining-via-the-dot-operator&quot;&gt;dot operator for function chaining&lt;/a&gt; to improve readability. For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regexp_replace(string, pattern, replacement)&lt;/code&gt; is formulated as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;string.regexp_replace(pattern, replacement)&lt;/code&gt;. The result is the following table:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────────────┬──────────────┬──────────────────┐
│      timeslot       │   location   │      event       │
│      timestamp      │   varchar    │     varchar      │
├─────────────────────┼──────────────┼──────────────────┤
│ 2024-10-10 09:00:00 │ room Mallard │ Keynote          │
│ 2024-10-10 10:30:00 │ room Mallard │ Customer stories │
│ 2024-10-10 10:30:00 │ room Fusca   │ Deep dive 1      │
│ 2024-10-10 12:30:00 │ main hall    │ Lunch            │
│ 2024-10-10 14:00:00 │ room Fusca   │ Deep dive 2      │
└─────────────────────┴──────────────┴──────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;filling-in-missing-values&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#filling-in-missing-values&quot;&gt;Filling in Missing Values&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Next, we would like to derive a schedule that includes the full picture: &lt;em&gt;every timeslot&lt;/em&gt; for &lt;em&gt;every location&lt;/em&gt; should have its line in the table. For the timeslot-location combinations, where there is no event specified, we would like to explicitly add a string that says &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;empty&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To achieve this, we first create a table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timeslot_location_combinations&lt;/code&gt; containing all possible combinations using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CROSS JOIN&lt;/code&gt;. Then, we can connect the original table on the combinations using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LEFT JOIN&lt;/code&gt;. Finally, we replace &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;empty&amp;gt;&lt;/code&gt; string using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/utility.html#coalesceexpr-&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coalesce&lt;/code&gt; function&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CROSS JOIN&lt;/code&gt; clause is equivalent to simply listing the tables in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause without specifying join conditions. By explicitly spelling out &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CROSS JOIN&lt;/code&gt;, we communicate that we intend to compute a Cartesian product – which is an expensive operation on large tables and should be avoided in most use cases.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot_location_combinations&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_cleaned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_cleaned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_filled&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;coalesce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&amp;lt;empty&amp;gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot_location_combinations&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_cleaned&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_filled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────────────┬──────────────┬──────────────────┐
│      timeslot       │   location   │      event       │
│      timestamp      │   varchar    │     varchar      │
├─────────────────────┼──────────────┼──────────────────┤
│ 2024-10-10 09:00:00 │ main hall    │ &amp;lt;empty&amp;gt;          │
│ 2024-10-10 09:00:00 │ room Fusca   │ &amp;lt;empty&amp;gt;          │
│ 2024-10-10 09:00:00 │ room Mallard │ Keynote          │
│ 2024-10-10 10:30:00 │ main hall    │ &amp;lt;empty&amp;gt;          │
│ 2024-10-10 10:30:00 │ room Fusca   │ Deep dive 1      │
│ 2024-10-10 10:30:00 │ room Mallard │ Customer stories │
│ 2024-10-10 12:30:00 │ main hall    │ Lunch            │
│ 2024-10-10 12:30:00 │ room Fusca   │ &amp;lt;empty&amp;gt;          │
│ 2024-10-10 12:30:00 │ room Mallard │ &amp;lt;empty&amp;gt;          │
│ 2024-10-10 14:00:00 │ main hall    │ &amp;lt;empty&amp;gt;          │
│ 2024-10-10 14:00:00 │ room Fusca   │ Deep dive 2      │
│ 2024-10-10 14:00:00 │ room Mallard │ &amp;lt;empty&amp;gt;          │
├─────────────────────┴──────────────┴──────────────────┤
│ 12 rows                                     3 columns │
└───────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can also put everything together in a single query using a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/with.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH&lt;/code&gt; clause&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot_location_combinations&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_cleaned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_cleaned&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;coalesce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&amp;lt;empty&amp;gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot_location_combinations&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_cleaned&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;repeated-data-transformation-steps&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#repeated-data-transformation-steps&quot;&gt;Repeated Data Transformation Steps&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Data cleaning and transformation usually happens as a sequence of transformations that shape the data into a form that’s best fitted to later analysis.
These transformations are often done by defining newer and newer tables using &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_table.html#create-table--as-select-ctas&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE TABLE ... AS SELECT&lt;/code&gt; statements&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For example, in the sections above, we created &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_raw&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_cleaned&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_filled&lt;/code&gt;. If, for some reason, we want to skip the cleaning steps for the timestamps, we have to reformulate the query computing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_filled&lt;/code&gt; to use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_raw&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_cleaned&lt;/code&gt;. This can be tedious and error-prone, and it results in a lot of unused temporary data – data that may accidentally get picked up by queries that we forgot to update!&lt;/p&gt;

&lt;p&gt;In interactive analysis, it’s often better to use the same table name by running &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_table.html#create-or-replace&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE OR REPLACE&lt;/code&gt; statements&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;table_name&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using this trick, we can run our analysis as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://duckdb.org/data/schedule.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39; (\d+)(am|pm)$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39; \1.00\2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;strptime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;%Y-%m-%d %H.%M%p&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot_location_combinations&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;coalesce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&amp;lt;empty&amp;gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeslot_location_combinations&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeslot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using this approach, we can skip any step and continue the analysis without adjusting the next one.&lt;/p&gt;

&lt;p&gt;What’s more, our script can now be re-run from the beginning without explicitly deleting any tables: the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE OR REPLACE&lt;/code&gt; statements will automatically replace any existing tables.&lt;/p&gt;
      &lt;h2 id=&quot;computing-checksums-for-columns&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#computing-checksums-for-columns&quot;&gt;Computing Checksums for Columns&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;It’s often beneficial to compute a checksum for each column in a table, e.g., to see whether a column’s content has changed between two operations.
We can compute a checksum for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule&lt;/code&gt; table as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bit_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;md5_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What’s going on here?
We first list columns (&lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#columns-expression&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS(*)&lt;/code&gt;&lt;/a&gt;) and cast all of them to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; values.
Then, we compute the numeric MD5 hashes with the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/utility.html#md5_numberstring&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;md5_number&lt;/code&gt; function&lt;/a&gt; and aggregate them using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#bit_xorarg&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bit_xor&lt;/code&gt; aggregate function&lt;/a&gt;.
This produces a single &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HUGEINT&lt;/code&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INT128&lt;/code&gt;) value per column that can be used to compare the content of tables.&lt;/p&gt;

&lt;p&gt;If we run this query in the script above, we get the following results:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────────────────────────────┬────────────────────────────────────────┬─────────────────────────────────────────┐
│                 timeslot                 │                location                │                  event                  │
│                  int128                  │                 int128                 │                 int128                  │
├──────────────────────────────────────────┼────────────────────────────────────────┼─────────────────────────────────────────┤
│ -134063647976146309049043791223896883700 │ 85181227364560750048971459330392988815 │ -65014404565339851967879683214612768044 │
└──────────────────────────────────────────┴────────────────────────────────────────┴─────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────────────┬────────────────────────────────────────┬─────────────────────────────────────────┐
│                timeslot                │                location                │                  event                  │
│                 int128                 │                 int128                 │                 int128                  │
├────────────────────────────────────────┼────────────────────────────────────────┼─────────────────────────────────────────┤
│ 62901011016747318977469778517845645961 │ 85181227364560750048971459330392988815 │ -65014404565339851967879683214612768044 │
└────────────────────────────────────────┴────────────────────────────────────────┴─────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────────────────────────────┬──────────┬──────────────────────────────────────────┐
│                 timeslot                 │ location │                  event                   │
│                  int128                  │  int128  │                  int128                  │
├──────────────────────────────────────────┼──────────┼──────────────────────────────────────────┤
│ -162418013182718436871288818115274808663 │        0 │ -135609337521255080720676586176293337793 │
└──────────────────────────────────────────┴──────────┴──────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;creating-a-macro-for-the-checksum-query&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#creating-a-macro-for-the-checksum-query&quot;&gt;Creating a Macro for the Checksum Query&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We can turn the &lt;a href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#computing-checksums-for-columns&quot;&gt;checksum query&lt;/a&gt; into a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_macro.html#table-macros&quot;&gt;table macro&lt;/a&gt; with the new &lt;a href=&quot;https://duckdb.org/docs/stable/guides/sql_features/query_and_query_table_functions.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; function&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;checksum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bit_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;md5_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;query_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This way, we can simply invoke it on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule&lt;/code&gt; table as follows (also leveraging DuckDB’s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;-first syntax&lt;/a&gt;):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;checksum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;schedule&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────────────────────────────┬────────────────────────────────────────┬─────────────────────────────────────────┐
│                 timeslot                 │                location                │                  event                  │
│                  int128                  │                 int128                 │                 int128                  │
├──────────────────────────────────────────┼────────────────────────────────────────┼─────────────────────────────────────────┤
│ -134063647976146309049043791223896883700 │ 85181227364560750048971459330392988815 │ -65014404565339851967879683214612768044 │
└──────────────────────────────────────────┴────────────────────────────────────────┴─────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;closing-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html#closing-thoughts&quot;&gt;Closing Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;That’s it for today!
We’ll be back soon with more DuckDB tricks and case studies.
In the meantime, if you have a trick that would like to share, please share it with the DuckDB team on our social media sites, or submit it to the &lt;a href=&quot;https://duckdbsnippets.com/&quot;&gt;DuckDB Snippets site&lt;/a&gt; (maintained by our friends at MotherDuck).&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/11/duckdb-tricks-part-2.html</guid><pubDate>Fri, 11 Oct 2024 00:00:00 GMT</pubDate><author>Gabor Szarnyas</author></item><item><title>Analyzing Open Government Data with duckplyr</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We use the duckplyr R library to clean and analyze an Open Data set published by the government of New Zealand.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
  &lt;p&gt;For the duckplyr documentation, visit &lt;a href=&quot;https://duckplyr.tidyverse.org/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckplyr.tidyverse.org&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duckplyr/duckplyr-logo.svg&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Wrangling data by throwing SQL strings at it is not the most ergonomic way to perform interactive data analysis in R. For a while now, we have been working with the dplyr project team at &lt;a href=&quot;https://posit.co/&quot;&gt;Posit&lt;/a&gt; (formerly RStudio) and Kirill Müller to develop &lt;em&gt;duckplyr&lt;/em&gt;. &lt;a href=&quot;https://duckplyr.tidyverse.org/&quot;&gt;duckplyr&lt;/a&gt; is a high-performance drop-in replacement for dplyr, powered by DuckDB. You can read more about duckplyr in the &lt;a href=&quot;https://duckdb.org/2024/04/02/duckplyr.html&quot;&gt;announcement blog post&lt;/a&gt;. In this post, we are going to walk through a challenging real-world use case with duckplyr. For those of you wishing to follow along, we have prepared a &lt;a href=&quot;https://colab.research.google.com/drive/1PxvkZ4FpMNtP-CpKpz5hvH-xKgaYC3-S&quot;&gt;Google Colab notebook&lt;/a&gt; with all the code snippets in this post. Timings reported below are also from Colab.&lt;/p&gt;

&lt;p&gt;Like many government statistics agencies, New Zealand&#39;s “Stats NZ Tatauranga Aotearoa” thankfully provides some of the datasets they maintain as &lt;a href=&quot;https://www.stats.govt.nz/large-datasets/csv-files-for-download/&quot;&gt;Open Data for download&lt;/a&gt;. The largest file available for download on that page contains “Age and sex by ethnic group (grouped total responses), for census usually resident population counts, 2006, 2013, and 2018 Censuses”, &lt;a href=&quot;https://www3.stats.govt.nz/2018census/Age-sex-by-ethnic-group-grouped-total-responses-census-usually-resident-population-counts-2006-2013-2018-Censuses-RC-TA-SA2-DHB.zip&quot;&gt;CSV zipped file&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We can download that file (mirrored from our CDN, we don&#39;t want to DDoS poor Stats NZ) and unzip like so:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;download.file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://blobs.duckdb.org/nzcensus.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nzcensus.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unzip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nzcensus.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&#39;s explore the CSV files in the zip and what their sizes are:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;file.info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sys.glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;*.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                               size
Data8277.csv              857672667
DimenLookupAge8277.csv         2720
DimenLookupArea8277.csv       65400
DimenLookupEthnic8277.csv       272
DimenLookupSex8277.csv           74
DimenLookupYear8277.csv          67
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As we can see, there is one large (~800 MB) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Data&lt;/code&gt; file and a bunch of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dimen...&lt;/code&gt; dimension files. This is a fairly common data layout, sometimes called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Star_schema&quot;&gt;“star schema”&lt;/a&gt;. From this, it&#39;s clear there are some joins in our future. But first lets focus on the main file, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Data8277.csv&lt;/code&gt;. Reading sizeable CSV files is not trivial and can be very frustrating. But enough whinging, as the Kiwis would say.&lt;/p&gt;

&lt;p&gt;To start with, let&#39;s just have a quick look what the file looks like:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readLines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Data8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collapse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Year,Age,Ethnic,Sex,Area,count
2018,000,1,1,01,795
2018,000,1,1,02,5067
2018,000,1,1,03,2229
2018,000,1,1,04,1356
2018,000,1,1,05,180
2018,000,1,1,06,738
2018,000,1,1,07,630
2018,000,1,1,08,1188
2018,000,1,1,09,2157
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So far this looks rather tame, there seem to be five columns. Thankfully, they have names. From just eyeballing the column values, it looks like they are all numeric and even integer values. However, looks can be deceiving, and the columns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Age&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Area&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count&lt;/code&gt; contain character values somewhere down the line. Fun fact: we have to wait till line 431&amp;nbsp;741 until the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Area&lt;/code&gt; column contains a non-integer value. Clearly we need a good CSV parser. R has no shortage of CSV readers, for example the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;readr&lt;/code&gt; package contains a flexible CSV parser. Reading this file with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;readr&lt;/code&gt; takes about a minute (on Colab).&lt;/p&gt;

&lt;p&gt;But let&#39;s now start using DuckDB and duckplyr. First, we install duckplyr (and DuckDB, which is a dependency):&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;duckplyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;SELECT version()&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This command prints out the installed DuckDB version, as of this writing the latest version on &lt;a href=&quot;https://cran.r-project.org/web/packages/duckdb/index.html&quot;&gt;CRAN&lt;/a&gt; is 1.1.0. We can now use DuckDB&#39;s advanced data wrangling capabilities. First off, DuckDB contains probably the &lt;a href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html&quot;&gt;world&#39;s most advanced CSV parser&lt;/a&gt;. For the extra curious, &lt;a href=&quot;https://www.youtube.com/watch?v=YrqSp8m7fmk&quot;&gt;here is a presentation on DuckDB&#39;s CSV parser&lt;/a&gt;. We use DuckDB&#39;s CSV reader to only read the first 10 rows from the CSV file:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;FROM Data8277.csv LIMIT 10&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   Year Age Ethnic Sex Area count
1  2018 000      1   1   01   795
2  2018 000      1   1   02  5067
3  2018 000      1   1   03  2229
4  2018 000      1   1   04  1356
5  2018 000      1   1   05   180
6  2018 000      1   1   06   738
7  2018 000      1   1   07   630
8  2018 000      1   1   08  1188
9  2018 000      1   1   09  2157
10 2018 000      1   1   12   177
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This only takes a few milliseconds because DuckDB&#39;s CSV reader produces results in a streaming fashion, and because we have only requested 10 rows we are done fairly quickly.&lt;/p&gt;

&lt;p&gt;DuckDB can also print out the schema it detected from the CSV file using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESCRIBE&lt;/code&gt; keyword:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DESCRIBE FROM Data8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  column_name column_type ...
1        Year      BIGINT ...
2         Age     VARCHAR ...
3      Ethnic      BIGINT ...
4         Sex      BIGINT ...
5        Area     VARCHAR ...
6       count     VARCHAR ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see that we have correctly detected the various data types for the columns. We can use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt; keyword to compute various summary statistics for all the columns in the file:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;SUMMARIZE FROM Data8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will take a little bit longer, but the results are very interesting:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# A tibble: 6 × 12
  column_name column_type min   max     approx_unique avg      std   q25   q50
  &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
1 Year        BIGINT      2006  2018                3 2012.33… 4.92… 2006  2013
2 Age         VARCHAR     000   999999            149 NA       NA    NA    NA
3 Ethnic      BIGINT      1     9999               11 930.545… 2867… 3     6
4 Sex         BIGINT      1     9                   3 4.0      3.55… 1     2
5 Area        VARCHAR     001   DHB9999          2048 NA       NA    NA    NA
6 count       VARCHAR     ..C   9999            16825 NA       NA    NA    NA
# ℹ 3 more variables: q75 &amp;lt;chr&amp;gt;, count &amp;lt;dbl&amp;gt;, null_percentage &amp;lt;dbl&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will show again the column names and their types, but also the summary statistics for minimum and maximum value, approximate count of unique values, average, standard deviations, 25, 50, and 75 quantiles, and percentage of NULL/NA values. So one gets a pretty good overview of what the data is like.&lt;/p&gt;

&lt;p&gt;But we&#39;re not here to ogle summary statistics, we want to do actual analysis of the data. In this use case, we would like to compute the number of non-Europeans between 20 and 40 that live in the Auckland area using the 2018 census data and the results should be grouped by sex. To do so, we need to join the dimension CSV files with the main data file in order to properly filter the dimension values. In SQL, the lingua franca of large-scale data analysis, this looks like this:&lt;/p&gt;

&lt;p&gt;We first join everything together:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Data8277.csv&#39;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DimenLookupAge8277.csv&#39;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DimenLookupArea8277.csv&#39;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Area&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DimenLookupEthnic8277.csv&#39;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ethnic&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ethnic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ethnic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DimenLookupSex8277.csv&#39;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sex&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DimenLookupYear8277.csv&#39;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Year&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; projection to perform some basic renames and data cleaning:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ethnic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ethnic_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TRY_CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39; years&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TRY_CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The data set contains various totals, so we remove them before proceeding:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Total%&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ethnic_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Total%&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Total%&#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We wrap the previous statements as a common-table-expression &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;expanded_cleaned_data&lt;/code&gt;, and we can then compute the actual aggregation using DuckDB&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group_count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expanded_cleaned_data&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Auckland%&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ethnic_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;European&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2018&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This takes ca. 20s on the limited Colab free tier compute. The result is:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    sex_ group_count
1 Female      398556
2   Male      397326
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So far, so good. However, writing SQL queries is not for everyone. The ergonomics of creating SQL strings in an interactive data analysis environment like R are questionable to say the least. Frameworks like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dplyr&lt;/code&gt; have shown how data wrangling ergonomics can be massively improved. Let&#39;s express our analysis using dplyr then after first reading the data into RAM from CSV:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Data8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupAge8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupArea8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ethnic&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupEthnic8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupSex8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupYear8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expanded_cleaned_data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grepl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^\\d+$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grepl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^\\d+ years$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grepl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^Total&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Area&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ethnic&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ethnic_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grepl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^Total&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ethnic_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ethnic&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grepl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^Total&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Year&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# create final aggregation, still completely lazily&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;twenty_till_fourty_non_european_in_auckland_area&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expanded_cleaned_data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grepl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^Auckland&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2018&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ethnic_&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;European&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.by&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sex_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;twenty_till_fourty_non_european_in_auckland_area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This looks nicer and completes in ca. one minute, but there are several hidden issues. First, we read the &lt;em&gt;entire&lt;/em&gt; dataset into RAM. While for this dataset this is likely possible because most computers have more than 1 GB of RAM, this will of course not work for larger datasets. Then, we execute a series of dplyr verbs. However, dplyr executes those eagerly, meaning it does not holistically optimize the sequence of verbs. For example, it cannot see that we are filtering out all non-European ethnicities in the last step and happily computes all of those for the intermediate result. The same happens with survey years that are not 2018, only in the last step we filter those out. We have computed an expensive join on all other years for nothing. Depending on data distributions, this can be extremely wasteful. And yes, it is possible to manually move the filters around but this is tedious and error-prone. At least the result is exactly the same as the SQL version above:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# A tibble: 2 × 2
  sex_   group_count
  &amp;lt;chr&amp;gt;        &amp;lt;int&amp;gt;
1 Female      398556
2 Male        397326
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we switch the exact same script over to duckplyr. Instead of reading the CSV files into RAM entirely using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;readr&lt;/code&gt;, we instead use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckplyr_df_from_csv&lt;/code&gt; function from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckplyr&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;duckplyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckplyr_df_from_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Data8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckplyr_df_from_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupAge8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckplyr_df_from_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupArea8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ethnic&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckplyr_df_from_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupEthnic8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckplyr_df_from_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupSex8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckplyr_df_from_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DimenLookupYear8277.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This takes exactly 0 seconds, because duckplyr is not actually doing much. We detect the schema of the CSV files using our award-winning “sniffer”, and create the six placeholder objects for each of those files. Part of the unique design of duckplyr is that those objects are “Heisenbergian”, they behave like completely normal R &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data.frame&lt;/code&gt;s once they are treated as such, but they can &lt;em&gt;also&lt;/em&gt; act as lazy evaluation placeholders when they are passed to downstream analysis steps. This is made possible by a little-known R feature known as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALTREP&lt;/code&gt; which allows R vectors to be computed on-demand among other things.&lt;/p&gt;

&lt;p&gt;Now we re-run the exact same dplyr pipeline as above. Only this time we are “done” in less than a second. This is because all we have done is &lt;em&gt;lazily&lt;/em&gt; constructing a so-called relation tree which encapsulates the entirety of the transformations. This allows &lt;em&gt;holistic&lt;/em&gt; optimization, for example pushing the year and ethnicity all the way down to the reading of the CSV file &lt;em&gt;before&lt;/em&gt; joining. We can also eliminate the reading of columns that are not used in the query at all.&lt;/p&gt;

&lt;p&gt;Only when we finally print the result&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;twenty_till_fourty_non_european_in_auckland_area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;actual computation is triggered. This finishes in the same time as the hand-rolled SQL query above, only that this time we had a much more pleasant experience from using the dplyr syntax. And, thankfully, the result is still exactly the same.&lt;/p&gt;

&lt;p&gt;This use case was also presented as part of &lt;a href=&quot;https://www.youtube.com/watch?v=GELhdezYmP0&quot;&gt;my keynote at this year&#39;s posit::conf&lt;/a&gt;:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/GELhdezYmP0?si=suO9fC652ooAZKOq&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&quot; referrerpolicy=&quot;no-referrer&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Finally, we should note that duckplyr is still being developed. We have taking great care in not breaking anything and will fall back on the existing dplyr implementation if anything cannot be run in DuckDB (yet). But we would love to &lt;a href=&quot;https://github.com/tidyverse/duckplyr/issues&quot;&gt;hear from you&lt;/a&gt; if anything does not work as expected.&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/09/analyzing-open-government-data-with-duckplyr.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/09/analyzing-open-government-data-with-duckplyr.html</guid><pubDate>Wed, 09 Oct 2024 00:00:00 GMT</pubDate><author>Hannes Mühleisen</author></item><item><title>DuckDB User Survey Analysis</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We share the findings from a survey of 500+ DuckDB users.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Earlier this year, we conducted a survey in the DuckDB community.
We were mostly curious about the following topics:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;How do people use DuckDB?&lt;/li&gt;
  &lt;li&gt;Where do people use DuckDB?&lt;/li&gt;
  &lt;li&gt;What do they like about DuckDB?&lt;/li&gt;
  &lt;li&gt;What improvements would they like to see in future releases?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The survey was open for about three weeks. More than 500 people submitted their answers, and we raffled 20 t-shirts and hoodies among the participants.&lt;/p&gt;
      &lt;h2 id=&quot;summary&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#summary&quot;&gt;Summary&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We summarize the key findings of the survey below:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Users run DuckDB most often on laptops but servers are also very popular.&lt;/li&gt;
  &lt;li&gt;The most popular clients are the Python API and the standalone CLI client.&lt;/li&gt;
  &lt;li&gt;Most users don&#39;t have huge data sets but they appreciate high performance very much.&lt;/li&gt;
  &lt;li&gt;Users would like to see performance optimizations related to time series and partitioned data.&lt;/li&gt;
  &lt;li&gt;DuckDB is popular among data engineers, analysts and scientists, and also among software engineers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&#39;s dive into the details!&lt;/p&gt;
      &lt;h2 id=&quot;using-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#using-duckdb&quot;&gt;Using DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;environments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#environments&quot;&gt;Environments&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We asked users about the environment where DuckDB is deployed and found that most of them, 87%, run DuckDB on their laptops.
This is in line with the vision that originally drove the creation of DuckDB: creating a system that harnesses the power of hardware available in modern end-user devices.
29% run DuckDB on desktop workstations, and 58% run it on servers (see the breakdown later in the &lt;a href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#server-types&quot;&gt;“Server Types” section&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/environments.svg&quot; alt=&quot;DuckDB environments&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h3 id=&quot;clients&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#clients&quot;&gt;Clients&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://www.tiobe.com/tiobe-index/python/&quot;&gt;Unsurprisingly&lt;/a&gt;, DuckDB is most often used from Python (73%), followed by the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;standalone command-line application&lt;/a&gt; (47%).
The third spot is hotly contested with R, WebAssembly (!) and Java all achieving around 14%, followed by Node.js (Javascript) at 9%&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/clients.svg&quot; alt=&quot;DuckDB clients&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The next few places, with 6-7% each, are occupied by ODBC, Rust, and Go.
Finally, Arrow (ADBC) rounds off the top 10 with 5%.&lt;/p&gt;
      &lt;h3 id=&quot;operating-systems&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#operating-systems&quot;&gt;Operating Systems&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We found that most users, 61%, run DuckDB on Linux servers.
These deployments include cloud instances, on-premises installations, and continuous integration (CI) runners.
Windows desktop and macOS have a similar share of users, 41–45%.
A further 9% run DuckDB on Windows servers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/platforms.svg&quot; alt=&quot;DuckDB platforms&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;We found the number of Linux desktop users quite striking.
While the overall &lt;a href=&quot;https://gs.statcounter.com/os-market-share/desktop/worldwide/2024&quot;&gt;market share of Linux desktop is around 4.5%&lt;/a&gt;,
&lt;em&gt;29% of respondents indicated that they run DuckDB on Linux desktop!&lt;/em&gt;
We suspect that this is thanks to DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#user-roles&quot;&gt;popularity among data engineers&lt;/a&gt;,
who often use Linux desktop due to its customizability and similarity to the Linux server-based deployment environments.&lt;/p&gt;
      &lt;h3 id=&quot;server-types&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#server-types&quot;&gt;Server Types&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As we discussed in the &lt;a href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#environments&quot;&gt;“Environments” section&lt;/a&gt;, DuckDB is often run on servers.
But how big are these servers, and where are they operated?
Both small servers (less than 16 GB of memory) and medium-sized servers (16-512 GB of memory) are popular, with 56% and 61% of users reporting that they run DuckDB on these.
About 14% of respondents run DuckDB on servers with more than 0.5 TB of memory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/server-sizes.svg&quot; alt=&quot;Server size&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Regarding &lt;em&gt;where&lt;/em&gt; the servers run, on-premises deployments and AWS are neck-and-neck with 27%.
They are followed by two other clouds, Microsoft Azure and the Google Cloud Platform.
Finally, about 4% of users run DuckDB on Hetzner servers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/server-premises.svg&quot; alt=&quot;Server premises&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#data&quot;&gt;Data&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;data-formats&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#data-formats&quot;&gt;Data Formats&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We inquired about the data formats used when working with DuckDB.
Parquet is the most popular format: 79% of users reporting to use it.
CSV is a close second with 73%.
JSON is also popular with vanilla JSON achieving 42% and NDJSON 11%.
About ⅓ reported to use Arrow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/data-formats.svg&quot; alt=&quot;Data formats&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h3 id=&quot;dataset-sizes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#dataset-sizes&quot;&gt;Dataset Sizes&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We asked users about the size of the largest dataset they processed with DuckDB. We defined &lt;em&gt;dataset size&lt;/em&gt; as the size of the data when stored in uncompressed CSV format.
For Parquet files and DuckDB database files, we asked users to approximate the CSV size by multiplying their file sizes by 5.&lt;/p&gt;

&lt;p&gt;The responses showed that only a few respondents use DuckDB to process &lt;a href=&quot;https://motherduck.com/blog/big-data-is-dead/&quot;&gt;Big Data&lt;/a&gt;.
For ¾ of users, their largest dataset size was less than 100 GB data,
20% of users processed a dataset between 100 GB and 1 TB, and approximately 5% of the users ventured into the 1 TB+ territory.
About 1% processed 10 TB+ datasets.
These findings are in line with &lt;a href=&quot;https://motherduck.com/blog/redshift-files-hunt-for-big-data/#whos-got-big-data&quot;&gt;statistics derived from a recent RedShift usage dataset&lt;/a&gt; by &lt;a href=&quot;https://motherduck.com/authors/jordan-tigani/&quot;&gt;Jordan Tigani of MotherDuck&lt;/a&gt;, and the recent analysis of the &lt;a href=&quot;https://www.fivetran.com/blog/how-do-people-use-snowflake-and-redshift&quot;&gt;Snowflake and RedShift datasets&lt;/a&gt; by &lt;a href=&quot;https://www.fivetran.com/people/george-fraser&quot;&gt;George Fraser of Fivetran&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/dataset_sizes.svg&quot; alt=&quot;Dataset sizes&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;While these results obviously are somewhat biased – users who need to crunch through huge datasets may not work with DuckDB (yet!) –, the skew towards smaller datasets is quite significant and shows that many real-world use cases can be tackled using small to medium-sized datasets. The results also show that DuckDB &lt;em&gt;can&lt;/em&gt; solve many problems on datasets larger than 1 TB.&lt;/p&gt;
      &lt;h2 id=&quot;features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#features&quot;&gt;Features&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;most-liked-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#most-liked-features&quot;&gt;Most Liked Features&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We were curious: what do users like most about DuckDB? The plot shows the most frequent responses:
&lt;img src=&quot;https://duckdb.org/images/blog/survey/most_liked_features.svg&quot; alt=&quot;Most liked DuckDB features&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The most liked feature is &lt;strong&gt;high performance&lt;/strong&gt;.
Users also enjoy &lt;strong&gt;file format support&lt;/strong&gt; (CSV, Parquet, JSON, etc.),
&lt;strong&gt;ease of use&lt;/strong&gt;,
&lt;strong&gt;extensive SQL support&lt;/strong&gt; (including &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;friendly SQL&lt;/a&gt;)
and &lt;strong&gt;in-memory integrations&lt;/strong&gt; such as support for Pandas, Arrow and NumPy.
Finally, users mentioned low memory usage, protocol support (e.g., HTTPS, S3), database integrations, and portability.&lt;/p&gt;
      &lt;h3 id=&quot;feature-requests&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#feature-requests&quot;&gt;Feature Requests&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We asked users about the features that they&#39;d most like to see in future DuckDB versions. The most popular requests are listed in the table below:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Feature&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Percentage&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Improved partitioning and optimizations related to partitioning&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;39%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Improved support for time series and optimizations for pre-sorted data&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;35%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Support for materialized views&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;28%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Support for vector search&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;24%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Support for attaching to database systems via ODBC&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;24%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Support for time travel queries (query the database as of a given time)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Support for the Delta Lake format&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;22%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Improved support for Iceberg (including writes)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We are happy to report that, since the survey was conducted pre-v1.0.0 and DuckDB is now at version 1.1.1, some of these requests are already a reality:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reading Delta Lake is now possible via the &lt;a href=&quot;https://duckdb.org/2024/06/10/delta.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; extension&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Vector search is now supported via the &lt;a href=&quot;https://duckdb.org/2024/05/03/vector-similarity-search-vss.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the rest of the requested features, several ones are in the making at DuckDB Labs. Stay tuned!&lt;/p&gt;
      &lt;h2 id=&quot;user-roles&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#user-roles&quot;&gt;User Roles&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We asked respondents to indicate their main roles in their organization. The top-5 answers were as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/survey/roles.svg&quot; alt=&quot;User roles&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;It&#39;s no surprise that DuckDB is popular in the “data” roles: 26% of the respondents are data engineers, 14% are data scientists, and 9% are data analysts.
The form had a surprisingly high share of software engineers, 23%.
Finally, about 2% of respondents indicated that their primary role is DBA.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We would like to thank all participants for taking the time to complete the survey.
We will use the answers to guide the future development of DuckDB, and we hope that readers of this analysis find it informative as well.&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/04/duckdb-user-survey-analysis.html</guid><pubDate>Fri, 04 Oct 2024 00:00:00 GMT</pubDate><author>Gabor Szarnyas</author></item><item><title>DuckDB in Python in the Browser with Pyodide, PyScript, and JupyterLite</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Run DuckDB in an in-browser Python environment to enable simple querying on remote files, interactive documentation, and easy to use training materials.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;



      &lt;h2 id=&quot;time-to-hello-world&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#time-to-hello-world&quot;&gt;Time to “Hello World”&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The first time that you are using a new library, the most important thing is how quickly you can get to “Hello World”.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note Want to see “Hello World”?
&lt;a href=&quot;https://duckdb.org/2024/10/02/pyodide.html#pyscript-editor&quot;&gt;Jump to the &lt;strong&gt;fully interactive&lt;/strong&gt; examples!&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Likewise, if someone is visiting any documentation you have written, you want them to quickly and easily get your tool up and running.
When you are giving a demo, you want to avoid &quot;demo hell&quot; and have it work the first try!&lt;/p&gt;

&lt;p&gt;If you want to try “expert mode”, try leading an entire conference room of people through those setup steps!
The classroom or conference workshop environment makes it far more critical that installation be bulletproof.&lt;/p&gt;

&lt;p&gt;Python is one of our favorite ways to use DuckDB, but Python is notoriously difficult to set up – doubly so for a novice programmer.
What the heck is a virtual environment?
Are you on Windows, Linux, or Mac?
Pip or Conda?
The new kid on the block uv?&lt;/p&gt;

&lt;p&gt;Experienced Pythonistas are not immune either!
Many, like me, have been forced to celebrate the time honored and &lt;a href=&quot;https://xkcd.com/1987/&quot;&gt;xkcd-chronicled&lt;/a&gt; tradition of just wiping everything related to Python and starting from scratch.&lt;/p&gt;

&lt;p&gt;How can we make it as easy and as fast as possible to test out DuckDB in Python?&lt;/p&gt;
      &lt;h2 id=&quot;difficulties-of-server-side-python&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#difficulties-of-server-side-python&quot;&gt;Difficulties of Server-Side Python&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;One response to this challenge is to host a Python environment on a server for each of your users.
This has a number of issues.&lt;/p&gt;

&lt;p&gt;Hosting Python on a server yourself is not free.
If you have many users, it can be far from free.&lt;/p&gt;

&lt;p&gt;If you want to use a free solution like Google Colab, each visitor will need a Google account, and you&#39;ll need to be comfortable with Google accessing your data.
Plus, it is hard to embed within an existing web page for a seamless experience.&lt;/p&gt;
      &lt;h2 id=&quot;enter-pyodide&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#enter-pyodide&quot;&gt;Enter Pyodide&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://pyodide.org/&quot;&gt;Pyodide&lt;/a&gt; is a way to run Python directly in your browser with no installation and no setup, thanks to the power of WebAssembly.
That makes it the easiest and fastest way to get a Python environment up and running – just load a web page!
All computation happens locally, so it can be served like any static website with tools like GitHub Pages.
No server-side Python required!&lt;/p&gt;

&lt;p&gt;Another benefit is that Pyodide is nicely sandboxed in the browser environment.
Each user gets their own workspace, and since it is all local, it is nice and secure.&lt;/p&gt;

&lt;p&gt;Part of what sets Pyodide apart from other in-browser-Python approaches is that it can even run libraries that are written in C, C++, or even Fortran, including much of the Python data science stack.
This means that now you can use DuckDB in Pyodide as well!
You can even combine it with NumPy, SciPy, and Pandas (in addition to many pure-Python libraries).
PyArrow and Ibis have experimental support also.&lt;/p&gt;
      &lt;h2 id=&quot;use-cases-for-pyodide-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#use-cases-for-pyodide-duckdb&quot;&gt;Use Cases for Pyodide DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;Want to quickly analyze some remote data using either Python or DuckDB?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Pyodide is the fastest way to get your questions answered using Python.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Want to quickly analyze some local data?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Pyodide can also &lt;a href=&quot;https://pyodide.org/en/stable/usage/accessing-files.html&quot;&gt;query local files&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Want to make your documentation interactive?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let your users test out your DuckDB-powered library with ease.
We will see an example below that demonstrates the &lt;a href=&quot;https://github.com/iqmo-org/magic_duckdb&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;magic-duckdb&lt;/code&gt; Jupyter plugin&lt;/a&gt; to enable SQL cells.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Leading a training session with DuckDB and Python?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Skip the hassles of local installation.
There is no need to work 1:1 with the 15% of folks in the audience with some quirky setup!
Everyone will get this to work on the first try, in seconds, so you can get to the content you want to teach.
Plus, it is free, with no signup required of any kind!&lt;/p&gt;
      &lt;h2 id=&quot;pyodide-examples&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#pyodide-examples&quot;&gt;Pyodide Examples&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We will cover multiple ways to embed Pyodide-powered-Python directly into your site, so your users can try out your new DuckDB-backed tool with a single click!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PyScript Editor
    &lt;ul&gt;
      &lt;li&gt;An editor with nice syntax highlighting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;JupyterLite Notebook
    &lt;ul&gt;
      &lt;li&gt;A classic notebook environment&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;JupyterLite Lab IDE
    &lt;ul&gt;
      &lt;li&gt;A full development environment&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;pyscript-editor&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#pyscript-editor&quot;&gt;PyScript Editor&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;This HTML snippet will embed a runnable PyScript editor into any page!&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;module&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://pyscript.net/releases/2024.8.2/core.js&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;py-editor&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;config=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;{&quot;packages&quot;:[&quot;duckdb&quot;]}&#39;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;SELECT &#39;42 in an editor&#39; AS s&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Just click the play button and you can execute a DuckDB query directly in the browser.
You can edit the code, add new lines, etc.
Try it out!&lt;/p&gt;




      &lt;h3 id=&quot;jupyterlite-notebook&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#jupyterlite-notebook&quot;&gt;JupyterLite Notebook&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Here is an example of using an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iframe&lt;/code&gt; that points to a JupyterLite environment that was deployed to GitHub Pages!&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;iframe&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://alex-monahan.github.io/jupyterlite_duckdb_demo/notebooks/index.html?path=hello_duckdb.ipynb&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;style=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;height: 600px; width: 100%;&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/iframe&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is a fully interactive Python notebook environment, with DuckDB running inside. 
Feel free to give it a run!&lt;/p&gt;


&lt;iframe src=&quot;https://alex-monahan.github.io/jupyterlite_duckdb_demo/notebooks/index.html?path=hello_duckdb.ipynb&quot; style=&quot;height: 600px; width: 100%;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/iframe&gt;


&lt;p&gt;Configuring a full JupyterLite environment is only a few steps!
The JupyterLite folks have built a demo page that serves as a template and have some &lt;a href=&quot;https://jupyterlite.readthedocs.io/en/latest/quickstart/deploy.html&quot;&gt;great documentation&lt;/a&gt;.
The main steps are to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Use the JupyterLite Demo Template to create your own repo&lt;/li&gt;
  &lt;li&gt;Enable GitHub Pages for that repo&lt;/li&gt;
  &lt;li&gt;Add and commit a .ipynb file in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;content&lt;/code&gt; folder&lt;/li&gt;
  &lt;li&gt;Visit &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_github_username&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;YOUR_REPOSITORY_NAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;notebooks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;your_notebook_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipynb&lt;/span&gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note that it can take a couple of minutes for GitHub Pages to deploy.
You can monitor the progress on GitHub&#39;s Actions tab.&lt;/p&gt;
      &lt;h3 id=&quot;jupyterlite-lab-ide&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#jupyterlite-lab-ide&quot;&gt;JupyterLite Lab IDE&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;After following the steps in the JupterLite Notebook setup, if you change your URL from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/notebooks/&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/lab/&lt;/code&gt;, you can have a full IDE experience instead!
This form factor is a bit harder to embed in another page, but great for interactive use.&lt;/p&gt;

&lt;p&gt;This example uses the &lt;a href=&quot;https://github.com/iqmo-org/magic_duckdb&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;magic-duckdb&lt;/code&gt; Jupyter extension&lt;/a&gt; that allows us to create SQL cells using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%%dql&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://alex-monahan.github.io/jupyterlite_duckdb_demo/lab/index.html?path=magic_duckdb.ipynb&quot;&gt;Follow this link to see the Lab IDE interface&lt;/a&gt;, or experiment with the Notebook-style version below.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;iframe&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://alex-monahan.github.io/jupyterlite_duckdb_demo/notebooks/index.html?path=magic_duckdb.ipynb&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;style=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;height: 600px; width: 100%;&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/iframe&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;


&lt;iframe src=&quot;https://alex-monahan.github.io/jupyterlite_duckdb_demo/notebooks/index.html?path=magic_duckdb.ipynb&quot; style=&quot;height: 600px; width: 100%;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/iframe&gt;
      &lt;h2 id=&quot;architecture-of-duckdb-in-pyodide&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#architecture-of-duckdb-in-pyodide&quot;&gt;Architecture of DuckDB in Pyodide&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;So how does DuckDB work in Pyodide exactly?
The DuckDB Python client is compiled to WebAssembly (Wasm) in its entirety.
This is different than the existing &lt;a href=&quot;https://github.com/duckdb/duckdb-wasm&quot;&gt;DuckDB Wasm&lt;/a&gt; approach, since that is compiling the C++ side of the library only and wrapping it with a JavaScript API.
Both approaches use the Emscripten toolchain to do the Wasm compilation.
It is DuckDB&#39;s design decision to avoid dependencies and the prior investments in DuckDB-Wasm that made this feasible to build in such a short period of time!&lt;/p&gt;

&lt;p&gt;The Pyodide team has added DuckDB to their hosted repository of libraries, and even set up DuckDB to run as a part of their CI/CD workflow.
That is what enables JupyterLite to simply run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%pip install duckdb&lt;/code&gt;, and PyScript to specify DuckDB as a package in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py-editor config&lt;/code&gt; parameter or in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;py-config&amp;gt;&lt;/code&gt; tag.
Pyodide then downloads the Wasm-compiled version of the DuckDB library from Pyodide&#39;s repository.
We want to send a big thank you to the Pyodide team, including &lt;a href=&quot;https://github.com/hoodmane&quot;&gt;Hood Chatham&lt;/a&gt; and &lt;a href=&quot;https://github.com/ryanking13&quot;&gt;Gyeongjae Choi&lt;/a&gt;, as well as the Voltron Data team including &lt;a href=&quot;https://github.com/cpcloud&quot;&gt;Phillip Cloud&lt;/a&gt; for leading the effort to get this to work.&lt;/p&gt;
      &lt;h3 id=&quot;limitations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#limitations&quot;&gt;Limitations&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Running in the browser is a more restrictive environment (for security purposes), so there are some limitations when using DuckDB in Pyodide.
There is no free lunch!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Single-threaded
    &lt;ul&gt;
      &lt;li&gt;Pyodide currently limits execution to a single thread&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A few extra steps to query remote files
    &lt;ul&gt;
      &lt;li&gt;Remote files can&#39;t be accessed by DuckDB directly&lt;/li&gt;
      &lt;li&gt;Instead, pull the files locally with Pyodide first&lt;/li&gt;
      &lt;li&gt;DuckDB-Wasm has custom enhancements to make this possible, but these are not present in DuckDB&#39;s Python client&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;No runtime-loaded extensions
    &lt;ul&gt;
      &lt;li&gt;Several extensions are automatically included: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;icu&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tpcds&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tpch&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Release cadence aligned with Pyodide
    &lt;ul&gt;
      &lt;li&gt;At the time of writing, duckdb-pyodide is at 1.0.0 rather than 1.1.1&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/10/02/pyodide.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Pyodide is now the fastest way to use Python and DuckDB together!
It is also an approach that scales to an arbitrary number of users because Pyodide&#39;s computations happen entirely locally.&lt;/p&gt;

&lt;p&gt;We have seen how to embed Pyodide in a static site in multiple ways, as well as how to read remote files.&lt;/p&gt;

&lt;p&gt;If you are excited about DuckDB in Pyodide, feel free to join us on Discord.
We have a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#show-and-tell&lt;/code&gt; channel where you can share what you build with the community.
You are also welcome to explore the &lt;a href=&quot;https://github.com/duckdb/duckdb-pyodide&quot;&gt;duckdb-pyodide repo&lt;/a&gt; and report any issues you find.
We would also really love some help with enabling runtime-loaded extensions – please reach out if you can help!&lt;/p&gt;

&lt;p&gt;Happy quacking about!&lt;/p&gt;

</description><link>https://duckdb.org/2024/10/02/pyodide.html</link><guid isPermaLink="false">https://duckdb.org/2024/10/02/pyodide.html</guid><pubDate>Wed, 02 Oct 2024 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>Creating a SQL-Only Extension for Excel-Style Pivoting in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Easily create sharable extensions using only SQL macros that can apply to any table and any columns. We demonstrate the power of this capability with the pivot_table extension that provides Excel-style pivoting.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;the-power-of-sql-only-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#the-power-of-sql-only-extensions&quot;&gt;The Power of SQL-Only Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;SQL is not a new language.
As a result, it has historically been missing some of the modern luxuries we take for granted.
With version 1.1, DuckDB has launched community extensions, bringing the incredible power of a package manager to the SQL language.
A bold goal of ours is for DuckDB to become a convenient way to wrap any C++ library, much the way that Python does today, but across any language with a DuckDB client.&lt;/p&gt;

&lt;p&gt;For extension builders, compilation and distribution are much easier.
For the user community, installation is as simple as two commands:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; pivot_table &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;community&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; pivot_table&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The extension can then be used in any query through SQL functions.&lt;/p&gt;

&lt;p&gt;However, &lt;strong&gt;not all of us are C++ developers&lt;/strong&gt;!
Can we, as a SQL community, build up a set of SQL helper functions?
What would it take to build these extensions with &lt;em&gt;just SQL?&lt;/em&gt;&lt;/p&gt;
      &lt;h3 id=&quot;reusability&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#reusability&quot;&gt;Reusability&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Traditionally, SQL is highly customized to the schema of the database on which it was written.
Can we make it reusable?
Some techniques for reusability were discussed in the &lt;a href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html&quot;&gt;SQL Gymnasics post&lt;/a&gt;, but now we can go even further.
With version 1.1, DuckDB&#39;s world-class friendly SQL dialect makes it possible to create macros that can be applied:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;To any tables&lt;/li&gt;
  &lt;li&gt;On any columns&lt;/li&gt;
  &lt;li&gt;Using any functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The new ability to work &lt;strong&gt;on any tables&lt;/strong&gt; is thanks to the &lt;a href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#query-and-query_table-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; functions&lt;/a&gt;!
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; function is a safe way to execute &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statements defined by SQL strings, while &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; is a way to make a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause pull from multiple tables at once.
They are very powerful when used in combination with other friendly SQL features like the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression and  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; lambda functions.&lt;/p&gt;
      &lt;h3 id=&quot;community-extensions-as-a-central-repository&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#community-extensions-as-a-central-repository&quot;&gt;Community Extensions as a Central Repository&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Traditionally, there has been no central repository for SQL functions across databases, let alone across companies!
DuckDB&#39;s community extensions can be that knowledge base.
DuckDB extensions can be used across all languages with a DuckDB client, including Python, NodeJS, Java, Rust, Go, and even WebAssembly (Wasm)!&lt;/p&gt;

&lt;p&gt;If you are a DuckDB fan and a SQL user, you can share your expertise back to the community with an extension.
This post will show you how!
No C++ knowledge is needed – just a little bit of copy/paste and GitHub Actions handles all the compilation. 
If I can do it, you can do it!&lt;/p&gt;
      &lt;h3 id=&quot;powerful-sql&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#powerful-sql&quot;&gt;Powerful SQL&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;All that said, just how valuable can a SQL &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MACRO&lt;/code&gt; be?
Can we do more than make small snippets?
I&#39;ll make the case that you can do quite complex and powerful operations in DuckDB SQL using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; extension as an example.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; function allows for Excel-style pivots, including &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_totals&lt;/code&gt;, and more.
It is also very similar to the Pandas &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; function, but with all the scalability and speed benefits of DuckDB.
It contains over &lt;strong&gt;250 tests&lt;/strong&gt;, so it is intended to be useful beyond just an example!&lt;/p&gt;

&lt;p&gt;To achieve this level of flexibility, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; extension uses many friendly and advanced SQL features:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;a href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#query-and-query_table-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; function&lt;/a&gt; to execute a SQL string&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#query-and-query_table-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; function&lt;/a&gt; to query a list of tables&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#columns-expression&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression&lt;/a&gt; to select a dynamic list of columns&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html&quot;&gt;List lambda functions&lt;/a&gt; to build up the SQL statement passed into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_transformlist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt;&lt;/a&gt; for string manipulation like quoting&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_reducelist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;&lt;/a&gt; to concatenate strings together&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/list.html#list_aggregatelist-name&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_aggregate&lt;/code&gt;&lt;/a&gt; to sum multiple columns and identify subtotal and grand total rows&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#stringbeginend&quot;&gt;Bracket notation for string slicing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/setops.html#union-all-by-name&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt;&lt;/a&gt; to stack data by column name for subtotals and grand totals&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#replace-clause&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * REPLACE&lt;/code&gt;&lt;/a&gt; to dynamically clean up subtotal columns&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#exclude-clause&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * EXCLUDE&lt;/code&gt;&lt;/a&gt; to remove internally generated columns from the final result&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/grouping_sets.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUPING SETS&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROLLUP&lt;/code&gt;&lt;/a&gt; to generate subtotals and grand totals&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/unnest.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNNEST&lt;/code&gt;&lt;/a&gt; to convert lists into separate rows for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values_axis := &#39;rows&#39;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_macro.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MACRO&lt;/code&gt;s&lt;/a&gt; to modularize the code&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/orderby.html#order-by-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY ALL&lt;/code&gt;&lt;/a&gt; to order the result dynamically&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_type.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s&lt;/a&gt; to determine what columns to pivot horizontally&lt;/li&gt;
  &lt;li&gt;And of course the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/pivot.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; function&lt;/a&gt; for horizontal pivoting!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DuckDB&#39;s innovative syntax makes this extension possible!&lt;/p&gt;

&lt;p&gt;So, we now have all 3 ingredients we will need: a central package manager, reusable macros, and enough syntactic flexibility to do valuable work.&lt;/p&gt;
      &lt;h2 id=&quot;create-your-own-sql-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#create-your-own-sql-extension&quot;&gt;Create Your Own SQL Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let&#39;s walk through the steps to creating your own SQL-only extension.&lt;/p&gt;
      &lt;h3 id=&quot;writing-the-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#writing-the-extension&quot;&gt;Writing the Extension&lt;/a&gt;
        
      &lt;/h3&gt;
    
      &lt;h4 id=&quot;extension-setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#extension-setup&quot;&gt;Extension Setup&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The first step is to create your own GitHub repo from the &lt;a href=&quot;https://github.com/duckdb/extension-template-sql&quot;&gt;DuckDB Extension Template for SQL&lt;/a&gt; by clicking &lt;em&gt;Use this template.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Then clone your new repository onto your local machine using the terminal:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;git clone&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--recurse-submodules&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    https://github.com/⟨your_github_username⟩/⟨your_extension_repo⟩.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--recurse-submodules&lt;/code&gt; will ensure DuckDB is pulled which is required to build the extension.&lt;/p&gt;

&lt;p&gt;Next, replace the name of the example extension with the name of your extension in all the right places by running the Python script below.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note If you don&#39;t have Python installed, head to &lt;a href=&quot;https://python.org/&quot;&gt;python.org&lt;/a&gt; and follow those instructions.
This script doesn&#39;t require any libraries, so Python is all you need! (No need to set up any environments.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;python3&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scripts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bootstrap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;⟨&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extension_name_you_want&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;⟩&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;initial-extension-test&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#initial-extension-test&quot;&gt;Initial Extension Test&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;At this point, you can follow the directions in the README to build and test locally if you would like.
However, even easier, you can simply commit your changes to git and push them to GitHub, and GitHub Actions can do the compilation for you!
GitHub Actions will also run tests on your extension to validate it is working properly.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note The instructions are not written for a Windows audience, so we recommend GitHub Actions in that case!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;git &lt;/span&gt;add &lt;span class=&quot;nt&quot;&gt;-A&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;git &lt;/span&gt;commit &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Initial commit of my SQL extension!&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;git &lt;/span&gt;push
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;write-your-sql-macros&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#write-your-sql-macros&quot;&gt;Write Your SQL Macros&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;It is likely a bit faster to iterate if you test your macros directly in DuckDB. 
After you have written your SQL, we will move it into the extension.
The example we will use demonstrates how to pull a dynamic set of columns from a dynamic table name (or a view name!).&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;select_distinct_columns_from_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;query_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;select_distinct_columns_from_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;duckdb_types&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;type_category&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;type_category&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;BOOLEAN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;COMPOSITE&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DATETIME&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NUMERIC&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;STRING&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h4 id=&quot;add-sql-macros&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#add-sql-macros&quot;&gt;Add SQL Macros&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Technically, this is the C++ part, but we are going to do some copy/paste and use GitHub Actions for compiling so it won&#39;t feel that way!&lt;/p&gt;

&lt;p&gt;DuckDB supports both scalar and table macros, and they have slightly different syntax.
The extension template has an example for each (and code comments too!) inside the file named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;⟨your_extension_name⟩.cpp&lt;/code&gt;.
Let&#39;s add a table macro here since it is the more complex one.
We will copy the example and modify it!&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DefaultTableMacro&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;⟨&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;your_extension_name&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;⟩&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_table_macros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DEFAULT_SCHEMA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;times_two_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;two&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}},&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;R&quot;(SELECT x * two AS output_column;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DEFAULT_SCHEMA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Leave the schema as the default&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;select_distinct_columns_from_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Function name&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;table_name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;columns_list&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Parameters&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}},&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Optional parameter names and values (we choose not to have any here)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// The SQL text inside of your SQL Macro, wrapped in R&quot;( )&quot;, which is a raw string in C++&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;R&quot;(
            SELECT DISTINCT
                COLUMNS(column_name -&amp;gt; list_contains(columns_list, column_name))
            FROM query_table(table_name)
            ORDER BY ALL
        )&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}},&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That&#39;s it!
All we had to provide were the name of the function, the names of the parameters, and the text of our SQL macro.&lt;/p&gt;
      &lt;h3 id=&quot;testing-the-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#testing-the-extension&quot;&gt;Testing the Extension&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We also recommend adding some tests for your extension to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;⟨your_extension_name⟩.test&lt;/code&gt; file.
This uses &lt;a href=&quot;https://duckdb.org/docs/stable/dev/sqllogictest/intro.html&quot;&gt;sqllogictest&lt;/a&gt; to test with just SQL!
Let&#39;s add the example from above.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note In sqllogictest, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query I&lt;/code&gt; indicates that there will be 1 column in the result.
We then add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;----&lt;/code&gt; and the resultset in tab separated format with no column names.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;select_distinct_columns_from_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;duckdb_types&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;type_category&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;----&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;BOOLEAN&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMPOSITE&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;DATETIME&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;NUMERIC&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;STRING&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, just add, commit, and push your changes to GitHub like before, and GitHub Actions will compile your extension and test it!&lt;/p&gt;

&lt;p&gt;If you would like to do further ad-hoc testing of your extension, you can download the extension from your GitHub Actions run&#39;s artifacts and then &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/overview.html#unsigned-extensions&quot;&gt;install it locally using these steps&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;uploading-to-the-community-extensions-repository&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#uploading-to-the-community-extensions-repository&quot;&gt;Uploading to the Community Extensions Repository&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Once you are happy with your extension, it&#39;s time to share it with the DuckDB community!
Follow the steps in the &lt;a href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#developer-experience&quot;&gt;Community Extensions post&lt;/a&gt;.
A summary of those steps is:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Send a PR with a metadata file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;description.yml&lt;/code&gt; that contains the description of the extension. For example, the &lt;a href=&quot;https://duckdb.org/community_extensions/extensions/h3.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h3&lt;/code&gt; community extension&lt;/a&gt; uses the following YAML configuration:&lt;/p&gt;

    &lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;extension&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;h3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Hierarchical hexagonal indexing for geospatial data&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1.0.0&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;C++&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cmake&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;license&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Apache-2.0&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;maintainers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;isaacbrodsky&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;repo&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;isaacbrodsky/h3-duckdb&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3c8a5358e42ab8d11e0253c70f7cc7d37781b2ef&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wait for approval from the maintainers.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And there you have it!
You have created a shareable DuckDB community extension.
Now let&#39;s have a look at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; extension as an example of just how powerful a SQL-only extension can be.&lt;/p&gt;
      &lt;h2 id=&quot;capabilities-of-the-pivot_table-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#capabilities-of-the-pivot_table-extension&quot;&gt;Capabilities of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; extension supports advanced pivoting functionality that was previously only available in spreadsheets, dataframe libraries, or custom host language functions.
It uses the Excel pivoting API: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rows&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filters&lt;/code&gt; – handling 0 or more of each of those parameters.
However, not only that, but it supports &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_totals&lt;/code&gt;.
If multiple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt; are passed in, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values_axis&lt;/code&gt; parameter allows the user to choose if each value should get its own column or its own row.&lt;/p&gt;

&lt;p&gt;Why is this a good example of how DuckDB moves beyond traditional SQL?
The Excel pivoting API requires dramatically different SQL syntax depending on which parameters are in use.
If no &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; are pivoted outward, a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; is all that is needed.
However, once &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; are involved, a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; is required.&lt;/p&gt;

&lt;p&gt;This function can operate on one or more &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;table_names&lt;/code&gt; that are passed in as a parameter.
Any set of tables (or views!) will first be vertically stacked and then pivoted.&lt;/p&gt;
      &lt;h2 id=&quot;example-using-pivot_table&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#example-using-pivot_table&quot;&gt;Example Using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;!-- markdownlint-disable MD034 --&gt;

&lt;p&gt;&lt;a href=&quot;https://shell.duckdb.org/#queries=v0,CREATE-OR-REPLACE-TABLE-business_metrics-(-----product_line-VARCHAR%2C-product-VARCHAR%2C-year-INTEGER%2C-quarter-VARCHAR%2C-revenue-integer%2C-cost-integer-)~,INSERT-INTO-business_metrics-VALUES-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2022%2C-&#39;Q1&#39;%2C-100%2C-100)%2C-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2022%2C-&#39;Q2&#39;%2C-200%2C-100)%2C-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2022%2C-&#39;Q3&#39;%2C-300%2C-100)%2C-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2022%2C-&#39;Q4&#39;%2C-400%2C-100)%2C-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2023%2C-&#39;Q1&#39;%2C-500%2C-100)%2C-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2023%2C-&#39;Q2&#39;%2C-600%2C-100)%2C-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2023%2C-&#39;Q3&#39;%2C-700%2C-100)%2C-----(&#39;Waterfowl-watercraft&#39;%2C-&#39;Duck-boats&#39;%2C-2023%2C-&#39;Q4&#39;%2C-800%2C-100)%2C------(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2022%2C-&#39;Q1&#39;%2C-10%2C-10)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2022%2C-&#39;Q2&#39;%2C-20%2C-10)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2022%2C-&#39;Q3&#39;%2C-30%2C-10)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2022%2C-&#39;Q4&#39;%2C-40%2C-10)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2023%2C-&#39;Q1&#39;%2C-50%2C-10)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2023%2C-&#39;Q2&#39;%2C-60%2C-10)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2023%2C-&#39;Q3&#39;%2C-70%2C-10)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-suits&#39;%2C-2023%2C-&#39;Q4&#39;%2C-80%2C-10)%2C------(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2022%2C-&#39;Q1&#39;%2C-1%2C-1)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2022%2C-&#39;Q2&#39;%2C-2%2C-1)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2022%2C-&#39;Q3&#39;%2C-3%2C-1)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2022%2C-&#39;Q4&#39;%2C-4%2C-1)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2023%2C-&#39;Q1&#39;%2C-5%2C-1)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2023%2C-&#39;Q2&#39;%2C-6%2C-1)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2023%2C-&#39;Q3&#39;%2C-7%2C-1)%2C-----(&#39;Duck-Duds&#39;%2C-&#39;Duck-neckties&#39;%2C-2023%2C-&#39;Q4&#39;%2C-8%2C-1)%2C~,FROM-business_metrics~,INSTALL-pivot_table-from-community~,LOAD-&#39;pivot_table&#39;~,DROP-TYPE-IF-EXISTS-columns_parameter_enum~,CREATE-TYPE-columns_parameter_enum-AS-ENUM-(FROM-build_my_enum([&#39;business_metrics&#39;]%2C-[&#39;year&#39;%2C-&#39;quarter&#39;]%2C-[]))~,FROM-pivot_table([&#39;business_metrics&#39;]%2C[&#39;sum(revenue)&#39;%2C-&#39;sum(cost)&#39;]%2C-[&#39;product_line&#39;%2C-&#39;product&#39;]%2C-[&#39;year&#39;%2C-&#39;quarter&#39;]%2C-[]%2C-subtotals-%3A%3D-1%2C-grand_totals-%3A%3D-1%2C-values_axis-%3A%3D-&#39;rows&#39;)~&quot;&gt;Check out a live example using the extension in the DuckDB Wasm shell here&lt;/a&gt;!&lt;/p&gt;

&lt;!-- markdownlint-enable MD034 --&gt;

&lt;details&gt;
  &lt;summary&gt;
    First we will create an example data table. We are a duck product distributor, and we are tracking our fowl finances.
&lt;/summary&gt;

  &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;business_metrics&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;product_line&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;product&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;quarter&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;revenue&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;business_metrics&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Waterfowl watercraft&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck boats&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck suits&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Duck Duds&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Duck neckties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Q4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;business_metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/details&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;product_line&lt;/th&gt;
      &lt;th&gt;product&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;year&lt;/th&gt;
      &lt;th&gt;quarter&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;revenue&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;cost&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;200&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;300&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;600&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;700&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;800&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;50&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;60&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;70&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2022&lt;/td&gt;
      &lt;td&gt;Q4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2023&lt;/td&gt;
      &lt;td&gt;Q4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Next, we install the extension from the community repository:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; pivot_table &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;community&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; pivot_table&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we can build pivot tables like the one below. 
There is a little bit of boilerplate required, and the details of how this works will be explained shortly.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns_parameter_enum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns_parameter_enum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ENUM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_my_enum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;business_metrics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;-- table_names&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;quarter&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;-- columns&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;                      &lt;span class=&quot;c1&quot;&gt;-- filters&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pivot_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;business_metrics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;-- table_names&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;sum(revenue)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sum(cost)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- values&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;product_line&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;product&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;-- rows&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;quarter&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;           &lt;span class=&quot;c1&quot;&gt;-- columns&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;                            &lt;span class=&quot;c1&quot;&gt;-- filters&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;subtotals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;grand_totals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;values_axis&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;rows&#39;&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;product_line&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;product&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;value_names&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2022_Q1&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2022_Q2&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2022_Q3&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2022_Q4&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2023_Q1&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2023_Q2&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2023_Q3&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2023_Q4&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck Duds&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck Duds&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck Duds&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck Duds&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;30&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;50&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;60&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;70&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck Duds&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck Duds&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;22&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;33&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;44&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;55&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;66&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;77&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;88&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;200&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;300&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;400&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;600&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;700&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;800&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;200&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;300&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;400&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;600&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;700&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;800&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Grand Total&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Grand Total&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Grand Total&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Grand Total&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;222&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;333&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;444&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;555&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;666&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;777&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;888&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;how-the-pivot_table-extension-works&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#how-the-pivot_table-extension-works&quot;&gt;How the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; Extension Works&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; extension is a collection of multiple scalar and table SQL macros.
This allows the logic to be modularized.
You can see below that the functions are used as building blocks to create more complex functions.
This is typically difficult to do in SQL, but it is easy in DuckDB!&lt;/p&gt;

&lt;p&gt;The functions and a brief description of each follows.&lt;/p&gt;
      &lt;h3 id=&quot;building-block-scalar-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#building-block-scalar-functions&quot;&gt;Building Block Scalar Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nq&lt;/code&gt;: “No quotes” – Escape semicolons in a string to prevent SQL injection&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sq&lt;/code&gt;: “Single quotes” – Wrap a string in single quotes and escape embedded single quotes&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dq&lt;/code&gt;: “Double quotes” – Wrap in double quotes and escape embedded double quotes&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nq_list&lt;/code&gt;: Escape semicolons for each string in a list. Uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nq&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sq_list&lt;/code&gt;: Wrap each string in a list in single quotes. Uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sq&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dq_list&lt;/code&gt;: Wrap each string in a list in double quotes. Uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dq&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nq_concat&lt;/code&gt;: Concatenate a list of strings together with semicolon escaping. Uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nq_list&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sq_concat&lt;/code&gt;: Concatenate a list of strings together, wrapping each in single quotes. Uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sq_list&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dq_concat&lt;/code&gt;: Concatenate a list of strings together, wrapping each in double quotes. Uses &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dq_list&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;functions-creating-during-refactoring-for-modularity&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#functions-creating-during-refactoring-for-modularity&quot;&gt;Functions Creating During Refactoring for Modularity&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;totals_list&lt;/code&gt;: Build up a list as a part of enabling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_totals&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replace_zzz&lt;/code&gt;: Rename &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotal&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_total&lt;/code&gt; indicators after sorting so they are more friendly.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;core-pivoting-logic-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#core-pivoting-logic-functions&quot;&gt;Core Pivoting Logic Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;build_my_enum&lt;/code&gt;: Determine which new columns to create when pivoting horizontally. Returns a table. See below for details.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt;: Based on inputs, decide whether to call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;no_columns&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns_values_axis_columns&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns_values_axis_rows&lt;/code&gt;. Execute &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; on the SQL string that is generated. Returns a table. See below for details.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;no_columns&lt;/code&gt;: Build up the SQL string for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; to execute when no &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; are pivoted out.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns_values_axis_columns&lt;/code&gt;: Build up the SQL string for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; to execute when pivoting horizontally with each entry in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt; receiving a separate column.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns_values_axis_rows&lt;/code&gt;: Build up the SQL string for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; to execute when pivoting horizontally with each entry in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt; receiving a separate row.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table_show_sql&lt;/code&gt;: Return the SQL string that would have been executed by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; for debugging purposes.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;the-build_my_enum-function&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#the-build_my_enum-function&quot;&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;build_my_enum&lt;/code&gt; Function&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The first step in using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; extension&#39;s capabilities is to define an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; (a user-defined type) containing all of the new column names to create when pivoting horizontally called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns_parameter_enum&lt;/code&gt;.
DuckDB&#39;s automatic &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; syntax can automatically define this, but in our case, we need 2 explicit steps.
The reason for this is that automatic pivoting runs 2 statements behind the scenes, but a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MACRO&lt;/code&gt; must only be a single statement.
If the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; parameter is not in use, this step is essentially a no-op, so it can be omitted or included for consistency (recommended).&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; functions only support &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statements (for security reasons), so the dynamic portion of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; creation occurs in the function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;build_my_enum&lt;/code&gt;.
If this type of usage becomes common, features could be added to DuckDB to enable a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE OR REPLACE&lt;/code&gt; syntax for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; types, or possibly even temporary enums.
That would reduce this pattern from 3 statements down to 2.
Please let us know!&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;build_my_enum&lt;/code&gt; function uses a combination of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; to pull from multiple input tables, and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; function so that double quotes (and correct character escaping) can be completed prior to passing in the list of table names.
It uses a similar pattern to the core &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; function: build up a SQL query as a string, then call it with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt;.
The SQL string is constructed using list lambda functions and the building block functions for quoting.&lt;/p&gt;
      &lt;h3 id=&quot;the-pivot_table-function&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#the-pivot_table-function&quot;&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; Function&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;At its core, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; function determines the SQL required to generate the desired pivot based on which parameters are in use.&lt;/p&gt;

&lt;p&gt;Since this SQL statement is a string at the end of the day, we can use a hierarchy of scalar SQL macros rather than a single large macro.
This is a common traditional issue with SQL – it tends to not be very modular or reusable, but we are able to compartmentalize our logic wth DuckDB&#39;s syntax.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note If a non-optional parameter is not in use, an empty list (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[]&lt;/code&gt;) should be passed in.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;table_names&lt;/code&gt;: A list of table or view names to aggregate or pivot. Multiple tables are combined with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt; prior to any other processing.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt;: A list of aggregation metrics in the format &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[&#39;agg_fn_1(col_1)&#39;, &#39;agg_fn_2(col_2)&#39;, ...]&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rows&lt;/code&gt;: A list of column names to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt;: A list of column names to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; horizontally into a separate column per value in the original column. If multiple column names are passed in, only unique combinations of data that appear in the dataset are pivoted.
    &lt;ul&gt;
      &lt;li&gt;Ex: If passing in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; parameter like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[&#39;continent&#39;, &#39;country&#39;]&lt;/code&gt;, only valid &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;continent&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;country&lt;/code&gt; pairs will be included.&lt;/li&gt;
      &lt;li&gt;(no &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Europe_Canada&lt;/code&gt; column would be generated).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filters&lt;/code&gt;: A list of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clause expressions to be applied to the raw dataset prior to aggregating in the format &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[&#39;col_1 = 123&#39;, &#39;col_2 LIKE &#39;&#39;woot%&#39;&#39;&#39;, ...]&lt;/code&gt;.
    &lt;ul&gt;
      &lt;li&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filters&lt;/code&gt; are combined with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AND&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values_axis&lt;/code&gt; (Optional): If multiple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt; are passed in, determine whether to create a separate row or column for each value. Either &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rows&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt;, defaulting to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt; (Optional): If enabled, calculate the aggregate metric at multiple levels of detail based on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rows&lt;/code&gt; parameter. Either 0 or 1, defaulting to 0.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_totals&lt;/code&gt; (Optional): If enabled, calculate the aggregate metric across all rows in the raw data in addition to at the granularity defined by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rows&lt;/code&gt;. Either 0 or 1, defaulting to 0.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h4 id=&quot;no-horizontal-pivoting-no-columns-in-use&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#no-horizontal-pivoting-no-columns-in-use&quot;&gt;No Horizontal Pivoting (No &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; in Use)&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;If not using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; parameter, no columns need to be pivoted horizontally.
As a result, a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; statement is used.
If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt; are in use, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROLLUP&lt;/code&gt; expression is used to calculate the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt; at the different levels of granularity.
If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_totals&lt;/code&gt; are in use, but not &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt;, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUPING SETS&lt;/code&gt; expression is used instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROLLUP&lt;/code&gt; to evaluate across all rows.&lt;/p&gt;

&lt;p&gt;In this example, we build a summary of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;revenue&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; of each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;product_line&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;product&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pivot_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;business_metrics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;sum(revenue)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sum(cost)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;product_line&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;product&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;subtotals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;grand_totals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;values_axis&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;columns&#39;&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;product_line&lt;/th&gt;
      &lt;th&gt;product&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sum(revenue)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sum(&quot;cost&quot;)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;36&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;360&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;396&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;88&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3600&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;800&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3600&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;800&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3996&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;888&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h4 id=&quot;pivot-horizontally-one-column-per-metric-in-values&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#pivot-horizontally-one-column-per-metric-in-values&quot;&gt;Pivot Horizontally, One Column per Metric in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Build up a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; statement that will pivot out all valid combinations of raw data values within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; parameter. 
If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_totals&lt;/code&gt; are in use, make multiple copies of the input data, but replace appropriate column names in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rows&lt;/code&gt; parameter with a string constant.
Pass all expressions in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt; to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; statement&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;USING&lt;/code&gt; clause so they each receive their own column.&lt;/p&gt;

&lt;p&gt;We enhance our previous example to pivot out a separate column for each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;year&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value&lt;/code&gt; combination:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns_parameter_enum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns_parameter_enum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ENUM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_my_enum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;business_metrics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pivot_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;business_metrics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;sum(revenue)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sum(cost)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;product_line&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;product&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;subtotals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;grand_totals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;values_axis&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;columns&#39;&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;product_line&lt;/th&gt;
      &lt;th&gt;product&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2022_sum(revenue)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2022_sum(&quot;cost&quot;)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2023_sum(revenue)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2023_sum(&quot;cost&quot;)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;26&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;260&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;40&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;110&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;44&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;286&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;44&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2600&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2600&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1110&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;444&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2886&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;444&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h4 id=&quot;pivot-horizontally-one-row-per-metric-in-values&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#pivot-horizontally-one-row-per-metric-in-values&quot;&gt;Pivot Horizontally, One Row per Metric in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Build up a separate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; statement for each metric in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values&lt;/code&gt; and combine them with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt;. 
If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subtotals&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grand_totals&lt;/code&gt; are in use, make multiple copies of the input data, but replace appropriate column names in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rows&lt;/code&gt; parameter with a string constant.&lt;/p&gt;

&lt;p&gt;To simplify the appearance slightly, we adjust one parameter in our previous query and set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;values_axis := &#39;rows&#39;&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns_parameter_enum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns_parameter_enum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ENUM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_my_enum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;business_metrics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                       &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pivot_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;business_metrics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;sum(revenue)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sum(cost)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;product_line&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;product&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;subtotals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;grand_totals&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;values_axis&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;rows&#39;&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;product_line&lt;/th&gt;
      &lt;th&gt;product&lt;/th&gt;
      &lt;th&gt;value_names&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2022&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2023&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck neckties&lt;/td&gt;
      &lt;td&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;40&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Duck suits&lt;/td&gt;
      &lt;td&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;260&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;44&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;44&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duck Duds&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;110&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;286&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Duck boats&lt;/td&gt;
      &lt;td&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;400&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Waterfowl watercraft&lt;/td&gt;
      &lt;td&gt;Subtotal&lt;/td&gt;
      &lt;td&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td&gt;sum(cost)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;444&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;444&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td&gt;Grand Total&lt;/td&gt;
      &lt;td&gt;sum(revenue)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1110&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2886&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/27/sql-only-extensions.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;With DuckDB 1.1, sharing your SQL knowledge with the community has never been easier!
DuckDB&#39;s community extension repository is truly a package manager for the SQL language.
Macros in DuckDB are now highly reusable (thanks to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt;), and DuckDB&#39;s SQL syntax provides plenty of power to accomplish complex tasks.&lt;/p&gt;

&lt;p&gt;Please let us know if the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivot_table&lt;/code&gt; extension is helpful to you – we are open to both contributions and feature requests!
Together we can write the ultimate pivoting capability just once and use it everywhere.&lt;/p&gt;

&lt;p&gt;In the future, we have plans to further simplify the creation of SQL extensions.
Of course, we would love your feedback!
&lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Join us on Discord&lt;/a&gt; in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;community-extensions&lt;/code&gt; channel.&lt;/p&gt;

&lt;p&gt;Happy analyzing!&lt;/p&gt;

</description><link>https://duckdb.org/2024/09/27/sql-only-extensions.html</link><guid isPermaLink="false">https://duckdb.org/2024/09/27/sql-only-extensions.html</guid><pubDate>Fri, 27 Sep 2024 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>Changing Data with Confidence and ACID</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Transactions are key features in database management systems and are also beneficial for data analysis workloads. DuckDB supports fully ACID transactions, confirmed by the TPC-H benchmark&#39;s test suite.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;The great quote “Everything changes and nothing stays the same” from &lt;a href=&quot;https://latin.stackexchange.com/a/9473&quot;&gt;Heraclitus, according to Socrates, according to Plato&lt;/a&gt; is not very controversial: change is as old as the universe. Yet somehow, when dealing with data, we often consider change as merely an afterthought.&lt;/p&gt;

&lt;p&gt;Static datasets are split-second snapshots of whatever the world looked like at one moment. But very quickly, the world moves on, and the dataset needs to catch up to remain useful. In the world of tables, new rows can be added, old rows may be deleted and sometimes rows have to be changed to reflect a new situation. Often, changes are interconnected. A row in a table that maps orders to customers is not very useful without the corresponding entry in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table. Most, if not all, datasets eventually get changed. As a data management system, managing change is thus not optional. However, managing changes properly is difficult.&lt;/p&gt;

&lt;p&gt;Early data management systems researchers invented a concept called “transactions”, the notions of which were &lt;a href=&quot;https://dl.acm.org/doi/abs/10.5555/48751.48761&quot;&gt;first formalized&lt;/a&gt; &lt;a href=&quot;https://dl.acm.org/doi/10.1145/289.291&quot;&gt;in the 1980s&lt;/a&gt;. In essence, transactionality and the well-known ACID principles describe a set of guarantees that a data management system has to provide in order to be considered safe. ACID is an acronym that stands for Atomicity, Consistency, Isolation and Durability.&lt;/p&gt;

&lt;p&gt;The ACID principles are not a theoretical exercise. Much like the rules governing airplanes or trains, they have been “written in blood” – they are hard-won lessons from decades of data management practice. It is very hard for an application to reason correctly when dealing with non-ACID systems. The end result of such problems is often corrupted data or data that no longer reflects reality accurately. For example, rows can be duplicated or missing.&lt;/p&gt;

&lt;p&gt;DuckDB provides full ACID guarantees by default without additional configuration. In this blog post, we will describe in detail what that means together with concrete examples, and show how you can take advantage of this functionality.&lt;/p&gt;
      &lt;h3 id=&quot;atomicity&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#atomicity&quot;&gt;Atomicity&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; means that &lt;em&gt;either all changes in a set of updates happen or none of them happen&lt;/em&gt;. Consider the example below, where we insert two rows in two separate tables. The inserts themselves are separate statements, but they can be made atomic by wrapping them in a transaction:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;customer_id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TRANSACTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DuckDB Labs&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;stale bread&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────┬─────────────┐
│ customer_id │    item     │
│    int32    │   varchar   │
├─────────────┼─────────────┤
│          42 │ stale bread │
└─────────────┴─────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By wrapping the changes in a transaction, we can be sure that &lt;em&gt;either both rows are written, or none of them are written&lt;/em&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BEGIN TRANSACTION&lt;/code&gt; statement signifies all following statements belong to that transaction. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COMMIT&lt;/code&gt; signifies the end of the transaction – and will persist the changes to disk.&lt;/p&gt;

&lt;p&gt;It is also possible to undo a set of changes by issuing a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROLLBACK&lt;/code&gt; at the end of a transaction. This will ensure that none of the changes made in the transaction are persisted.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TRANSACTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;iceberg lettuce&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;dried worms&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ROLLBACK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────┬─────────────┐
│ customer_id │    item     │
│    int32    │   varchar   │
├─────────────┼─────────────┤
│          42 │ stale bread │
└─────────────┴─────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As we can see, the two new rows have not been inserted permanently.&lt;/p&gt;

&lt;p&gt;Atomicity is great to have because it allows the application to move the database from one consistent state to another consistent state without ever having to worry about intermediate states being visible to an application.&lt;/p&gt;

&lt;p&gt;We should note that queries by default run in the so-called “auto-commit” mode, where each query will automatically be run in its own transaction. That said, even for these single-statement queries, transactions are very useful. For example, when bulk loading data into a table using an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; command, either &lt;em&gt;all&lt;/em&gt; of the data is loaded, or &lt;em&gt;none&lt;/em&gt; of the data is loaded. The system will not partially load a CSV file into a table.&lt;/p&gt;

&lt;p&gt;We should also note that in DuckDB &lt;em&gt;schema changes are also transactional&lt;/em&gt;. This means that you can create or delete tables, as well as alter the schema of a table, all within the safety of a transaction. It also means that you can undo any of these operations by issuing a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROLLBACK&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;consistency&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#consistency&quot;&gt;Consistency&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;strong&gt;Consistency&lt;/strong&gt; means that all of &lt;a href=&quot;https://duckdb.org/docs/stable/sql/constraints.html&quot;&gt;the constraints that are defined in the database&lt;/a&gt; must always hold, both before and after a transaction. The constraints can never be violated. Examples of constraints are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRIMARY KEY&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FOREIGN KEY&lt;/code&gt; constraints.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DuckDB Labs&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Wilbur the Duck&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the example above, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt; table requires the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt; column to be unique for all entries, otherwise multiple customers would be associated with the same orders. We can enforce this constraint by defining a so-called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRIMARY KEY&lt;/code&gt; on that column. When we insert two entries with the same id, the consistency check fails, and we get an error message:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Constraint Error: Duplicate key &quot;id: 42&quot; violates primary key
constraint. (...)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Having these kinds of constraints in place is a great way to make sure data &lt;em&gt;remains&lt;/em&gt; consistent even after many updates have taken place.&lt;/p&gt;
      &lt;h3 id=&quot;isolation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#isolation&quot;&gt;Isolation&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;strong&gt;Isolation&lt;/strong&gt; means that concurrent transactions are isolated from one another. A database can have many clients interacting with it &lt;em&gt;at the same time,&lt;/em&gt; causing many transactions to happen all at once. An easy way of isolating these transactions is to execute them one after another. However, that would be prohibitively slow. Thousands of requests might have to wait for one particularly slow one.&lt;/p&gt;

&lt;p&gt;To avoid this problem, transactions are typically executed &lt;em&gt;interleaved&lt;/em&gt;. However, as those transactions change data, one must ensure that each transaction is logically &lt;em&gt;isolated&lt;/em&gt; – it only ever sees a consistent state of the database and can – for example – never read data from a transaction that has not yet committed.&lt;/p&gt;

&lt;p&gt;DuckDB does not have connections in the typical sense – as it is not a client/server database that allows separate applications to connect to it. However, DuckDB has &lt;a href=&quot;https://duckdb.org/docs/stable/connect/concurrency.html&quot;&gt;full multi-client support&lt;/a&gt; within a single application. The user can create multiple clients that all connect to the same DuckDB instance. The transactions can be run concurrently and they are isolated using &lt;a href=&quot;https://jepsen.io/consistency/models/snapshot-isolation&quot;&gt;Snapshot Isolation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The way that multiple connections are created differs per client. Below is an example where we showcase the transactionality of the system using the Python client.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:memory:mydb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CREATE TABLE customer (id INTEGER, name VARCHAR)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;INSERT INTO customer VALUES (42, &#39;DuckDB Labs&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;INSERT INTO customer VALUES (43, &#39;Wilbur the Duck&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# no commit!
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# start a new connection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:memory:mydb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT name FROM customer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# ┌─────────────┐
# │    name     │
# │   varchar   │
# ├─────────────┤
# │ DuckDB Labs │
# └─────────────┘
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# commit from the first connection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;commit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# now the changes are visible
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT name FROM customer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# ┌─────────────────┐
# │      name       │
# │     varchar     │
# ├─────────────────┤
# │ DuckDB Labs     │
# │ Wilbur the Duck │
# └─────────────────┘
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see, we have two connections to the same database, and the first connection inserts the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wilbur the Duck&lt;/code&gt; customer but &lt;em&gt;does not yet commit the change&lt;/em&gt;. Meanwhile, the second connection reads from the customer table. The result does not yet show the new entry, because the two transactions are isolated from each other with regards to uncommitted changes. After the first connection commits, the second connection can read its changes.&lt;/p&gt;
      &lt;h3 id=&quot;durability&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#durability&quot;&gt;Durability&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Finally, &lt;strong&gt;durability&lt;/strong&gt; is the behavior of a system under failure. This is important as a process might crash or power to a computer may be lost. A database system now needs to ensure that &lt;em&gt;all committed transactions&lt;/em&gt; are durable, meaning their effects will be visible after restarting the database. Transactions that have not yet completed cannot leave any visible traces behind. Databases typically guarantee this property by keeping close tabs on the various caches, for example by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fsync&lt;/code&gt; to force changes to disk as transactions complete. Skipping the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fsync&lt;/code&gt; is a common “optimization” that endangers durability.&lt;/p&gt;

&lt;p&gt;Here is an example, again using Python:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;signal&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mydb.duckdb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CREATE TABLE customer (id INTEGER, name VARCHAR)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;INSERT INTO customer VALUES (42, &#39;DuckDB Labs&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# begin a transaction
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;INSERT INTO customer VALUES (43, &#39;Wilbur the Duck&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# no commit!
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getpid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SIGKILL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After restarting, we can check the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt; table:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mydb.duckdb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT name FROM customer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────┐
│    name     │
│   varchar   │
├─────────────┤
│ DuckDB Labs │
└─────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this example, we first create the customer table in the database file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mydb.duckdb&lt;/code&gt;. We then insert a single row with DuckDB Labs as a first transaction. Then, we begin but &lt;em&gt;do not commit&lt;/em&gt; a second transaction that adds the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Wilbur the Duck&lt;/code&gt; entry. If we then kill the process and with it the database, we can see that upon restart only the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DuckDB Labs&lt;/code&gt; entry has survived. This is because the second transaction was not committed and hence not subject to durability. Of course, this gets more complicated when non-clean exits such as operating system crashes have to be considered. DuckDB also guarantees durability in those circumstances, some more on this below.&lt;/p&gt;
      &lt;h2 id=&quot;why-acid-in-olap&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#why-acid-in-olap&quot;&gt;Why ACID in OLAP?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are two main classes of data management systems, transactional systems (OLTP) and analytical systems (OLAP). As the name implies, transactional systems are far more concerned with guaranteeing the ACID properties than analytical ones. Systems like the venerable PostgreSQL deservedly pride themselves on doing the “right thing” with regard to providing transactional guarantees by default. Even NoSQL transactional systems such as MongoDB that swore off guaranteeing the ACID principles “for performance” early on had to eventually &lt;a href=&quot;https://www.mongodb.com/resources/basics/databases/acid-transactions&quot;&gt;“roll back” to offering ACID guarantees&lt;/a&gt; with &lt;a href=&quot;https://jepsen.io/analyses/mongodb-4.2.6&quot;&gt;one or two hurdles along the way&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Analytical systems such as DuckDB – in principle – have less of a imperative to provide strong transactional guarantees. They are often not the so-called “system of record”, which is the data management system that is considered the source truth. In fact, DuckDB offers various connectors to load data from systems of record, like the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/postgres.html&quot;&gt;PostgreSQL scanner&lt;/a&gt;. If an OLAP database would become corrupted, it is often possible to recover from that source of truth. Of course, that first requires that users notice that something has gone wrong, which is not always simple to detect. For example, a common mistake is ingesting data from the same CSV file twice into a database because the first attempt went wrong at some point. This can lead to duplicate rows causing incorrect aggregate results. ACID prevents these kinds of problems. ACID properties enable  useful functionality in OLAP systems. For example:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Concurrent Ingestion and Reporting.&lt;/strong&gt; As change is continuous, we often have data ingestion streams adding new data to a database system. In analytical systems, it is common to have a single connection append new data to a database, while other connections read from the database in order to e.g., generate graphs and reports. If these connections are isolated, then the generated graphs and aggregates will always be executed over a complete and consistent snapshot of the database, ensuring that the generated graphs and aggregates are correct.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rolling Back Incorrect Transformations.&lt;/strong&gt; When analyzing data, a common pattern is loading data from data sets stored in flat files followed by performing a number of transformations on that data. For example, we might load a data set from a CSV file, followed by cleaning up &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values and then deleting incomplete rows. If we make an incorrect transformation, it is possible we accidentally delete too many rows.&lt;/p&gt;

&lt;p&gt;This is not the end of the world, as we can recover by re-reading from the original CSV files. However, we can save ourselves a lot of time by wrapping the transformations in a transaction and rolling back when something goes wrong. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;people.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TRANSACTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; people &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;-99&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- oops, we deleted all rows!&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;non-existent name&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- we can recover our original table by rolling back the delete&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ROLLBACK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;SQL Assertions.&lt;/strong&gt; When a (non-syntax) error occurs in a transaction, the transaction is automatically aborted, and the changes cannot be committed. We can use this property of transactions to add assertions to our transactions. When one of these assertions is triggered, an error is raised, and the transaction cannot be committed. We can use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;error&lt;/code&gt; function to define our own &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;assert&lt;/code&gt; macro:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;CASE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHEN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;THEN&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;END&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can then use this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;assert&lt;/code&gt; macro to assert that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;people&lt;/code&gt; table is not empty:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;people.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TRANSACTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;UPDATE&lt;/span&gt; people &lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;-99&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- oops, we deleted all rows!&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;non-existent name&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;people&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;s1&quot;&gt;&#39;People should not be empty&#39;&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COMMIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When the assertion triggers, the transaction is automatically aborted, and the changes are rolled back.&lt;/p&gt;
      &lt;h2 id=&quot;full-tpc-h-benchmark-implementation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#full-tpc-h-benchmark-implementation&quot;&gt;Full TPC-H Benchmark Implementation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;a href=&quot;https://www.tpc.org/tpch/&quot;&gt;Transaction Processing Performance Council (TPC)&lt;/a&gt; is an industry association of data management systems and hardware vendors. TPC publishes database benchmark specifications and oversees auditing of benchmark results, which it then publishes on its website. There are various benchmarks aimed at different use cases. The &lt;a href=&quot;https://www.tpc.org/tpch/&quot;&gt;TPC-H decision support benchmark&lt;/a&gt; is specifically aimed at analytical query processing on large volumes of data. Its famous 22 SQL queries and data generator specifics have been thourougly analyzed by both database vendors and &lt;a href=&quot;https://homepages.cwi.nl/~boncz/snb-challenge/chokepoints-tpctc.pdf&quot;&gt;academics&lt;/a&gt; ad nauseam.&lt;/p&gt;

&lt;p&gt;It is less well known that the official TPC-H benchmark includes &lt;em&gt;data modification transactions&lt;/em&gt; that require ACID compliance, which is not too-surprising given the name of the organization. For one-off performance shoot-outs, the updates are typically ignored and only the run-times of the 22 queries on a static dataset are reported. Such results are purely informational and cannot be audited or formally published by the TPC. But as we have argued above, change is inevitable, so let&#39;s perform the TPC-H experiments &lt;em&gt;with updates&lt;/em&gt; with DuckDB.&lt;/p&gt;

&lt;p&gt;TPC-H generates data for a fictional company selling things. The largest tables are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt;, which contains elements of each order. The benchmark can generate data of different sizes, the size is controlled by a so-called “scale factor” (SF). The specification defines two “refresh functions”, that modify the database. The first refresh function will add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SF * 1500&lt;/code&gt; new rows into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table, and randomly between 1 and 7 new entries for each order into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; table. The second refresh function will delete &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SF * 1500&lt;/code&gt; entries from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table along with the associated &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; entries. The benchmark data generator &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dbgen&lt;/code&gt; can generate an arbitrary amount of refresh function CSV files with new entries for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; along with rows to be deleted.&lt;/p&gt;
      &lt;h3 id=&quot;metrics&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#metrics&quot;&gt;Metrics&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;TPC-H&#39;s main benchmark metric is combined from both a “power” and a “throughput” test result.&lt;/p&gt;

&lt;p&gt;The power test will run the first refresh function and time it, then run the 22 queries, then run the second refresh function, and calculate the geometric mean of all timings. With a scale factor of 100 and DuckDB 1.1.1 on a MacBook Pro with an M3 Max CPU and 64 GB of RAM, we get a &lt;em&gt;Power@Size value of 650&amp;nbsp;536&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The throughput test will run a number of concurrent query “streams” that execute the 22 benchmark queries in shuffled order in parallel. In addition, a single refresh stream will run both refresh functions a number of times. The number of query streams and refresh sets is derived from the scale factor. For SF100, there are 5 query streams and 10 refresh sets. For our experiment, we get a &lt;em&gt;Throughput@Size of 452&amp;nbsp;571&lt;/em&gt;. Results are hard to compare, but the result does not look too shabby when compared with the &lt;a href=&quot;https://www.tpc.org/tpch/results/tpch_results5.asp?print=false&amp;amp;orderby=tpm&amp;amp;sortby=desc&amp;amp;version=3%&quot;&gt;official result list&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;acid-tests&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#acid-tests&quot;&gt;ACID Tests&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Section 3 of the TPC-H benchmark specification discusses the ACID properties in detail. The specification defines a set of tests to stress the ACID guarantees of a data management system. The spec duly notes that no test can prove that the ACID properties are fully supported, passing them is a “necessary but not sufficient condition” of compliance.  Below, we will give an overview of what is tested.&lt;/p&gt;

&lt;p&gt;The tests specify an “ACID Transaction”, which modifies the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; tables in such a way that an invariant holds: the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table contains a total sum of all the prices of all the lineitems that belong to this order. The transaction picks a random order, and modifies the last lineitem to have a new price. It then re-calculates the order total price and updates the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; table with that. Finally, the transaction inserts information about which row was updated when and the price delta used in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;history&lt;/code&gt; table.&lt;/p&gt;

&lt;p&gt;To test &lt;em&gt;atomicity&lt;/em&gt;, the ACID transaction is ran for a random order and then committed. It is verified that the database has been changed accordingly with the specified values. The test is repeated but this time the transaction is aborted. It is verified that the database has not been changed.&lt;/p&gt;

&lt;p&gt;For &lt;em&gt;consistency&lt;/em&gt;, a number of threads run the ACID transaction in parallel 100 times on random orders. Before and after the test, a consistency condition is checked, which essentially makes sure that the sum of all lineitem prices for an order is consistent with the sum in the order.&lt;/p&gt;

&lt;p&gt;To test &lt;em&gt;isolation&lt;/em&gt;, one thread will run the transaction, but not commit or rollback yet. Another connection will make sure the changes are not visible to it. Another set of tests will have two threads running transactions on the same order, and ensure that one of them is aborted by the system due to the conflict.&lt;/p&gt;

&lt;p&gt;Finally, to test &lt;em&gt;durability&lt;/em&gt;, a number of threads run the ACID transaction and log the results. They are allowed to complete at least 100 transactions each. Then, a failure is caused, in our case, we simply killed the process (using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SIGKILL&lt;/code&gt;). Then, the database system is allowed to recover the committed changes from the &lt;a href=&quot;https://en.wikipedia.org/wiki/Write-ahead_logging&quot;&gt;write-ahead log&lt;/a&gt;. The log is checked to ensure that there are no log entries that are not reflected in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;history&lt;/code&gt; table and there are no history entries that don&#39;t have log entries, minus very few that might have been lost in flight (i.e., persisted by the database but not yet logged by the benchmark driver). Finally, the consistency is checked again.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We&#39;re happy to report that DuckDB passed all tests.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Our scripts to run the benchmark are &lt;a href=&quot;https://github.com/hannes/duckdb-tpch-power-test&quot;&gt;available on GitHub&lt;/a&gt;. We are planning to perform a formal audit of our results in the future. We will update this post when that happens.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Change in datasets is inevitable, and data management systems need to be able to safely manage change. DuckDB supports strong ACID guarantees that allow for safe and concurrent data modification. We have run extensive experiments with TPC-H&#39;s transactional validation tests and found that they pass.&lt;/p&gt;

</description><link>https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html</link><guid isPermaLink="false">https://duckdb.org/2024/09/25/changing-data-with-confidence-and-acid.html</guid><pubDate>Wed, 25 Sep 2024 00:00:00 GMT</pubDate><author>Hannes Mühleisen and Mark Raasveldt</author></item><item><title>Announcing DuckDB 1.1.0</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The DuckDB team is happy to announce that today we&#39;re releasing DuckDB version 1.1.0, codenamed “Eatoni”.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;.
For the release notes, see the &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v1.1.0&quot;&gt;release page&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Some packages (R, Java) take a few extra days to release due to the reviews required in the release pipelines.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We are proud to release DuckDB 1.1.0, our first release since we released version 1.0.0 three months ago.
This release is codenamed “Eatoni” after the &lt;a href=&quot;https://en.wikipedia.org/wiki/Eaton%27s_pintail&quot;&gt;Eaton&#39;s pintail (Anas eatoni)&lt;/a&gt;,
a dabbling duck that occurs only on two very remote island groups in the southern Indian Ocean.&lt;/p&gt;
      &lt;h2 id=&quot;whats-new-in-110&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#whats-new-in-110&quot;&gt;What&#39;s New in 1.1.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There have been far too many changes to discuss them each in detail, but we would like to highlight several particularly exciting features!
Below is a summary of those new features with examples.&lt;/p&gt;
      &lt;h2 id=&quot;breaking-sql-changes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#breaking-sql-changes&quot;&gt;Breaking SQL Changes&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/13493&quot;&gt;&lt;strong&gt;IEEE-754 semantics for division by zero.&lt;/strong&gt;&lt;/a&gt; The &lt;a href=&quot;https://en.wikipedia.org/wiki/IEEE_754&quot;&gt;IEEE-754 floating point standard&lt;/a&gt; states that division by zero returns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inf&lt;/code&gt;. Previously, DuckDB would return &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; when dividing by zero, also for floating point division. Starting with this release, DuckDB will return &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inf&lt;/code&gt; instead.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;division_by_zero&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────┐
│ division_by_zero │
│      double      │
├──────────────────┤
│              inf │
└──────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ieee_floating_point_ops&lt;/code&gt; can be set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt; to revert this behavior:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;ieee_floating_point_ops&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;division_by_zero&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────┐
│ division_by_zero │
│      double      │
├──────────────────┤
│             NULL │
└──────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/13514&quot;&gt;&lt;strong&gt;Error when scalar subquery returns multiple values.&lt;/strong&gt;&lt;/a&gt; Scalar subqueries can only return a single value per input row. Previously, DuckDB would match SQLite&#39;s behavior and select an arbitrary row to return when multiple rows were returned. In practice this behavior often led to confusion. Starting with this release, an error is returned instead, matching the behavior of Postgres. The subquery can be wrapped with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt; to collect all of the results of the subquery in a list.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Invalid Input Error: More than one row returned by a subquery used as
an expression - scalar subqueries can only return a single row.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ARRAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subquery_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────┐
│        subquery_result         │
│            int64[]             │
├────────────────────────────────┤
│ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] │
└────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scalar_subquery_error_on_multiple_rows&lt;/code&gt; setting can be set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt; to revert this behavior.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;scalar_subquery_error_on_multiple_rows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────┐
│ result │
│ int64  │
├────────┤
│      0 │
└────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;community-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#community-extensions&quot;&gt;Community Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Recently we introduced &lt;a href=&quot;https://duckdb.org/2024/07/05/community-extensions.html&quot;&gt;Community Extensions&lt;/a&gt;. Community extensions allow anyone to build extensions for DuckDB, that are then built and distributed by us. The &lt;a href=&quot;https://duckdb.org/community_extensions/list_of_extensions.html&quot;&gt;list of community extensions&lt;/a&gt; has been growing since then.&lt;/p&gt;

&lt;p&gt;In this release, we have been working towards making community extensions easier to build and produce. This release includes a new method of registering extensions &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12682&quot;&gt;using the C API&lt;/a&gt; in addition to a lot of extensions to the C API allowing &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11786&quot;&gt;scalar functions&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/13229&quot;&gt;aggregate functions&lt;/a&gt; and &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/13499&quot;&gt;custom types&lt;/a&gt; to be defined. These changes will enable building extensions against a stable API, that are smaller in size, that will work across different DuckDB versions. In addition, these changes will enable building extensions in other programming languages in the future.&lt;/p&gt;
      &lt;h2 id=&quot;friendly-sql&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#friendly-sql&quot;&gt;Friendly SQL&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12590&quot;&gt;&lt;strong&gt;Histogram.&lt;/strong&gt;&lt;/a&gt; This version introduces the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;histogram&lt;/code&gt; function that can be used to compute histograms over columns of a dataset. The histogram function works for columns of any type, and allows for various different binning strategies and a custom amount of bins.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;histogram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/ontime.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;UniqueCarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;bin_count&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────┬────────┬──────────────────────────────────────────────────────────────────────────────────┐
│      bin       │ count  │                                       bar                                        │
│    varchar     │ uint64 │                                     varchar                                      │
├────────────────┼────────┼──────────────────────────────────────────────────────────────────────────────────┤
│ AA             │ 677215 │ ██████████████████████████████████████████████████████▏                          │
│ DL             │ 696931 │ ███████████████████████████████████████████████████████▊                         │
│ OO             │ 521956 │ █████████████████████████████████████████▊                                       │
│ UA             │ 435757 │ ██████████████████████████████████▉                                              │
│ WN             │ 999114 │ ████████████████████████████████████████████████████████████████████████████████ │
│ (other values) │ 945484 │ ███████████████████████████████████████████████████████████████████████████▋     │
└────────────────┴────────┴──────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/13084&quot;&gt;&lt;strong&gt;SQL variables.&lt;/strong&gt;&lt;/a&gt; This release introduces support for variables that can be defined in SQL. Variables can hold a single value of any type – including nested types like lists or structs. Variables can be set as literals, or from scalar subqueries.&lt;/p&gt;

&lt;p&gt;The value stored within variables can be read using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getvariable&lt;/code&gt;. When used in a query, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getvariable&lt;/code&gt; is treated as a literal during query planning and optimization. This allows variables to be used in places where we normally cannot read values from within tables, for example, when specifying which CSV files to read:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VARIABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list_of_files&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;LIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csv_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;getvariable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;list_of_files&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────┬───────────┐
│   a   │ filename  │
│ int64 │  varchar  │
├───────┼───────────┤
│    42 │ test.csv  │
│    84 │ test2.csv │
└───────┴───────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;unpacked-columns&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#unpacked-columns&quot;&gt;Unpacked Columns&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#columns-expression&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression&lt;/a&gt; allows users to write dynamic SQL over a set of columns without needing to explicitly list the columns in the SQL string. Instead, the columns can be selected through either a regex or computed with a &lt;a href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html&quot;&gt;lambda function&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This release expands this capability by &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11872&quot;&gt;allowing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression to be &lt;em&gt;unpacked&lt;/em&gt; into a function&lt;/a&gt;.
This is especially useful when combined with nested functions like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;struct_pack&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_value&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;many_measurements&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m3&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;many_measurements&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;struct_pack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;m\d&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;measurements&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;many_measurements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────┬────────────────────────────────────────────┐
│  id   │                measurements                │
│ int32 │ struct(m1 integer, m2 integer, m3 integer) │
├───────┼────────────────────────────────────────────┤
│     1 │ {&#39;m1&#39;: 10, &#39;m2&#39;: 100, &#39;m3&#39;: 20}            │
└───────┴────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;query-and-query_table-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#query-and-query_table-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10586&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_table&lt;/code&gt; functions&lt;/a&gt; take a string literal, and convert it into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; subquery or a table reference. Note that these functions can only take literal strings. As such, they are not as powerful (or dangerous) as a generic &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eval&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;These functions are conceptually simple, but enable powerful and more dynamic SQL. For example, they allow passing in a table name as a prepared statement parameter:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;PREPARE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;select_from_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;query_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXECUTE&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;select_from_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;my_table&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────┐
│   i   │
│ int32 │
├───────┤
│    42 │
└───────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When combined with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression, we can write very generic SQL-only macros. For example, below is a custom version of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt; that computes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt; of every column in a table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;my_summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;alias_.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;min_.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;max_.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_value&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;any_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;alias_\0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;min_\0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;max_\0&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;query_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;my_summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/ontime.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────┬───────────┬───────────┐
│ column_name │ min_value │ max_value │
│   varchar   │  varchar  │  varchar  │
├─────────────┼───────────┼───────────┤
│ year        │ 2017      │ 2017      │
│ quarter     │ 1         │ 3         │
│ month       │ 1         │ 9         │
└─────────────┴───────────┴───────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;performance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#performance&quot;&gt;Performance&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;dynamic-filter-pushdown-from-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#dynamic-filter-pushdown-from-joins&quot;&gt;Dynamic Filter Pushdown from Joins&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;This release adds a &lt;em&gt;very cool&lt;/em&gt; optimization for joins: DuckDB now &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12908&quot;&gt;automatically creates filters&lt;/a&gt; for the larger table in the join during execution. Say we are joining two tables &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; has 100 rows, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; has one million rows. We are joining on a shared key &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;. If there were any filter on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;, DuckDB would already push that filter into the scan, greatly reducing the cost to complete the query. But we are now filtering on another column from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;, namely &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;j&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB will execute this join by building a hash table on the smaller table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;, and then probe said hash table with the contents of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;. DuckDB will now observe the values of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; during construction of the hash table on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;. It will then create a min-max range filter of those values of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; and then &lt;em&gt;automatically&lt;/em&gt; apply that filter to the values of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;! That way, we early remove (in this case) 90% of data from the large table before even looking at the hash table. In this example, this leads to a roughly 10× improvement in query performance. The optimization can also be observed in the output of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;automatic-cte-materialization&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#automatic-cte-materialization&quot;&gt;Automatic CTE Materialization&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Common Table Expressions (CTE) are a convenient way to break up complex queries into manageable pieces without endless nesting of subqueries. Here is a small example for a CTE:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_cte&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_cte&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Sometimes, the same CTE is referenced multiple times in the same query. Previously, the CTE would be “copied” wherever it appeared. This creates a potential performance problem: if computing the CTE is computationally expensive, it would be better to cache (“materialize”) its results instead of computing the result multiple times in different places within the same query. However, different filter conditions might apply for different instantiations of the CTE, which could drastically reduce their computation cost. A classical no-win scenario in databases. It was &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/with.html&quot;&gt;already possible&lt;/a&gt; to explicitly mark a CTE as materialized using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MATERIALIZED&lt;/code&gt; keyword, but that required manual intervention.&lt;/p&gt;

&lt;p&gt;This release adds a feature where DuckDB &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12290&quot;&gt;automatically decides&lt;/a&gt; whether a CTE result should be materialized or not using a heuristic. The heuristic currently is that if the CTE performs aggregation and is queried more than once, it should be materialized. We plan to expand that heuristic in the future.&lt;/p&gt;
      &lt;h3 id=&quot;parallel-streaming-queries&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#parallel-streaming-queries&quot;&gt;Parallel Streaming Queries&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB has two different methods for fetching results: &lt;em&gt;materialized&lt;/em&gt; results and &lt;em&gt;streaming&lt;/em&gt; results. Materialized results fetch all of the data that is present in a result at once, and return it. Streaming results instead allow iterating over the data in incremental steps. Streaming results are critical when working with large result sets as they do not require the entire result set to fit in memory. However, in previous releases, the final streaming phase was limited to a single thread.&lt;/p&gt;

&lt;p&gt;Parallelism is critical for obtaining good query performance on modern hardware, and this release adds support for &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11494&quot;&gt;parallel streaming of query results&lt;/a&gt;. The system will use all available threads to fill up a query result buffer of a limited size (a few megabytes). When data is consumed from the result buffer, the threads will restart and start filling up the buffer again. The size of the buffer can be configured through the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;streaming_buffer_size&lt;/code&gt; parameter.&lt;/p&gt;

&lt;p&gt;Below is a small benchmark using &lt;a href=&quot;https://blobs.duckdb.org/data/ontime.parquet&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ontime.parquet&lt;/code&gt;&lt;/a&gt; to illustrate the performance benefits that can be obtained using the Python streaming result interface:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM &#39;ontime.parquet&#39; WHERE flightnum = 6805;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v1.0&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v1.1&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.17 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.12 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;parallel-union_by_name&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#parallel-union_by_name&quot;&gt;Parallel &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt; parameter allows combination of – for example – CSV files that have the same columns in them but not in the same order. This release &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12957&quot;&gt;adds support for parallelism&lt;/a&gt; when using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union_by_name&lt;/code&gt;. This greatly improves reading performance when using the union by name feature on multiple files.&lt;/p&gt;
      &lt;h3 id=&quot;nested-art-rework-foreign-key-load-speed-up&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#nested-art-rework-foreign-key-load-speed-up&quot;&gt;Nested ART Rework (Foreign Key Load Speed-Up)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We have &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/13373&quot;&gt;greatly improved&lt;/a&gt; index insertion and deletion performance for foreign keys. Normally, we directly inline row identifiers into the tree structure. However, this is impossible for indexes that contain a lot of duplicates, as is the case with foreign keys. Instead, we now actually create another index entry for each key that is itself another “recursive” index tree in its own right. That way, we can achieve good insertion and deletion performance inside index entries. The performance results of this change are drastic, consider the following example where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; has 100 rows and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt; has one million rows that all reference &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOREIGN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REFERENCES&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On the previous version, this would take ca. 10 seconds on a MacBook to complete. It now takes 0.2 seconds thanks to the new index structure, a ca. 50× improvement!&lt;/p&gt;
      &lt;h3 id=&quot;window-function-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#window-function-improvements&quot;&gt;Window Function Improvements&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Window functions see a lot of use in DuckDB, which is why we are continuously improving performance of executing Window functions over large datasets.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12311&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12250&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FILTER&lt;/code&gt;&lt;/a&gt; window function modifiers can now be executed in streaming mode. Streaming mode means that the input data for the operator does not need to be completely collected and buffered before the operator can execute. For large intermediate results, this can have a very large performance impact. For example, the following query will now use the streaming window operator:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FILTER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UNBOUNDED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We have &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12685&quot;&gt;also implemented streaming mode&lt;/a&gt; for positive &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lead&lt;/code&gt; offsets.&lt;/p&gt;

&lt;p&gt;We can now &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10932&quot;&gt;push filters on columns through window functions that are partitioned by the same column&lt;/a&gt;. For example, consider the following scenario:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Previously, the filter on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; could not be pushed into the scan on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tbl&lt;/code&gt;. But we now recognize that pushing this filter “through” the window is safe and the optimizer will do so. This can be verified through &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────────────────────┐
│┌───────────────────────────┐│
││       Physical Plan       ││
│└───────────────────────────┘│
└─────────────────────────────┘
              …
┌─────────────┴─────────────┐
│           WINDOW          │
│    ────────────────────   │
│        Projections:       │
│ sum(i) OVER (PARTITION BY │
│             i)            │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         SEQ_SCAN          │
│    ────────────────────   │
│            tbl            │
│                           │
│       Projections: i      │
│                           │
│          Filters:         │
│   i&amp;gt;5 AND i IS NOT NULL   │
│                           │
│          ~2 Rows          │
└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The blocking (non-streaming) version of the window operator &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12907&quot;&gt;now processes input data in parallel&lt;/a&gt;. This greatly reduces the footprint of the window operator.&lt;/p&gt;

&lt;p&gt;See also &lt;a href=&quot;https://www.youtube.com/watch?v=QubE0u8Kq7Y&amp;amp;list=PLzIMXBizEZjhbacz4PWGuCUSxizmLei8Y&amp;amp;index=8&quot;&gt;Richard&#39;s talk on the topic&lt;/a&gt; at &lt;a href=&quot;https://duckdb.org/events/2024/08/15/duckcon5/&quot;&gt;DuckCon #5&lt;/a&gt; in Seattle a few weeks ago.&lt;/p&gt;
      &lt;h2 id=&quot;spatial-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#spatial-features&quot;&gt;Spatial Features&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;geoparquet&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#geoparquet&quot;&gt;GeoParquet&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;GeoParquet is an extension format of the ubiquitous Parquet format that standardizes how to encode vector geometries and their metadata in Parquet files. This can be used to store geographic data sets in Parquet files efficiently. When the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spatial&lt;/code&gt; extension&lt;/a&gt; is installed and loaded, reading from a GeoParquet file through DuckDB&#39;s normal Parquet reader will now &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/12503&quot;&gt;automatically convert geometry columns to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOMETRY&lt;/code&gt; type&lt;/a&gt;, for example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/geoparquet-example.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;GEOMETRY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                                       g                                                        │
│                                                    geometry                                                    │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ MULTIPOLYGON (((180 -16.067132663642447, 180 -16.555216566639196, 179.36414266196414 -16.801354076946883, 17…  │
│ POLYGON ((33.90371119710453 -0.95, 34.07261999999997 -1.059819999999945, 37.69868999999994 -3.09698999999994…  │
│ POLYGON ((-8.665589565454809 27.656425889592356, -8.665124477564191 27.589479071558227, -8.684399786809053 2…  │
│ MULTIPOLYGON (((-122.84000000000003 49.000000000000114, -122.97421000000001 49.00253777777778, -124.91024 49…  │
│ MULTIPOLYGON (((-122.84000000000003 49.000000000000114, -120 49.000000000000114, -117.03121 49, -116.04818 4…  │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;r-tree&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#r-tree&quot;&gt;R-Tree&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The spatial extension accompanying this release also implements initial support for creating “R-Tree” spatial indexes. An R-Tree index stores the approximate bounding boxes of each geometry in a column into an auxiliary hierarchical tree-like data structure where every “node” contains a bounding box covering all of its child nodes. This makes it really fast to check what geometries intersect a specific region of interest as you can quickly prune out a lot of candidates by recursively moving down the tree.&lt;/p&gt;

&lt;p&gt;Support for spatial indexes has been a long-requested feature on the spatial extension roadmap, and now that we have one, a ton of new use cases and directions for further development are opening up. However, as of now they are only used to accelerate simple  queries that select from a table with a filter using one out of a hardcoded set of spatial predicate functions applied on an indexed geometry column and a constant geometry. This makes R-Tree indexes useful when you have a very large table of geometries that you repeatedly query, but you don&#39;t want to perform a full table scan when you&#39;re only interested in the rows whose geometries intersect or fit within a certain region anyway. Here is an example where we can see that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RTREE_INDEX_SCAN&lt;/code&gt; operator is used:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Create a table with 10_000_000 random points&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;GEOMETRY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;st_generatepoints&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;BOX_2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;10_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;1337&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Create an index on the table&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_idx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RTREE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Perform a query with a &quot;spatial predicate&quot; on the indexed geometry&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- column. Note how the second argument in this case,&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- the ST_MakeEnvelope call is a &quot;constant&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ST_Within&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ST_MakeEnvelope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;450&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;450&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3986
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;R-Tree indexes mostly share the same feature-set as DuckDB&#39;s built-in ART index. They are buffer-managed, persistent, lazily-loaded from disk and support inserts, updates and deletes to the base table. Although they can not be used to enforce constraints.&lt;/p&gt;
      &lt;h2 id=&quot;final-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/09/09/announcing-duckdb-110.html#final-thoughts&quot;&gt;Final Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;These were a few highlights – but there are many more features and improvements in this release. The full release notes can be &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v1.1.0&quot;&gt;found on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We would like to thank again our amazing community for using DuckDB, building cool projects on DuckDB and improving DuckDB by providing us feedback. Your contributions truly mean a lot!&lt;/p&gt;

</description><link>https://duckdb.org/2024/09/09/announcing-duckdb-110.html</link><guid isPermaLink="false">https://duckdb.org/2024/09/09/announcing-duckdb-110.html</guid><pubDate>Mon, 09 Sep 2024 00:00:00 GMT</pubDate><author>The DuckDB team</author></item><item><title>DuckDB Tricks – Part 1</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We use a simple example data set to present a few tricks that are useful when using DuckDB.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;In this blog post, we present five simple DuckDB operations that we found particularly useful for interactive use cases.
The operations are summarized in the following table:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Operation&lt;/th&gt;
      &lt;th&gt;Snippet&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#pretty-printing-floating-point-numbers&quot;&gt;Pretty-printing floats&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#copying-the-schema-of-a-table&quot;&gt;Copying the schema&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#shuffling-data&quot;&gt;Shuffling data&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rowid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#specifying-types-in-the-csv-loader&quot;&gt;Specifying types when reading CSVs&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;x&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DECIMAL(15, 3)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#updating-csv-files-in-place&quot;&gt;Updating CSV files in-place&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;creating-the-example-data-set&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#creating-the-example-data-set&quot;&gt;Creating the Example Data Set&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We start by creating a data set that we&#39;ll use in the rest of the blog post. To this end, we define a table, populate it with some data and export it to a CSV file.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;STRING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;foo&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;bar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;qux&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Wait a bit, that’s way too verbose! DuckDB’s syntax has several SQL shorthands including the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;“friendly SQL” clauses&lt;/a&gt;.
Here, we combine the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/values.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VALUES&lt;/code&gt; clause&lt;/a&gt; with the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#from-first-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;-first syntax&lt;/a&gt;, which makes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause optional.
With these, we can compress the data creation script to ~60% of its original size.
The new formulation omits the schema definition and creates the CSV with a single command:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;foo&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;bar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;qux&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Regardless of which script we run, the resulting CSV file will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;s,x
foo,1.1111111111111112
bar,7.142857142857143
qux,2.25
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s continue with the code snippets and their explanations.&lt;/p&gt;
      &lt;h2 id=&quot;pretty-printing-floating-point-numbers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#pretty-printing-floating-point-numbers&quot;&gt;Pretty-Printing Floating-Point Numbers&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When printing a floating-point number to the output, the fractional parts can be difficult to read and compare. For example, the following query returns three numbers between 1 and 8 but their printed widths are very different due to their fractional parts.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────┐
│         x          │
│       double       │
├────────────────────┤
│ 1.1111111111111112 │
│  7.142857142857143 │
│               2.25 │
└────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By casting a column to a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DECIMAL&lt;/code&gt; with a fixed number of digits after the decimal point, we can pretty-print it as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────┐
│       x       │
│ decimal(15,3) │
├───────────────┤
│         1.111 │
│         7.143 │
│         2.250 │
└───────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A typical alternative solution is to use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#printf-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;printf&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#fmt-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;format&lt;/code&gt;&lt;/a&gt; functions, e.g.:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;%.3f&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, these approaches require us to specify a formatting string that&#39;s easy to forget.
What&#39;s worse, the statement above returns string values, which makes subsequent operations (e.g., sorting) more difficult.
Therefore, unless keeping the full precision of the floating-point numbers is a concern, casting to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DECIMAL&lt;/code&gt; values should be the preferred solution for most use cases.&lt;/p&gt;
      &lt;h2 id=&quot;copying-the-schema-of-a-table&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#copying-the-schema-of-a-table&quot;&gt;Copying the Schema of a Table&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To copy the schema from a table without copying its data, we can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT 0&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will result in an empty table with the same schema as the source table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DESCRIBE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐
│ column_name │ column_type │  null   │   key   │ default │  extra  │
│   varchar   │   varchar   │ varchar │ varchar │ varchar │ varchar │
├─────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤
│ s           │ VARCHAR     │ YES     │         │         │         │
│ x           │ DOUBLE      │ YES     │         │         │         │
└─────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, in the CLI client, we can run the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.schema&lt;/code&gt; &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/dot_commands.html&quot;&gt;dot command&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;schema&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will return the schema of the table.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After editing the table’s name (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;example&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tbl&lt;/code&gt;), this query can be used to create a new table with the same schema.&lt;/p&gt;
      &lt;h2 id=&quot;shuffling-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#shuffling-data&quot;&gt;Shuffling Data&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Sometimes, we need to introduce some entropy into the ordering of the data by shuffling it.
To shuffle &lt;em&gt;non-deterministically&lt;/em&gt;, we can simply sort on a random value provided the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/numeric.html#random&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random()&lt;/code&gt; function&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Shuffling &lt;em&gt;deterministically&lt;/em&gt; is a bit more tricky. To achieve this, we can order on the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/utility.html#hashvalue&quot;&gt;hash&lt;/a&gt;, of the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/select.html#row-ids&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rowid&lt;/code&gt; pseudocolumn&lt;/a&gt;. Note that this column is only available in physical tables, so we first have to load the CSV in a table, then perform the shuffle operation as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rowid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result of this shuffle operation is deterministic – if we run the script repeatedly, it will always return the following table:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────┬────────────────────┐
│    s    │         x          │
│ varchar │       double       │
├─────────┼────────────────────┤
│ bar     │  7.142857142857143 │
│ qux     │               2.25 │
│ foo     │ 1.1111111111111112 │
└─────────┴────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+ 42&lt;/code&gt; is only necessary to nudge the first row from its position – as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hash(0)&lt;/code&gt; returns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;, the smallest possible value, using it for ordering leaves the first row in its place.&lt;/p&gt;
      &lt;h2 id=&quot;specifying-types-in-the-csv-loader&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#specifying-types-in-the-csv-loader&quot;&gt;Specifying Types in the CSV Loader&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB’s CSV loader auto-detects types from a &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/auto_detection.html#type-detection&quot;&gt;short list&lt;/a&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOLEAN&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;.
In some cases, it’s desirable to override the detected type of a given column with a type outside of this list.
For example, we may want to treat column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; as a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DECIMAL&lt;/code&gt; value from the get-go.
We can do this on a per-column basis with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;types&lt;/code&gt; argument of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;x&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;DECIMAL(15, 3)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, we can simply query the table to see the result:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────┬───────────────┐
│    s    │       x       │
│ varchar │ decimal(15,3) │
├─────────┼───────────────┤
│ foo     │         1.111 │
│ bar     │         7.143 │
│ qux     │         2.250 │
└─────────┴───────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;updating-csv-files-in-place&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#updating-csv-files-in-place&quot;&gt;Updating CSV Files In-Place&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In DuckDB, it is possible to read, process and write CSV files in-place. For example, to project the column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; into the same file, we can simply run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;example.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The resulting &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;example.csv&lt;/code&gt; file will have the following content:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;s
foo
bar
qux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that this trick is not possible in Unix shells without a workaround.
One might be tempted to run the following command on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;example.csv&lt;/code&gt; file and expect the same result:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt; example.csv &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; example.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, due to the intricacies of Unix pipelines, executing this command leaves us with an empty &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;example.csv&lt;/code&gt; file.
The solution is to use different file names, then perform a rename operation:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt; example.csv &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; tmp.csv &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;mv &lt;/span&gt;tmp.csv example.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;closing-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html#closing-thoughts&quot;&gt;Closing Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;That’s it for today. The tricks shown in this post are available on &lt;a href=&quot;https://duckdbsnippets.com/page/1/most-recent&quot;&gt;duckdbsnippets.com&lt;/a&gt;. If you have a trick that would like to share, please submit it there, or send it to us via social media or &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Discord&lt;/a&gt;. Happy hacking!&lt;/p&gt;

</description><link>https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html</link><guid isPermaLink="false">https://duckdb.org/2024/08/19/duckdb-tricks-part-1.html</guid><pubDate>Mon, 19 Aug 2024 00:00:00 GMT</pubDate><author>Gabor Szarnyas</author></item><item><title>Friendly Lists and Their Buddies, the Lambdas</title><description>&lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Nested data types, such as lists and structs, are widespread in analytics.
Several popular formats, such as Parquet and JSON, support nested types.
Traditionally, working with nested types requires normalizing steps before any analysis.
Then, to return nested results, systems need to (re-)aggregate their data.
Normalization and aggregation are undesirable from both a usability and performance perspective.
To streamline the operation on nested data, analytical systems, including DuckDB, provide native functionality on these nested types.&lt;/p&gt;

&lt;p&gt;In this blog post, we&#39;ll first cover the basics of &lt;a href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#lists&quot;&gt;lists&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#lambdas&quot;&gt;lambdas&lt;/a&gt;.
Then, we dive into their &lt;a href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#zooming-in-list-transformations&quot;&gt;technical details&lt;/a&gt;.
Finally, we&#39;ll show some &lt;a href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#lists-and-lambdas-in-the-community&quot;&gt;examples&lt;/a&gt; from the community.
Feel free to skip ahead if you&#39;re already familiar with lists and lambdas and are just here for our out-of-the-box examples!&lt;/p&gt;
      &lt;h2 id=&quot;lists&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#lists&quot;&gt;Lists&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Before jumping into lambdas, let&#39;s take a quick detour into DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/list.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; type&lt;/a&gt;.
A list contains any number of elements with the same data type.
Below is a table containing two columns, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l&lt;/code&gt; contains lists of integers, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; contains integers.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lists&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lists&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────┬───────┐
│       l       │   n   │
│    int32[]    │ int32 │
├───────────────┼───────┤
│ [1]           │     1 │
│ [1, 2, 3]     │     2 │
│ [-1, NULL, 2] │     2 │
└───────────────┴───────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Internally, all data moves through DuckDB&#39;s execution engine in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vectors&lt;/code&gt;.
For more details on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vectors&lt;/code&gt; and vectorized execution, please refer to the &lt;a href=&quot;https://duckdb.org/docs/stable/internals/vector.html&quot;&gt;documentation&lt;/a&gt; and respective research papers (&lt;a href=&quot;https://15721.courses.cs.cmu.edu/spring2016/papers/p5-sompolski.pdf&quot;&gt;1&lt;/a&gt; and &lt;a href=&quot;https://drive.google.com/file/d/1LJeys01Ho9DREfRJhb9wHu3ssSC22Lll/view&quot;&gt;2&lt;/a&gt;).
In this case, we get two vectors, as depicted below.
This representation is mostly similar to &lt;a href=&quot;https://arrow.apache.org/&quot;&gt;Arrow&#39;s&lt;/a&gt; physical list representation.&lt;/p&gt;

&lt;p&gt;When examined closely, we can observe that the nested child vector of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l&lt;/code&gt; looks suspiciously similar to the vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;.
These nested vector representations enable our execution engine to reuse existing components on nested types.
We&#39;ll elaborate more on why this is relevant later.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/lambda/vectors.png&quot; alt=&quot;drawing&quot; width=&quot;240&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt;
      &lt;h2 id=&quot;lambdas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#lambdas&quot;&gt;Lambdas&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A &lt;strong&gt;lambda function&lt;/strong&gt; is an anonymous function, i.e., a function without a name.
In DuckDB, a lambda function&#39;s syntax is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(param1, param2, ...) -&amp;gt; expression&lt;/code&gt;.
The parameters can have any name, and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;expression&lt;/code&gt; can be any SQL expression.&lt;/p&gt;

&lt;p&gt;Currently, DuckDB has three scalar functions for working with lambdas:
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_transformlist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_filterlist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_filter&lt;/code&gt;&lt;/a&gt;,
and
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_reducelist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;&lt;/a&gt;,
along with their aliases.
Each accepts a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; as its first argument and a lambda function as its second argument.&lt;/p&gt;

&lt;p&gt;Lambdas were the guest star in our &lt;a href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#creating-the-macro!&quot;&gt;SQL Gymnastics: Bending SQL into Flexible New Shapes&lt;/a&gt; blog post.
This time, we want to put them in the spotlight.&lt;/p&gt;
      &lt;h2 id=&quot;zooming-in-list-transformations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#zooming-in-list-transformations&quot;&gt;Zooming In: List Transformations&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To return to our previous example, let&#39;s say we want to add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; to each element of the corresponding list &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;pure-relational-solution&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#pure-relational-solution&quot;&gt;Pure Relational Solution&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Using pure relational operators, i.e., avoiding list-native functions, we would need to perform the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Unnest the lists while keeping the connection to their respective rows.
We can achieve this by inventing a temporary unique identifier, such as a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/select.html#row-ids&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rowid&lt;/code&gt;&lt;/a&gt; or a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/numeric.html#universally-unique-identifiers-uuids&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UUID&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Transform each element by adding &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Using our temporary identifier &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rowid&lt;/code&gt;, we can reaggregate the transformed elements by grouping them into lists.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In SQL, it would look like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flattened_tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowid&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lists&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flattened_tbl&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowid&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────┐
│    result    │
│   int32[]    │
├──────────────┤
│ [2]          │
│ [3, 4, 5]    │
│ [1, NULL, 4] │
└──────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While the above example is reasonably readable, more complex transformations can become lengthy queries, which are difficult to compose and maintain.
More importantly, this query adds an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unnest&lt;/code&gt; operation and an aggregation (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_agg&lt;/code&gt;) with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt;.
Adding a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; can be costly, especially for large datasets.&lt;/p&gt;

&lt;p&gt;We have to dive into the technical implications to fully understand why the above query yields suboptimal performance.
Internally, the query execution performs the steps depicted in the diagram below.
We can directly emit the child vector for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unnest&lt;/code&gt; operation, i.e., without copying any data.
For the correlated columns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rowid&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;, we use &lt;a href=&quot;https://duckdb.org/docs/internals/vector.html&quot;&gt;selection vectors&lt;/a&gt;, which again prevents the copying of data.
This way, we can fire our expression execution on the child vector, another nested vector, and the expanded vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/lambda/relational.png&quot; alt=&quot;drawing&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt;

&lt;p&gt;The heavy-hitting operation is the last one, reaggregating the transformed elements into their respective lists.
As we don&#39;t propagate the parent vector, we have no information about the resulting element&#39;s correlation to the initial lists.
Recreating these lists requires a full copy of the data and partitioning, which impacts performance even with &lt;a href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html&quot;&gt;DuckDB&#39;s high-performance aggregation operator&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a consequence, the normalized approach is both cumbersome to write and it is inefficient as it produces a significant (and unnecessary) overhead despite the relative simplicity of the query.
This is yet another example of how shaping nested data into relational forms or &lt;a href=&quot;https://open.substack.com/pub/lloydtabb/p/data-is-rectangular-and-other-limiting?utm_campaign=post&amp;amp;utm_medium=web&quot;&gt;forcing it through rectangles&lt;/a&gt; can have a significant negative performance impact.&lt;/p&gt;
      &lt;h3 id=&quot;native-list-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#native-list-functions&quot;&gt;Native List Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;With support for native list functions, DuckDB mitigates these drawbacks by operating directly on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; data structure.
Since, as we&#39;ve seen, lists are essentially nested columns, we can reshape these functions into concepts already understood by our execution engine and leverage their full potential.&lt;/p&gt;

&lt;p&gt;In the case of transformations, the corresponding list-native function is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt;.
Here is the rewritten query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, with Python&#39;s list comprehension syntax:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Internally, this query expands all related vectors, which is just &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; in this case.
Just like before, we employ selection vectors to avoid any data copies.
Then, we use the lambda function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x -&amp;gt; x + n&lt;/code&gt; to fire our expression execution on the child vector and the expanded vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;.
As this is a list-native function, we’re aware of the existence of a parent vector and keep it alive.
So, once we get the result from the transformation, we can completely omit the reaggregation step.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/lambda/native.png&quot; alt=&quot;drawing&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt;

&lt;p&gt;To see the efficiency of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt; in action, we executed a simple benchmark.
Firstly, we added 1M rows to our table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my_lists&lt;/code&gt;, each containing five elements.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lists&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, we ran both our normalized and list-native queries on this data.
Both queries were run in the CLI with DuckDB v1.0.0 on a MacBook Pro 2021 with a M1 Max chip.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Normalized&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Native&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.522 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.027 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As we can see, the native query is more than 10× faster. Amazing!
If we look at the execution plan using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN ANALYZE&lt;/code&gt; (not shown in this blog post), we can see that DuckDB spends most of its time in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HASH_GROUP_BY&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNNEST&lt;/code&gt; operators.
In comparison, these operators no longer exist in the list-native query plan.&lt;/p&gt;
      &lt;h2 id=&quot;lists-and-lambdas-in-the-community&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#lists-and-lambdas-in-the-community&quot;&gt;Lists and Lambdas in the Community&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To better present what&#39;s possible by combining our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; type and lambda functions, we&#39;ve scoured the community Discord and GitHub, as well as some far corners of the internet, for exciting use cases.&lt;/p&gt;
      &lt;h3 id=&quot;list_transform&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#list_transform&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As established earlier, &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_transformlist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt;&lt;/a&gt; applies a lambda function to each element of the input list and returns a new list with the transformed elements.
Here, one of our &lt;a href=&quot;https://discord.com/channels/909674491309850675/1032659480539824208/1248004651983573162&quot;&gt;users&lt;/a&gt; implemented a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_shuffle&lt;/code&gt; function by nesting different &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; native functions.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;list_select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_grade_up&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another &lt;a href=&quot;https://til.simonwillison.net/duckdb/remote-parquet&quot;&gt;user&lt;/a&gt; investigated querying remote Parquet files using DuckDB.
In their query, they first use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt; to generate a list of URLs for Parquet files.
This is followed by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt; function, which reads the Parquet files and calculates the total size of the data.
The query looks like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;https://huggingface.co/datasets/vivym/midjourney-messages/resolve/main/data/&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;{:06d}&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;.parquet&#39;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IN&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;55&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;list_filter&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#list_filter&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_filter&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_filterlist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_filter&lt;/code&gt; function&lt;/a&gt; filters all elements of the input list for which the lambda function returns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here is an example using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_filter&lt;/code&gt; from a &lt;a href=&quot;https://discord.com/channels/909674491309850675/921073327009853451/1235818484047544371&quot;&gt;discussion on our Discord&lt;/a&gt; where the user wanted to remove the element at index &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;idx&lt;/code&gt; from each list.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;remove_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;list_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So far, we&#39;ve primarily focused on showcasing our lambda function support in this blog post.
Yet, there are often many possible paths with SQL and its rich dialects.
We couldn&#39;t help but show how we can achieve the same functionality with some of our other native list functions.
In this case, we used &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/list.html#list_slicelist-begin-end&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_slice&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/list.html#list_concatlist1-list2&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_concat&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;remove_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;list_reduce&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#list_reduce&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Most recently, we&#39;ve added &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html#list_reducelist-lambda&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;&lt;/a&gt;, which applies a lambda function to an accumulator value.
The accumulator is the result of the previous lambda function and is also what the function ultimately returns.&lt;/p&gt;

&lt;p&gt;We took the following example from a &lt;a href=&quot;https://github.com/duckdb/duckdb/discussions/9752&quot;&gt;discussion on GitHub&lt;/a&gt;.
The user wanted to use a lambda to validate &lt;a href=&quot;https://www.netherlandsworldwide.nl/bsn&quot;&gt;BSN numbers&lt;/a&gt;, the Dutch equivalent of social security numbers.
A BSN must be 8 or 9 digits, but to limit our scope we&#39;ll just focus on BSNs that are 9 digits long.
After multiplying each digit by its index, from 9 down to 2, and the last digit by -1, the sum must be divisible by 11 to be valid.&lt;/p&gt;
      &lt;h4 id=&quot;setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#setup&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;For our example, we assume that input BSNs are of type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER[]&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bsn_tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;solution&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#solution&quot;&gt;Solution&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;When this problem was initially proposed, DuckDB didn&#39;t have support for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;.
Instead, the user came up with the following:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;valid_bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;list_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IN&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;, we can rewrite the query as follows.
We also added a check validating that the length is always nine digits.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;valid_bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;list_reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list_reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using our macro with the example table we get the following result:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;valid_bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bsn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bsn_tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────┬─────────┐
│              bsn               │  valid  │
│            int32[]             │ boolean │
├────────────────────────────────┼─────────┤
│ [2, 4, 6, 7, 4, 7, 5, 9, 6]    │ true    │
│ [1, 2, 3, 4, 5, 6, 7, 8, 9]    │ false   │
│ [7, 6, 7, 4, 4, 5, 2, 1, 1]    │ true    │
│ [8, 7, 9, 0, 2, 3, 4, 1, 7]    │ true    │
│ [1, 2, 3, 4, 5, 6, 7, 8, 9, 0] │ false   │
└────────────────────────────────┴─────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Native nested type support is critical for analytical systems.
As such, DuckDB offers native nested type support and many functions to work with these types directly.
These functions make working with nested types easier and substantially faster.
In this blog post, we looked at the technical details of working with nested types by diving into our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt; function.
Additionally, we highlighted various use cases that we came across in our community.&lt;/p&gt;

</description><link>https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html</link><guid isPermaLink="false">https://duckdb.org/2024/08/08/friendly-lists-and-their-buddies-the-lambdas.html</guid><pubDate>Thu, 08 Aug 2024 00:00:00 GMT</pubDate><author>Tania Bogatsch and Maia de Graaf</author></item><item><title>Memory Management in DuckDB</title><description>&lt;p&gt;Memory is an important resource when processing large amounts of data. Memory is a fast caching layer that can provide immense speed-ups to query processing. However, memory is finite and expensive, and when working with large data sets there is generally not enough memory available to keep all necessary data structures cached. Managing memory effectively is critical for a high-performance query engine – as memory must be utilized in order to provide that high performance, but we must be careful so that we do not use excessive memory which can cause out-of-memory errors or can cause the ominous &lt;a href=&quot;https://en.wikipedia.org/wiki/Out_of_memory#Recovery&quot;&gt;OOM killer&lt;/a&gt; to zap the process out of existence.&lt;/p&gt;

&lt;p&gt;DuckDB is built to effectively utilize available memory while avoiding running out of memory:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The streaming execution engine allows small chunks of data to flow through the system without requiring entire data sets to be materialized in memory.&lt;/li&gt;
  &lt;li&gt;Data from intermediates can be spilled to disk temporarily in order to free up space in memory, allowing computation of complex queries that would otherwise exceed the available memory.&lt;/li&gt;
  &lt;li&gt;The buffer manager caches as many pages as possible from any attached databases without exceeding the pre-defined memory limits.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this blog post we will cover these aspects of memory management within DuckDB – and provide examples of where they are utilized.&lt;/p&gt;
      &lt;h2 id=&quot;streaming-execution&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/09/memory-management.html#streaming-execution&quot;&gt;Streaming Execution&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB uses a streaming execution engine to process queries. Data sources, such as tables, CSV files or Parquet files, are never fully materialized in memory. Instead, data is read and processed one chunk at a time. For example, consider the execution of the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UserAgent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hits.csv&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UserAgent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Instead of reading the entire CSV file at once, DuckDB reads data from the CSV file in pieces, and computes the aggregation incrementally using the data read from those pieces. This happens continuously until the entire CSV file is read, at which point the entire aggregation result is computed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/streamingexecution.png&quot; alt=&quot;DuckDB Streaming Execution&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;In the above example we are only showing a single data stream. In practice, DuckDB uses multiple data streams to enable multi-threaded execution – each thread executes its own data stream. The aggregation results of the different threads are combined to compute the final result.&lt;/p&gt;

&lt;p&gt;While streaming execution is conceptually simple, it is powerful, and is sufficient to provide larger-than-memory support for many simple use cases. For example, streaming execution enables larger-than-memory support for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computing aggregations where the total number of groups is small&lt;/li&gt;
  &lt;li&gt;Reading data from one file and writing to another (e.g., reading from CSV and writing to Parquet)&lt;/li&gt;
  &lt;li&gt;Computing a Top-N over the data (where N is small)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that nothing needs to be done to enable streaming execution – DuckDB always processes queries in this manner.&lt;/p&gt;
      &lt;h2 id=&quot;intermediate-spilling&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/09/memory-management.html#intermediate-spilling&quot;&gt;Intermediate Spilling&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;While streaming execution enables larger-than-memory processing for simple queries, there are many cases where streaming execution alone is not sufficient.&lt;/p&gt;

&lt;p&gt;In the previous example, streaming execution enabled larger-than-memory processing because the computed aggregate result was very small – as there are very few unique user agents in comparison to the total number of web requests. As a result, the aggregate hash table would always remain small, and never exceed the amount of available memory.&lt;/p&gt;

&lt;p&gt;Streaming execution is not sufficient if the intermediates required to process a query are larger than memory. For example, suppose we group by the source IP in the previous example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IPNetworkID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hits.csv&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IPNetworkID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Since there are many more unique source IPs, the hash table we need to maintain is significantly larger. If the size of the aggregate hash table exceeds memory, the streaming execution engine is not sufficient to prevent out-of-memory issues.&lt;/p&gt;

&lt;p&gt;Larger-than-memory intermediates can happen in many scenarios, in particular when executing more complex queries. For example, the following scenarios can lead to larger-than-memory intermediates:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computing an aggregation with many unique groups&lt;/li&gt;
  &lt;li&gt;Computing an exact distinct count of a column with many distinct values&lt;/li&gt;
  &lt;li&gt;Joining two tables together that are both larger than memory&lt;/li&gt;
  &lt;li&gt;Sorting a larger-than-memory dataset&lt;/li&gt;
  &lt;li&gt;Computing a complex window over a larger-than-memory table&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DuckDB deals with these scenarios by disk spilling. Larger-than-memory intermediates are (partially) written to disk in the temporary directory when required. While powerful, disk spilling reduces performance – as additional I/O must be performed. For that reason, DuckDB tries to minimize disk spilling. Disk spilling is adaptively used only when the size of the intermediates increases past the memory limit. Even in those scenarios, as much data is kept in memory as possible to maximize performance. The exact way this is done depends on the operators and is detailed in other blog posts
(&lt;a href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html&quot;&gt;aggregation&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html&quot;&gt;sorting&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;memory_limit&lt;/code&gt; setting controls how much data DuckDB is allowed to keep in memory. By default, this is set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;80%&lt;/code&gt; of the physical RAM of your system (e.g., if your system has 16 GB RAM, this defaults to 12.8 GB). The memory limit can be changed using the following command:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;memory_limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;4GB&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The location of the temporary directory can be chosen using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;temp_directory&lt;/code&gt; setting, and is by default the connected database with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.tmp&lt;/code&gt; suffix (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;database.db.tmp&lt;/code&gt;), or only &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.tmp&lt;/code&gt; if connecting to an in-memory database. The maximum size of the temporary directory can be limited using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_temp_directory_size&lt;/code&gt; setting, which defaults to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;90%&lt;/code&gt; of the remaining disk space on the drive where the temporary files are stored. These settings can be adjusted as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;temp_directory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/tmp/duckdb_swap&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;max_temp_directory_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;100GB&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If the memory limit is exceeded and disk spilling cannot be used, either because disk spilling is explicitly disabled, the temporary directory size exceeds the provided limit, or a system limitation means that disk spilling cannot be used for a given query – an out-of-memory error is reported and the query is canceled.&lt;/p&gt;
      &lt;h2 id=&quot;buffer-manager&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/09/memory-management.html#buffer-manager&quot;&gt;Buffer Manager&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another core component of memory management in DuckDB is the buffer manager. The buffer manager is responsible for caching pages from DuckDB&#39;s own persistent storage. Conceptually the buffer manager works in a similar fashion to the intermediate spilling. Pages are kept in memory as much as possible, and evicted from memory when space is required for other data structures. The buffer manager abides by the same memory limit as any intermediate data structures. Pages in the buffer manager can be freed up to make space for intermediate data structures, or vice versa.&lt;/p&gt;

&lt;p&gt;There are two main differences between the buffer manager and intermediate data structures:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As the buffer manager caches pages that already exist on disk (in DuckDB&#39;s persistent storage) – they do not need to be written to the temporary directory when evicted. Instead, when they are required again, they can be re-read from the attached storage file directly.&lt;/li&gt;
  &lt;li&gt;Query intermediates have a natural life-cycle, namely when the query is finished processing the intermediates are no longer required. Pages that are buffer managed from the persistent storage are useful across queries. As such, the pages kept by the buffer manager are kept cached until either the persistent database is closed, or until space must be freed up for other operations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The performance boost of the buffer manager depends on the speed of the underlying storage medium. When data is stored on a very fast disk, reading data is fast and the speed-up is minimal. When data is stored on a network drive or read over http/S3, reading requires performing network requests, and the speed-up can be very large.&lt;/p&gt;
      &lt;h2 id=&quot;profiling-memory-usage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/09/memory-management.html#profiling-memory-usage&quot;&gt;Profiling Memory Usage&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB contains a number of tools that can be used to profile memory usage.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb_memory()&lt;/code&gt; function can be used to inspect which components of the system are using memory. Memory used by the buffer manager is labeled as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BASE_TABLE&lt;/code&gt;, while query intermediates are divided into separate groups.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duckdb_memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────┬────────────────────┬─────────────────────────┐
│       tag        │ memory_usage_bytes │ temporary_storage_bytes │
│     varchar      │       int64        │          int64          │
├──────────────────┼────────────────────┼─────────────────────────┤
│ BASE_TABLE       │          168558592 │                       0 │
│ HASH_TABLE       │                  0 │                       0 │
│ PARQUET_READER   │                  0 │                       0 │
│ CSV_READER       │                  0 │                       0 │
│ ORDER_BY         │                  0 │                       0 │
│ ART_INDEX        │                  0 │                       0 │
│ COLUMN_DATA      │                  0 │                       0 │
│ METADATA         │                  0 │                       0 │
│ OVERFLOW_STRINGS │                  0 │                       0 │
│ IN_MEMORY_TABLE  │                  0 │                       0 │
│ ALLOCATOR        │                  0 │                       0 │
│ EXTENSION        │                  0 │                       0 │
├──────────────────┴────────────────────┴─────────────────────────┤
│ 12 rows                                               3 columns │
└─────────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb_temporary_files&lt;/code&gt; function can be used to examine the current contents of the temporary directory.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duckdb_temporary_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────────────────────────┬───────────┐
│              path              │   size    │
│            varchar             │   int64   │
├────────────────────────────────┼───────────┤
│ .tmp/duckdb_temp_storage-0.tmp │ 967049216 │
└────────────────────────────────┴───────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/09/memory-management.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Memory management is critical for a high-performance analytics engine. DuckDB is built to take advantage of any available memory to speed up query processing, while gracefully dealing with larger-than-memory datasets using intermediate spilling. Memory management is still an active area of development and has &lt;a href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#scale-tests&quot;&gt;continuously improved across DuckDB versions&lt;/a&gt;. Amongst others, we are working on improving memory management for complex queries that involve multiple operators with larger-than-memory intermediates.&lt;/p&gt;

</description><link>https://duckdb.org/2024/07/09/memory-management.html</link><guid isPermaLink="false">https://duckdb.org/2024/07/09/memory-management.html</guid><pubDate>Tue, 09 Jul 2024 00:00:00 GMT</pubDate><author>Mark Raasveldt</author></item><item><title>DuckDB Community Extensions</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB extensions can now be published via the &lt;a href=&quot;https://github.com/duckdb/community-extensions&quot;&gt;DuckDB Community Extensions repository&lt;/a&gt;. The repository makes it easier for users to install extensions using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSTALL extension_name FROM community&lt;/code&gt; syntax. Extension developers avoid the burdens of compilation and distribution.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;duckdb-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#duckdb-extensions&quot;&gt;DuckDB Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;design-philosophy&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#design-philosophy&quot;&gt;Design Philosophy&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;One of the main design goals of DuckDB is &lt;em&gt;simplicity&lt;/em&gt;, which – to us – implies that the system should be rather nimble, very light on dependencies, and generally small enough to run on constrained platforms like &lt;a href=&quot;https://duckdb.org/docs/stable/clients/wasm/overview.html&quot;&gt;WebAssembly&lt;/a&gt;. This goal is in direct conflict with very reasonable user requests to support advanced features like spatial data analysis, vector indexes, connectivity to various other databases, support for data formats, etc. Baking all those features into a monolithic binary is certainly possible and the route some systems take. But we want to preserve DuckDB’s simplicity. Also, shipping all possible features would be quite excessive for most users because no use cases require &lt;em&gt;all&lt;/em&gt; extensions at the same time (the “Microsoft Word paradox”, where even power users only use a few features of the system, but the exact set of features vary between users).&lt;/p&gt;

&lt;p&gt;To achieve this, DuckDB has a powerful extension mechanism, which allows users to add new functionalities to DuckDB. This mechanism allows for registering new functions, supporting new file formats and compression methods, handling new network protocols, etc. In fact, many of DuckDB’s popular features are implemented as extensions: the &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;Parquet reader&lt;/a&gt;, the &lt;a href=&quot;https://duckdb.org/docs/stable/data/json/overview.html&quot;&gt;JSON reader&lt;/a&gt;, and the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html&quot;&gt;HTTPS/S3 connector&lt;/a&gt; all use the extension mechanism.&lt;/p&gt;
      &lt;h3 id=&quot;using-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#using-extensions&quot;&gt;Using Extensions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Since &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.3.2&quot;&gt;version 0.3.2&lt;/a&gt;, we have already greatly simplified the discovery and installation by hosting them on a centralized extension repository. So, for example, to install the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;spatial extension&lt;/a&gt;, one can just run the following commands using DuckDB’s SQL interface:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- once&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;-- on each use&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What happens behind the scenes is that DuckDB downloads an extension binary suitable to the current operating system and processor architecture (e.g., macOS on ARM64) and stores it in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.duckdb&lt;/code&gt; folder. On each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LOAD&lt;/code&gt;, this file is loaded into the running DuckDB instance, and things happily continue from there. Of course, for this to work, we compile, sign and host the extensions for a rather large and growing list of processor architecture – operating system combinations. This mechanism is already heavily used, currently, we see around six million extension downloads &lt;em&gt;each week&lt;/em&gt; with a corresponding data transfer volume of around 40 terabytes!&lt;/p&gt;

&lt;p&gt;Until now, publishing third-party extensions has been a &lt;em&gt;difficult process&lt;/em&gt; which required the extension developer to build the extensions in their repositories for a host of platforms. Moreover, they were unable to sign the extensions using official keys, forcing users to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;allow_unsigned_extensions&lt;/code&gt; option that disables signature checks which is problematic in itself.&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-community-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#duckdb-community-extensions&quot;&gt;DuckDB Community Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Distributing software in a safe way has never been easier, allowing us to reach a wide base of users across pip, conda, cran, npm, brew, etc. We want to provide a similar experience both to users who can easily grab the extension they will want to use, and developers who should not be burdened with distribution details. We are also interested in lowering the bar to package utilities and scripts as a DuckDB extension, empowering users to package useful functionality connected to their area of expertise (or pain points).&lt;/p&gt;

&lt;p&gt;We believe that fostering a community extension ecosystem is the next logical step for DuckDB. That’s why we’re very excited about launching our &lt;a href=&quot;https://github.com/duckdb/community-extensions/&quot;&gt;Community Extensions repository&lt;/a&gt; which was &lt;a href=&quot;https://youtu.be/wuP6iEYH11E?t=275&quot;&gt;announced at the Data + AI Summit&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For users, this repository allows for easy discovery, installation and maintenance of community extensions directly from the DuckDB SQL prompt. For developers, it greatly streamlines the publication process of extensions. In the following, we’ll discuss how the new extension repository enhances the experiences of these groups.&lt;/p&gt;
      &lt;h3 id=&quot;user-experience&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#user-experience&quot;&gt;User Experience&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We are going to use the &lt;a href=&quot;https://github.com/isaacbrodsky/h3-duckdb&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h3&lt;/code&gt; extension&lt;/a&gt; as our example. This extension implements &lt;a href=&quot;https://github.com/uber/h3&quot;&gt;hierarchical hexagonal indexing&lt;/a&gt; for geospatial data.&lt;/p&gt;

&lt;p&gt;Using the DuckDB Community Extensions repository, you can now install and load the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h3&lt;/code&gt; extension as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; h3 &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;community&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; h3&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, you can instantly start using it. Note that the sample data is 500 MB:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;h3_latlng_to_cell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pickup_latitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_longitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cell_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;h3_cell_to_boundary_wkt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cell_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/yellow_tripdata_2010-01.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cell_id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;HAVING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On load, the extension’s signature is checked, both to ensure platform and versions are compatible, and to verify that the source of the binary is the Community Extensions repository. Extensions are built, signed and distributed for Linux, macOS, Windows, and WebAssembly. This allows extensions to be available to any DuckDB client using version 1.0.0 and upcoming versions.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h3&lt;/code&gt; extension’s documentation is available at &lt;a href=&quot;https://duckdb.org/community_extensions/extensions/h3&quot;&gt;https://duckdb.org/community_extensions/extensions/h3&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;developer-experience&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#developer-experience&quot;&gt;Developer Experience&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;From the developer’s perspective, the Community Extensions repository performs the steps required for publishing extensions, including building the extensions for all relevant &lt;a href=&quot;https://duckdb.org/docs/stable/dev/building/overview.html#supported-platforms&quot;&gt;platforms&lt;/a&gt;, signing the extension binaries and serving them from the repository.&lt;/p&gt;

&lt;p&gt;For the &lt;a href=&quot;https://github.com/isaacbrodsky/&quot;&gt;maintainer of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h3&lt;/code&gt;&lt;/a&gt;, the publication process required performing the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Sending a PR with a metadata file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;description.yml&lt;/code&gt; contains the description of the extension:&lt;/p&gt;

    &lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;extension&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;h3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Hierarchical hexagonal indexing for geospatial data&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1.0.0&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;C++&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cmake&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;license&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Apache-2.0&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;maintainers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;isaacbrodsky&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;repo&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;isaacbrodsky/h3-duckdb&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3c8a5358e42ab8d11e0253c70f7cc7d37781b2ef&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The CI will build and test the extension. The checks performed by the CI are aligned with the &lt;a href=&quot;https://github.com/duckdb/extension-template&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;extension-template&lt;/code&gt; repository&lt;/a&gt;, so iterations can be done independently.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wait for approval from the DuckDB Community Extensions repository’s maintainers and for the build process to complete.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;published-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#published-extensions&quot;&gt;Published Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To show that it’s feasible to publish extensions, we reached out to a few developers of key extensions. At the time of the publication of this blog post, the DuckDB Community Extensions repository already contains the following extensions.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/rustyconover/duckdb-crypto-extension&quot;&gt;crypto&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Adds cryptographic hash functions and &lt;a href=&quot;https://en.wikipedia.org/wiki/HMAC&quot;&gt;HMAC&lt;/a&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/isaacbrodsky/h3-duckdb&quot;&gt;h3&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Implements hierarchical hexagonal indexing for geospatial data.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/rustyconover/duckdb-lindel-extension&quot;&gt;lindel&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Implements linearization/delinearization, Z-Order, Hilbert and Morton curves.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/ywelsch/duckdb-prql&quot;&gt;prql&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Allows running &lt;a href=&quot;https://prql-lang.org/&quot;&gt;PRQL&lt;/a&gt; commands directly within DuckDB.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/pdet/Scrooge-McDuck&quot;&gt;scrooge&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Supports a set of aggregation functions and data scanners for financial data.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/rustyconover/duckdb-shellfs-extension&quot;&gt;shellfs&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Allows shell commands to be used for input and output.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;DuckDB Labs and the DuckDB Foundation do not vet the code within community extensions and, therefore, cannot guarantee that DuckDB community extensions are safe to use. The loading of community extensions can be explicitly disabled with the following one-way configuration option:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;allow_community_extensions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For more details, see the documentation’s &lt;a href=&quot;https://duckdb.org/docs/stable/operations_manual/securing_duckdb/securing_extensions.html#community-extensions&quot;&gt;Securing DuckDB page&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;summary-and-looking-ahead&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/07/05/community-extensions.html#summary-and-looking-ahead&quot;&gt;Summary and Looking Ahead&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we introduced the DuckDB Community Extensions repository, which allows easy installation of third-party DuckDB extensions.&lt;/p&gt;

&lt;p&gt;We are looking forward to continuously extending this repository. If you have an idea for creating an extension, take a look at the already published extension source codes, which provide good examples of how to package community extensions, and join the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#extensions&lt;/code&gt; channel on our &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Discord&lt;/a&gt;.
Once you have an extension, please contribute it via a &lt;a href=&quot;https://github.com/duckdb/community-extensions/pulls&quot;&gt;pull request&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Finally, we would like to thank the early adopters of DuckDB’s extension mechanism and Community Extensions repository. Thanks for iterating with us and providing feedback to us.&lt;/p&gt;

</description><link>https://duckdb.org/2024/07/05/community-extensions.html</link><guid isPermaLink="false">https://duckdb.org/2024/07/05/community-extensions.html</guid><pubDate>Fri, 05 Jul 2024 00:00:00 GMT</pubDate><author>The DuckDB team</author></item><item><title>Benchmarking Ourselves over Time at DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: In the last 3 years, DuckDB has become 3-25× faster and can analyze ~10× larger datasets all on the same hardware.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;!-- &lt;script src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt; --&gt;


&lt;div id=&quot;overall_results_by_time_header&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;A big part of DuckDB&#39;s focus is on the developer experience of working with data.
However, performance is an important consideration when investigating data management systems.
Fairly comparing data processing systems using benchmarks is &lt;a href=&quot;https://mytherin.github.io/papers/2018-dbtest.pdf&quot;&gt;very difficult&lt;/a&gt;.
Whoever creates the benchmark is likely to know one system better than the rest, influencing benchmark selection, how much time is spent tuning parameters, and more.&lt;/p&gt;

&lt;p&gt;Instead, this post focuses on benchmarking &lt;em&gt;our own&lt;/em&gt; performance over time.
&lt;!-- (Of course, we encourage you to conduct your own benchmarks and welcome your feedback on our [Discord server](https://discord.duckdb.org/) or in [GitHub discussions](https://github.com/duckdb/duckdb/discussions)!). --&gt;
This approach avoids many comparison pitfalls, and also provides several valuable data points to consider when selecting a system.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;How fast is it improving?&lt;/strong&gt;
  Learning a new tool is an investment.
  Picking a vibrant, rapidly improving database ensures your choice pays dividends for years to come.
  Plus, if you haven&#39;t experimented with a tool in a while, you can see how much faster it has become since you last checked!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;What is it especially good at?&lt;/strong&gt;
  The choice of benchmark is an indicator of what types of workloads a tool is useful for.
  The higher the variety of analyses in the benchmark, the more broadly useful the tool can be.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;What scale of data can it handle?&lt;/strong&gt;
  Many benchmarks are deliberately smaller than typical workloads.
  This allows the benchmark to complete in a reasonable amount of time when run with many configurations.
  However, an important question to answer when selecting a system is whether the size of your data can be handled within the size of your compute resources.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- #### Limitations of Benchmarking over Time --&gt;

&lt;p&gt;There are some limitations when looking at the performance of a system over time.
If a feature is brand new, there is no prior performance to compare to!
As a result, this post focuses on fundamental workloads rather than DuckDB&#39;s ever-increasing set of integrations with different lakehouse data formats, cloud services, and more.&lt;/p&gt;

&lt;p&gt;The code used to run the benchmark also avoids many of DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;Friendlier SQL&lt;/a&gt; additions, as those have also been added more recently.
(When writing these queries, it felt like going back in time!)&lt;/p&gt;
      &lt;h2 id=&quot;benchmark-design-summary&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#benchmark-design-summary&quot;&gt;Benchmark Design Summary&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This post measures DuckDB&#39;s performance over time using the &lt;a href=&quot;https://duckdblabs.github.io/db-benchmark/&quot;&gt;H2O.ai benchmark&lt;/a&gt;, plus some new benchmarks added for importing, exporting, and using window functions.
Please see our previous &lt;a href=&quot;https://duckdb.org/2023/04/14/h2oai.html&quot;&gt;blog&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html&quot;&gt;posts&lt;/a&gt; for details on why we believe the H2O.ai benchmark is a good approach! The full details of the benchmark design are in the appendix.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;H2O.ai, plus import/export and window function tests&lt;/li&gt;
  &lt;li&gt;Python instead of R&lt;/li&gt;
  &lt;li&gt;5 GB scale for everything, plus 50 GB scale for group bys and joins&lt;/li&gt;
  &lt;li&gt;Median of 3 runs&lt;/li&gt;
  &lt;li&gt;Using a MacBook Pro M1 with 16 GB RAM&lt;/li&gt;
  &lt;li&gt;DuckDB versions 0.2.7 through 1.0.0
    &lt;ul&gt;
      &lt;li&gt;Nearly 3 years, from 2021-06-14 to 2024-06-03&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Default settings&lt;/li&gt;
  &lt;li&gt;Pandas pre-version 0.5.1, Apache Arrow 0.5.1+&lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;overall-benchmark-results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#overall-benchmark-results&quot;&gt;Overall Benchmark Results&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The latest DuckDB can complete one run of the full benchmark suite in under 35 seconds, while version 0.2.7 required nearly 500 seconds for the same task in June 2021.
&lt;strong&gt;That is 14 times faster, in only 3 years!&lt;/strong&gt;&lt;/p&gt;
      &lt;h3 id=&quot;performance-over-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#performance-over-time&quot;&gt;Performance over Time&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div id=&quot;overall_results_by_time&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;blockquote&gt;
  &lt;p&gt;Note These graphs are interactive, thanks to &lt;a href=&quot;https://plotly.com/javascript/&quot;&gt;Plotly.js&lt;/a&gt;!
Feel free to filter the various series (single click to hide, double click to show only that series) and click-and-drag to zoom in.
Individual benchmark results are visible on hover.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The above plot shows the median runtime in seconds for all tests.
Due to the variety of uses for window functions, and their relative algorithmic complexity, the 16 window function tests require the most time of any category.&lt;/p&gt;

&lt;div id=&quot;overall_results_by_time_relative&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;This plot normalizes performance to the latest version of DuckDB to show relative improvements over time.
If you look at the point in time when you most recently measured DuckDB performance, that number will show you how many times faster DuckDB is now!&lt;/p&gt;

&lt;p&gt;A portion of the overall improvement is DuckDB&#39;s addition of multi-threading, which became the default in November 2021 with version 0.3.1.
DuckDB also moved to a push-based execution model in that version for additional gains.
Parallel data loading boosted performance in December 2022 with version 0.6.1, as did improvements to the core &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JOIN&lt;/code&gt; algorithm.
We will explore other improvements in detail later in the post.&lt;/p&gt;

&lt;p&gt;However, we see that all aspects of the system have seen improvements, not just raw query performance!
DuckDB focuses on the entire data analysis workflow, not just aggregate or join performance.
CSV parsing has seen significant gains, import and export have improved significantly, and window functions have improved the most of all.&lt;/p&gt;

&lt;p&gt;What was the slight regression from December 2022 to June 2023?
Window functions received additional capabilities and experienced a slight performance degradation in the process.
However, from June 2023 onward we see substantial performance improvement across the board for window functions.
If window functions are filtered out of the chart, we see a smoother trend.&lt;/p&gt;

&lt;p&gt;You may also notice that starting with version 0.9 in September 2023, the performance appears to plateau.
What is happening here?
First, don&#39;t forget to zoom in!
Over the last year, DuckDB has still improved over 3×!
More recently, the DuckDB Labs team focused on scalability by developing algorithms that support larger-than-memory calculations.
We will see the fruits of those labors in the scale section later on!
In addition, DuckDB focused exclusively on bug fixes in versions 0.10.1, 0.10.2, and 0.10.3 in preparation for an especially robust DuckDB 1.0.
Now that those two major milestones (larger than memory calculations and DuckDB 1.0) have been accomplished, performance improvements will resume!
It is worth noting that the boost from moving to multi-threading will only occur once, but there are still many opportunities moving forward.&lt;/p&gt;
      &lt;h3 id=&quot;performance-by-version&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#performance-by-version&quot;&gt;Performance by Version&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We can also recreate the overall plot by version rather than by time.
This demonstrates that DuckDB has been doing more frequent releases recently.
See &lt;a href=&quot;https://duckdb.org/docs/stable/dev/release_calendar.html&quot;&gt;DuckDB&#39;s release calendar&lt;/a&gt; for the full version history.&lt;/p&gt;

&lt;div id=&quot;overall_results_by_version&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;If you remember the version that you last tested, you can compare how much faster things are now with 1.0!&lt;/p&gt;

&lt;div id=&quot;overall_results_by_version_relative&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;

      &lt;h2 id=&quot;results-by-workload&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#results-by-workload&quot;&gt;Results by Workload&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;csv-reader&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#csv-reader&quot;&gt;CSV Reader&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div id=&quot;perf_over_time_csv_reader_area&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;DuckDB has invested substantially in building a &lt;a href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html&quot;&gt;fast and robust CSV parser&lt;/a&gt;.
This is often the first task in a data analysis workload, and it tends to be undervalued and underbenchmarked.
DuckDB has &lt;strong&gt;improved CSV reader performance by nearly 3×&lt;/strong&gt;, while adding the ability to handle many more CSV dialects automatically.&lt;/p&gt;
      &lt;h3 id=&quot;group-by&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#group-by&quot;&gt;Group By&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div id=&quot;perf_over_time_group_by_area&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;Group by or aggregation operations are critical steps in OLAP workloads, and have therefore received substantial focus in DuckDB, &lt;strong&gt;improving over 12× in the last 3 years&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In November 2021, version 0.3.1 enabled multithreaded aggregation by default, providing a significant speedup.&lt;/p&gt;

&lt;p&gt;In December 2022, data loads into tables were parallelized with the release of version 0.6.1.
This is another example of improving the entire data workflow, as this group by benchmark actually stressed the insertion performance substantially.
Inserting the results was taking the majority of the time!&lt;/p&gt;

&lt;p&gt;Enums were also used in place of strings for categorical columns in version 0.6.1.
This means that DuckDB was able to use integers rather than strings when operating on those columns, further boosting performance.&lt;/p&gt;

&lt;p&gt;Despite what appears at first glance to be a performance plateau, zooming in to 2023 and 2024 reveals a ~20% improvement.
In addition, aggregations have received significant attention in the most recent versions to enable larger-than-memory aggregations.
You can see that this was achieved while continuing to improve performance for the smaller-than-memory case.&lt;/p&gt;
      &lt;h3 id=&quot;join&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#join&quot;&gt;Join&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div id=&quot;perf_over_time_join_area&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;Join operations are another area of focus for analytical databases, and DuckDB in particular.
Join speeds have &lt;strong&gt;improved by 4× in the last 3 years&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;Version 0.6.1 in December 2022 introduced improvements to the out-of-core hash join that actually improved the smaller-than-memory case as well.
Parallel data loading from 0.6.1 also helps in this benchmark as well, as some results are the same size as the input table.&lt;/p&gt;

&lt;p&gt;In recent versions, joins have also been upgraded to support larger-than-memory capabilities.
This focus has also benefitted the smaller-than-memory case and has led to the improvements in 0.10, launched in February 2024.&lt;/p&gt;
      &lt;h3 id=&quot;window-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#window-functions&quot;&gt;Window Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div id=&quot;perf_over_time_window_area&quot; style=&quot;width:100%;height:510px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;Over the time horizon studied, window functions have &lt;strong&gt;improved a dramatic 25×&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;Window function performance was improved substantially with the 0.9.0 release in September 2023.
&lt;a href=&quot;https://github.com/duckdb/duckdb/issues/7809#issuecomment-1679387022&quot;&gt;14 different performance optimizations contributed&lt;/a&gt;.
Aggregate computation was vectorized (with special focus on the &lt;a href=&quot;https://www.vldb.org/pvldb/vol8/p1058-leis.pdf&quot;&gt;segment tree data structure&lt;/a&gt;).
Work stealing enabled multi-threaded processing and sorting was adapted to run in parallel.
Care was also taken to pre-allocate memory in larger batches.&lt;/p&gt;

&lt;p&gt;DuckDB&#39;s window functions are also capable of processing larger-than-memory datasets.
We leave benchmarking that feature for future work!&lt;/p&gt;
      &lt;h3 id=&quot;export&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#export&quot;&gt;Export&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div id=&quot;perf_over_time_export_area&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;Often DuckDB is not the final step in a workflow, so export performance has an impact.
Exports are &lt;strong&gt;10× faster now!&lt;/strong&gt;
Until recently, the DuckDB format was not backward compatible, so the recommended long term persistence format was Parquet.
Parquet is also critical to interoperability with many other systems, especially data lakes.
DuckDB works well as a workflow engine, so exporting to other in-memory formats is quite common as well.&lt;/p&gt;

&lt;p&gt;In the September 2022 release (version 0.5.1) we see significant improvements driven by switching from Pandas to Apache Arrow as the recommended in-memory export format.
DuckDB&#39;s underlying data types share many similarities with Arrow, so data transfer is quite quick.&lt;/p&gt;

&lt;p&gt;Parquet export performance has improved by 4–5× over the course of the benchmark, with dramatic improvements in versions 0.8.1 (June 2023) and 0.10.2 (April 2024).
Version 0.8.1 added &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7375&quot;&gt;parallel Parquet writing&lt;/a&gt; while continuing to preserve insertion order.&lt;/p&gt;

&lt;p&gt;The change driving the improvement in 0.10.2 was more subtle.
When exporting strings with high cardinality, DuckDB decides whether or not to do dictionary compression depending on if it reduces file size.
From 0.10.2 onward, the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11461&quot;&gt;compression ratio is tested after a sample of the values are inserted into the dictionary&lt;/a&gt;, rather than after all values are added.
This prevents substantial unnecessary processing for high-cardinality columns where dictionary compression is unhelpful.&lt;/p&gt;
      &lt;h4 id=&quot;exporting-apache-arrow-vs-pandas-vs-parquet&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#exporting-apache-arrow-vs-pandas-vs-parquet&quot;&gt;Exporting Apache Arrow vs. Pandas vs. Parquet&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;div id=&quot;perf_over_time_export_arrow_pandas_parquet&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;This plot shows the performance of all three export formats over the entire time horizon (rather than picking the winner between Pandas and Arrow).
It allows us to see at what point Apache Arrow passes Pandas in performance.&lt;/p&gt;

&lt;p&gt;Pandas export performance has improved substantially over the course of the benchmark.
However, Apache Arrow has proven to be the more efficient data format, so Arrow is now preferred for in-memory exports.
Interestingly, DuckDB&#39;s Parquet export is now so efficient that it is faster to write a persistent Parquet file than it is to write to an in-memory Pandas dataframe!
It is even competitive with Apache Arrow.&lt;/p&gt;
      &lt;h3 id=&quot;scan-other-formats&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#scan-other-formats&quot;&gt;Scan Other Formats&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div id=&quot;perf_over_time_scan_other_formats_area&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;In some use cases, DuckDB does not need to store the raw data, but instead should simply read and analyze it.
This allows DuckDB to fit seamlessly into other workflows.
This benchmark measures how fast DuckDB can scan and aggregate various data formats.&lt;/p&gt;

&lt;p&gt;To enable comparisons over time, we switch from Pandas to Arrow at version 0.5.1 as mentioned.
DuckDB is &lt;strong&gt;over 8× faster in this workload&lt;/strong&gt;, and the absolute time required is very short.
DuckDB is a great fit for this type of work!&lt;/p&gt;
      &lt;h4 id=&quot;scanning-apache-arrow-vs-pandas-vs-parquet&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#scanning-apache-arrow-vs-pandas-vs-parquet&quot;&gt;Scanning Apache Arrow vs. Pandas vs. Parquet&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;div id=&quot;perf_over_time_scan_other_formats_arrow_pandas_parquet&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;Once again, we examine all three formats over the entire time horizon.&lt;/p&gt;

&lt;p&gt;When scanning data, Apache Arrow and Pandas are more comparable in performance.
As a result, while Arrow is clearly preferable for exports, DuckDB will happily read Pandas with similar speed.
However, in this case, the in-memory nature of both Arrow and Pandas allow them to perform 2–3× faster than Parquet.
In absolute terms, the time required to complete this operation is a very small fraction of the benchmark, so other operations should be the deciding factor.&lt;/p&gt;
      &lt;h2 id=&quot;scale-tests&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#scale-tests&quot;&gt;Scale tests&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Analyzing larger-than-memory data is a superpower for DuckDB, allowing it to be used for substantially larger data analysis tasks than were previously possible.&lt;/p&gt;

&lt;div id=&quot;perf_over_time_scale_by_time&quot; style=&quot;width:100%;height:400px;&quot;&gt;&lt;/div&gt;


&lt;p&gt;In version 0.9.0, launched in September 2023, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7931&quot;&gt;DuckDB&#39;s hash aggregate was enhanced to handle out-of-core (larger than memory) intermediates&lt;/a&gt;.
The details of the algorithm, along with some benchmarks, are available in &lt;a href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html&quot;&gt;this blog post&lt;/a&gt;.
This allows for DuckDB to aggregate one billion rows of data (50 GB in size) on a MacBook Pro with only 16 GB of RAM, even when the number of unique groups in the group by is large.
This represents at least a 10× improvement in aggregate processing scale over the course of the 3 years of the benchmark.&lt;/p&gt;

&lt;p&gt;DuckDB&#39;s hash join operator has supported larger-than-memory joins since version 0.6.1 in December 2022.
However, the scale of this benchmark (coupled with the limited RAM of the benchmarking hardware), meant that this benchmark could still not complete successfully.
In version 0.10.0, launched in February 2024, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10147&quot;&gt;DuckDB&#39;s memory management received a significant upgrade&lt;/a&gt; to handle multiple concurrent operators all requiring significant memory.
The &lt;a href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#temporary-memory-manager&quot;&gt;0.10.0 release blog post&lt;/a&gt; shares additional details about this feature.&lt;/p&gt;

&lt;p&gt;As a result, by version 0.10.0 DuckDB was able to handle calculations on data that is significantly larger than memory, even if the intermediate calculations are large in size.
All operators are supported, including sorting, aggregating, joining, and windowing.
Future work can further test the boundaries of what is possible with DuckDB&#39;s out-of-core support, including window functions and even larger data sizes.&lt;/p&gt;
      &lt;h3 id=&quot;hardware-capabilities-over-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#hardware-capabilities-over-time&quot;&gt;Hardware Capabilities over Time&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB&#39;s performance on the same hardware has improved dramatically, and at the same time, the capabilities of hardware are increasing rapidly as well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/performance_over_time/historical-cost-of-computer-memory-and-storage-memory.png&quot; alt=&quot;ram-prices&quot; width=&quot;360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;img src=&quot;https://duckdb.org/images/blog/performance_over_time/historical-cost-of-computer-memory-and-storage-SSDs.png&quot; alt=&quot;ssd-prices&quot; width=&quot;360&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Source: &lt;a href=&quot;https://ourworldindata.org/grapher/historical-cost-of-computer-memory-and-storage?yScale=linear&amp;amp;time=2021..latest&amp;amp;facet=metric&amp;amp;uniformYAxis=0&quot;&gt;Our World in Data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The price of RAM has declined by 2.2× and the price of SSD storage has decreased by 2.7× from 2021 to 2023 alone.
Thanks to the combination of DuckDB enhancements and hardware prices, the scale of analysis possible on a single node has increased by substantially more than an order of magnitude in just 3 years!&lt;/p&gt;
      &lt;h2 id=&quot;analyzing-the-results-yourself&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#analyzing-the-results-yourself&quot;&gt;Analyzing the Results Yourself&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A DuckDB 1.0 database containing the results of these benchmarks is available at &lt;a href=&quot;https://blobs.duckdb.org/data/duckdb_perf_over_time.duckdb&quot;&gt;https://blobs.duckdb.org/data/duckdb_perf_over_time.duckdb&lt;/a&gt;.
Any DuckDB client with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; extension can read that file.&lt;/p&gt;

&lt;p&gt;You can even use the DuckDB Wasm web shell to &lt;strong&gt;&lt;a href=&quot;https://shell.duckdb.org/#queries=v0,ATTACH-&#39;https%3A%2F%2Fblobs.duckdb.org%2Fdata%2Fduckdb_perf_over_time.duckdb&#39;-AS-performance_results~,FROM-performance_results.benchmark_results-SELECT-%22DuckDB-Version%22%2C-sum(%22Time-(seconds)%22)%3A%3ADECIMAL(15%2C2)-as-sum_time-GROUP-BY-%22DuckDB-Version%22-ORDER-BY-any_value(%22Release-Date%22)~&quot;&gt;query the file directly from your browser&lt;/a&gt;&lt;/strong&gt; (with the queries pre-populated and automatically executed!):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; httpfs&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/duckdb_perf_over_time.duckdb&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;performance_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;USE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;performance_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The file contains two tables: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;benchmark_results&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scale_benchmark_results&lt;/code&gt;.
Please let us know if you uncover any interesting findings!&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In summary, not only is DuckDB&#39;s feature set growing substantially with each release, DuckDB is getting faster very fast!
Overall, performance has &lt;strong&gt;improved by 14× in only 3 years!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Yet query performance is only part of the story!
The variety of workloads that DuckDB can handle is wide and growing wider thanks to a full-featured SQL dialect, including high performance window functions.
Additionally, critical workloads like data import, CSV parsing, and data export have improved dramatically over time.
The complete developer experience is critical for DuckDB!&lt;/p&gt;

&lt;p&gt;Finally, DuckDB now supports larger-than-memory calculations across all operators: sorting, aggregating, joining, and windowing.
The size of problem that you can handle on your current compute resources just got 10× bigger, or more!&lt;/p&gt;

&lt;p&gt;If you have made it this far, welcome to the flock! 🦆
&lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Join us on Discord&lt;/a&gt;, we value your feedback!&lt;/p&gt;
      &lt;h2 id=&quot;appendix&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#appendix&quot;&gt;Appendix&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;benchmark-design&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#benchmark-design&quot;&gt;Benchmark Design&lt;/a&gt;
        
      &lt;/h3&gt;
    
      &lt;h4 id=&quot;h2oai-as-the-foundation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#h2oai-as-the-foundation&quot;&gt;H2O.ai as the Foundation&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;This post measures DuckDB&#39;s performance over time on the H2O.ai benchmark for both joins and group by queries.&lt;/p&gt;

&lt;p&gt;The result of each H2O.ai query is written to a table in a persistent DuckDB file.
This does require additional work when compared with an in-memory workflow (especially the burden on the SSD rather than RAM), but improves scalability and is a common approach for larger analyses.&lt;/p&gt;

&lt;p&gt;As in the current H2O.ai benchmark, categorical-type columns (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; columns with low cardinality) were converted to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; type as a part of the benchmark.
The time for converting into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; columns was included in the benchmark time, and resulted in a lower total amount of time (so the upfront conversion was worthwhile).
However, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; data type was not fully operational in DuckDB until version 0.6.1 (December 2022), so earlier versions skip this step.&lt;/p&gt;
      &lt;h4 id=&quot;python-client&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#python-client&quot;&gt;Python Client&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;To measure interoperability with other dataframe formats, we have used Python rather than R (used by H2O.ai) for this analysis.
We do continue to use R for the data generation step for consistency with the benchmark.
Python is DuckDB&#39;s most popular client, great for data science, and also the author&#39;s favorite language for this type of work.&lt;/p&gt;
      &lt;h4 id=&quot;export-and-replacement-scans&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#export-and-replacement-scans&quot;&gt;Export and Replacement Scans&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;We now extend this benchmark in several important ways.
In addition to considering raw query performance, we measure import and export performance with several formats: Pandas, Apache Arrow, and Apache Parquet.
The results of both the join and group by benchmarks are exported to each format.&lt;/p&gt;

&lt;p&gt;When exporting to dataframes, we measured the performance in both cases.
However, when summarizing the total performance, we chose the best performing format at the time.
This likely mirrors the behavior of performance-sensitive users (as they would likely not write to both formats!).
In version 0.5.1, released September 2022, DuckDB&#39;s performance when writing to and reading from the Apache Arrow format surpassed Pandas.
As a result, versions 0.2.7 to 0.4.0 use Pandas, and 0.5.1 onward uses Arrow.&lt;/p&gt;

&lt;p&gt;On the import side, replacement scans allow DuckDB to read those same formats without a prior import step.
In the replacement scan benchmark, the data that is scanned is the output of the final H2O.ai group by benchmark query.
At the 5 GB scale it is a 100 million row dataset.
Only one column is read, and a single aggregate is calculated.
This focuses the benchmark on the speed of scanning the data rather than DuckDB&#39;s aggregation algorithms or speed of outputting results.
The query used follows the format:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;dataframe_or_Parquet_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;window-functions-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#window-functions-1&quot;&gt;Window Functions&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;We also added an entire series of window function benchmarks.
Window functions are a critical workload in real world data analysis scenarios, and can stress test a system in other ways.
DuckDB has implemented state of the art algorithms to quickly process even the most complex window functions.
We use the largest table from the join benchmark as the raw data for these new tests to help with comparability to the rest of the benchmark.&lt;/p&gt;

&lt;p&gt;Window function benchmarks are much less common than more traditional joins and aggregations, and we were unable to find a suitable suite off the shelf.
These queries were designed to showcase the variety of uses for window functions, but there are certainly more that could be added.
We are open to your suggestions for queries to add, and hope these queries could prove useful for other systems!&lt;/p&gt;

&lt;p&gt;Since the window functions benchmark is new, the window functions from each of the queries included are shown in the appendix at the end of the post.&lt;/p&gt;
      &lt;h4 id=&quot;workload-size&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#workload-size&quot;&gt;Workload Size&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;We test only the middle 5 GB dataset size for the workloads mentioned thus far, primarily because some import and export operations to external formats like Pandas must fit in memory (and we used a MacBook Pro M1 with only 16 GB of RAM).
Additionally, running the tests for 21 DuckDB versions was time-intensive even at that scale, due to the performance of older versions.&lt;/p&gt;
      &lt;h4 id=&quot;scale-tests-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#scale-tests-1&quot;&gt;Scale Tests&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Using only 5 GB of data does not answer our second key question: “What scale of data can it handle?”!
We also ran only the group by and join related operations (avoiding in-memory imports and exports) at the 5 GB and the 50 GB scale.
Older versions of DuckDB could not handle the 50 GB dataset when joining or aggregating, but modern versions can handle both, even on a memory-constrained 16 GB RAM laptop.
Instead of measuring performance, we measure the size of the benchmark that was able to complete on a given version.&lt;/p&gt;
      &lt;h4 id=&quot;summary-metrics&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#summary-metrics&quot;&gt;Summary Metrics&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;With the exception of the scale tests, each benchmark was run 3 times and the median time was used for reporting results.
The scale tests were run once and produced a binary metric, success or failure, at each data size tested.
As older versions would not fail gracefully, the scale metrics were accumulated across multiple partial runs.&lt;/p&gt;
      &lt;h4 id=&quot;computing-resources&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#computing-resources&quot;&gt;Computing Resources&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;All tests use a MacBook Pro M1 with 16 GB of RAM.
In 2024, this is far from state of the art!
If you have more powerful hardware, you will see both improved performance and scalability.&lt;/p&gt;
      &lt;h4 id=&quot;duckdb-versions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#duckdb-versions&quot;&gt;DuckDB Versions&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Version 0.2.7, published in June 2021, was the first version to include a Python client compiled for ARM64, so it was the first version that could easily run on the benchmarking compute resources.
Version 1.0.0 is the latest available at the time of publication (June 2024), although we also provide a sneak preview of an in-development feature branch.&lt;/p&gt;
      &lt;h4 id=&quot;default-settings&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#default-settings&quot;&gt;Default Settings&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;All versions were run with the default settings.
As a result, improvements from a new feature only appear in these results once that feature became the default and was therefore ready for production workloads.&lt;/p&gt;
      &lt;h3 id=&quot;window-functions-benchmark&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/26/benchmarks-over-time.html#window-functions-benchmark&quot;&gt;Window Functions Benchmark&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Each benchmark query follows the format below, but with different sets of window functions in the &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;ge&quot;&gt;window_function(s)&lt;/span&gt;&lt;/code&gt; placeholder.
The table in use is the largest table from the H2O.ai join benchmark, and in this case the 5 GB scale was used.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;windowing_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;windowing_results&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;ge&quot;&gt;window_function(s)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join_benchmark_largest_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The various window functions that replace the placeholder are below and are labelled to match the result graphs.
These were selected to showcase the variety of use cases for window functions, as well as the variety of algorithms required to support the full range of the syntax.
The DuckDB documentation contains a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html#syntax&quot;&gt;full railroad diagram of the available syntax&lt;/a&gt;.
If there are common use cases for window functions that are not well-covered in this benchmark, please let us know!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/* 302 Basic Window */&lt;/span&gt; 
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_basic&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 303 Sorted Window */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_order_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_number_order_by&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 304 Quantiles Entire Dataset */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;quantile_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quantile_entire_dataset&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 305 PARTITION BY */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_by_id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_by_id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum_by_id3&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 306 PARTITION BY ORDER BY */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_by_id2_ordered_by_id3&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 307 Lead and Lag */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lead&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 308 Moving Averages */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_moving_average&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_dynamic_moving_average&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 309 Rolling Sum */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UNBOUNDED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_rolling_sum&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 310 RANGE BETWEEN */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_range_between&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_dynamic_range_between&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 311 Quantiles PARTITION BY */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;quantile_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_quantiles_by_id2&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 312 Quantiles PARTITION BY ROWS BETWEEN */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lag_by_id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_lead_by_id2&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 313 Moving Averages PARTITION BY */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_moving_average_by_id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_dynamic_moving_average_by_id2&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 314 Rolling Sum PARTITION BY */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;UNBOUNDED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_rolling_sum_by_id2&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 315 RANGE BETWEEN PARTITION BY */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_range_between_by_id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_dynamic_range_between_by_id2&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/* 316 Quantiles PARTITION BY ROWS BETWEEN */&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;quantile_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_quantiles_by_id2_rows_between&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description><link>https://duckdb.org/2024/06/26/benchmarks-over-time.html</link><guid isPermaLink="false">https://duckdb.org/2024/06/26/benchmarks-over-time.html</guid><pubDate>Wed, 26 Jun 2024 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>20 000 Stars on GitHub</title><description>&lt;p&gt;DuckDB reached 20&amp;nbsp;000 stars today on &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;GitHub&lt;/a&gt;.
We would like to thank our amazing community of users and &lt;a href=&quot;https://github.com/duckdb/duckdb/graphs/contributors&quot;&gt;contributors&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To this day, we continue to be amazed by the adoption of DuckDB.
We hit the previous milestone, &lt;a href=&quot;https://duckdb.org/2023/05/12/github-10k-stars.html&quot;&gt;10&amp;nbsp;000 stars&lt;/a&gt; just a little over a year ago.
Since then, the growth of stars has been slowly increasing, until the &lt;a href=&quot;https://duckdb.org/2024/06/03/announcing-duckdb-100.html&quot;&gt;release of version 1.0.0 in early June&lt;/a&gt; gave the boost that propelled the star count to 20&amp;nbsp;000.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/github-20k-stars-duckdb.png&quot; alt=&quot;Star History of DuckDB&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
    &lt;br&gt;
    (image source: &lt;a href=&quot;https://star-history.com/&quot;&gt;star-history.com&lt;/a&gt;)
&lt;/div&gt;
      &lt;h2 id=&quot;what-else-happened-in-june&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/22/github-20k-stars.html#what-else-happened-in-june&quot;&gt;What Else Happened in June?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The last few weeks since the release were quite eventful:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;MotherDuck, a DuckDB-based cloud warehouse, just &lt;a href=&quot;https://motherduck.com/blog/announcing-motherduck-general-availability-data-warehousing-with-duckdb/&quot;&gt;reached General Availability&lt;/a&gt; last week.
 Congratulations to the team on the successful release!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We added support to DuckDB for &lt;a href=&quot;https://delta.io/&quot;&gt;Delta Lake&lt;/a&gt;, an open-source lakehouse framework.
 This feature was described in Sam Ansmink&#39;s &lt;a href=&quot;https://duckdb.org/2024/06/10/delta.html&quot;&gt;blog post&lt;/a&gt; and Hannes Mühleisen&#39;s &lt;a href=&quot;https://www.youtube.com/watch?v=wuP6iEYH11E&quot;&gt;keynote segment at the DATA+AI summit&lt;/a&gt;.&lt;/p&gt;

    &lt;p&gt;With extensions for both &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta.html&quot;&gt;Delta Lake&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/iceberg/overview.html&quot;&gt;Iceberg&lt;/a&gt;,
 DuckDB can now read the two most popular data lake formats.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We ran a poster campaign for DuckDB in Amsterdam:&lt;/p&gt;

    &lt;div align=&quot;center&quot;&gt;
     &lt;img src=&quot;https://duckdb.org/images/blog/duckdb-poster-campaign-amsterdam.jpg&quot; alt=&quot;Big Data on your Laptop Poster in Amsterdam&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
     &lt;br&gt;
 &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://duckdblabs.com/&quot;&gt;DuckDB Labs&lt;/a&gt; sponsored the &lt;a href=&quot;https://hack4her.github.io/&quot;&gt;Hack4Her event&lt;/a&gt;, a female-focused student hackathon in the Netherlands. During the DuckDB Challenge of the event, teams built a community-driven app providing safe walking routes in Amsterdam using DuckDB and its &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;geospatial library&lt;/a&gt;.&lt;/p&gt;

    &lt;div align=&quot;center&quot;&gt;
     &lt;img src=&quot;https://duckdb.org/images/blog/hack4her-duckdb-amsterdam.jpg&quot; alt=&quot;Hack4Her Event&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
     &lt;br&gt;
 &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;looking-ahead&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/22/github-20k-stars.html#looking-ahead&quot;&gt;Looking Ahead&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are several interesting events lined up for the summer.&lt;/p&gt;

&lt;p&gt;First, two books about DuckDB are expected to be released:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.packtpub.com/product/getting-started-with-duckdb/9781803241005&quot;&gt;&lt;strong&gt;Getting Started with DuckDB&lt;/strong&gt;&lt;/a&gt;, authored by Simon Aubury and Ned Letcher, and published by Packt Publishing&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.manning.com/books/duckdb-in-action&quot;&gt;&lt;strong&gt;DuckDB in Action&lt;/strong&gt;&lt;/a&gt;, authored by Mark Needham, Michael Hunger and Michael Simons, and published by Manning Publications&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Second, we are holding our next user community meeting, &lt;a href=&quot;https://duckdb.org/events/2024/08/15/duckcon5/&quot;&gt;DuckCon #5&lt;/a&gt; in Seattle on August 15 with the regular &quot;State of the Duck&quot; update as well as three regular talks and several lightning talks.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt; &lt;a href=&quot;https://duckdb.org/events/2024/08/15/duckcon5/&quot;&gt;&lt;img src=&quot;https://duckdb.org/images/duckcon5-splashscreen.svg&quot; alt=&quot;DuckCon #5 Splashscreen&quot; width=&quot;680&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/div&gt;

&lt;p&gt;Third, we will improve DuckDB&#39;s extension ecosystem and streamline the publication process for community extensions.&lt;/p&gt;

&lt;p&gt;Finally, we have a series of blog posts lined up for publication.
These will discuss DuckDB&#39;s performance over time, the results of the user survey we conducted during the spring, DuckDB&#39;s storage format, and many more.
Stay tuned!&lt;/p&gt;

&lt;p&gt;We are looking forward to next part of our journey and, of course, the next 10&amp;nbsp;000 stars on GitHub.&lt;/p&gt;

</description><link>https://duckdb.org/2024/06/22/github-20k-stars.html</link><guid isPermaLink="false">https://duckdb.org/2024/06/22/github-20k-stars.html</guid><pubDate>Sat, 22 Jun 2024 00:00:00 GMT</pubDate><author>The DuckDB Team</author></item><item><title>Command Line Data Processing: Using DuckDB as a Unix Tool</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB&#39;s CLI client is portable to many platforms and architectures. It handles CSV files conveniently and offers users the same rich SQL syntax everywhere. These characteristics make DuckDB an ideal tool to complement traditional Unix tools for data processing in the command line.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;In this blog post, we dive into the terminal to compare DuckDB with traditional tools used in Unix shells (Bash, Zsh, etc.).
We solve several problems requiring operations such as projection and filtering to demonstrate the differences between using SQL queries in DuckDB versus specialized command line tools.
In the process, we will show off some cool features such as DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html&quot;&gt;powerful CSV reader&lt;/a&gt; and the &lt;a href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-positional-join&quot;&gt;positional join operator&lt;/a&gt;.
Let&#39;s get started!&lt;/p&gt;
      &lt;h2 id=&quot;the-unix-philosophy&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#the-unix-philosophy&quot;&gt;The Unix Philosophy&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To set the stage, let&#39;s recall the &lt;a href=&quot;https://en.wikipedia.org/wiki/Unix_philosophy&quot;&gt;Unix philosophy&lt;/a&gt;. This states that programs should:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;do one thing and do it well,&lt;/li&gt;
  &lt;li&gt;work together, and&lt;/li&gt;
  &lt;li&gt;handle text streams.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unix-like systems such as macOS, Linux and &lt;a href=&quot;https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux&quot;&gt;WSL in Windows&lt;/a&gt; have embraced this philosophy.
Tools such as
&lt;a href=&quot;https://man7.org/linux/man-pages/man1/grep.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&quot;https://man7.org/linux/man-pages/man1/sed.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt;&lt;/a&gt;, and
&lt;a href=&quot;https://man7.org/linux/man-pages/man1/sort.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort&lt;/code&gt;&lt;/a&gt;
are ubiquitious and widely used in &lt;a href=&quot;https://en.wikipedia.org/wiki/Shell_script&quot;&gt;shell scripts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a purpose-built data processing tool, DuckDB fits the Unix philosophy quite well.
First, it was designed to be a fast in-process analytical SQL database system &lt;em&gt;(do one thing and do it well).&lt;/em&gt;
Second, it has a standalone &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;command line client&lt;/a&gt;, which can consume and produce CSV files &lt;em&gt;(work together),&lt;/em&gt;
and also supports reading and writing text streams &lt;em&gt;(handle text streams)&lt;/em&gt;.
Thanks to these, DuckDB works well in the ecosystem of Unix CLI tools, as
shown
&lt;a href=&quot;https://x.com/jooon/status/1781401858411565473&quot;&gt;in&lt;/a&gt;
&lt;a href=&quot;https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/&quot;&gt;several&lt;/a&gt;
&lt;a href=&quot;https://x.com/MarginaliaNu/status/1701532341225583044&quot;&gt;posts&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;portability-and-usability&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#portability-and-usability&quot;&gt;Portability and Usability&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;While Unix CLI tools are fast, robust, and available on all major platforms, they often have cumbersome syntax that&#39;s difficult to remember.
To make matters worse, these tools often come with slight differences between systems – think of the &lt;a href=&quot;https://unix.stackexchange.com/a/131940/315847&quot;&gt;differences between GNU &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt; and macOS&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt;&lt;/a&gt; or the differences between regex syntax among programs, which is aptly captured by Donald Knuth&#39;s quip &lt;a href=&quot;https://en.wikiquote.org/wiki/Donald_Knuth#Quotes&quot;&gt;&lt;em&gt;“I define Unix as 30 definitions of regular expressions living under one roof.”&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;While there are shells specialized specifically for dataframe processing, such as the &lt;a href=&quot;https://github.com/nushell/nushell&quot;&gt;Nushell project&lt;/a&gt;, older Unix shells (e.g., the Bourne shell &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sh&lt;/code&gt; and Bash) are still the most wide-spread, especially on servers.&lt;/p&gt;

&lt;p&gt;At the same time, we have DuckDB, an extremely portable database system which uses the same SQL syntax on all platforms.
With &lt;a href=&quot;https://duckdb.org/2024/06/03/announcing-duckdb-100.html&quot;&gt;version 1.0.0 released recently&lt;/a&gt;, DuckDB&#39;s syntax – based on the proven and widely used PostgeSQL dialect – is now in a stable state.
Another attractive feature of DuckDB is that it offers an interactive shell, which aids quick debugging. Moreover, DuckDB is available in &lt;a href=&quot;https://duckdb.org/docs/stable/clients/overview.html&quot;&gt;several host languages&lt;/a&gt; as well as in the browser &lt;a href=&quot;https://shell.duckdb.org/&quot;&gt;via WebAssembly&lt;/a&gt;, so if you ever decide to use your SQL scripts outside of the shell, DuckDB SQL scripts can be ported to a wide variety of environments without any changes.&lt;/p&gt;
      &lt;h2 id=&quot;data-processing-with-unix-tools-and-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#data-processing-with-unix-tools-and-duckdb&quot;&gt;Data Processing with Unix Tools and DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In the following, we give examples for implementing simple data processing tasks using the CLI tools provided in most Unix shells and using DuckDB SQL queries.
We use DuckDB v1.0.0 and run it in &lt;a href=&quot;https://duckdb.org/docs/stable/connect/overview.html#in-memory-database&quot;&gt;in-memory mode&lt;/a&gt;.
This mode makes sense for the problems we are tackling, as we do not create any tables and the operations are not memory-intensive, so there is no data to persist or to spill on disk.&lt;/p&gt;
      &lt;h3 id=&quot;datasets&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#datasets&quot;&gt;Datasets&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We use the four input files capturing information on cities and airports in the Netherlands.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
    &lt;a href=&quot;https://duckdb.org/data/cli/pop.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pop.csv&lt;/code&gt;&lt;/a&gt;, the population of each of the top-10 most populous cities.
&lt;/summary&gt;
  &lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city,province,population
Amsterdam,North Holland,905234
Rotterdam,South Holland,656050
The Hague,South Holland,552995
Utrecht,Utrecht,361924
Eindhoven,North Brabant,238478
Groningen,Groningen,234649
Tilburg,North Brabant,224702
Almere,Flevoland,218096
Breda,North Brabant,184716
Nijmegen,Gelderland,179073
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;
    &lt;a href=&quot;https://duckdb.org/data/cli/area.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;area.csv&lt;/code&gt;&lt;/a&gt;, the area of each of the top-10 most populous cities.
&lt;/summary&gt;
  &lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city,area
Amsterdam,219.32
Rotterdam,324.14
The Hague,98.13
Utrecht,99.21
Eindhoven,88.92
Groningen,197.96
Tilburg,118.13
Almere,248.77
Breda,128.68
Nijmegen,57.63
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;
    &lt;a href=&quot;https://duckdb.org/data/cli/cities-airports.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cities-airports.csv&lt;/code&gt;&lt;/a&gt;, the &lt;a href=&quot;https://en.wikipedia.org/wiki/IATA_airport_code&quot;&gt;IATA codes&lt;/a&gt; of civilian airports serving given cities.
&lt;/summary&gt;
  &lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city,IATA
Amsterdam,AMS
Haarlemmermeer,AMS
Eindhoven,EIN
Groningen,GRQ
Eelde,GRQ
Maastricht,MST
Beek,MST
Rotterdam,RTM
The Hague,RTM
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;
    &lt;a href=&quot;https://duckdb.org/data/cli/airport-names.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;airport-names.csv&lt;/code&gt;&lt;/a&gt;, the airport names belonging to given IATA codes.
&lt;/summary&gt;
  &lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;IATA,airport name
AMS,Amsterdam Airport Schiphol
EIN,Eindhoven Airport
GRQ,Groningen Airport Eelde
MST,Maastricht Aachen Airport
RTM,Rotterdam The Hague Airport
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;p&gt;You can download all input files as a &lt;a href=&quot;https://duckdb.org/data/cli/duckdb-cli-data.zip&quot;&gt;single zip file&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;projecting-columns&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#projecting-columns&quot;&gt;Projecting Columns&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Projecting columns is a very common data processing step. Let&#39;s take the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pop.csv&lt;/code&gt; file and project the first and last columns, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;city&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;population&lt;/code&gt;.&lt;/p&gt;
      &lt;h4 id=&quot;unix-shell-cut&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-cut&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cut&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In the Unix shell, we use the &lt;a href=&quot;https://man7.org/linux/man-pages/man1/cut.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cut&lt;/code&gt; command&lt;/a&gt; and specify the file&#39;s delimiter (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-d&lt;/code&gt;) and the columns to be projected (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-f&lt;/code&gt;).&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1,3 pop.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This produces the following output:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city,population
Amsterdam,905234
Rotterdam,656050
The Hague,552995
Utrecht,361924
Eindhoven,238478
Groningen,234649
Tilburg,224702
Almere,218096
Breda,184716
Nijmegen,179073
&lt;/code&gt;&lt;/pre&gt;
      &lt;h4 id=&quot;duckdb-select&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-select&quot;&gt;DuckDB: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In DuckDB, we can use the CSV reader to load the data, then use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause with column indexes (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#i&lt;/code&gt;) to designate the columns to be projected:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;pop.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that we did not have to define any schema or load the data to a table.
Instead, we simply used &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;pop.csv&#39;&lt;/code&gt; in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause as we would do with a regular table.
DuckDB detects that this is a CSV file and invokes the &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html#csv-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; function&lt;/a&gt;, which automatically infers the CSV file&#39;s dialect (delimiter, presence of quotes, etc.) as well as the schema of the table.
This allows us to simply project columns using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT #1, #3&lt;/code&gt;.
We could also use the more readable syntax &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT city, population&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To make the output of the solutions using Unix tools and DuckDB equivalent, we wrap the query into a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/copy.html#copy--to&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY ... TO&lt;/code&gt; statement&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;pop.csv&#39;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query produces the same result as the Unix command&#39;s output shown &lt;a href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-cut&quot;&gt;above&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To turn this into a standalone CLI command, we can invoke the DuckDB command line client with the &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;query&lt;/span&gt;&lt;/code&gt; argument, which runs the SQL query and exits once it&#39;s finished.
Using this technique, the query above can be turned into the following one-liner:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;COPY (SELECT #1, #3 FROM &#39;pop.csv&#39;) TO &#39;/dev/stdout/&#39;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the following, we&#39;ll omit the code blocks using the standalone &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;/code&gt; command: all solutions can be executed in the &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;query&lt;/span&gt;&lt;/code&gt; template and yield the same result as the solutions using Unix tools.&lt;/p&gt;
      &lt;h3 id=&quot;sorting-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#sorting-files&quot;&gt;Sorting Files&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Another common task is to sort files based on given columns.
Let&#39;s rank the cities within provinces based on their populations.
To do so, we need to sort the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pop.csv&lt;/code&gt; file first based on the name of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;province&lt;/code&gt; using an ascending order, then on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;population&lt;/code&gt; using a descending order.
We then return the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;province&lt;/code&gt; column first, followed by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;city&lt;/code&gt; and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;population&lt;/code&gt; columns.&lt;/p&gt;
      &lt;h4 id=&quot;unix-shell-sort&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-sort&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In the Unix shell, we rely on the &lt;a href=&quot;https://man7.org/linux/man-pages/man1/sort.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort&lt;/code&gt;&lt;/a&gt; tool.
We specify the CSV file&#39;s separator with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-t&lt;/code&gt; argument and set the keys to sort on using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-k&lt;/code&gt; arguments.
We first sort on the second column (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;province&lt;/code&gt;) with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-k 2,2&lt;/code&gt;.
Then, we sort on the third column (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;population&lt;/code&gt;), setting the ordering to be reversed (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;r&lt;/code&gt;) and numeric (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;) with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-k 3rn&lt;/code&gt;.
Note that we need to handle the header of the file separately: we take the first row with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;head -n 1&lt;/code&gt; and the rest of the rows with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tail -n +2&lt;/code&gt;, sort the latter, and glue them back together with the header.
Finally, we perform a projection to reorder the columns.
Unfortunately, the &lt;a href=&quot;https://stackoverflow.com/questions/2129123/rearrange-columns-using-cut&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cut&lt;/code&gt; command cannot reorder the columns&lt;/a&gt;, so we use &lt;a href=&quot;https://man7.org/linux/man-pages/man1/awk.1p.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awk&lt;/code&gt;&lt;/a&gt; instead:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 1 pop.csv&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; +2 pop.csv &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    | &lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; 2,2 &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; 3rn&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    | &lt;span class=&quot;nb&quot;&gt;awk&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-F&lt;/span&gt; , &lt;span class=&quot;s1&quot;&gt;&#39;{ print $2 &quot;,&quot; $1 &quot;,&quot; $3 }&#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result is the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;province,city,population
Flevoland,Almere,218096
Gelderland,Nijmegen,179073
Groningen,Groningen,234649
North Brabant,Eindhoven,238478
North Brabant,Tilburg,224702
North Brabant,Breda,184716
North Holland,Amsterdam,905234
South Holland,Rotterdam,656050
South Holland,The Hague,552995
Utrecht,Utrecht,361924
&lt;/code&gt;&lt;/pre&gt;
      &lt;h4 id=&quot;duckdb-order-by&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-order-by&quot;&gt;DuckDB: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In DuckDB, we simply load the CSV and specify the column ordering via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT province, city, population&lt;/code&gt;, then set the sorting criteria on the selected columns (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;province ASC&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;population DESC&lt;/code&gt;).
The CSV reader automatically detects types, so the sorting is numeric by default. Finally, we surround the query with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; statement to print the results to the standard output.&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;population&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;pop.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;province&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;population&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;intersecting-columns&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#intersecting-columns&quot;&gt;Intersecting Columns&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;A common task is to calculate the intersection of two columns, i.e., to find entities that are present in both.
Let&#39;s find the cities that are both in the top-10 most populous cities and have their own airports.&lt;/p&gt;
      &lt;h4 id=&quot;unix-shell-comm&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-comm&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;comm&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The Unix solution for intersection uses the &lt;a href=&quot;https://linux.die.net/man/1/comm&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;comm&lt;/code&gt; tool&lt;/a&gt;, intended to compare two &lt;em&gt;sorted&lt;/em&gt; files line-by-line.
We first &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cut&lt;/code&gt; the relevant colum from both files.
Due to the sorting requirement, we apply &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort&lt;/code&gt; on both inputs before performing the intersection.
The intersection is performed using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;comm -12&lt;/code&gt; where the argument &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-12&lt;/code&gt; means that we only want to keep lines that are in both files.
We again rely on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;head&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tail&lt;/code&gt; to treat the headers and the rest of the files separately during processing and glue them together at the end.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 1 pop.csv | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;comm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-12&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
        &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; +2 pop.csv | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1 | &lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
        &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; +2 cities-airports.csv | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1 | &lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The script produces the following output:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city
Amsterdam
Eindhoven
Groningen
Rotterdam
The Hague
&lt;/code&gt;&lt;/pre&gt;
      &lt;h4 id=&quot;duckdb-intersect-all&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-intersect-all&quot;&gt;DuckDB: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERSECT ALL&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The DuckDB solution reads the CSV files, projects the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;city&lt;/code&gt; fields and applies the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/setops.html#intersect-all-bag-semantics&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERSECT ALL&lt;/code&gt; clause&lt;/a&gt; to calculate the intersection:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;pop.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;INTERSECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;cities-airports.csv&#39;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;pasting-rows-together&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#pasting-rows-together&quot;&gt;Pasting Rows Together&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Pasting rows together line-by-line is a recurring task.
In our example, we know that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pop.csv&lt;/code&gt; and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;area.csv&lt;/code&gt; files have an equal number of rows, so we can produce a single file that contains both the population and the area of every city in the dataset.&lt;/p&gt;
      &lt;h4 id=&quot;unix-shell-paste&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-paste&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;paste&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In the Unix shell, we use the &lt;a href=&quot;https://man7.org/linux/man-pages/man1/paste.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;paste&lt;/code&gt;&lt;/a&gt; command and remove the duplicate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;city&lt;/code&gt; field using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cut&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;paste&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; , pop.csv area.csv | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1,2,3,5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The output is the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city,province,population,area
Amsterdam,North Holland,905234,219.32
Rotterdam,South Holland,656050,324.14
The Hague,South Holland,552995,98.13
Utrecht,Utrecht,361924,99.21
Eindhoven,North Brabant,238478,88.92
Groningen,Groningen,234649,197.96
Tilburg,North Brabant,224702,118.13
Almere,Flevoland,218096,248.77
Breda,North Brabant,184716,128.68
Nijmegen,Gelderland,179073,57.63
&lt;/code&gt;&lt;/pre&gt;
      &lt;h4 id=&quot;duckdb-positional-join&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-positional-join&quot;&gt;DuckDB: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSITIONAL JOIN&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In DuckDB, we can use a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#positional-joins&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSITIONAL JOIN&lt;/code&gt;&lt;/a&gt;.
This join type is one of DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;SQL extensions&lt;/a&gt; and it provides a concise syntax to combine tables row-by-row based on each row&#39;s position in the table.
Joining the two tables together using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSITIONAL JOIN&lt;/code&gt; results in two &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;city&lt;/code&gt; columns – we use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#exclude-clause&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; clause&lt;/a&gt; to remove the duplicate column:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;pop.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;POSITIONAL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;area.csv&#39;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;filtering&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#filtering&quot;&gt;Filtering&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Filtering is another very common operation. For this, we&#39;ll use &lt;a href=&quot;https://duckdb.org/data/cli/cities-airports.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cities-airports.csv&lt;/code&gt; file&lt;/a&gt;.
For each airport, this file contains its &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IATA&lt;/code&gt; code and the main cities that it serves:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city,IATA
Amsterdam,AMS
Haarlemmermeer,AMS
Eindhoven,EIN
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&#39;s try to formulate two queries:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Find all cities whose name ends in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dam&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Find all airports whose IATA code is equivalent to the first three letters of a served city&#39;s name, but the city&#39;s name does &lt;em&gt;not&lt;/em&gt; end in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dam&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
      &lt;h4 id=&quot;unix-shell-grep&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-grep&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;To answer the first question in the Unix shell, we use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; and the regular expression &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;^[^,]*dam,&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;^[^,]*dam,&quot;&lt;/span&gt; cities-airports.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this expression, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;^&lt;/code&gt; denotes the start of the line, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[^,]*&lt;/code&gt; searches for a string that does not contain the comma character (the separator).
The expression &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dam,&lt;/code&gt; ensures that the end of the string in the first field is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dam&lt;/code&gt;.
The output is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;Amsterdam,AMS
Rotterdam,RTM
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&#39;s try to answer the second question. For this, we need to match the first three characters in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;city&lt;/code&gt; field to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IATA&lt;/code&gt; field but we need to do so in a case-insensitive manner.
We also need to use a negative condition to exclude the lines where the city&#39;s name ends in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dam&lt;/code&gt;.
Both of these requirements are difficult to achieve with a single &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;egrep&lt;/code&gt; command as they lack support for two features.
First, they do not support case-insensitive matching &lt;em&gt;using a backreference&lt;/em&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep -i&lt;/code&gt; alone is not sufficient to ensure this).
Second, they do not support &lt;a href=&quot;https://www.regular-expressions.info/lookaround.html&quot;&gt;negative lookbehinds&lt;/a&gt;.
Therefore, we use &lt;a href=&quot;https://man7.org/linux/man-pages/man1/pcregrep.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt;&lt;/a&gt;, and formulate our question as follows:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;pcregrep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;^([a-z]{3}).*?(?&amp;lt;!dam),\1$&#39;&lt;/span&gt; cities-airports.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt; with the case-insensitive flag (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-i&lt;/code&gt;), which in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt; also affects backreferences such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\1&lt;/code&gt;.
We capture the first three letters with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;([a-z]{3})&lt;/code&gt; (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ams&lt;/code&gt;) and match it to the second field with the backreference: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;,\1$&lt;/code&gt;.
We use a non-greedy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.*?&lt;/code&gt; to seek to the end of the first field, then apply a negative lookbehind with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(?&amp;lt;!dam)&lt;/code&gt; expression to ensure that the field does not end in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dam&lt;/code&gt;.
The result is a single line:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;Eindhoven,EIN
&lt;/code&gt;&lt;/pre&gt;
      &lt;h4 id=&quot;duckdb-where--like&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-where--like&quot;&gt;DuckDB: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE ... LIKE&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Let&#39;s answer the questions now in DuckDB.
To answer the first question, we can use &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/pattern_matching.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; for pattern matching&lt;/a&gt;.
The header should not be part of the output, so we disable it with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HEADER false&lt;/code&gt;.
The complete query looks like follows:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;cities-airports.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%dam&#39;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;HEADER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For the second question, we use &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#stringbeginend&quot;&gt;string slicing&lt;/a&gt; to extract the first three characters, &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#upperstring&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;upper&lt;/code&gt;&lt;/a&gt; to ensure case-insensitivity, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NOT LIKE&lt;/code&gt; for the negative condition:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;cities-airports.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IATA&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%dam&#39;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;HEADER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These queries return exactly the same results as the solutions using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In both of these queries, we used the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#from-first-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;-first syntax&lt;/a&gt;.
If the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause is omitted, the query is executed as if &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT *&lt;/code&gt; was used, i.e., it returns all columns.&lt;/p&gt;
      &lt;h3 id=&quot;joining-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#joining-files&quot;&gt;Joining Files&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Joining tables is an essential task in data processing. Our next example is going to use a join to return city name–airport name combinations.
This is achieved by joining the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cities-airports.csv&lt;/code&gt; and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;airport-names.csv&lt;/code&gt; files on their IATA code fields.&lt;/p&gt;
      &lt;h4 id=&quot;unix-shell-join&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-join&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;join&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Unix tools support joining files via the &lt;a href=&quot;https://man7.org/linux/man-pages/man1/join.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;join&lt;/code&gt; command&lt;/a&gt;, which joins lines of two &lt;em&gt;sorted&lt;/em&gt; inputs on a common field.
To make this work, we sort the files based on their &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IATA&lt;/code&gt; fields, then perform the join on the first file&#39;s 2nd column (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-1 2&lt;/code&gt;) and the second file&#39;s 1st column (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-2 1&lt;/code&gt;).
We have to omit the header for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;join&lt;/code&gt; command to work, so we do just that and construct a new header with an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;echo&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;IATA,city,airport name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; 2 &lt;span class=&quot;nt&quot;&gt;-2&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
        &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; +2 cities-airports.csv | &lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; 2,2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
        &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; +2 airport-names.csv   | &lt;span class=&quot;nb&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; , &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; 1,1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result is the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;IATA,city,airport name
AMS,Amsterdam,Amsterdam Airport Schiphol
AMS,Haarlemmermeer,Amsterdam Airport Schiphol
EIN,Eindhoven,Eindhoven Airport
GRQ,Eelde,Groningen Airport Eelde
GRQ,Groningen,Groningen Airport Eelde
MST,Beek,Maastricht Aachen Airport
MST,Maastricht,Maastricht Aachen Airport
RTM,Rotterdam,Rotterdam The Hague Airport
RTM,The Hague,Rotterdam The Hague Airport
&lt;/code&gt;&lt;/pre&gt;
      &lt;h4 id=&quot;duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb&quot;&gt;DuckDB&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In DuckDB, we load the CSV files and connect them using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#natural-joins&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NATURAL JOIN&lt;/code&gt; clause&lt;/a&gt;, which joins on column(s) with the same name.
To ensure that the result matches with that of the Unix solution, we use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/orderby.html#order-by-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY ALL&lt;/code&gt; clause&lt;/a&gt;, which sorts the result on all columns, starting from the first one, and stepping through them for tie-breaking to the last column.&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;IATA&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;airport name&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;cities-airports.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;NATURAL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;airport-names.csv&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;replacing-strings&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#replacing-strings&quot;&gt;Replacing Strings&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;You may have noticed that we are using very clean datasets. This is of course very unrealistic, so in an evil twist, let&#39;s reduce the data quality a bit:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Replace the space in the province&#39;s name with an underscore, e.g., turning &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;North Holland&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;North_Holland&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Add thousand separating commas, e.g., turning &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;905234&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;905,234&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Change the CSV&#39;s separator to the semicolon character (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;;&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And while we&#39;re at it, also fetch the data set via HTTPS this time, using the URL &lt;a href=&quot;https://duckdb.org/data/cli/pop.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://duckdb.org/data/cli/pop.csv&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
      &lt;h4 id=&quot;unix-shell-curl-and-sed&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-curl-and-sed&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In Unix, remote data sets are typically fetched via &lt;a href=&quot;https://man7.org/linux/man-pages/man1/curl.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt;&lt;/a&gt;.
The output of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt; is piped into the subsequent processing steps, in this case, a bunch of &lt;a href=&quot;https://man7.org/linux/man-pages/man1/sed.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt;&lt;/a&gt; commands.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;curl&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; https://duckdb.org/data/cli/pop.csv &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    | &lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s/\([^,]*,.*\) \(.*,[^,]*\)/\1_\2/g&#39;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    | &lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s/,/;/g&#39;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    | &lt;span class=&quot;nb&quot;&gt;sed&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s/\([0-9][0-9][0-9]\)$/,\1/&#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This results in the following output:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;city;province;population
Amsterdam;North_Holland;905,234
Rotterdam;South_Holland;656,050
The Hague;South_Holland;552,995
Utrecht;Utrecht;361,924
Eindhoven;North_Brabant;238,478
Groningen;Groningen;234,649
Tilburg;North_Brabant;224,702
Almere;Flevoland;218,096
Breda;North_Brabant;184,716
Nijmegen;Gelderland;179,073
&lt;/code&gt;&lt;/pre&gt;
      &lt;h4 id=&quot;duckdb-httpfs-and-regexp_replace&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-httpfs-and-regexp_replace&quot;&gt;DuckDB: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regexp_replace&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In DuckDB, we use the following query:&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39; &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;_&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;regexp_replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;population&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;([0-9][0-9][0-9])$&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;,\1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;population&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://duckdb.org/data/cli/pop.csv&#39;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/dev/stdout/&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DELIMITER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause now has an HTTPS URL instead of a simple CSV file.
The presence of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://&lt;/code&gt; prefix triggers DuckDB to load the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; extension&lt;/a&gt; and use it to fetch the JSON document.
We use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#replacestring-source-target&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replace&lt;/code&gt; function&lt;/a&gt; to substitute the spaces with underscores,
and the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#regexp_replacestring-pattern-replacement&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;regexp_replace&lt;/code&gt; function&lt;/a&gt; for the replacement using a regular expression.
(We could have also used string formatting functions such as &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#fmt-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;format&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#printf-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;printf&lt;/code&gt;&lt;/a&gt;).
To change the separator to a semicolon, we serialize the file using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; statement with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELIMITER &#39;;&#39;&lt;/code&gt; option.&lt;/p&gt;
      &lt;h3 id=&quot;reading-json&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#reading-json&quot;&gt;Reading JSON&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As a final exercise, let&#39;s query the number of stars given to the &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb/duckdb&lt;/code&gt; repository on GitHub&lt;/a&gt;.&lt;/p&gt;
      &lt;h4 id=&quot;unix-shell-curl-and-jq&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#unix-shell-curl-and-jq&quot;&gt;Unix Shell: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jq&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In Unix tools, we can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt; to get the JSON file from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://api.github.com&lt;/code&gt; and pipe its output to &lt;a href=&quot;https://jqlang.github.io/jq/manual/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jq&lt;/code&gt;&lt;/a&gt; to query the JSON object.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;curl&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; https://api.github.com/repos/duckdb/duckdb &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    | &lt;span class=&quot;nb&quot;&gt;jq&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.stargazers_count&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;duckdb-read_json&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#duckdb-read_json&quot;&gt;DuckDB: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In DuckDB, we use the &lt;a href=&quot;https://duckdb.org/docs/stable/data/json/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt; function&lt;/a&gt;, invoking it with the remote HTTPS endpoint&#39;s URL.
The schema of the JSON file is detected automatically, so we can simply use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; to return the required field.&lt;/p&gt;

&lt;div class=&quot;language-plsql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stargazers_count&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;https://api.github.com/repos/duckdb/duckdb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;output&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#output&quot;&gt;Output&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Both of these commands return the current number of stars of the repository.&lt;/p&gt;
      &lt;h2 id=&quot;performance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#performance&quot;&gt;Performance&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;At this point, you might be wondering about the performance of the DuckDB solutions.
After all, all of our prior examples have only consisted of a few lines, so benchmarking them against each other will not result in any measurable performance differences.
So, let&#39;s switch to the Dutch railway services dataset that we used in a &lt;a href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html&quot;&gt;previous blog post&lt;/a&gt; and formulate a different problem.&lt;/p&gt;

&lt;p&gt;We&#39;ll use the &lt;a href=&quot;https://blobs.duckdb.org/nl-railway/services-2023.csv.gz&quot;&gt;2023 railway services file (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services-2023.csv.gz&lt;/code&gt;)&lt;/a&gt; and count the number of Intercity services that operated in that year.&lt;/p&gt;

&lt;p&gt;In Unix, we can use the &lt;a href=&quot;https://man7.org/linux/man-pages/man1/zcat.1p.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gzcat&lt;/code&gt;&lt;/a&gt; command to decompress the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;csv.gz&lt;/code&gt; file into a pipeline. Then, we can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt; (which is more performant), and top it off with the &lt;a href=&quot;https://man7.org/linux/man-pages/man1/wc.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wc&lt;/code&gt;&lt;/a&gt; command to count the number of lines (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-l&lt;/code&gt;).
In DuckDB, the built-in CSV reader also supports &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html#parameters&quot;&gt;compressed CSV files&lt;/a&gt;, so we can use that without any extra configuration.&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;gzcat &lt;/span&gt;services-2023.csv.gz | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;^[^,]*,[^,]*,Intercity,&#39;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;wc&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;gzcat &lt;/span&gt;services-2023.csv.gz | &lt;span class=&quot;nb&quot;&gt;pcregrep&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;^[^,]*,[^,]*,Intercity,&#39;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;wc&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;SELECT count(*) FROM &#39;services-2023.csv.gz&#39; WHERE &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Service:Type&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; = &#39;Intercity&#39;;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We also test the tools on uncompressed input:&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;gunzip&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-k&lt;/span&gt; services-2023.csv.gz
&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;^[^,]*,[^,]*,Intercity,&#39;&lt;/span&gt; services-2023.csv | &lt;span class=&quot;nb&quot;&gt;wc&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;pcregrep&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;^[^,]*,[^,]*,Intercity,&#39;&lt;/span&gt; services-2023.csv | &lt;span class=&quot;nb&quot;&gt;wc&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;SELECT count(*) FROM &#39;services-2023.csv&#39; WHERE &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Service:Type&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; = &#39;Intercity&#39;;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To reduce the noise in the measurements, we used the &lt;a href=&quot;https://github.com/sharkdp/hyperfine&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hyperfine&lt;/code&gt;&lt;/a&gt; benchmarking tool and took the mean execution time of 10 runs.
The experiments were carried out on a MacBook Pro with a 12-core M2 Pro CPU and 32 GB RAM, running macOS Sonoma 14.5.
To reproduce them, run the &lt;a href=&quot;https://duckdb.org/microbenchmarks/grep-vs-duckdb-microbenchmark.sh&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep-vs-duckdb-microbenchmark.sh&lt;/code&gt; script&lt;/a&gt;.
The following table shows the runtimes of the solutions on both compressed and uncompressed inputs:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Tool&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Runtime (compressed)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Runtime (uncompressed)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;grep 2.6.0-FreeBSD&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20.9 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20.5 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pcregrep 8.45&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.1 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.9 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB 1.0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.2 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.2 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The results show that on compressed input, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; was the slowest, while DuckDB is slightly edged out by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gzcat&lt;/code&gt;+&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt;, which ran in 3.1 seconds compared to DuckDB&#39;s 4.2 seconds.
On uncompressed input, DuckDB can utilize all CPU cores from the get-go (instead of starting with a single-threaded decompression step), allowing it to outperform both &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt; by a significant margin: 2.5× faster than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pcregrep&lt;/code&gt; and more than 15× faster than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;While this example is quite simple, as queries get more complex, there are more opportunities for optimization and larger intermediate dataset may be produced. While both of these can be tackled within a shell script (by manually implementing optimizations and writing the intermediate datasets to disk), these will likely be less efficient than what a DBMS can come up with. Shell scripts implementing complex pipelines can also be very brittle and need to be rethought even for small changes, making the performance advantage of using a database even more significant for more complex problems.&lt;/p&gt;
      &lt;h2 id=&quot;summary&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html#summary&quot;&gt;Summary&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this post, we used DuckDB as a standalone CLI application, and explored its abilities to complement or substitute existing command line tools (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;comm&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;join&lt;/code&gt;, etc.).
While we obviously like DuckDB a lot and prefer to use it in many cases, we also believe Unix tools have their place:
on most systems, they are already pre-installed and a well-chosen toolchain of Unix commands &lt;em&gt;can&lt;/em&gt; be
&lt;a href=&quot;https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html&quot;&gt;fast&lt;/a&gt;,
&lt;a href=&quot;https://pesin.space/posts/2019-07-02/&quot;&gt;efficient&lt;/a&gt;,
and portable (thanks to &lt;a href=&quot;https://en.wikipedia.org/wiki/POSIX#POSIX-oriented_operating_systems&quot;&gt;POSIX-compliance&lt;/a&gt;).
Additionally, they can be very concise for certain problems.
However, to reap their benefits, you will need to learn the syntax and quirks of each tool such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;grep&lt;/code&gt; variants, &lt;a href=&quot;https://man7.org/linux/man-pages/man1/awk.1p.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;awk&lt;/code&gt;&lt;/a&gt;
as well as advanced ones such as &lt;a href=&quot;https://man7.org/linux/man-pages/man1/xargs.1.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xargs&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://www.gnu.org/software/parallel/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parallel&lt;/code&gt;&lt;/a&gt;.
In the meantime, DuckDB&#39;s SQL is easy-to-learn (you likely know quite a bit of it already) and DuckDB handles most of the optimization for you.&lt;/p&gt;

&lt;p&gt;If you have a favorite CLI use case for DuckDB, let us know on social media or submit it to &lt;a href=&quot;https://duckdbsnippets.com/&quot;&gt;DuckDB snippets&lt;/a&gt;. Happy hacking!&lt;/p&gt;

</description><link>https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html</link><guid isPermaLink="false">https://duckdb.org/2024/06/20/cli-data-processing-using-duckdb-as-a-unix-tool.html</guid><pubDate>Thu, 20 Jun 2024 00:00:00 GMT</pubDate><author>Gabor Szarnyas</author></item><item><title>Native Delta Lake Support in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB now has native support for &lt;a href=&quot;https://delta.io/&quot;&gt;Delta Lake&lt;/a&gt;, an open-source lakehouse framework, with the &lt;a href=&quot;https://duckdb.org/docs/extensions/delta&quot;&gt;Delta&lt;/a&gt; extension.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Over the past few months, DuckDB Labs has teamed up with Databricks to add first-party support for Delta Lake in DuckDB using
the new &lt;a href=&quot;https://github.com/delta-incubator/delta-kernel-rs&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-kernel-rs&lt;/code&gt;&lt;/a&gt; project. In this blog post we&#39;ll give you a short
overview of Delta Lake, Delta Kernel and, of course, present the new DuckDB Delta extension.&lt;/p&gt;

&lt;p&gt;If you&#39;re already dearly familiar with Delta Lake and Delta Kernel, or you are just here to know how to boogie, feel free to
&lt;a href=&quot;https://duckdb.org/2024/06/10/delta.html#how-to-use-delta-in-duckdb&quot;&gt;skip to the juicy bits&lt;/a&gt; on how to use the DuckDB with Delta.&lt;/p&gt;
      &lt;h2 id=&quot;intro&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#intro&quot;&gt;Intro&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://delta.io/&quot;&gt;Delta Lake&lt;/a&gt; is an open-source storage framework that enables building a lakehouse architecture. So to understand Delta Lake,
we need to understand what the lakehouse architecture is. Lakehouse is a data management architecture that strives to combine the cost-effectiveness
of cheap object storage with a smart management layer. In simple terms, lakehouse architectures are a collection of files in various formats,
with some additional metadata layers on top. These metadata layers aim to provide extra functionality on top of the raw collection of files
such as ACID transactions, time travel, partition- and schema evolution, statistics, and much more.
What a lakehouse architecture enables, is to run various types of data-intensive applications
such as data analytics and machine learning applications, directly on a vast collection of structured, semi-structured and
unstructured data, without the need for an intermediate data warehousing step. If you&#39;re ready for the deep dive, we recommend reading the
CIDR 2021 paper &lt;a href=&quot;https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf&quot;&gt;&quot;Lakehouse: A New Generation of Open Platforms that Unify Data Warehousing and Advanced Analytics&quot;&lt;/a&gt; by Michael Armbrust et al.
However, if you&#39;re (understandably) hesitant to dive into dense scientific literature, this image sums it up pretty well:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/delta/lakehouse_arch.png&quot; alt=&quot;Image describing lakehouse architecture&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;Lakehouse architecture (image source: &lt;a href=&quot;https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf#page=2&quot;&gt;Armburst et al., CIDR 2021&lt;/a&gt;)&lt;/div&gt;
      &lt;h2 id=&quot;delta-lake&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#delta-lake&quot;&gt;Delta Lake&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now let’s zoom in a little on our star of the show for tonight, Delta Lake. Delta Lake (or simply &quot;Delta&quot;) is currently one of the leading open-source
lakehouse formats, along with &lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Apache Iceberg™&lt;/a&gt; and &lt;a href=&quot;https://hudi.apache.org/&quot;&gt;Apache HUDI™&lt;/a&gt;. The easiest way to get a feeling for what a Delta table is, is to think of
a Delta table as a &quot;collection of Parquet files with some metadata&quot;. With this slight oversimplification in mind, we will now create a
Delta table and examine the files that are created, to improve our understanding. To do this, we&#39;ll set up Python with the packages: &lt;a href=&quot;https://pypi.org/project/duckdb/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://pypi.org/project/pandas/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://pypi.org/project/deltalake/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deltalake&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;pip &lt;/span&gt;install &lt;span class=&quot;nb&quot;&gt;duckdb &lt;/span&gt;pandas deltalake
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, we use DuckDB to create some dataframes with test data, and write that to a Delta table using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deltalake&lt;/code&gt; package:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;deltalake&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DeltaTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;write_deltalake&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT i AS id, i % 2 AS part, &#39;value-&#39; || i AS value FROM range(0, 5) tbl(i)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT i AS id, i % 2 AS part, &#39;value-&#39; || i AS value FROM range(5, 10) tbl(i)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;write_deltalake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./my_delta_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;partition_by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;part&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;write_deltalake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./my_delta_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;partition_by&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;part&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;append&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With this script run, we have created a basic Delta table containing 10 rows, split across two partitions that we added in
two separate steps. To double-check that everything is going to plan, let’s use DuckDB to query the table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;./my_delta_table&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;id&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;part&lt;/th&gt;
      &lt;th&gt;value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td&gt;value-0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;value-1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td&gt;value-2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;value-3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td&gt;value-4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;value-5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td&gt;value-6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;value-7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td&gt;value-8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;value-9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;That looks great! All our expected data is there. Now let’s take a look at what files have actually been created using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tree&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;tree&lt;/span&gt; ./my_delta_table&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;my_delta_table
├── _delta_log
│   ├── 00000000000000000000.json
│   └── 00000000000000000001.json
├── part=0
│   ├── 0-f45132f6-2231-4dbd-aabb-1af29bf8724a-0.parquet
│   └── 1-76c82535-d1e7-4c2f-b700-669019d94a0a-0.parquet
└── part=1
    ├── 0-f45132f6-2231-4dbd-aabb-1af29bf8724a-0.parquet
    └── 1-76c82535-d1e7-4c2f-b700-669019d94a0a-0.parquet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tree&lt;/code&gt; output shows 2 different types of files. While a Delta table can contain various other types of files, these form
the basis of any Delta table.&lt;/p&gt;

&lt;p&gt;Firstly, there are &lt;strong&gt;data files&lt;/strong&gt; in Parquet format. The data files contain all the data that is stored in the table. This is very similar
to how data is stored when DuckDB is used to write &lt;a href=&quot;https://duckdb.org/docs/stable/data/partitioning/partitioned_writes.html&quot;&gt;partitioned Parquet files&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Secondly, there are &lt;strong&gt;delta files&lt;/strong&gt; in JSON format. The Delta files contain a
log of the changes that have been made to the table. By replaying this log, a reader can construct a valid view of the table. To illustrate this, let’s
take a small peek into one of the first Delta log files:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;my_delta_table/_delta_log/00000000000000000000.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;add&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;part=1/0-f45132f6-2231-4dbd-aabb-1af29bf8724a-0.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;partitionValues&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;part&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;add&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;part=0/0-f45132f6-2231-4dbd-aabb-1af29bf8724a-0.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;partitionValues&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;part&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As we can see, this log file contains two &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;add&lt;/code&gt; objects that describe some data being added to respectively the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt; partitions. Note also
that the partition values themselves are stored in these Delta files explicitly, so even though the file structure looks very similar
to a &lt;a href=&quot;https://duckdb.org/docs/stable/data/partitioning/hive_partitioning.html&quot;&gt;Hive-style&lt;/a&gt; partitioning scheme, the folder names are not actually used by Delta internally. Instead, the partition values are read from the metadata.&lt;/p&gt;

&lt;p&gt;Now with this simple example, we&#39;ve shown the basics of how Delta works. For a more thorough understanding of the internals,
we refer to the &lt;a href=&quot;https://github.com/delta-io/delta/blob/master/PROTOCOL.md&quot;&gt;official Delta specification&lt;/a&gt;, which is, by protocol specification standards,
quite easy to read. The official specification describes in detail how Delta handles every detail, from the basics described here to more complex things like checkpointing, deletes, schema evolution, and much more.&lt;/p&gt;
      &lt;h2 id=&quot;implementation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#implementation&quot;&gt;Implementation&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;the-delta-kernel&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#the-delta-kernel&quot;&gt;The Delta Kernel&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Supporting a relatively complex protocol such as Delta, requires significant development and maintenance effort. For this reason, when looking to
add support for such a protocol to an engine, the logical choice would be to look for a ready-to-use library to take care of this. In the case of Delta Lake, we could, for example, opt for the &lt;a href=&quot;https://github.com/delta-io/delta-rs&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-rs&lt;/code&gt; library&lt;/a&gt;.
However, when it comes to implementing a native DuckDB Delta extension, this is problematic:
if we were to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-rs&lt;/code&gt; library for implementing the DuckDB extension, all interaction with the Delta tables would go through the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-rs&lt;/code&gt; library. But remember,
a Delta table is effectively &lt;em&gt;&quot;just a bunch of Parquet files with some metadata&quot;&lt;/em&gt;. Therefore, this would mean that when DuckDB wants to read a Delta table,
the data files will be read by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-rs&lt;/code&gt; Parquet reader, using the&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-rs&lt;/code&gt; filesystem. But that&#39;s annoying: DuckDB already comes shipped with
an &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;excellent Parquet reader&lt;/a&gt;. Also, DuckDB already has support for a &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/hugging_face.html&quot;&gt;variety&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/s3api.html&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/azure.html&quot;&gt;filesystems&lt;/a&gt; with its own &lt;a href=&quot;https://duckdb.org/docs/stable/configuration/secrets_manager.html&quot;&gt;credential management system&lt;/a&gt;. By using a library like
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-rs&lt;/code&gt; for DuckDB&#39;s Delta extension this would actually run into a variety of problems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;increased extension binary size&lt;/li&gt;
  &lt;li&gt;inconsistent user experience between &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;increased maintenance load&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now to solve these problems, we would prefer to have some library that implements &lt;strong&gt;only the Delta protocol&lt;/strong&gt; while letting DuckDB handle all the things it already knows how to handle.&lt;/p&gt;

&lt;p&gt;Fortunately for us, this library exists and it&#39;s called the &lt;a href=&quot;https://delta.io/blog/delta-kernel&quot;&gt;Delta Kernel Project&lt;/a&gt;.
The Delta Kernel is a &quot;set of libraries for building Delta connectors that can read from and write into Delta tables without the need to understand the Delta protocol details&quot;.
This is done by exposing two relatively simple sets of APIs that an engine would implement, as shown in the image below:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/delta/kernel.png&quot; alt=&quot;Diagram showing APIs of delta kernel&quot; width=&quot;665&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/div&gt;

&lt;p&gt;For more details on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-kernel-rs&lt;/code&gt; project, we refer to this &lt;a href=&quot;https://delta.io/blog/delta-kernel/&quot;&gt;excellent blog post&lt;/a&gt;, which goes in-depth into
the internals and design rationale.&lt;/p&gt;

&lt;p&gt;Now while the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-kernel-rs&lt;/code&gt; library is still experimental, it has &lt;a href=&quot;https://github.com/delta-incubator/delta-kernel-rs/releases/tag/v0.1.0&quot;&gt;recently launched its v0.1.0 version&lt;/a&gt;, and already offers a lot of functionality.
Furthermore, because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-kernel-rs&lt;/code&gt; exposes a C/C++ foreign function interface, integrating it into a DuckDB extension has been very straightforward.&lt;/p&gt;
      &lt;h3 id=&quot;duckdb-delta-extension-delta_scan&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#duckdb-delta-extension-delta_scan&quot;&gt;DuckDB Delta Extension &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Now we&#39;re ready to dive into the nitty-gritties of the DuckDB Delta extension internals. To start, the Delta extension
currently implements a single table function: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;. It&#39;s a simple but powerful function that scans a Delta Table.&lt;/p&gt;

&lt;p&gt;To understand how this function is implemented, we first need to establish the four main components involved:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Component&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Delta kernel&lt;/td&gt;
      &lt;td&gt;The &lt;a href=&quot;https://duckdb.org/2024/06/10/delta.html#the-delta-kernel&quot;&gt;delta-kernel-rs&lt;/a&gt; library&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Delta extension&lt;/td&gt;
      &lt;td&gt;DuckDB&#39;s loadable &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta.html&quot;&gt;Delta extension&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet extension&lt;/td&gt;
      &lt;td&gt;DuckDB&#39;s loadable &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;Parquet extension&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB&lt;/td&gt;
      &lt;td&gt;Super cool duck-themed analytical database&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Additionally, we need to understand that there are four main APIs involved:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;API&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FileSystem&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;DuckDB&#39;s API for I/O (for local files, &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/azure.html&quot;&gt;Azure&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/s3api.html&quot;&gt;S3&lt;/a&gt;, etc.)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TableFunction&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;DuckDB&#39;s API for table functions (e.g., &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/guides/file_formats/csv_import.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt;&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MultiFileReader&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;DuckDB&#39;s API for handling multi-file scans&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Delta Kernel C/C++ FFI&lt;/td&gt;
      &lt;td&gt;Delta Kernel &lt;a href=&quot;https://github.com/delta-incubator/delta-kernel-rs&quot;&gt;FFI&lt;/a&gt; for Delta Lake&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we have all the links, let&#39;s tie them all together. When a user runs a query with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; table function,
DuckDB will call into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; function from the Delta extension using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TableFunction&lt;/code&gt; API. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; table function, however,
is actually just an exact copy of the regular &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt; function.
To change the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt; into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt;, it will replace the regular &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MultiFileReader&lt;/code&gt; of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_scan&lt;/code&gt; (which simply scans a list or glob of files), with
a custom &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DeltaMultiFileReader&lt;/code&gt; that will generate a list of files based on the Delta Table metadata. Finally, whenever the Parquet extension requires
any IO, it will call into DuckDB using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FileSystem&lt;/code&gt; API to handle the I/O. This entire interaction is captured in the diagram below.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/delta/delta_ext_overview.svg&quot; alt=&quot;Diagram showing operation of delta_scan&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/div&gt;

&lt;p&gt;In this Diagram, we can see all four components involved in the processing of query containing a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_scan&lt;/code&gt; table function. The arrows represent the communication that occurs
between the components across the four APIs. Now when reading a Delta Table, we can see that the Metadata is handled on the right side going through the Delta Kernel. On the left side
we can see how the Parquet data flows through the Parquet extension.&lt;/p&gt;

&lt;p&gt;While there are obviously some important details missing here, such as the handling of deletion vectors and column mappings, we have now covered the basic concept of the DuckDB
Delta extension. Also, we have demonstrated how the current implementation achieves a very natural logical separation, with component internals being abstracted away by connecting
through clearly defined APIs. In doing so, the implementation achieves the following key properties:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The details of the Delta protocol remain largely opaque to any DuckDB component.&lt;/strong&gt; The only point of contact with the internals of the Delta protocol is the narrow
FFI exposed by the Delta kernel. This is fully handled by the Delta extension, whose only job is to translate this into native DuckDB APIs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Full reuse of existing Parquet scanning logic&lt;/strong&gt; of DuckDB, without any code reuse or compile time dependencies between extensions. Because all interaction between the Delta and Parquet extension is done over DuckDB APIs through the running DuckDB instance, the extensions only interface over the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TableFunction&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MultiFileReader&lt;/code&gt; APIs. This also means that any future optimizations that are made to the Parquet extension will automatically be available in the Delta extension.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;All I/O will go through DuckDB&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FileSystem&lt;/code&gt; API.&lt;/strong&gt; This means that all file systems (&lt;a href=&quot;https://duckdb.org/docs/stable/extensions/azure.html&quot;&gt;Azure&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/s3api.html&quot;&gt;S3&lt;/a&gt;, etc.) that are available to DuckDB, are available to scan with.
This means that any DuckDB file system that can read and list files can be used for Delta. This is also useful in DuckDB-Wasm where custom filesystem implementations are used. &lt;em&gt;Warning&lt;/em&gt;, two small notes need to
be made here. Firstly, currently the DuckDB Delta extension still lets a small part of IO be handled by the Delta kernel through internal filesystem libraries, this is due to the FFI not yet exposing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FileSystem&lt;/code&gt; APIs, but this will change very soon. Secondly, while the architectural
design of the Delta Extension is made with DuckDB-Wasm in mind, the Wasm version of the extension is not yet available.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;how-to-use-delta-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#how-to-use-delta-in-duckdb&quot;&gt;How to Use Delta in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Using the Delta extension in DuckDB is very simple, as it is distributed as one of the core DuckDB extensions, and available for &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/overview.html#autoloading-extensions&quot;&gt;autoloading&lt;/a&gt;.
What this means is that you can simply start DuckDB (using v0.10.3 or higher) and run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;./my_delta_table&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB will automatically install and load the Delta Extension. Then it will query the local Delta table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./my_delta_table&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In case your Delta table lives on S3, there are probably some S3 credentials that you want to set. If these credentials are already in
one of the &lt;a href=&quot;https://github.com/aws/aws-sdk-cpp/blob/main/docs/Credentials_Providers.md&quot;&gt;default places&lt;/a&gt;, such as an environment variable, or in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.aws/credentials&lt;/code&gt; file? Simply run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_s1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PROVIDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;credential_chain&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;some_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;path/to/a/delta/table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Do you prefer remembering your AWS tokens by heart, and would like to type them out? Go with:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_s2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;AKIAIOSFODNN7EXAMPLE&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;REGION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;eu-west-1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;some_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;path/to/a/delta/table&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Do you have multiple Delta tables, with different credentials? No problem, you can use scoped secrets:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_s3&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;AKIAIOSFODNN7EXAMPLE1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;REGION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;eu-west-1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SCOPE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;some_bucket1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_s4&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;AKIAIOSFODNN7EXAMPLE2&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY2&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;REGION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;us-west-1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SCOPE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;some_bucket2&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;some_bucket1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;table1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;some_bucket2&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;table2&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, is your table public, but outside the default AWS region? Make sure you set the region using an empty S3 Secret:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_s5&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;REGION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;eu-west-2&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;delta_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;some_public_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;table1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;current-state-of-the-delta-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#current-state-of-the-delta-extension&quot;&gt;Current State of the Delta Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Currently, the Delta Extension is still considered &lt;strong&gt;experimental&lt;/strong&gt;. This is partly because the Delta extension itself is still very new,
but also because the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-kernel-rs&lt;/code&gt; project it relies on is still experimental. Nevertheless, core Delta scanning features are
already supported by the current version of the Delta extension, such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;All data types&lt;/li&gt;
  &lt;li&gt;Filter and projection pushdown&lt;/li&gt;
  &lt;li&gt;File skipping based on filter pushdown&lt;/li&gt;
  &lt;li&gt;Deletion vectors&lt;/li&gt;
  &lt;li&gt;Partitioned tables&lt;/li&gt;
  &lt;li&gt;Fully parallel scanning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Architecture-wise, the Delta extension is available on the platforms &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;linux_amd64&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;linux_amd64_gcc4&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;osx_amd64&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;osx_arm64&lt;/code&gt;. Support for the remaining core platforms is coming
soon. Additionally, we will continue to work together with Databricks on further improving the Delta Extension to add more features like&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Write support&lt;/li&gt;
  &lt;li&gt;Column mapping&lt;/li&gt;
  &lt;li&gt;Time travel&lt;/li&gt;
  &lt;li&gt;Variant, RowIds&lt;/li&gt;
  &lt;li&gt;Wasm support&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For details and info on newly added features, keep an eye on the Delta extension &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta.html&quot;&gt;docs&lt;/a&gt; and &lt;a href=&quot;https://github.com/duckdb/duckdb-delta&quot;&gt;repository&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/10/delta.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we presented DuckDB&#39;s new Delta extension, enabling easy interaction with
Delta Lake directly from the comfort of your own DuckDB environment. To do so, we demonstrated what the Delta
Lake format looks like by creating a Delta table and analyzing it using DuckDB.&lt;/p&gt;

&lt;p&gt;We want to emphasize the fact that by implementing the Delta extension with the &lt;a href=&quot;https://github.com/delta-incubator/delta-kernel-rs&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta-kernel-rs&lt;/code&gt;&lt;/a&gt; library, both DuckDB and
the Delta extension have been kept relatively simple and largely agnostic to the internals of the Delta protocol.&lt;/p&gt;

&lt;p&gt;We hope you give the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/delta.html&quot;&gt;Delta extension&lt;/a&gt; a try and look forward to any feedback from the community! Also, if you&#39;re attending the
&lt;a href=&quot;https://www.databricks.com/dataaisummit&quot;&gt;2024 Databricks Data + AI Summit&lt;/a&gt; be sure to check out DuckDB co-founder &lt;a href=&quot;https://hannes.muehleisen.org/&quot;&gt;Hannes Mühleisen&#39;s&lt;/a&gt; talk on Thursday during
the keynote and the in-depth &lt;a href=&quot;https://www.databricks.com/dataaisummit/session/delta-lake-meets-duckdb-delta-kernel&quot;&gt;breakout session&lt;/a&gt;, also on Thursday, for more details on the DuckDB–Delta integration.&lt;/p&gt;

</description><link>https://duckdb.org/2024/06/10/delta.html</link><guid isPermaLink="false">https://duckdb.org/2024/06/10/delta.html</guid><pubDate>Mon, 10 Jun 2024 00:00:00 GMT</pubDate><author>Sam Ansmink</author></item><item><title>Announcing DuckDB 1.0.0</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The DuckDB team is &lt;i&gt;very happy&lt;/i&gt; to announce that today we’re releasing DuckDB version 1.0.0, codename “Snow Duck” (anas nivis).&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;.
For the release notes, see the &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v1.0.0&quot;&gt;release page&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/paddling-of-ducks.svg&quot; alt=&quot;Logos of DuckDB releases&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;It has been almost six years since the first source code was written for the project back in 2018, and a &lt;em&gt;lot&lt;/em&gt; has happened since: There are now over 300&amp;nbsp;000 lines of C++ engine code, over 42&amp;nbsp;000 commits and almost 4&amp;nbsp;000 issues were opened and closed again. DuckDB has also gained significant popularity: the project has attracted tens of thousands of stars and followers on GitHub and social media platforms. Download counts are in the millions each month, and download traffic just for extensions is upwards of four terabytes &lt;em&gt;each day&lt;/em&gt;. There are even &lt;a href=&quot;https://www.manning.com/books/duckdb-in-action&quot;&gt;books&lt;/a&gt; &lt;a href=&quot;https://www.amazon.com/Getting-Started-DuckDB-practical-efficiently/dp/1803241004&quot;&gt;being&lt;/a&gt; &lt;a href=&quot;https://www.oreilly.com/library/view/duckdb-up-and/9781098159689/&quot;&gt;written&lt;/a&gt; about DuckDB, and – most importantly – now even &lt;a href=&quot;https://en.wikipedia.org/wiki/DuckDB&quot;&gt;Wikipedia considers DuckDB notable&lt;/a&gt;, albeit barely.&lt;/p&gt;
      &lt;h2 id=&quot;why-now&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/03/announcing-duckdb-100.html#why-now&quot;&gt;Why Now?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Of course, version numbers are somewhat arbitrary and “feely”, despite &lt;a href=&quot;https://semver.org/spec/v2.0.0.html&quot;&gt;attempts&lt;/a&gt; at making them more mechanical. We could have released DuckDB 1.0.0 back in 2018, or we could have waited ten more years. There is never a great moment, because software (with the exception of &lt;a href=&quot;https://x.com/fermatslibrary/status/1740324503308169507&quot;&gt;TeX&lt;/a&gt;) is never “done”. Why choose today?&lt;/p&gt;

&lt;p&gt;Data management systems – even purely analytical ones – are such core components of any application that there is always an implicit contract of trust between their developers and users. Users rely on databases to provide correct query results and to not lose their data. At the same time, system developers need to be aware of their responsibility of not breaking people’s applications willy-nilly. Intuitively, version 1.0.0 means something else for a data management system than it means for an egg timer app (no offense). From the very beginning, we were committed to making DuckDB a reliable base for people to build their applications on. This is also why the 1.0.0 release is named after the non-existent &lt;em&gt;snow duck (anas nivis),&lt;/em&gt; harking back to Apple’s &lt;a href=&quot;https://arstechnica.com/gadgets/2009/08/mac-os-x-10-6/&quot;&gt;Snow Leopard&lt;/a&gt; release some years ago.&lt;/p&gt;

&lt;p&gt;For us, one of the major blockers to releasing 1.0.0 was the storage format. DuckDB has its own custom-built data storage format. This format allows users to manage many (possibly very large) tables in a single file with full transactional semantics and state-of-the-art compression. Of course, designing a new file format is not without its challenges, and we had to make significant changes to the format over time. This led to the suboptimal situation that whenever a new DuckDB version was released, the files created with the old version did not work with the new DuckDB version and had to be manually upgraded. This problem was addressed in v0.10.0 back in February – where we introduced &lt;a href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#backward-compatibility&quot;&gt;backward compatibility and limited forward compatibility for DuckDB’s storage format&lt;/a&gt;. This feature has now been used in the wild for a while without serious issues – providing us with the confidence to offer a guarantee that DuckDB files created with DuckDB 1.0.0 will be compatible with future DuckDB versions.&lt;/p&gt;
      &lt;h2 id=&quot;stability&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/03/announcing-duckdb-100.html#stability&quot;&gt;Stability&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The core theme of the 1.0.0 release is stability. This contrasts it with previous releases where we have had blog posts talk about long lists of new features. Instead, the 1.0.0 release has very limited new features (a &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11677&quot;&gt;few&lt;/a&gt; &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11918&quot;&gt;might&lt;/a&gt; &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11831&quot;&gt;have&lt;/a&gt; &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/11835&quot;&gt;snuck&lt;/a&gt; in). Instead, our focus has been on stability.&lt;/p&gt;

&lt;p&gt;We’ve observed the frankly staggering growth in the amount and breadth of use of DuckDB in the wild, and have not seen an increase in serious issues being reported. Meanwhile, there are thousands of test cases with millions of test queries being run every night. We run loads of microbenchmarks and standardized benchmark suites to spot performance regressions. DuckDB is constantly being tortured by various fuzzers that construct all manners of wild SQL queries to make sure we don’t miss weird corner cases. All told, this has built the necessary confidence in us to release a 1.0.0.&lt;/p&gt;

&lt;p&gt;Another core aspect of stability with the 1.0.0 release is stability across versions. While &lt;a href=&quot;https://xkcd.com/1172/&quot;&gt;never breaking anyone&#39;s workflow is likely impossible&lt;/a&gt;, we plan to be much more careful with user-facing changes going forward. In particular, we plan to focus on providing stability for the SQL dialect, as well as the C API. While we do not guarantee that we will never change semantics in these layers in the future – we will try to provide ample warning when doing so, as well as providing workarounds that allow previously working code to keep on working.&lt;/p&gt;
      &lt;h2 id=&quot;looking-ahead&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/03/announcing-duckdb-100.html#looking-ahead&quot;&gt;Looking ahead&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Unlike many open-source projects, DuckDB also has a healthy long-term funding strategy. &lt;a href=&quot;https://duckdblabs.com/&quot;&gt;DuckDB Labs&lt;/a&gt;, the company that employs DuckDB’s core contributors, has not had any outside investments, and as a result, the company is fully owned by the team. Labs’ business model is to provide consulting and support services for DuckDB, and we’re happy to report that this is going well. With the revenue from contracts, we fund long-term and strategic DuckDB development with a team of almost 20 people. At the same time, the intellectual property in the project is guarded by the independent &lt;a href=&quot;https://duckdb.org/foundation/&quot;&gt;DuckDB Foundation&lt;/a&gt;. This non-profit foundation ensures that DuckDB will be around long-term under the MIT license.&lt;/p&gt;

&lt;p&gt;Regarding long-term plans, there are, of course, many things on the roadmap still. One thing we’re very excited about is the ability to expand the extension environment around DuckDB. Extensions are plug-ins that can add new SQL-level functions, file formats, optimizers, etc. while keeping the DuckDB core mean and lean. There are already an impressive number of third-party extensions to DuckDB, and we’re working hard to streamline the process of building and distributing community-contributed extensions. We think DuckDB can become the basis for the next revolution in data through community extensions connected by a high-performance data fabric accessible through a unified SQL interface.&lt;/p&gt;

&lt;p&gt;Of course, there will be issues found in today’s release. But rest assured, there will be a 1.0.1 release. There will be a 1.1.0. And there might also be a 2.0.0 at some point. We’re in this for the long run, all of us, together. We have the team and the structures and resources to do so.&lt;/p&gt;
      &lt;h2 id=&quot;acknowledgments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/06/03/announcing-duckdb-100.html#acknowledgments&quot;&gt;Acknowledgments&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;First of all, we are very, very grateful to you all. Our massive and heartfelt thanks go to everyone who has contributed code, filed issues or engaged in discussions, promoted DuckDB in their environment, and, of course, all DuckDB users. We could not have done it without you!&lt;/p&gt;

&lt;p&gt;We would also like to thank the &lt;a href=&quot;https://www.cwi.nl/en/groups/database-architectures/&quot;&gt;CWI Database Architectures group&lt;/a&gt; for providing us with the environment and expertise to build DuckDB, the organizations that provided us with research grants early on, the excellent &lt;a href=&quot;https://duckdblabs.com/#collaborators&quot;&gt;customers of DuckDB Labs&lt;/a&gt; that make it all work (especially the early ones), and the generous donors to the &lt;a href=&quot;https://duckdb.org/foundation/&quot;&gt;DuckDB Foundation&lt;/a&gt;. We are particularly grateful to our long-standing Gold sponsors &lt;a href=&quot;https://motherduck.com/&quot;&gt;MotherDuck&lt;/a&gt;, &lt;a href=&quot;https://voltrondata.com/&quot;&gt;Voltron Data&lt;/a&gt; and &lt;a href=&quot;https://posit.co/&quot;&gt;Posit&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Finally, we would like to thank the &lt;a href=&quot;https://duckdblabs.com/#about&quot;&gt;excellent and amazing team at DuckDB Labs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So join us now in being nostalgic, teary-eyed and excited for what’s to come for DuckDB and celebrate the release of DuckDB 1.0.0 with us. We certainly will.&lt;/p&gt;

&lt;p&gt;Mark and Hannes&lt;/p&gt;

&lt;p&gt;PS: We are holding our next community event, &lt;a href=&quot;https://duckdb.org/events/2024/08/15/duckcon5/&quot;&gt;DuckCon #5&lt;/a&gt;, in Seattle on August 15, only a few short weeks from today. Attendance is free. Hope to see you there!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For press inquiries, please reach out to &lt;a href=&quot;https://duckdb.org/cdn-cgi/l/email-protection#deb9bfbcb1ac9ebaabbdb5babcb2bfbcadf0bdb1b3&quot;&gt;Gabor Szarnyas&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

</description><link>https://duckdb.org/2024/06/03/announcing-duckdb-100.html</link><guid isPermaLink="false">https://duckdb.org/2024/06/03/announcing-duckdb-100.html</guid><pubDate>Mon, 03 Jun 2024 00:00:00 GMT</pubDate><author>Mark Raasveldt and Hannes Mühleisen</author></item><item><title>Analyzing Railway Traffic in the Netherlands</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We use a real-world railway dataset to demonstrate some of DuckDB&#39;s key features, including querying different file formats, connecting to remote endpoints, and using advanced SQL features.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The Netherlands, the birthplace of DuckDB, has an area of about 42,000&amp;nbsp;km² with a population of about 18 million people.
The high density of the country is a key factor in its &lt;a href=&quot;https://en.wikipedia.org/wiki/Rail_transport_in_the_Netherlands&quot;&gt;extensive railway network&lt;/a&gt;,
which consists of 3,223 km of tracks and 397 stations.&lt;/p&gt;

&lt;p&gt;Information about this network&#39;s stations and services is available in the form of &lt;a href=&quot;https://www.rijdendetreinen.nl/en/open-data/&quot;&gt;open datasets&lt;/a&gt;.
These high-quality datasets are maintained by the team behind the &lt;a href=&quot;https://www.rijdendetreinen.nl/en/about&quot;&gt;Rijden de Treinen &lt;em&gt;(Are the trains running?)&lt;/em&gt; application&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this post, we&#39;ll demonstrate some of DuckDB&#39;s analytical capabilities on the Dutch railway network dataset.
Unlike most of our other blog posts, this one doesn&#39;t introduce a new feature or release: instead, it demonstrates several existing features using a single domain.
Some of the queries explained in this blog post are shown in simplified form on &lt;a href=&quot;https://duckdb.org/&quot;&gt;DuckDB&#39;s landing page&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;loading-the-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#loading-the-data&quot;&gt;Loading the Data&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;For our initial queries, we&#39;ll use the 2023 &lt;a href=&quot;https://www.rijdendetreinen.nl/en/open-data/train-archive&quot;&gt;railway services dataset&lt;/a&gt;.
To get this dataset, download the &lt;a href=&quot;https://blobs.duckdb.org/nl-railway/services-2023.csv.gz&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services-2023.csv.gz&lt;/code&gt; file&lt;/a&gt; (330 MB) and load it into DuckDB.&lt;/p&gt;

&lt;p&gt;First, start the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;DuckDB command line client&lt;/a&gt; on a persistent database:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb &lt;/span&gt;railway.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, load the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services-2023.csv.gz&lt;/code&gt; file into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services&lt;/code&gt; table.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;services-2023.csv.gz&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Despite the seemingly simple query, there is quite a lot going on here.
Let&#39;s deconstruct the query:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;First, there is no need to explicitly define a schema for our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services&lt;/code&gt; table, nor is it necessary to use a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/copy.html#copy--from&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY ... FROM&lt;/code&gt; statement&lt;/a&gt;.
DuckDB automatically detects that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;services-2023.csv.gz&#39;&lt;/code&gt; refers to a gzip-compressed CSV file, so it calls the &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html#csv-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; function&lt;/a&gt;,
which decompresses the file and infers its schema from its content using the &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/auto_detection.html&quot;&gt;CSV sniffer&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Second, the query makes use of DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html#from-first-syntax&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;-first syntax&lt;/a&gt;, which allows users to omit the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT *&lt;/code&gt; clause.
Hence, the SQL statement &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM &#39;services-2023.csv.gz&#39;;&lt;/code&gt; is a shorthand for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM &#39;services-2023.csv.gz&#39;;&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Third, the query creates a table called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services&lt;/code&gt; and populates it with the result from the CSV reader. This is achieved using a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_table.html#create-table--as-select-ctas&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE TABLE ... AS&lt;/code&gt; statement&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;DuckDB v0.10.3&lt;/a&gt;, loading the dataset takes approximately 5&amp;nbsp;seconds on an M2 MacBook Pro. To check the amount of data loaded, we can run the following query which &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/char.html#print-numbers-with-thousand-separators&quot;&gt;pretty-prints&lt;/a&gt; the number of rows in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services&lt;/code&gt; table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;{:,}&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;num_services&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21,239,393&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that more than 21&amp;nbsp;million train services ran in the Netherlands in 2023.&lt;/p&gt;
      &lt;h2 id=&quot;finding-the-busiest-station-per-month&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#finding-the-busiest-station-per-month&quot;&gt;Finding the Busiest Station per Month&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let&#39;s ask a simple query first: &lt;em&gt;What were the busiest railway stations in the Netherlands in the first 6 months of 2023?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;First, for every month, let&#39;s compute the number of services passing through each station.
To do so, we extract the month from the service&#39;s date using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/datepart.html#monthdate&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;month&lt;/code&gt; function&lt;/a&gt;,
then perform a group-by aggregation with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count(*)&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Service:Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;&quot;Stop:Station name&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that this query showcases a common redundancy in SQL: we list the names of non-aggregated columns in both the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clauses.
Using DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/groupby.html#group-by-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY ALL&lt;/code&gt; feature&lt;/a&gt;, we can eliminate this.
At the same time, let&#39;s also turn this result into an intermediate table called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services_per_month&lt;/code&gt; using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE TABLE ...  AS&lt;/code&gt; statement:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services_per_month&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Service:Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;&quot;Stop:Station name&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To answer the question, we can use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#arg_maxarg-val&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_max(arg, val)&lt;/code&gt; aggregation function&lt;/a&gt;,
which returns the column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg&lt;/code&gt; in the row with the maximum value &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;val&lt;/code&gt;.
We filter on the month and return the results:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;arg_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services_per_month&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;month&lt;/th&gt;
      &lt;th&gt;station&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;num_services&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td&gt;Utrecht Centraal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;34760&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td&gt;Utrecht Centraal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;32300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td&gt;Utrecht Centraal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;37386&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td&gt;Amsterdam Centraal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;33426&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td&gt;Utrecht Centraal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;35383&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td&gt;Utrecht Centraal&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;35632&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Maybe surprisingly, in most months, the busiest railway station is not in Amsterdam but in the country&#39;s 4th largest city, &lt;a href=&quot;https://en.wikipedia.org/wiki/Utrecht&quot;&gt;Utrecht&lt;/a&gt;, thanks to its central geographic location.&lt;/p&gt;
      &lt;h2 id=&quot;finding-the-top-3-busiest-stations-for-each-summer-month&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#finding-the-top-3-busiest-stations-for-each-summer-month&quot;&gt;Finding the Top-3 Busiest Stations for Each Summer Month&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let&#39;s change the question to: &lt;em&gt;Which are the top-3 busiest stations for each summer month?&lt;/em&gt;
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg_max()&lt;/code&gt; function only helps us find the top-1 value but it is not sufficient for finding top-k results.&lt;/p&gt;
      &lt;h3 id=&quot;using-a-window-function-over&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#using-a-window-function-over&quot;&gt;Using a Window Function (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt;)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB has extensive support for SQL features, including &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html&quot;&gt;window functions&lt;/a&gt; and we can use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html#rank&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rank()&lt;/code&gt; function&lt;/a&gt; to find top-k values.
Addtionally, we use &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/date.html#make_dateyear-month-day&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make_date&lt;/code&gt;&lt;/a&gt; to reconstruct the date, &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/timestamptz.html#strftimetimestamptz-format&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strftime&lt;/code&gt;&lt;/a&gt; to turn it into the month&#39;s name and &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#array_aggarg&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_agg&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top3_stations&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;strftime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;make_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%B&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services_per_month&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This gives the following result:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;month&lt;/th&gt;
      &lt;th&gt;month_name&lt;/th&gt;
      &lt;th&gt;top3_stations&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td&gt;June&lt;/td&gt;
      &lt;td&gt;[Utrecht Centraal, Amsterdam Centraal, Schiphol Airport]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td&gt;July&lt;/td&gt;
      &lt;td&gt;[Utrecht Centraal, Amsterdam Centraal, Schiphol Airport]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td&gt;August&lt;/td&gt;
      &lt;td&gt;[Utrecht Centraal, Amsterdam Centraal, Amsterdam Sloterdijk]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that the top 3 spots are shared between four stations: Utrecht Centraal, Amsterdam Centraal, Schiphol Airport, and Amsterdam Sloterdijk.&lt;/p&gt;
      &lt;h3 id=&quot;using-the-max_byarg-val-n-function&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#using-the-max_byarg-val-n-function&quot;&gt;Using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by(arg, val, n)&lt;/code&gt; Function&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Starting with DuckDB version 1.1.0, you can use a variant of the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#max_byarg-val-n&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_by&lt;/code&gt; function&lt;/a&gt; that accepts a third parameter, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;, for the number of rows.
The resulting code is more concise and faster than the one using a window function.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;strftime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;make_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%B&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services_per_month&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;directly-querying-parquet-files-through-https-or-s3&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#directly-querying-parquet-files-through-https-or-s3&quot;&gt;Directly Querying Parquet Files through HTTPS or S3&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB supports querying remote files, including CSV and Parquet, via &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html&quot;&gt;the HTTP(S) protocol and the S3 API&lt;/a&gt;.
For example, we can run the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Service:Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Stop:Station name&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/nl-railway/services-2023.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It returns the following result:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Service:Date&lt;/th&gt;
      &lt;th&gt;Stop:Station name&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;2023-01-01&lt;/td&gt;
      &lt;td&gt;Rotterdam Centraal&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2023-01-01&lt;/td&gt;
      &lt;td&gt;Delft&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2023-01-01&lt;/td&gt;
      &lt;td&gt;Den Haag HS&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Using the remote Parquet file, the query for answering &lt;a href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#finding-the-top-3-busiest-stations-for-each-summer-month&quot;&gt;&lt;em&gt;Which are the top-3 busiest stations for each summer month?&lt;/em&gt;&lt;/a&gt; can be run directly on a remote Parquet file without creating any local tables.
To do this, we can define the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;services_per_month&lt;/code&gt; table as a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/with.html&quot;&gt;common table expression in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH&lt;/code&gt; clause&lt;/a&gt;.
The rest of the query remains the same:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services_per_month&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Service:Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;&quot;Stop:Station name&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/nl-railway/services-2023.parquet&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top3_stations&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;strftime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;make_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2023&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%B&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;num_services&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;services_per_month&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query yields the same result as the query above, and completes (depending on the network speed) in about 1–2 seconds.
This speed is possible because DuckDB doesn&#39;t need to download the whole Parquet file to evaluate the query:
while the file size is 309&amp;nbsp;MB, it only uses about 20&amp;nbsp;MB of network traffic, approximately 6% of the total file size.&lt;/p&gt;

&lt;p&gt;The reduction in network traffic is possible because of &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html#partial-reading&quot;&gt;partial reading&lt;/a&gt; along both the columns and the rows of the data.
First, Parquet&#39;s columnar layout allows the reader to only access the required columns.
Second, the &lt;a href=&quot;https://duckdb.org/docs/stable/guides/performance/indexing.html#zonemaps&quot;&gt;zonemaps&lt;/a&gt; available in the Parquet file&#39;s metadata allow the filter pushdown optimization (e.g., the reader only fetches &lt;a href=&quot;https://duckdb.org/docs/stable/internals/storage.html#row-groups&quot;&gt;row groups&lt;/a&gt; with dates in the summer months).
Both of these optimizations are implemented via &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Range_requests&quot;&gt;HTTP range requests&lt;/a&gt;,
saving considerable traffic and time when running queries on remote Parquet files.&lt;/p&gt;
      &lt;h2 id=&quot;largest-distance-between-train-stations-in-the-netherlands&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#largest-distance-between-train-stations-in-the-netherlands&quot;&gt;Largest Distance between Train Stations in the Netherlands&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let&#39;s answer the following question: &lt;em&gt;Which two train stations in the Netherlands have the largest distance between them when traveling via rail?&lt;/em&gt;
For this, we&#39;ll use two datasets.
The first, &lt;a href=&quot;https://blobs.duckdb.org/data/stations-2022-01.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stations-2022-01.csv&lt;/code&gt;&lt;/a&gt;, contains information on the &lt;a href=&quot;https://www.rijdendetreinen.nl/en/open-data/stations&quot;&gt;railway stations&lt;/a&gt; (station name, country, etc.). We can simply load and query this dataset as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/stations-2022-01.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name_short&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name_long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;%.2f&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geo_lat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;%.2f&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geo_lng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;longitude&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;id&lt;/th&gt;
      &lt;th&gt;name_short&lt;/th&gt;
      &lt;th&gt;name_long&lt;/th&gt;
      &lt;th&gt;country&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;latitude&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;longitude&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;266&lt;/td&gt;
      &lt;td&gt;Den Bosch&lt;/td&gt;
      &lt;td&gt;&#39;s-Hertogenbosch&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;51.69&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;269&lt;/td&gt;
      &lt;td&gt;Dn Bosch O&lt;/td&gt;
      &lt;td&gt;&#39;s-Hertogenbosch Oost&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;51.70&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;227&lt;/td&gt;
      &lt;td&gt;&#39;t Harde&lt;/td&gt;
      &lt;td&gt;&#39;t Harde&lt;/td&gt;
      &lt;td&gt;NL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;52.41&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.89&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td&gt;Aachen&lt;/td&gt;
      &lt;td&gt;Aachen Hbf&lt;/td&gt;
      &lt;td&gt;D&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;50.77&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.09&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;818&lt;/td&gt;
      &lt;td&gt;Aachen W&lt;/td&gt;
      &lt;td&gt;Aachen West&lt;/td&gt;
      &lt;td&gt;D&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;50.78&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.07&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The second dataset, &lt;a href=&quot;https://blobs.duckdb.org/data/tariff-distances-2022-01.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tariff-distances-2022-01.csv&lt;/code&gt;&lt;/a&gt;, contains the &lt;a href=&quot;https://www.rijdendetreinen.nl/en/open-data/station-distances&quot;&gt;station distances&lt;/a&gt;. The distances are defined as the shortest route on the railway network and they are used to calculate the tariffs for ticket.
Let&#39;s peek into this file:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 9 tariff-distances-2022-01.csv | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;, &lt;span class=&quot;nt&quot;&gt;-f1-9&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;Station,AC,AH,AHP,AHPR,AHZ,AKL,AKM,ALM
AC,XXX,82,83,85,90,71,188,32
AH,82,XXX,1,3,8,77,153,98
AHP,83,1,XXX,2,9,78,152,99
AHPR,85,3,2,XXX,11,80,150,101
AHZ,90,8,9,11,XXX,69,161,106
AKL,71,77,78,80,69,XXX,211,96
AKM,188,153,152,150,161,211,XXX,158
ALM,32,98,99,101,106,96,158,XXX
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can see that the distances are encoded as a matrix with the diagonal entries set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;XXX&lt;/code&gt;.
As explained in the &lt;a href=&quot;https://www.rijdendetreinen.nl/en/open-data/station-distances#description&quot;&gt;dataset&#39;s description&lt;/a&gt;, this string implies that the two stations are the same station.
If we just load the values as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;XXX&lt;/code&gt;, the CSV reader will assume that all columns have the type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; instead of numeric values.
While this can be cleaned up later, it&#39;s a lot easier to avoid this problem altogether.
To do so, we use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; function and set the &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html#parameters&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nullstr&lt;/code&gt; parameter&lt;/a&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;XXX&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/tariff-distances-2022-01.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;nullstr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;XXX&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To make the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values visible in the command line output, we set the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/dot_commands.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.nullvalue&lt;/code&gt; dot command&lt;/a&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nullvalue&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, using the &lt;a href=&quot;https://duckdb.org/docs/stable/guides/meta/describe.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESCRIBE&lt;/code&gt; statement&lt;/a&gt;, we can confirm that DuckDB has inferred the column correctly as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;DESCRIBE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;column_name&lt;/th&gt;
      &lt;th&gt;column_type&lt;/th&gt;
      &lt;th&gt;null&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;default&lt;/th&gt;
      &lt;th&gt;extra&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Station&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AC&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AH&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AHP&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AHPR&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;YES&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To show the first 9 columns, we can run the following query with the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/select.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#2&lt;/code&gt;, etc. column indexes in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Station&lt;/th&gt;
      &lt;th&gt;AC&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;AH&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;AHP&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;AHPR&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;AHZ&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;AKL&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;AKM&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;ALM&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AC&lt;/td&gt;
      &lt;td&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;82&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;83&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;85&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;71&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;188&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AH&lt;/td&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;77&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;153&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;98&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AHP&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;78&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;152&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;99&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AHPR&lt;/td&gt;
      &lt;td&gt;85&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;150&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;101&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AHZ&lt;/td&gt;
      &lt;td&gt;90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;69&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;161&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;106&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AKL&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;77&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;78&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;69&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;211&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;96&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AKM&lt;/td&gt;
      &lt;td&gt;188&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;153&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;152&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;150&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;161&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;211&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;158&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ALM&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;98&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;99&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;101&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;106&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;96&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;158&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that the data was loaded correctly but the wide table format is a bit unwieldy for further processing:
to query for pairs of stations, we need to first turn it into a long table using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/unpivot.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt;&lt;/a&gt; statement.
Naïvely, we would write something like the following:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances_long&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;UNPIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AHP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, we have almost 400 stations, so spelling out their names would be quite tedious.
Fortunately, DuckDB has a trick to help with this:
the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#columns-expression&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS(*)&lt;/code&gt; expression&lt;/a&gt; lists all columns
and its optional &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; clause can remove given column names from the list.
Therefore, the expression &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS(* EXCLUDE station)&lt;/code&gt; lists all column names except &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;station&lt;/code&gt;, precisely what we need for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances_long&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;UNPIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other_station&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This results in the following table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other_station&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances_long&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Station&lt;/th&gt;
      &lt;th&gt;other_station&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;distance&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AC&lt;/td&gt;
      &lt;td&gt;AH&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;82&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AC&lt;/td&gt;
      &lt;td&gt;AHP&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AC&lt;/td&gt;
      &lt;td&gt;AHPR&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;85&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we can join the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;distances_long&lt;/code&gt; table on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stations&lt;/code&gt; table along both the start and end stations,
then filter for stations which are located in the Netherlands.
We introduce symmetry breaking (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;station &amp;lt; other_station&lt;/code&gt;) to ensure that the same pair of stations only occurs once in the output.
Finally, we select the top-3 results:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name_long&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name_long&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;distances_long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances_long&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances_long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;station&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stations&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distances_long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other_station&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;country&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NL&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;country&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NL&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other_station&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The results show that there are pairs of train stations, which are at least 425 km away – quite the distance for such a small country!&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;station1&lt;/th&gt;
      &lt;th&gt;station2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;distance&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Eemshaven&lt;/td&gt;
      &lt;td&gt;Vlissingen&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;426&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Eemshaven&lt;/td&gt;
      &lt;td&gt;Vlissingen Souburg&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;425&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bad Nieuweschans&lt;/td&gt;
      &lt;td&gt;Vlissingen&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;425&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this post, we demonstrated some of DuckDB&#39;s key features,
including
&lt;a href=&quot;https://duckdb.org/docs/stable/data/overview.html&quot;&gt;automatic detection of formats based on filenames&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html&quot;&gt;auto-inferencing the schema of CSV files&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html&quot;&gt;direct Parquet querying&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html&quot;&gt;remote querying&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/2021/10/13/windowing.html&quot;&gt;window functions&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/unpivot.html&quot;&gt;unpivot&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;several friendly SQL features&lt;/a&gt; (such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;-first, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY ALL&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS(*)&lt;/code&gt;),
and so on.
The combination of these allows for formulating queries using different file formats (CSV, Parquet), data sources (local, HTTPS, S3), and SQL features.
This helps users answer queries quickly and efficiently.&lt;/p&gt;

&lt;p&gt;In the next installment, we&#39;ll take a look at
temporal data using &lt;a href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html&quot;&gt;AsOf joins&lt;/a&gt;
and
geospatial data using the DuckDB &lt;a href=&quot;https://duckdb.org/2023/04/28/spatial.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spatial&lt;/code&gt; extension&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html</link><guid isPermaLink="false">https://duckdb.org/2024/05/31/analyzing-railway-traffic-in-the-netherlands.html</guid><pubDate>Fri, 31 May 2024 00:00:00 GMT</pubDate><author>Gabor Szarnyas</author></item><item><title>Access 150k+ Datasets from Hugging Face with DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB can now read data from &lt;a href=&quot;https://huggingface.co/&quot;&gt;Hugging Face&lt;/a&gt; via the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hf://&lt;/code&gt; prefix.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;We are excited to announce that we added support for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hf://&lt;/code&gt; paths in DuckDB, providing access to more than 150,000 datasets for artificial intelligence. We worked with Hugging Face to democratize the access, manipulation, and exploration of datasets used to train and evaluate AI models.&lt;/p&gt;
      &lt;h2 id=&quot;dataset-repositories&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html#dataset-repositories&quot;&gt;Dataset Repositories&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://huggingface.co/&quot;&gt;Hugging Face&lt;/a&gt; is a popular central platform where users can store, share, and collaborate on machine learning models, datasets, and other resources.&lt;/p&gt;

&lt;p&gt;A dataset typically includes the following content:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;README&lt;/code&gt; file: This plain text file provides an overview of the repository and its contents. It often describes the purpose, usage, and specific requirements or dependencies.&lt;/li&gt;
  &lt;li&gt;Data files: Depending on the type of repository, it can include data files like CSV, Parquet, JSONL, etc. These are the core components of the repository.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A typical repository looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/hugging-face-example-repository.png&quot; alt=&quot;Hugging face repository&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;read-using-hf-paths&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html#read-using-hf-paths&quot;&gt;Read Using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hf://&lt;/code&gt; Paths&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;You often need to read files in various formats (such as CSV, JSONL, and Parquet) when working with data. As of version v0.10.3, DuckDB has native support for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hf://&lt;/code&gt; paths as part of the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; extension&lt;/a&gt;, allowing easy access to all these formats.&lt;/p&gt;

&lt;p&gt;Now, it is possible to query them using the URL pattern below:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hf://datasets/⟨my_username⟩/⟨my_dataset⟩/⟨path_to_file⟩
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For example, to read a CSV file, you can use the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/datasets-examples/doc-formats-csv-1/data.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;datasets-examples&lt;/code&gt; is the name of the user/organization&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;doc-formats-csv-1&lt;/code&gt; is the name of the dataset repository&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data.csv&lt;/code&gt; is the file path in the repository&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The result of the query is:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;kind&lt;/th&gt;
      &lt;th&gt;sound&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;dog&lt;/td&gt;
      &lt;td&gt;woof&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;cat&lt;/td&gt;
      &lt;td&gt;meow&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pokemon&lt;/td&gt;
      &lt;td&gt;pika&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;human&lt;/td&gt;
      &lt;td&gt;hello&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To read a JSONL file, you can run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/datasets-examples/doc-formats-jsonl-1/data.jsonl&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, for reading a Parquet file, use the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/datasets-examples/doc-formats-parquet-1/data/train-00000-of-00001.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Each of these commands reads the data from the specified file format and displays it in a structured tabular format. Choose the appropriate command based on the file format you are working with.&lt;/p&gt;
      &lt;h2 id=&quot;creating-a-local-table&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html#creating-a-local-table&quot;&gt;Creating a Local Table&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To avoid accessing the remote endpoint for every query, you can save the data in a DuckDB table by running a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_table.html#create-table--as-select-ctas&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE TABLE ... AS&lt;/code&gt; command&lt;/a&gt;. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/datasets-examples/doc-formats-csv-1/data.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, simply query the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data&lt;/code&gt; table as follows:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;multiple-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html#multiple-files&quot;&gt;Multiple Files&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;You might need to query multiple files simultaneously when working with large datasets. Let&#39;s see a quick sample using the &lt;a href=&quot;https://huggingface.co/datasets/cais/mmlu&quot;&gt;cais/mmlu&lt;/a&gt; (Measuring Massive Multitask Language Understanding) dataset. This dataset captures a test consisting of multiple-choice questions from various branches of knowledge. It covers 57 tasks, including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, AI models must possess extensive world knowledge and problem-solving ability.&lt;/p&gt;

&lt;p&gt;First, let&#39;s count the number of rows in individual files. To get the row count from a single file in the cais/mmlu dataset, use the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/cais/mmlu/astronomy/dev-00000-of-00001.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Similarly, for another file (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test-00000-of-00001.parquet&lt;/code&gt;) in the same dataset, we can run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/cais/mmlu/astronomy/test-00000-of-00001.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;152&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To query all files under a specific format, you can use a &lt;a href=&quot;https://duckdb.org/docs/stable/data/multiple_files/overview.html#multi-file-reads-and-globs&quot;&gt;glob pattern&lt;/a&gt;. Here’s how you can count the rows in all files that match the pattern &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*.parquet&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/cais/mmlu/astronomy/*.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;173&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;By using glob patterns, you can efficiently handle large datasets and perform comprehensive queries across multiple files, simplifying your data inspections and processing tasks.
Here, you can see how you can look for questions that contain the word “planet” in astronomy:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/cais/mmlu/astronomy/*.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%planet%&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;And see some examples:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/cais/mmlu/astronomy/*.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%planet%&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;question&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Why isn&#39;t there a planet where the asteroid belt is located?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;On which planet in our solar system can you find the Great Red Spot?&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;The lithosphere of a planet is the layer that consists of&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;versioning-and-revisions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html#versioning-and-revisions&quot;&gt;Versioning and Revisions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In Hugging Face repositories, dataset versions or revisions are different dataset updates. Each version is a snapshot at a specific time, allowing you to track changes and improvements. In git terms, it can be understood as a branch or specific commit.&lt;/p&gt;

&lt;p&gt;You can query different dataset versions/revisions by using the following URL:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;my_username&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;my_dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;my_branch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;path_to_file&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;hf://datasets/datasets-examples/doc-formats-csv-1@~parquet/**/*.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;kind&lt;/th&gt;
      &lt;th&gt;sound&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;dog&lt;/td&gt;
      &lt;td&gt;woof&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;cat&lt;/td&gt;
      &lt;td&gt;meow&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pokemon&lt;/td&gt;
      &lt;td&gt;pika&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;human&lt;/td&gt;
      &lt;td&gt;hello&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The previous query will read all parquet files under the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~parquet&lt;/code&gt; revision. This is a special branch where Hugging Face automatically generates the Parquet files of every dataset to enable efficient scanning.&lt;/p&gt;
      &lt;h2 id=&quot;authentication&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html#authentication&quot;&gt;Authentication&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Configure your Hugging Face Token in the DuckDB Secrets Manager to access private or gated datasets.
First, visit &lt;a href=&quot;https://huggingface.co/settings/tokens&quot;&gt;Hugging Face Settings – Tokens&lt;/a&gt; to obtain your access token.
Second, set it in your DuckDB session using DuckDB’s &lt;a href=&quot;https://duckdb.org/docs/stable/configuration/secrets_manager.html&quot;&gt;Secrets Manager&lt;/a&gt;. DuckDB supports two providers for managing secrets:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CONFIG&lt;/code&gt;: The user must pass all configuration information into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE SECRET&lt;/code&gt; statement. To create a secret using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CONFIG&lt;/code&gt; provider, use the following command:&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hf_token&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;huggingface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;TOKEN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;your_hf_token&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;credential_chain&lt;/code&gt;: Automatically tries to fetch credentials. For the Hugging Face token, it will try to get it from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.cache/huggingface/token&lt;/code&gt;. To create a secret using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;credential_chain&lt;/code&gt; provider, use the following command:&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hf_token&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;huggingface&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;PROVIDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;credential_chain&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The integration of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hf://&lt;/code&gt; paths in DuckDB significantly streamlines accessing and querying over 150,000 datasets available on Hugging Face. This feature democratizes data manipulation and exploration, making it easier for users to interact with various file formats such as CSV, JSON,  JSONL, and Parquet. By utilizing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hf://&lt;/code&gt; paths, users can execute complex queries, efficiently handle large datasets, and harness the extensive resources of Hugging Face repositories.&lt;/p&gt;

&lt;p&gt;The integration supports seamless access to individual files, multiple files using glob patterns, and different dataset versions. DuckDB&#39;s robust capabilities ensure a flexible and streamlined data processing experience. This integration is a significant leap forward in making AI dataset access more accessible and efficient for researchers and developers, fostering innovation and accelerating progress in machine learning.&lt;/p&gt;

&lt;p&gt;Want to learn more about leveraging DuckDB with Hugging Face datasets? Explore the &lt;a href=&quot;https://huggingface.co/docs/hub/datasets-duckdb&quot;&gt;detailed guide&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html</link><guid isPermaLink="false">https://duckdb.org/2024/05/29/access-150k-plus-datasets-from-hugging-face-with-duckdb.html</guid><pubDate>Wed, 29 May 2024 00:00:00 GMT</pubDate><author>The Hugging Face and DuckDB teams</author></item><item><title>Vector Similarity Search in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: This blog post shows a preview of DuckDB&#39;s new &lt;a href=&quot;https://duckdb.org/docs/extensions/vss&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension&lt;/a&gt;, which introduces support for HNSW (Hierarchical Navigable Small Worlds) indexes to accelerate vector similarity search.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;In DuckDB v0.10.0, we introduced the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/array.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt; data type&lt;/a&gt;, which stores fixed-sized lists, to complement the existing variable-size &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/list.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; data type&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The initial motivation for adding this data type was to provide optimized operations for lists that can utilize the positional semantics of their child elements and avoid branching as all lists have the same length. Think e.g., the sort of array manipulations you&#39;d do in NumPy: stacking, shifting, multiplying – you name it. Additionally, we wanted to improve our interoperability with Apache Arrow, as previously Arrow&#39;s fixed-size list types would be converted to regular variable-size lists when ingested into DuckDB, losing some type information.&lt;/p&gt;

&lt;p&gt;However, as the hype for &lt;strong&gt;vector embeddings&lt;/strong&gt; and &lt;strong&gt;semantic similarity search&lt;/strong&gt; was growing, we also snuck in a couple of distance metric functions for this new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt; type:
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/array.html#array_distancearray1-array2&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_distance&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/array.html#array_negative_inner_productarray1-array2&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_negative_inner_product&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/array.html#array_cosine_distancearray1-array2&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_distance&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you&#39;re one of today&#39;s &lt;a href=&quot;https://xkcd.com/1053/&quot;&gt;lucky 10,000&lt;/a&gt; and haven&#39;t heard of word embeddings or vector search, the short version is that it&#39;s a technique used to represent documents, images, entities – &lt;em&gt;data&lt;/em&gt; as high-dimensional &lt;em&gt;vectors&lt;/em&gt; and then search for &lt;em&gt;similar&lt;/em&gt; vectors in a vector space, using some sort of mathematical &quot;distance&quot; expression to measure similarity. This is used in a wide range of applications, from natural language processing to recommendation systems and image recognition, and has recently seen a surge in popularity due to the advent of generative AI and availability of pre-trained models.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This got the community really excited! While we (DuckDB Labs) initially went on record saying that we would not be adding a vector similarity search index to DuckDB as we deemed it to be too far out of scope, we were very interested in supporting custom indexes through extensions in general. Shoot, I&#39;ve been &lt;em&gt;personally&lt;/em&gt; nagging on about wanting to plug-in an &quot;R-Tree&quot; index since the inception of DuckDBs &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;spatial extension&lt;/a&gt;! So when one of our client projects evolved into creating a proof-of-concept custom &quot;HNSW&quot; index extension, we said that we&#39;d give it a shot. And… well, one thing led to another.&lt;/p&gt;

&lt;p&gt;Fast forward to now and we&#39;re happy to announce the availability of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; vector similarity search extension for DuckDB! While some may say we&#39;re late to the vector search party, &lt;a href=&quot;https://www.gartner.com/en/newsroom/press-releases/2023-10-11-gartner-says-more-than-80-percent-of-enterprises-will-have-used-generative-ai-apis-or-deployed-generative-ai-enabled-applications-by-2026&quot;&gt;we&#39;d like to think the party is just getting started!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alright, so what&#39;s in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt;?&lt;/p&gt;
      &lt;h2 id=&quot;the-vector-similarity-search-vss-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/03/vector-similarity-search-vss.html#the-vector-similarity-search-vss-extension&quot;&gt;The Vector Similarity Search (VSS) Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;On the surface, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; seems like a comparatively small DuckDB extension. It does not provide any new data types, scalar functions or copy functions, but rather a single new index type: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; (&lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_Navigable_Small_World_graphs&quot;&gt;Hierarchical Navigable Small Worlds&lt;/a&gt;), which is a graph-based index structure that is particularly well-suited for high-dimensional vector similarity search.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Create a table with an array column&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Create an HNSW index on the column&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;HNSW&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This index type can&#39;t be used to enforce constraints or uniqueness like the built-in &lt;a href=&quot;https://duckdb.org/docs/stable/sql/indexes.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ART&lt;/code&gt; index&lt;/a&gt;, and can&#39;t be used to speed up joins or index regular columns either. Instead, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index is only applicable to columns of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt; type containing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt; elements and will only be used to accelerate queries calculating the &quot;distance&quot; between a constant &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt; and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt;&#39;s in the indexed column, ordered by the resulting distance and returning the top-n results. That is, queries of the form:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;will have their logical plan optimized to become a projection over a new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index scan operator, removing the limit and sort altogether. We can verify this by checking the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN&lt;/code&gt; output:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;EXPLAIN&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│         PROJECTION        │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│             #0            │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│         PROJECTION        │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│            vec            │
│array_distance(vec, [1.0, 2│
│         .0, 3.0])         │
└─────────────┬─────────────┘
┌─────────────┴─────────────┐
│      HNSW_INDEX_SCAN      │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│   t1 (HNSW INDEX SCAN :   │
│            idx)           │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│            vec            │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│           EC: 3           │
└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can pass the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index creation statement a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;metric&lt;/code&gt; parameter to decide what kind of distance metric to use. The supported metrics are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l2sq&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cosine&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inner_product&lt;/code&gt;, matching the three built-in distance functions: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_distance&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_distance&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_negative_inner_product&lt;/code&gt;.
The default is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l2sq&lt;/code&gt;, which uses Euclidean distance (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_distance&lt;/code&gt;):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2sq_idx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;HNSW&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;l2sq&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To use cosine distance (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_distance&lt;/code&gt;):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos_idx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;HNSW&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;cosine&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To use inner product (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_negative_inner_product&lt;/code&gt;):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip_idx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;HNSW&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;ip&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;implementation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/03/vector-similarity-search-vss.html#implementation&quot;&gt;Implementation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension is based on the &lt;a href=&quot;https://github.com/unum-cloud/usearch&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;usearch&lt;/code&gt;&lt;/a&gt; library, which provides a flexible C++ implementation of the HNSW index data structure boasting very impressive performance benchmarks. While we currently only use a subset of all the functionality and tuning options provided by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;usearch&lt;/code&gt;, we&#39;re excited to explore how we can leverage more of its features in the future. So far we&#39;re mostly happy that it aligns so nicely with DuckDB&#39;s development ethos. Much like DuckDB itself, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;usearch&lt;/code&gt; is written in portable C++11 with no external dependencies and released under a permissive license, making it super smooth to integrate into our extension build and distribution pipeline.&lt;/p&gt;
      &lt;h2 id=&quot;limitations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/03/vector-similarity-search-vss.html#limitations&quot;&gt;Limitations&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The big limitation as of now is that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index can only be created in in-memory databases, unless the &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hnsw_enable_experimental_persistence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ge&quot;&gt;bool&lt;/span&gt;&lt;/code&gt; configuration parameter is set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt;. If this parameter is not set, any attempt to create an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index in a disk-backed database will result in an error message, but if the parameter is set, the index will not only be created in memory, but also persisted to disk as part of the DuckDB database file during checkpointing. After restarting or loading a database file with a persisted &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index, the index will be lazily loaded back into memory whenever the associated table is first accessed, which is significantly faster than having to re-create the index from scratch.&lt;/p&gt;

&lt;p&gt;The reasoning for locking this feature behind an experimental flag is that we still have some known issues related to persistence of custom indexes that we want to address before enabling it by default. In particular, WAL recovery is not yet properly implemented for custom indexes, meaning that if a crash occurs or the database is shut down unexpectedly while there are uncommited changes to a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt;-indexed table, you can end up with data loss or corruption of the index. While it is technically possible to recover from a unexpected shutdown manually by first starting DuckDB separately, loading the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension and then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt;ing the database file, which ensures that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index functionality is available during WAL-playback, you should not rely on this for production workloads.&lt;/p&gt;

&lt;p&gt;We&#39;re actively working on addressing this and other issues related to index persistence, which will hopefully make it into &lt;a href=&quot;https://duckdb.org/docs/stable/dev/release_calendar.html#upcoming-releases&quot;&gt;DuckDB v0.10.3&lt;/a&gt;, but for now we recommend using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index in in-memory databases only.&lt;/p&gt;

&lt;p&gt;At runtime however, much like the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ART&lt;/code&gt; the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index must be able to fit into RAM in its entirety, and the memory allocated by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; at runtime is allocated &quot;outside&quot; of the DuckDB memory management system, meaning that it wont respect DuckDB&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;memory_limit&lt;/code&gt; configuration parameter.&lt;/p&gt;

&lt;p&gt;Another current limitation with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HNSW&lt;/code&gt; index so far are that it only supports the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt; (a 32-bit, single-precision floating point) type for the array elements and only distance metrics corresponding to the three built in distance functions, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_distance&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_negative_inner_product&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_distance&lt;/code&gt;. But this is also something we&#39;re looking to expand upon in the near future as it is much less of a technical limitation and more of a &quot;we haven&#39;t gotten around to it yet&quot; limitation.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/05/03/vector-similarity-search-vss.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension for DuckDB is a new extension that adds support for creating HNSW indexes on fixed-size list columns in DuckDB, accelerating vector similarity search queries. The extension can currently be installed on DuckDB v0.10.2 on all supported platforms (including Wasm!) by running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSTALL vss; LOAD vss&lt;/code&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension treads new ground for DuckDB extensions by providing a custom index type and we&#39;re excited to refine and expand on this functionality going forward.&lt;/p&gt;

&lt;p&gt;While we&#39;re still working on addressing some of the limitations above, particularly those related to persistence (and performance), we still really want to share this early version the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension as we believe this will open up a lot of cool opportunities for the community. So make sure to check out the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/vss.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension documentation&lt;/a&gt; for more information on how to work with this extension!&lt;/p&gt;

&lt;p&gt;This work was made possible by the sponsorship of a DuckDB Labs customer! If you are interested in similar work for specific capabilities, please reach out to &lt;a href=&quot;https://duckdblabs.com/&quot;&gt;DuckDB Labs&lt;/a&gt;. Alternatively, we&#39;re happy to welcome contributors! Please reach out to the DuckDB Labs team over on Discord or on the &lt;a href=&quot;https://github.com/duckdb/duckdb-vss&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vss&lt;/code&gt; extension GitHub repository&lt;/a&gt; to keep up with the latest developments.&lt;/p&gt;

</description><link>https://duckdb.org/2024/05/03/vector-similarity-search-vss.html</link><guid isPermaLink="false">https://duckdb.org/2024/05/03/vector-similarity-search-vss.html</guid><pubDate>Fri, 03 May 2024 00:00:00 GMT</pubDate><author>Max Gabrielsson</author></item><item><title>duckplyr: dplyr Powered by DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The new R package duckplyr translates the dplyr API to DuckDB&#39;s execution engine.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duckplyr/duckplyr.png&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For the duckplyr documentation, visit &lt;a href=&quot;https://duckplyr.tidyverse.org/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckplyr.tidyverse.org&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;background&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/04/02/duckplyr.html#background&quot;&gt;Background&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Wrangling tabular data into a form suitable for analysis can be a challenging task. Somehow, every data set is created differently. Differences between datasets exist in their logical organization of information into rows and columns or in more specific choices like the representation of dates, currency, categorical values, missing data and so on. The task is not simplified by the lack of global consensus on trivial issues like which character to use as a decimal separator. To gain new insights, we also commonly need to combine information from multiple sources, for example by joining two data sets using a common identifier. There are some common recurring operations however, that have been found to be universally useful in reshaping data for analysis. For example, the &lt;a href=&quot;https://s3.us.cloud-object-storage.appdomain.cloud/res-files/2705-sequel-1974.pdf&quot;&gt;Structured (English) Query Language&lt;/a&gt;, or SQL (“See-Quel”) for short describes a set of common operations that can be applied to tabular data like selection, projections, joins, aggregation, sorting, windowing, and more. SQL proved to be a huge success, despite its many warts and many attempts to replace it, it is still the de-facto language for data transformation with a gigantic industry behind it.&lt;/p&gt;

&lt;!-- markdownlint-disable MD036 --&gt;
&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;DBI&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbConnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbGetQuery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;SELECT something, very, complicated FROM some_table JOIN another_table BY (some_shared_attribute) GROUP BY group_one, group_two ORDER BY some_column, and_another_column;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;A not very ergonomic way of pulling data into R&lt;/em&gt;
&lt;!-- markdownlint-enable MD036 --&gt;&lt;/p&gt;

&lt;p&gt;For data analysts in interactive programming environments like R or Python possibly from within IDEs such as RStudio or Jupyter Notebooks, using SQL to reshape data was never really a natural choice. Sure, sometimes it was required to use SQL to pull data from operational systems as shown above, but when given a choice, analysts much preferred to use the more ergonomic data reshaping facilities provided by those languages. R had built-in data wrangling from the start as part of the language with the &lt;a href=&quot;https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html&quot;&gt;data.frame class to represent tabular data&lt;/a&gt;. Later on, in 2014, Hadley Wickham defined the logical structure of tabular data for so-called &lt;a href=&quot;https://vita.had.co.nz/papers/tidy-data.pdf&quot;&gt;“tidy” data&lt;/a&gt; and published the first version of the &lt;a href=&quot;https://dplyr.tidyverse.org/&quot;&gt;dplyr&lt;/a&gt; package designed to unify and simplify the previously unwieldy R commands to reshape data into a singular, unified and consistent API. In Python-land, the widely popular &lt;a href=&quot;https://pandas.pydata.org/&quot;&gt;Pandas project&lt;/a&gt; extended Python with a de-facto tabular data representation along with relational-style operators albeit without any attempt at “tidiness”.&lt;/p&gt;

&lt;p&gt;At some point however, the R and Python data &lt;em&gt;processing&lt;/em&gt; facilities started to creak under the ever-increasing weight of datasets that people wished to analyze. Datasets quickly grew into millions of rows. For example, one of the early datasets that required &lt;a href=&quot;https://www.r-bloggers.com/2012/12/analyze-the-american-community-survey-acs-with-r-and-monetdb/&quot;&gt;special handling&lt;/a&gt; was the American Community Survey dataset, because there are just so many Americans.  But tools like Pandas and dplyr had been designed for convenience, not necessarily efficiency. For example, they lack the ability to parallelize data reshaping jobs on the now-common multicore processors.&lt;/p&gt;

&lt;p&gt;And while there was a whole set of emerging “Big Data” tools, using those from an interactive data analysis environment proved to be a poor developer experience, for example due to multi-second job startup times and very complex setup procedures far beyond the skill set of most data analysts. However, the world of relational data management systems had not stood still in the meantime. Great progress had been made to improve the efficiency of analytical data analysis from SQL: Innovations around &lt;a href=&quot;https://ir.cwi.nl/pub/21772/1900000024-Abadi-Vol5-DBS-024.pdf&quot;&gt;columnar data representation&lt;/a&gt;, &lt;a href=&quot;https://www.cidrdb.org/cidr2005/papers/P19.pdf&quot;&gt;efficient query interpretation&lt;/a&gt; or even &lt;a href=&quot;https://www.vldb.org/pvldb/vol4/p539-neumann.pdf&quot;&gt;compilation&lt;/a&gt;, and &lt;a href=&quot;https://db.in.tum.de/~leis/papers/morsels.pdf&quot;&gt;automatic efficient parallelization&lt;/a&gt; increased query processing efficiency by several orders of magnitude. Regrettably, those innovations did not find their way into the data analysts toolkit – even as decades passed – due to lack of communication between communities and siloing of innovations into corporate, commercial, and close-source products.&lt;/p&gt;

&lt;p&gt;There are two possible ways out of this unfortunate scenario:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;improve the data analysis capabilities of R and Python to be able to handle larger datasets through general efficiency improvements, optimization, and parallelization;&lt;/li&gt;
  &lt;li&gt;somehow integrate existing state-of-the-art technology into interactive data analysis environments.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The main issue with approach one is that building a &lt;em&gt;competitive&lt;/em&gt; analytical query engine from scratch is a multi-million dollar effort requiring a team of highly specialized experts on query engine construction. There are many moving highly complex parts that all have to play together nicely. There are seemingly-obvious questions in query engines that one can &lt;a href=&quot;https://hannes.muehleisen.org/publications/ICDE2023-sorting.pdf&quot;&gt;get a PhD in data management systems for a solution&lt;/a&gt;. Recouping such a massive investment in a space where it is common that tools are built by volunteers in their spare time and released for free is challenging. That being said, there are a few commendable projects in this space like &lt;a href=&quot;https://cran.r-project.org/package=data.table&quot;&gt;data.table&lt;/a&gt; or more recently &lt;a href=&quot;https://pola.rs/&quot;&gt;pola.rs&lt;/a&gt; that offer greatly improved performance over older tools.&lt;/p&gt;

&lt;p&gt;Approach two is also not without its challenges: State of the art query engine technology is often hidden behind incompatible architectures. For example, the two-tier architecture where a data management system runs on a dedicated database server and client applications use a client protocol to interact with said server is rather incompatible with interactive analysis. Setting up and maintaining a separate database “server” – even on the same computer – is still painful. Moving data back and forth between the analysis environment and the database server has been &lt;a href=&quot;https://hannes.muehleisen.org/publications/p852-muehleisen.pdf&quot;&gt;shown to be quite expensive&lt;/a&gt;. Unfortunately, those architectural decisions deeply influence the query engine trade-offs and are therefore difficult to change afterwards.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duckplyr/generic-dbms-protocol.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;There has been movement in this space however: One of the stated goals of DuckDB is to &lt;a href=&quot;https://hannes.muehleisen.org/publications/CIDR2020-raasveldt-muehleisen-duckdb.pdf&quot;&gt;unshackle state-of-the-art analytical data management technology from system architecture with its in-process architecture&lt;/a&gt;. Simply put, this means there is no separate database server and DuckDB instead runs within a “host” process. This host can be any application that requires data management capabilities or just an interactive data analysis environment like Python or R. Running within the host environment has another massive advantage: Moving data back and forth between the host and DuckDB is very cheap. For R and Python, DuckDB can  directly run complex queries on data frames within the analysis environment without any import or conversion steps. Conversely, DuckDB’s query results can directly be converted to data frames, greatly reducing the overhead of integrating with downstream libraries for plotting, further analysis or Machine Learning. DuckDB is able to efficiently execute arbitrarily complex relational queries including recursive and correlated queries. DuckDB is able to handle larger-than-memory datasets both in reading and writing but also when dealing with large intermediate results, for example resulting from aggregations with millions of groups. DuckDB has a sophisticated full query optimizer that removes the previously common manual optimization steps. DuckDB also offers persistence, tabular data being stored in files on disk. The tables in those files can be changed, too – while keeping transactional integrity. Those are unheard-of features in interactive data analysis, they are the result of decades of research and engineering in analytical data systems.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duckplyr/duckdb-in-r.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;One issue remains however, DuckDB speaks SQL. While SQL is a popular language, not all analysts want to express their data transformations in SQL. One of the main issues here is that typically, queries are expressed as strings in R or Python scripts, which are sent to a database system in an opaque way. This means that those queries carry all-or-nothing semantics and it can be challenging to debug problems (“You have an error in your SQL syntax; check the manual…”). APIs like dplyr are often more convenient for the user, they allow an IDE to support things like auto-completion on functions, variable names etc. In addition, the additive nature of the dplyr API allows to build a sequence of data transformation in small steps, which reduces the cognitive load of the analyst considerably compared to writing a hundred-line SQL query. There have been some &lt;a href=&quot;https://hannes.muehleisen.org/publications/SSDBM2013-databases-and-statistics.pdf&quot;&gt;early experimental attempts&lt;/a&gt; to overload R’s native data frame API in order to map to SQL databases, but those approaches have been found to be too limited in generality, surprising to users and generally too brittle. A better approach is needed.&lt;/p&gt;
      &lt;h2 id=&quot;the-duckplyr-r-package&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/04/02/duckplyr.html#the-duckplyr-r-package&quot;&gt;The duckplyr R Package&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To address those issues, we have partnered up with the dplyr project team at &lt;a href=&quot;https://posit.co/&quot;&gt;Posit&lt;/a&gt; (formerly RStudio) and &lt;a href=&quot;https://www.cynkra.com/&quot;&gt;cynkra&lt;/a&gt; to develop &lt;a href=&quot;https://duckplyr.tidyverse.org/&quot;&gt;&lt;strong&gt;duckplyr&lt;/strong&gt;&lt;/a&gt;. duckplyr is a drop-in replacement for &lt;a href=&quot;https://dplyr.tidyverse.org/&quot;&gt;dplyr&lt;/a&gt;, powered by DuckDB for performance. Duckplyr implements several innovations in the interactive analysis space. First of all, installing duckplyr is just as easy as installing dplyr. DuckDB has been packaged for R as a &lt;a href=&quot;https://cran.r-project.org/package=duckdb&quot;&gt;stand-alone R package&lt;/a&gt; that contains the entire data management system code as well as wrappers for R. Both the DuckDB R package as well as duckplyr are available on CRAN, making installation on all major platforms a straightforward:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;duckplyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;verbs&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/04/02/duckplyr.html#verbs&quot;&gt;Verbs&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Under the hood, duckplyr translates the sort-of-relational &lt;a href=&quot;https://dplyr.tidyverse.org/reference/index.html#data-frame-verbs&quot;&gt;dplyr operations&lt;/a&gt; (“verbs”) to DuckDB’s relational query processing engine. Apart from some naming confusion, there is a mostly straightforward mapping between dplyr’s verbs such as select, filter, summarise, etc. and DuckDB’s project, filter and aggregate operators. A crucial difference from previous approaches is that duckplyr does not go through DuckDB’s SQL interface to create query plans. Instead, duckplyr uses DuckDB’s so-called “relational” API to directly construct logical query plans. This API allows to bypass the SQL parser entirely, greatly reducing the difficulty in operator, identifier, constant, and table name escaping that plagues other approaches such as dbplyr.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duckplyr/dplyr-duckdb-plans.png&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;We have &lt;a href=&quot;https://github.com/duckdb/duckdb-r/blob/main/R/relational.R&quot;&gt;exposed the C++-level relational API to R&lt;/a&gt;, so that it is possible to directly construct DuckDB query plans from R. This low-level API is not meant to be used directly, but it is used by duckplyr to transform the dplyr verbs to the DuckDB relational API and thus to query plans. Here is an example:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;duckplyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_duckplyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;+1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│         PROJECTION        │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│             n             │
└─────────────┬─────────────┘                             
┌─────────────┴─────────────┐
│    UNGROUPED_AGGREGATE    │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│        count_star()       │
└─────────────┬─────────────┘                                                             
┌─────────────┴─────────────┐
│           FILTER          │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│(+(CAST(n AS DOUBLE), 1.0) │
│           &amp;gt; 5.0)          │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│           EC: 10          │
└─────────────┬─────────────┘                             
┌─────────────┴─────────────┐
│     R_DATAFRAME_SCAN      │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│         data.frame        │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│             n             │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│           EC: 10          │
└───────────────────────────┘  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see how a sequence of dplyr verbs mutate, filter, and count is “magically” transformed into a DuckDB query plan consisting of a scan, a filter, projections and an aggregate. We can see at the very bottom an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;R_DATAFRAME_SCAN&lt;/code&gt; operator is added. This operator directly reads an R data frame as if it were a table in DuckDB, without requiring actual data import. The new verb &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;explain()&lt;/code&gt; causes DuckDB’s logical query plan to be printed so that we can expect what DuckDB intends to execute based on the duckplyr sequence of verbs.&lt;/p&gt;
      &lt;h3 id=&quot;expressions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/04/02/duckplyr.html#expressions&quot;&gt;Expressions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;An often overlooked yet crucial component of data transformations are so-called expressions. Expressions are (conceptually) scalar transformations of constants and columns from the data that can be used to for example produce derived columns or to transform actual column values to boolean values to be used in filters. For example, one might write an expression like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(amount - discount) * tax&lt;/code&gt; to compute the actual invoiced amount without that amount actually being stored in a column or use an expression like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value &amp;gt; 42&lt;/code&gt; in a filter expression to remove all rows where the value is less than or equal to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;42&lt;/code&gt;. Dplyr relies on the base R engine to evaluate expressions with some minor modifications to resolve variable names to columns in the input data. When moving evaluation of expressions over to DuckDB, the process becomes a little bit more involved. DuckDB has its own and independent expression system consisting of a built-in set of functions (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;), scalar values and types. To transform R expressions into DuckDB expressions, we use an interesting R feature to capture un-evaluated abstract syntax trees from function arguments. By traversing the tree, we can transform R scalar values into DuckDB scalar values, R function calls into DuckDB function calls, and R-level variable references into DuckDB column references. It should be clear that this transformation cannot be perfect: There are functions in R that DuckDB simply does not support, for example those coming from the myriad of contributed packages. While we are working on expanding the set of supported expressions, there will always be some that cannot be translated. However, in the case of non-translatable expressions, we would still be able to return a result to the user. To  achieve this, we have implemented a transparent fall-back mechanism that uses the existing R-level expression evaluation method in the case that an expression cannot be translated to DuckDB’s expression language. For example, the following transformation &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m = n + 1&lt;/code&gt; can be translated:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;as_duckplyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;+1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│         PROJECTION        │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│             n             │
│             m             │
└─────────────┬─────────────┘                             
┌─────────────┴─────────────┐
│     R_DATAFRAME_SCAN      │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│         data.frame        │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│             n             │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│           EC: 10          │
└───────────────────────────┘  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While the following transformation using a inline lambda function cannot (yet):&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;as_duckplyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;+1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│     R_DATAFRAME_SCAN      │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│         data.frame        │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│             n             │
│             m             │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│           EC: 10          │
└───────────────────────────┘           
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is a little hard to see (and we are working on improving this), the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;explain()&lt;/code&gt; output clearly differs between the two mutate expressions. In the first case, DuckDB computes the  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+ 1&lt;/code&gt; as part of the projection operator, in the second case, the translation failed and a fallback was used, leading to the computation happening in the R engine. The upside of automatic fallback is that things “just work”. The downside is that there will usually be a performance hit from the fallback due to – for example – the lack of automatic parallelization. We are planning to add a debug mode where users can inspect the translation process and get insight into why translations fail.&lt;/p&gt;
      &lt;h3 id=&quot;eager-vs-lazy-materialization&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/04/02/duckplyr.html#eager-vs-lazy-materialization&quot;&gt;Eager vs. Lazy Materialization&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Dplyr and Pandas follow an execution strategy known as “eager materialization”. Every time an operation is invoked on a data frame, this operation is immediately executed and the result created in memory. This can be problematic. Consider the following example, a ten million row dataset is modified by adding 1 to a column. Then, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;top_n&lt;/code&gt; operation is invoked to retrieve the first ten rows only. Because of eager materialization, the addition operation is executed on ten million rows, the result is created in memory, only for almost all of it to be thrown away immediately because only the first ten rows were requested. Duckplyr solves this problem by using a so-called “lazy materialization” strategy where no action is performed initially but instead the users’ intent is being captured. This means that the addition of one to ten million rows will not be performed immediately. The system is instead able to optimize the requested computation and will only perform the addition on the first few rows. Also importantly, the intermediate result of the addition is never actually created in memory, greatly reducing the memory pressure.&lt;/p&gt;

&lt;p&gt;However, lazy computation presents a possible integration issue: The result of lazy computation has to be some sort of lazy computation placeholder object, that can be passed to another lazy operation or forced to be evaluated, e.g., via a special print method. However, this would break backwards compatibility with dplyr, where the result of each dplyr operation is a fully materialized data frame itself. This means that those results can be directly passed on to downstream operations like plotting without the plotting package having to be aware of the “lazyness” of the duckplyr result object. To address this, we have creatively used a R feature known as &lt;a href=&quot;https://homepage.stat.uiowa.edu/~luke/talks/uiowa-2018.pdf&quot;&gt;ALTREP&lt;/a&gt;. ALTREP allows R objects to have different in-memory representations, and for custom code to be executed whenever those objects are accessed. Duckplyr results are lazy placeholder objects, yes, but they appear to be bog-standard R data frames at the same time. R data frames are essentially named lists of typed vectors with a special row.names attribute. Because DuckDB’s lazy query planning already knows the names and types of the resulting table, we can export the names into the lazy data frame. We do not however know the number of rows nor their contents yet. We therefore make both the actual data vectors and the row names vector that contains the data frame length lazy vectors. Those vectors carry a callback that the R engine will invoke whenever downstream code – e.g., plotting code – touches those vectors. The callback will actually trigger computation of the entire pipeline and transformation of the result ot a R data frame. Duckplyr’s own operations will refrain from touching those vectors, they instead continue lazily using a special lazy computation object that is also stored in the lazy data frame. This method allows duckplyr to be both lazy and not at the same time, which allows full drop-in replacement with the eagerly evaluated dplyr while keeping the lazy evaluation that is crucial for DuckDB to be able to do a full-query optimization of the various transformation steps.&lt;/p&gt;

&lt;p&gt;Here is an example of the duality of the result of duckplyr operations using R’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inspect()&lt;/code&gt; method:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dd&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_duckplyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;+1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.Internal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inspect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@12daad988 19 VECSXP g0c2 [OBJ,REF(2),ATT] (len=2, tl=0)
  @13e0c9d60 13 INTSXP g0c0 [REF(4)] DUCKDB_ALTREP_REL_VECTOR n (INTEGER)
  @13e0ca1c0 14 REALSXP g0c0 [REF(4)] DUCKDB_ALTREP_REL_VECTOR m (DOUBLE)
ATTRIB:
  @12817a838 02 LISTSXP g0c0 [REF(1)]
    TAG: @13d80d420 01 SYMSXP g1c0 [MARK,REF(65535),LCK,gp=0x4000] &quot;names&quot; (has value)
    @12daada08 16 STRSXP g0c2 [REF(65535)] (len=2, tl=0)
      @13d852ef0 09 CHARSXP g1c1 [MARK,REF(553),gp=0x61] [ASCII] [cached] &quot;n&quot;
      @13e086338 09 CHARSXP g1c1 [MARK,REF(150),gp=0x61] [ASCII] [cached] &quot;m&quot;
    TAG: @13d80d9d0 01 SYMSXP g1c0 [MARK,REF(56009),LCK,gp=0x4000] &quot;class&quot; (has value)
    @12da9e208 16 STRSXP g0c2 [REF(65535)] (len=2, tl=0)
      @11ff15708 09 CHARSXP g0c2 [MARK,REF(423),gp=0x60] [ASCII] [cached] &quot;duckplyr_df&quot;
      @13d892308 09 CHARSXP g1c2 [MARK,REF(1513),gp=0x61,ATT] [ASCII] [cached] &quot;data.frame&quot;
    TAG: @13d80d1f0 01 SYMSXP g1c0 [MARK,REF(65535),LCK,gp=0x4000] &quot;row.names&quot; (has value)
    @13e0c9970 13 INTSXP g0c0 [REF(65535)] DUCKDB_ALTREP_REL_ROWNAMES
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see that the internal structure of the data frame indeed reflects a data frame, but we can also see the special vectors &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DUCKDB_ALTREP_REL_VECTOR&lt;/code&gt; that hide the un-evaluated data vectors as well as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DUCKDB_ALTREP_REL_ROWNAMES&lt;/code&gt; that hide the fact that the true dimensions of the data frame are not yet known.&lt;/p&gt;
      &lt;h2 id=&quot;benchmark-tpc-h-q1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/04/02/duckplyr.html#benchmark-tpc-h-q1&quot;&gt;Benchmark: TPC-H Q1&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let’s finish with a quick demonstration of duckplyr’s performance improvements. We use the data generator from the well known TPC-H benchmark, which is helpfully available as a DuckDB extension. With the “scale factor” of 1, the following DuckDB/R one-liner will generate a data set with a little over 6 million rows and store it in the R data frame named “lineitem”:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;INSTALL tpch; LOAD tpch; CALL dbgen(sf=1); FROM lineitem;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We have transformed the TPC-H benchmark query 1 from its original SQL formulation to dplyr syntax:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tpch_01&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_tax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as.Date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1998-09-02&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_tax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum_qty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum_base_price&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum_disc_price&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum_charge&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_tax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_qty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_price&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_disc&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_order&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.by&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can now execute this function with both dplyr and duckplyr and observe the time required to compute the result. &quot;Stock&quot; dplyr takes ca. 400 milliseconds on my MacBook for this query, duckplyr requires only ca 70 milliseconds. Again, this time includes all the magic transforming the sequence of dplyr verbs into a relational operator tree, optimizing said tree, converting the input R data frame into a DuckDB intermediate on-the-fly, and transforming the (admittedly small) result back to a R data frame. Of course, the data set used here is still relatively small and the query is not that complex either, essentially a single grouped aggregation. The differences will be much more pronounced for more complex transformations on larger data sets. duckplyr can also directly access large collections of e.g., Parquet files on storage, and push down filters into those scans, which can also greatly improve performance.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/04/02/duckplyr.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The duckplyr package for R wraps DuckDB&#39;s state-of-the-art analytical query processing techniques in a dplyr-compatible API. We have gone to great lengths to ensure compatibility despite switching execution paradigms from eager to lazy and having to translate expressions to a different environment. We continue to work to expand duckplyr&#39;s capabilites but would love to hear your experiences trying it out.&lt;/p&gt;

&lt;p&gt;Here are two recordings from last year&#39;s posit::conf where we present DuckDB for R and duckplyr:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=9OFzOvV-to4&quot;&gt;In-Process Analytical Data Management with DuckDB – posit::conf(2023)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=V9GwSPjKMKw&quot;&gt;duckplyr: Tight Integration of duckdb with R and the tidyverse – posit::conf(2023)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description><link>https://duckdb.org/2024/04/02/duckplyr.html</link><guid isPermaLink="false">https://duckdb.org/2024/04/02/duckplyr.html</guid><pubDate>Tue, 02 Apr 2024 00:00:00 GMT</pubDate><author>Hannes Mühleisen</author></item><item><title>No Memory? No Problem. External Aggregation in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Since the 0.9.0 release, DuckDB’s fully parallel aggregate hash table can efficiently aggregate over many more groups than fit in memory.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Most grouped aggregation queries yield just a few output rows.
For example, “How many flights departed from each European capital in the past ten years?” yields one row per European capital, even if the table containing all the flight information has millions of rows.
This is not always the case, as “How many orders did each customer place in the past ten years?” yields one row per customer, which could be millions, which significantly increases the memory consumption of the query.
However, even if the aggregation does not fit in memory, DuckDB can still complete the query.&lt;/p&gt;

&lt;p&gt;Not interested in the implementation? &lt;a href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#experiments&quot;&gt;Jump straight to the experiments!&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Around two years ago, we published our first blog post on DuckDB’s hash aggregation, titled &lt;a href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html&quot;&gt;“Parallel Grouped Aggregation in DuckDB”&lt;/a&gt;.
So why are we writing another blog post now?&lt;/p&gt;

&lt;p&gt;Unlike most database systems, which are servers, DuckDB is used in all kinds of environments, which may not have much memory.
However, some database queries, like aggregations with many unique groups, require a lot of memory.
The laptop I am writing this on has 16 GB of RAM.
What if a query needs 20 GB?
If this happens:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Out of Memory Error: could not allocate block of size X (Y/Z used)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The query is aborted.
Sadly, we can’t &lt;a href=&quot;https://knowyourmeme.com/memes/download-more-ram&quot;&gt;download more RAM&lt;/a&gt;.
But luckily, this laptop also has a fast SSD with 1 TB of storage.
In many cases, we don’t need all 20 GB of data to be in memory simultaneously, and we can temporarily place some data in storage.
If we load it back whenever needed, we can still complete the query.
We must be careful to use storage sparingly because despite modern SSDs being fast, they are still much slower than memory.&lt;/p&gt;

&lt;p&gt;In a nutshell, that’s what this post is about.
Since the &lt;a href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html&quot;&gt;0.9.0 release&lt;/a&gt;, DuckDB’s hash aggregation can process more unique groups than fit in memory by offloading data to storage.
In this post, we’ll explain how this works.
If you want to know what hash aggregation is, how hash collisions are resolved, or how DuckDB’s hash table is structured, check out &lt;a href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html&quot;&gt;our first blog post on hash aggregation&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;memory-management&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#memory-management&quot;&gt;Memory Management&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Most database systems store persistent data on “pages”.
Upon request, these pages can be read from the &lt;em&gt;database file&lt;/em&gt; in storage, put into memory, and written back again if necessary.
The common wisdom is to make all pages the same size: This allows pages to be swapped and avoids &lt;a href=&quot;https://en.wikipedia.org/wiki/Fragmentation_(computing)&quot;&gt;fragmentation&lt;/a&gt; in memory and storage.
When the database is started, a portion of memory is allocated and reserved for these pages, called the “buffer pool”.
The database component that is responsible for managing the buffer pool is aptly called the “buffer manager”.&lt;/p&gt;

&lt;p&gt;The remaining memory is reserved for short-lived, i.e., &lt;em&gt;temporary&lt;/em&gt;, memory allocations, such as hash tables for aggregation.
These allocations are done differently, which is good because if there are many unique groups, hash tables may need to be very large, so we wouldn’t have been able to use the fixed-size pages for that anyway.
If we have more temporary data than fits in memory, operators like aggregation have to decide when to selectively write data to a &lt;em&gt;temporary file&lt;/em&gt; in storage.&lt;/p&gt;

&lt;p&gt;… At least, that’s the traditional way of doing things.
This made little sense for DuckDB.
Why should we manage persistent and temporary data so differently?
The difference is that &lt;em&gt;persistent&lt;/em&gt; data should be &lt;em&gt;persisted&lt;/em&gt;, and &lt;em&gt;temporary&lt;/em&gt; data should not.
Why can’t a buffer manager manage both?&lt;/p&gt;

&lt;p&gt;DuckDB’s buffer manager is not traditional.
Most persistent and temporary data is stored on fixed-size pages and managed by the buffer manager.
The buffer manager tries to make the best use of your memory.
That means we don’t reserve a portion of memory for a buffer pool.
This allows DuckDB to use all memory for persistent data, not just a portion if that’s what’s best for your workload.
If you’re doing large aggregations that need a lot of memory, DuckDB can evict the persistent data from memory to free up space for a large hash table.&lt;/p&gt;

&lt;p&gt;Because DuckDB’s buffer manager manages &lt;em&gt;all&lt;/em&gt; memory, both persistent and temporary data, it is much better at choosing when to write temporary data to storage than operators like aggregation could ever be.
Leaving the responsibility of offloading to the buffer manager also saves us the effort of implementing reading and writing data to a temporary file in every operator that needs to process data that does not fit in memory.&lt;/p&gt;

&lt;p&gt;Why don’t buffer managers in other database systems manage temporary data?
There are two problems: &lt;em&gt;Memory Fragmentation&lt;/em&gt; and &lt;em&gt;Invalid References&lt;/em&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;memory-fragmentation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#memory-fragmentation&quot;&gt;Memory Fragmentation&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Hash tables and other data structures used in query operators don’t exactly have a fixed size like the pages used for persistent data.
We also don’t want to have a lot of pages with variable sizes floating around in memory alongside the pages with a fixed size, as this would cause memory fragmentation.&lt;/p&gt;

&lt;p&gt;Ideally, we would use the fixed size for &lt;em&gt;all&lt;/em&gt; of our memory allocations, but this is not a good idea: Sometimes, the most efficient way to process a query requires allocating, for example, a large array.
So, we settled for using a fixed size for &lt;em&gt;almost all&lt;/em&gt; of our allocations.
These short-lived allocations are immediately deallocated after use, unlike the fixed-size pages for persistent data, which are kept around.
These allocations do not cause fragmentation with each other because &lt;a href=&quot;https://jemalloc.net/&quot;&gt;jemalloc&lt;/a&gt;, which DuckDB uses for allocating memory when possible, categorizes allocations using size classes and maintains separate arenas for them.&lt;/p&gt;
      &lt;h3 id=&quot;invalid-references&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#invalid-references&quot;&gt;Invalid References&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Temporary data usually cannot be written to storage as-is because it often contains pointers.
For example, DuckDB implements the string type proposed by &lt;a href=&quot;https://db.in.tum.de/~freitag/papers/p29-neumann-cidr20.pdf&quot;&gt;Umbra&lt;/a&gt;, which has a fixed width.
Strings longer than 12 characters are not stored within the string type, but &lt;em&gt;somewhere else&lt;/em&gt;, and a pointer to this “somewhere else” is stored instead.&lt;/p&gt;

&lt;p&gt;This creates a problem when we want to offload data to storage.
Let’s say this “somewhere else” where strings longer than 12 characters are stored is one of those pages that the buffer manager can offload to storage at any time to free up some memory.
If the page is offloaded and then loaded back, it will most likely be loaded into a different address in memory.
The pointers that pointed to the long strings are now &lt;em&gt;invalid&lt;/em&gt; because they still point to the previous address!&lt;/p&gt;

&lt;p&gt;The usual way of writing data containing pointers to storage is by &lt;em&gt;serializing&lt;/em&gt; it first.
When reading it back into memory, it has to be &lt;em&gt;deserialized&lt;/em&gt; again.
&lt;a href=&quot;https://www.vldb.org/pvldb/vol10/p1022-muehleisen.pdf&quot;&gt;(De-)serialization can be an expensive operation&lt;/a&gt;, hence why data formats like &lt;a href=&quot;https://arrow.apache.org/blog/2019/10/13/introducing-arrow-flight/&quot;&gt;Arrow Flight&lt;/a&gt; exist, which try to minimize the cost.
However, we can’t use Arrow here because Arrow is a column-major layout, but &lt;a href=&quot;https://ir.cwi.nl/pub/13807/13807B.pdf&quot;&gt;a row-major layout is more efficient for hash tables&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We could create a row-major version of Arrow Flight, but we can just avoid (de-)serialization altogether:
We’ve created a specialized row-major &lt;em&gt;page layout&lt;/em&gt; that actually uses the old invalidated pointers to &lt;em&gt;recompute&lt;/em&gt; new valid pointers after reading the data back into memory.&lt;/p&gt;

&lt;p&gt;The page layout places fixed-size rows and variable-size data like strings on separate pages.
The size of the rows is fixed for a query: After a SQL query is issued, DuckDB creates and executes a query plan.
So, even before executing the said plan, we already know which columns we need, their types, and how wide these types are.&lt;/p&gt;

&lt;p&gt;As shown in the image below, a small amount of “MetaData” is needed to recompute the pointers.
The fixed-size rows are stored in “Row Pages”, and variable-size rows in “Var Pages”.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/external_aggregation/TupleDataCollection.svg&quot; alt=&quot;DuckDB&#39;s spillable page layout&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/p&gt;

&lt;p&gt;Remember that there are pointers within the fixed-size rows pointing to variable-size data.
The MetaData describes which fixed-size rows point to which Var Page and the last known address of the Var Page.
For example, MetaData 1 describes 5 rows stored in Row Page 1 at offset 0, with variable-size data stored in Var Page 1, which had an address of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x42&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Let’s say the buffer manager decides to offload Var Page 1.
When we request Var Page 1 again, it’s loaded into address &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x500&lt;/code&gt;.
The pointers within those 5 rows are now invalid.
For example, one of the rows contains the pointer &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x48&lt;/code&gt;, which means that it is stored at offset &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x48 - 0x42 = 6&lt;/code&gt; in Var Page 1.
We can recompute the pointer by adding the offset to the new address of the page: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x500 + 6 = 0x506&lt;/code&gt;.
Pointer recomputation is done for rows with their strings stored on the same Row and Var Page, so we create a new MetaData every time a Row Page or Var Page is full.&lt;/p&gt;

&lt;p&gt;The advantage of pointer recomputation over (de-)serialization is that it can be done lazily.
We can check whether the Var Page was offloaded by comparing the pointer in the MetaData with the current pointer to the page.
We don’t have to recompute the pointers if they are the same.&lt;/p&gt;
      &lt;h2 id=&quot;external-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#external-aggregation&quot;&gt;External Aggregation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we’ve figured out how to deal with temporary data, it’s finally time to talk about hash aggregation.
The first big challenge is to perform the aggregation in parallel.&lt;/p&gt;

&lt;p&gt;DuckDB uses &lt;a href=&quot;https://db.in.tum.de/~leis/papers/morsels.pdf&quot;&gt;Morsel-Driven Parallelism&lt;/a&gt; parallelize query execution, which essentially means that query operators, such as aggregation, must be parallelism-aware.
This differs from &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/93605.98720&quot;&gt;plan-driven parallelism&lt;/a&gt;, keeping operators unaware of parallelism.&lt;/p&gt;

&lt;p&gt;To briefly summarize &lt;a href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html&quot;&gt;our first blog post on aggregation&lt;/a&gt;: In DuckDB, all active threads have their own thread-local hash table, which they sink input data into.
This will keep threads busy until all input data has been read.
Multiple threads will likely have the &lt;em&gt;exact same group&lt;/em&gt; in their hash table.
Therefore, the thread-local hash tables must be combined to complete the grouped aggregation.
This can be done in parallel by partitioning the hash tables and assigning each thread to combine the data from each partition.
For the most part, we still use this same approach.
You’ll see this in the image below, which illustrates our new implementation.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/external_aggregation/OOCHA.svg&quot; alt=&quot;DuckDB&#39;s external hash aggregation&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/p&gt;

&lt;p&gt;We call the first phase &lt;em&gt;Thread-Local Pre-Aggregation&lt;/em&gt;.
The input data are &lt;em&gt;morsels&lt;/em&gt;, chunks of around 100,000 rows.
These are assigned to active threads, which sink them into their thread-local hash table until all input data has been read.
We use &lt;em&gt;linear probing&lt;/em&gt; to resolve collisions and &lt;em&gt;salt&lt;/em&gt; to reduce the overhead of dealing with said collisions.
This is explained in &lt;a href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html&quot;&gt;our first blog post on aggregation&lt;/a&gt;, so I won’t repeat it here.&lt;/p&gt;

&lt;p&gt;Now that we’ve explained what &lt;em&gt;hasn’t&lt;/em&gt; changed, we can talk about what &lt;em&gt;has&lt;/em&gt; changed.
The first difference compared to last time is the way that we partition.
Before, if we had, for example, 32 threads, each thread would create 32 hash tables, one for each partition.
This totals a whopping 1024 hash tables, which did not scale well when even more threads were active.
Now, each thread has one hash table, &lt;em&gt;but the data within each hash table is partitioned&lt;/em&gt;.
The data is also stored on the specialized page layout we presented earlier so that it can easily be offloaded to storage.&lt;/p&gt;

&lt;p&gt;The second difference is that the hash tables are not &lt;em&gt;resized&lt;/em&gt; during Thread-Local Pre-Aggregation.
We keep the hash tables’ size small, reducing the amount of cache misses during this phase.
This means that the hash table will be full at some point.
When it’s full, we reset it and start over.
We can do this because we’ll finish the aggregation later in the second phase.
When we reset the hash table, we “unpin” the pages that store the actual data, which tells our buffer manager it can write them to storage when it needs to free up memory.&lt;/p&gt;

&lt;p&gt;Together, these two changes result in a low memory requirement during the first phase.
Each thread only needs to keep a small hash table in memory.
We may collect a lot of data by filling up the hash table many times, but the buffer manager can offload almost all of it if needed.&lt;/p&gt;

&lt;p&gt;For the second phase, &lt;em&gt;Partition-Wise Aggregation&lt;/em&gt;, the thread-local partitioned data is exchanged, and each thread combines the data of a single partition into a hash table.
This phase is mostly the same as before, except that we now sometimes create many more partitions than threads.
Why? The hash table for one partition might fit in memory, but 8 threads could be combining a partition simultaneously, and we might not be able to fit 8 partitions in memory.
The easy solution to this problem is to &lt;em&gt;over-partition&lt;/em&gt;.
If we make more partitions than threads, for example, 32 partitions, the size of the partitions will be smaller, and the 8 threads will combine only 8 out of the 32 partitions simultaneously, which won’t require nearly as much memory.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;experiments&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;experiments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#experiments&quot;&gt;Experiments&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Aggregations that result in only a few unique groups can easily fit in memory.
To evaluate our external hash aggregation implementation, we need aggregations that have many unique groups.
For this purpose, we will use the &lt;a href=&quot;https://duckdblabs.github.io/db-benchmark/&quot;&gt;H2O.ai database-like ops benchmark&lt;/a&gt;, which &lt;a href=&quot;https://duckdb.org/2023/04/14/h2oai.html&quot;&gt;we&#39;ve resurrected&lt;/a&gt;, and &lt;a href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html&quot;&gt;now maintain&lt;/a&gt;.
Specifically, we will use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;G1_1e9_2e0_0_0.csv.zst&lt;/code&gt; file, which is 50 GB uncompressed.
The source code for the H2O.ai benchmark can be found &lt;a href=&quot;https://github.com/duckdblabs/db-benchmark&quot;&gt;here&lt;/a&gt;.
You can download the file yourself from &lt;a href=&quot;https://blobs.duckdb.org/data/G1_1e9_2e0_0_0.csv.zst&quot;&gt;https://blobs.duckdb.org/data/G1_1e9_2e0_0_0.csv.zst&lt;/a&gt; (18.8 GB compressed).&lt;/p&gt;

&lt;p&gt;We use the following queries from the benchmark to load the data:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;preserve_insertion_order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id5&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;G1_1e9_2e0_0_0.csv.zst&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AUTO_DETECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1ENUM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ENUM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2ENUM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ENUM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1ENUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2ENUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id5&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FLOAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The H2O.ai aggregation benchmark consists of 10 queries, which vary in the number of unique groups:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 1: ~100 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 2: ~10,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 3: ~10,000,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 4: ~100 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 5: ~1,000,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 6: ~10,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;id5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;quantile_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;median_v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd_v3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 7: ~10,000,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range_v1_v2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 8: ~10,000,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;largest2_v3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order_v3&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sub_query&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order_v3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 9: ~10,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;corr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;r2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Query 10: ~1,000,000,000 unique groups&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;a href=&quot;https://duckdblabs.github.io/db-benchmark/&quot;&gt;results on the benchmark page&lt;/a&gt; are obtained using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c6id.metal&lt;/code&gt; AWS EC2 instance.
On this instance, all the queries easily fit in memory, and having many threads doesn&#39;t hurt performance either.
DuckDB only takes 8.58 seconds to complete even the largest query, query 10, which returns 1 billion unique groups.
However, many people will not use such a beefy machine to crunch numbers.
On my laptop, a 2020 MacBook Pro, some smaller queries will fit in memory, like query 1, but query 10 will definitely not.&lt;/p&gt;

&lt;p&gt;The following table is a summary of the hardware used.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Specs&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c6id.metal&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Laptop&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Ratio&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Memory&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;256 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CPU cores&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CPU threads&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;128&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Hourly cost&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$6.45&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;$0.00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Although the CPU cores of the AWS EC2 instance are not directly comparable with those of my laptop, the instance clearly has much more compute power and memory available.
Despite the large differences in hardware, DuckDB can complete all 10 queries without a problem:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Query&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c6id.metal&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Laptop&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Ratio&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.08&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.74&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9.25×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.09&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.76&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.44×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;156.63&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.55×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.26&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.07&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.96×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.72&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;145.00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.58×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.28&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.13×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.33&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;124.85&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.72×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.53&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;126.35&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19.35×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.32&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.94×&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.58&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;264.14&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;30.79×&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The runtime of the queries is reported in seconds, and was obtained by taking the median of 3 runs on my laptop using DuckDB 0.10.1.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c6id.metal&lt;/code&gt; instance results were obtained from the &lt;a href=&quot;https://duckdblabs.github.io/db-benchmark/&quot;&gt;benchmark website&lt;/a&gt;.
Despite being unable to &lt;em&gt;fit&lt;/em&gt; all unique groups in my laptop&#39;s memory, DuckDB can &lt;em&gt;compute&lt;/em&gt; all unique groups and return them.
The largest query, query 10, takes almost 4.5 minutes to complete.
This is over 30× longer than with the beefy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c6id.metal&lt;/code&gt; instance.
The large difference is, of course, explained by the large differences in hardware.
Interestingly, this is still faster than Spark on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c6id.metal&lt;/code&gt; instance, which takes 603.05 seconds!&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/29/external-aggregation.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB is constantly improving its larger-than-memory query processing capabilities.
In this blog post, we showed some of the tricks DuckDB uses for spilling and loading data from storage.
These tricks are implemented in DuckDB&#39;s external hash aggregation, released since 0.9.0.
We took the hash aggregation for a spin on the H2O.ai benchmark, and DuckDB could complete all 50 GB queries on a laptop with only 16 GB of memory.&lt;/p&gt;

&lt;p&gt;Interested in reading more? &lt;a href=&quot;https://hannes.muehleisen.org/publications/icde2024-out-of-core-kuiper-boncz-muehleisen.pdf&quot;&gt;Read our paper on external aggregation&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2024/03/29/external-aggregation.html</link><guid isPermaLink="false">https://duckdb.org/2024/03/29/external-aggregation.html</guid><pubDate>Fri, 29 Mar 2024 00:00:00 GMT</pubDate><author>Laurens Kuiper</author></item><item><title>42.parquet – A Zip Bomb for the Big Data Age</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: A 42 kB Parquet file can contain over 4 PB of data.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;a href=&quot;https://parquet.apache.org/&quot;&gt;Apache Parquet&lt;/a&gt; has become the de-facto standard for tabular data interchange. It is greatly superior to its scary cousin CSV by using a binary, columnar and &lt;em&gt;compressed&lt;/em&gt; data representation. In addition, Parquet files come with enough metadata so that files can be correctly interpreted without additional information. Most modern data tools and services support reading and writing Parquet files.&lt;/p&gt;

&lt;p&gt;However, Parquet files are not without their dangers: For example, corrupt files can crash readers that are not being very careful in interpreting internal offsets and such. But even perfectly valid files can be problematic and lead to crashes and service downtime as we will show below.&lt;/p&gt;

&lt;p&gt;A pretty well-known attack on naive firewalls and virus scanners is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Zip_bomb&quot;&gt;Zip Bomb&lt;/a&gt;, one famous example being &lt;a href=&quot;https://www.unforgettable.dk/&quot;&gt;42.zip&lt;/a&gt;, named so because of course &lt;a href=&quot;https://en.wikipedia.org/wiki/42_(number)#The_Hitchhiker&#39;s_Guide_to_the_Galaxy&quot;&gt;42 is the perfect number&lt;/a&gt; and the file is only 42 kilobytes large. This perfectly-valid zip file has a bunch of other zip files in it, which again contain other zip files and so on. Eventually, if one would try to unpack all of that, you would end up with 4 petabytes of data. Big Data indeed.&lt;/p&gt;

&lt;p&gt;Parquet files support various methods to compress data. How big of a table can one create with a Parquet file that is only 42 kilobytes large in the spirit of a zip bomb? Let&#39;s find out! For reasons of portability, we have implemented our own &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;Parquet reader and writers for DuckDB&lt;/a&gt;. It is unavoidable to learn a great deal about the Parquet format when implementing it.&lt;/p&gt;

&lt;p&gt;A Parquet file is made up of one or more row groups, which contain columns, which in turn contain so-called pages that contain the actual data in encoded format. Among other encodings, Parquet supports &lt;a href=&quot;https://en.wikipedia.org/wiki/Dictionary_coder&quot;&gt;dictionary encoding&lt;/a&gt;, where we first have a page with a dictionary, followed by data pages that refer to the dictionary instead of containing plain values. This is more efficient for columns where long values such as categorical strings repeat often, because the dictionary references can be much smaller.&lt;/p&gt;

&lt;p&gt;Let&#39;s exploit that. We write a dictionary with a single value and refer to it over and over. In our example, we use a single 64-bit integer, the biggest possible value because why not. Then, we refer back to this dictionary entry using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RLE_DICTIONARY&lt;/code&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Run-length_encoding&quot;&gt;run-length encoding&lt;/a&gt; specified in parquet. The &lt;a href=&quot;https://parquet.apache.org/docs/file-format/data-pages/encodings/#run-length-encoding--bit-packing-hybrid-rle--3&quot;&gt;specified encoding&lt;/a&gt; is a bit weird because for some reason it combines bit packing and run-length encoding but essentially we can use the biggest run-length possible, which is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2^31-1&lt;/code&gt;, a little over 2 billion. Since the dictionary is tiny (one entry), the value we repeat is 0, referring to the only entry. Including its required metadata headers and footers (like all metadata in Parquet, this is encoded using &lt;a href=&quot;https://thrift.apache.org/&quot;&gt;Thrift&lt;/a&gt;), this file is only 133 bytes large. 133 bytes to represent 2 billion 8-byte integers is not too bad, even if they&#39;re all the same.&lt;/p&gt;

&lt;p&gt;But we can go up from there. Columns can contain multiple pages referring to &lt;em&gt;the same&lt;/em&gt; dictionary, so we can just repeat our data page over and over, each time only adding 31 bytes to the file, but 2 billion values to the table the file represents. We can also use another trick to blow up the data size: as mentioned, Parquet files contain one or more row groups, those are stored in a Thrift footer at the end of the file. Each column in this row group contains byte offsets (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data_page_offset&lt;/code&gt; and friends) into the file where the pages for the columns are stored.  Nothing keeps us from adding multiple row groups that &lt;em&gt;all refer to the same byte offset&lt;/em&gt;, the one where we stored our slightly mischievous dictionary and data pages. Each row group we add logically repeats all the pages. Of course, adding row groups also requires metadata storage, so there is some sort of trade-off between adding pages (2 billion values) and row groups (2x whatever other row group it duplicates).&lt;/p&gt;

&lt;p&gt;With some fiddling, we found that if we repeat the data page 1000 times and repeat the row group 290 times, we end up with &lt;a href=&quot;https://github.com/hannes/fortytwodotparquet/raw/main/42.parquet&quot;&gt;a Parquet file&lt;/a&gt; that is 42 kilobytes large, yet contains &lt;em&gt;622 trillion&lt;/em&gt; values (622,770,257,630,000 to be exact). If one would materialize this table in memory, it would require over &lt;em&gt;4 petabytes&lt;/em&gt; of memory, finally a real example of &lt;a href=&quot;https://motherduck.com/blog/big-data-is-dead/&quot;&gt;Big Data&lt;/a&gt;, coincidentally roughly the same size as the original &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;42.zip&lt;/code&gt; mentioned above.&lt;/p&gt;

&lt;p&gt;We&#39;ve made the &lt;a href=&quot;https://github.com/hannes/fortytwodotparquet/blob/main/create-parquet-file.py&quot;&gt;script that we use to generate this file available as well&lt;/a&gt;, we hope it can be used to test Parquet readers better. We hope to have shown that Parquet files can be considered harmful and should certainly not be shoved into some pipeline without being extra careful. And while DuckDB &lt;em&gt;can&lt;/em&gt; read data from our file (e.g., with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt;), if you would make it read through it all, you better get some coffee.&lt;/p&gt;

</description><link>https://duckdb.org/2024/03/26/42-parquet-a-zip-bomb-for-the-big-data-age.html</link><guid isPermaLink="false">https://duckdb.org/2024/03/26/42-parquet-a-zip-bomb-for-the-big-data-age.html</guid><pubDate>Tue, 26 Mar 2024 00:00:00 GMT</pubDate><author>Hannes Mühleisen</author></item><item><title>Dependency Management in DuckDB Extensions</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: While core DuckDB has zero external dependencies, building extensions with dependencies is now very simple, with built-in support for vcpkg, an open-source package manager with support for over 2000 C/C++ packages. Interested in building your own? Check out the &lt;a href=&quot;https://github.com/duckdb/extension-template&quot;&gt;extension template&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Ever since the birth of DuckDB, one of its main pillars has been its strict no-external-dependencies philosophy.
Paraphrasing &lt;a href=&quot;https://hannes.muehleisen.org/publications/SIGMOD2019-demo-duckdb.pdf&quot;&gt;this 2019 SIGMOD paper&lt;/a&gt; on DuckDB:
&lt;em&gt;To achieve the requirement of having practical “embeddability” and portability, the database needs to run in whatever
environment the host does. Dependencies on external libraries (e.g., openssh) for either compile- or runtime have been
found to be problematic.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In this blog post, we will cover how DuckDB manages to stay true to this philosophy without forcing DuckDB developers
down the path of complete abstinence. Along the way, we will show practical examples of how external dependencies are
possible, and how you can use this when creating your own DuckDB extension.&lt;/p&gt;
      &lt;h2 id=&quot;the-difficulties-of-complete-abstinence&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#the-difficulties-of-complete-abstinence&quot;&gt;The Difficulties of Complete Abstinence&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Having no external dependencies is conceptually very simple. However, in a real-world system with real-world
requirements, it is difficult to achieve. Many features require complex implementations of protocols and algorithms, and
many high-quality libraries exist that implement them. What this means for DuckDB (and most other systems, for that matter)
is that there are basically three options for handling requirements with potential external dependencies:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Inlining external code&lt;/li&gt;
  &lt;li&gt;Rewriting the external dependency&lt;/li&gt;
  &lt;li&gt;Breaking the no-dependency rule&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first two options are pretty straightforward: to avoid depending on some external software, just make it part of
the codebase. By doing so, the unpredictable nature of depending on somebody else is now eliminated! DuckDB has applied
both inlining and rewriting to prevent dependencies. For example, the &lt;a href=&quot;https://github.com/duckdb/duckdb/tree/main/third_party/libpg_query&quot;&gt;Postgres parser&lt;/a&gt; and
&lt;a href=&quot;https://github.com/duckdb/duckdb/tree/main/third_party/mbedtls&quot;&gt;MbedTLS&lt;/a&gt; libraries are inlined into DuckDB, whereas the S3 support is provided
using a custom implementation of the AWS S3 protocol.&lt;/p&gt;

&lt;p&gt;Okay, great – problem solved, right? Well, not so fast. Most people with some software engineering experience will realize
that both inlining and rewriting come with serious drawbacks. The
most fundamental issue is probably related to code maintenance. Every significant piece of software needs some level of
maintenance. Ranging from fixing bugs to dealing with changing (build) environments or requirements, code will
need to be modified to stay functional and relevant. When inlining/rewriting dependencies, this also copies over the
maintenance burden.&lt;/p&gt;

&lt;p&gt;For DuckDB, this historically meant that for each dependency, very careful consideration was made to balance the
increased maintenance burden against the necessity of dependency. Including a dependency meant the responsibility of
maintaining it, so this decision was never taken lightly. This works well in many cases and has the added benefit of forcing
developers to think critically about including a dependency and not mindlessly bolt on library after library. However,
for some dependencies, this just doesn&#39;t work. Take, for example, the SDKs of large cloud providers. They tend to be pretty
massive, very frequently updated, and packed with arguably essential functionality for an increasingly mature analytical
database. This leaves an awkward choice: either not provide these essential features or break the no-dependency rule.&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#duckdb-extensions&quot;&gt;DuckDB Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This is where extensions come in. Extensions provide an elegant solution to the dilemma of dependencies by allowing
fine-grained breakage of the no-dependency rule. Moving dependencies out of DuckDB&#39;s core into extensions, the core
codebase can remain, and does remain, dependency-free.
This means that DuckDB&#39;s “Practical embeddability and portability” remains unthreatened. On the other hand, DuckDB can
still provide features that inevitably require depending on some 3rd party library. Furthermore, by moving dependencies
to extensions, each extension can have different levels of exposure to instability from dependencies. For example, some
extensions may choose to depend only on highly mature, stable libraries with good portability, whereas others may choose
to include more experimental dependencies with limited portability. This choice is then forwarded to the user by
allowing them to choose which extension to use.&lt;/p&gt;

&lt;p&gt;At DuckDB, this realization of the importance of extensions and its relation to the no-dependency rule came
&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/594&quot;&gt;very early&lt;/a&gt;, and consequently extensibility has been ingrained into DuckDB&#39;s
design since its early days. Today, many parts of DuckDB can be extended. For example, you can add functions (table,
scalar, copy, aggregation), filesystems, parsers, optimizer rules, and much more. Many new features that are added to
DuckDB are added in extensions and are grouped by either functionality or by set of dependencies. Some examples of
extensions are the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/sqlite.html&quot;&gt;SQLite&lt;/a&gt; extension for reading/writing to/from SQLite files or the
&lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;Spatial&lt;/a&gt; extension which offers support for a wide range of geospatial processing
features. DuckDB&#39;s extensions are distributed as loadable binaries for most major platforms (including
&lt;a href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html&quot;&gt;DuckDB-Wasm&lt;/a&gt;), allowing loading and installing extensions with two simple SQL
statements:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For most core extensions maintained by the DuckDB team, there is even an auto-install and auto-load feature which will detect the required extensions for
a SQL statement and automatically install and load them. For a detailed description of which extensions are available
and how to use them, check out the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/overview.html&quot;&gt;docs&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;dependency-management&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#dependency-management&quot;&gt;Dependency Management&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;So far, we&#39;ve seen how DuckDB avoids external dependencies in its core codebase by moving them out of the core repository into
extensions. However, we&#39;re not out of the woods yet. As DuckDB is written in C++, the most natural way to write
extensions is C++. In C++, though, there is no standard tooling like a package manager and the answer to the
question of how to do dependency management in C++ has been, for many years: &lt;em&gt;“Through much pain and anguish.”&lt;/em&gt; Given
DuckDB&#39;s focus on portability and support for many platforms, managing dependencies manually is not feasible: dependencies generally are built from source, with each their own intricacies requiring special build flags and
configuration for different platforms. With a growing ecosystem of extensions, this would quickly turn into an
unmaintainable mess.&lt;/p&gt;

&lt;p&gt;Fortunately, much has changed in the C++ landscape over the past few years. Today, good dependency managers do exist.
One of them is Microsoft&#39;s &lt;a href=&quot;https://vcpkg.io/&quot;&gt;vcpkg&lt;/a&gt;. It has become a highly notable player among C++ dependency
managers, as proven by its 20k+ GitHub stars and native support
from &lt;a href=&quot;https://blog.jetbrains.com/clion/2023/01/support-for-vcpkg-in-clion/&quot;&gt;CLion&lt;/a&gt;
and &lt;a href=&quot;https://devblogs.microsoft.com/cppblog/vcpkg-is-now-included-with-visual-studio/&quot;&gt;Visual Studio&lt;/a&gt;. vcpkg contains
over 2000 dependencies such
as &lt;a href=&quot;https://github.com/microsoft/vcpkg/tree/master/ports/arrow&quot;&gt;Apache Arrow&lt;/a&gt;, &lt;a href=&quot;https://github.com/microsoft/vcpkg/tree/master/ports/yyjson&quot;&gt;yyjson&lt;/a&gt;,
and &lt;a href=&quot;https://github.com/microsoft/vcpkg/tree/master/ports/azure-core-cpp&quot;&gt;various&lt;/a&gt; &lt;a href=&quot;https://github.com/microsoft/vcpkg/tree/master/ports/aws-sdk-cpp&quot;&gt;cloud&lt;/a&gt; &lt;a href=&quot;https://github.com/googleapis/google-cloud-cpp&quot;&gt;provider&lt;/a&gt;
SDKs.&lt;/p&gt;

&lt;p&gt;For anyone who has ever used a package manager, using vcpkg will feel quite natural. Dependencies are specified in
a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vcpkg.json&lt;/code&gt; file, and vcpkg is hooked into the build system. Now, when building, vcpkg ensures that the dependencies
specified in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vcpkg.json&lt;/code&gt; are built and available. vcpkg supports integration with multiple build systems, with a
focus on its seamless CMake integration.&lt;/p&gt;
      &lt;h2 id=&quot;using-vcpkg-with-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#using-vcpkg-with-duckdb&quot;&gt;Using vcpkg with DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we covered DuckDB extensions and vcpkg, we have shown how DuckDB can manage dependencies without sacrificing
portability, maintainability and stability more than necessary. Next, we&#39;ll make things a bit more tangible by looking at
one of DuckDB&#39;s extensions and how it uses vcpkg to manage its dependencies.&lt;/p&gt;
      &lt;h3 id=&quot;example-azure-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#example-azure-extension&quot;&gt;Example: Azure extension&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/azure.html&quot;&gt;Azure&lt;/a&gt; extension provides functionality related to &lt;a href=&quot;https://azure.microsoft.com/&quot;&gt;Microsoft Azure&lt;/a&gt;,
one of the major cloud providers. DuckDB&#39;s Azure extension depends on the Azure C++ SDK to support reading directly from
Azure Storage. To do so it adds a custom filesystem and &lt;a href=&quot;https://duckdb.org/docs/stable/configuration/secrets_manager.html&quot;&gt;secret type&lt;/a&gt;, which can be
used to easily query from authenticated Azure containers:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;az1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;azure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;CONNECTION_STRING&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;redacted&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column_b&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;az://my-container/some-file.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To implement these features, the Azure extension depends on different parts of the Azure SDK. These are specified in the
Azure extensions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vcpkg.json&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dependencies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;azure-identity-cpp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;azure-storage-blobs-cpp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;azure-storage-files-datalake-cpp&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, in the Azure extension&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CMakelists.txt&lt;/code&gt; file, we find the following lines:&lt;/p&gt;

&lt;div class=&quot;language-cmake highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;find_package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;azure-identity-cpp CONFIG&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;find_package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;azure-storage-blobs-cpp CONFIG&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;find_package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;azure-storage-files-datalake-cpp CONFIG&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;target_link_libraries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;EXTENSION_NAME&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; Azure::azure-identity Azure::azure-storage-blobs Azure::azure-storage-files-datalake&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;target_include_directories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;EXTENSION_NAME&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; PRIVATE Azure::azure-identity Azure::azure-storage-blobs Azure::azure-storage-files-datalake&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And that&#39;s basically it! Every time the Azure extension is built, vcpkg will be called first to
ensure &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;azure-identity-cpp&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;azure-storage-blobs-cpp&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;azure-storage-files-datalake-cpp&lt;/code&gt; are built using the correct platform-specific flags and
available in CMake through &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;find_package&lt;/code&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;building-your-own-duckdb-extension&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#building-your-own-duckdb-extension&quot;&gt;Building Your Own DuckDB Extension&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Up until this part, we&#39;ve focused on managing dependencies from a point-of-view of the developers of core DuckDB
contributors. However, all of this applies to anyone who wants to build an extension. DuckDB maintains a &lt;a href=&quot;https://github.com/duckdb/extension-template&quot;&gt;C++ Extension Template&lt;/a&gt;,
which contains all the necessary build scripts, CI/CD pipeline and vcpkg configuration to build, test and deploy a DuckDB extension in
minutes. It can automatically build the loadable extension binaries for all available platforms, including Wasm.&lt;/p&gt;
      &lt;h3 id=&quot;setting-up-the-extension-template&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#setting-up-the-extension-template&quot;&gt;Setting up the Extension Template&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To demonstrate how simple this process is, let&#39;s go through all the steps of building a DuckDB extension from scratch,
including adding a vcpkg-managed external dependency.&lt;/p&gt;

&lt;p&gt;Firstly, you will need to install vcpkg:&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;git clone &lt;/span&gt;https://github.com/Microsoft/vcpkg.git
./vcpkg/bootstrap-vcpkg.sh
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;VCPKG_TOOLCHAIN_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;/vcpkg/scripts/buildsystems/vcpkg.cmake
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, you create a GitHub repository based on &lt;a href=&quot;https://github.com/duckdb/extension-template&quot;&gt;the template&lt;/a&gt; by clicking “Use this
template”.&lt;/p&gt;

&lt;p&gt;Now to clone your newly created extension repo (including its submodules) and initialize the template:&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;git clone&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--recurse-submodules&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    https://github.com/⟨your_username⟩/⟨your_extension_repo⟩
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;your-extension-repo
./scripts/bootstrap-template.py url_parser
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, to confirm everything works as expected, run the tests:&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;make test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;adding-functionality&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#adding-functionality&quot;&gt;Adding Functionality&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In its current state, the extension is, of course, a little boring. Therefore, let&#39;s add some functionality! To keep
things simple, we&#39;ll add a scalar function that parses a URL and returns the scheme. We&#39;ll call the
function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;url_scheme&lt;/code&gt;. We start by adding a dependency to the boost url library in our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vcpkg.json&lt;/code&gt; file:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dependencies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;boost-url&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, we follow up with changing our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CMakelists.txt&lt;/code&gt; to ensure our dependencies are correctly included in the build.&lt;/p&gt;

&lt;div class=&quot;language-cmake highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;find_package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Boost REQUIRED COMPONENTS url&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;target_link_libraries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;EXTENSION_NAME&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; Boost::url&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;target_link_libraries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;LOADABLE_EXTENSION_NAME&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; Boost::url&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;src/url_parser_extension.cpp&lt;/code&gt;, we remove the default example functions and replace them with our
implementation of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;url_scheme&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kr&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;UrlParserScalarFun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataChunk&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExpressionState&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name_vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;UnaryExecutor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;boost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url_view&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parse_result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_uri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url_string&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;has_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;has_scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scheme&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parse_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StringVector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AddString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LoadInternal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DatabaseInstance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url_parser_scalar_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ScalarFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;url_scheme&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogicalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogicalType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UrlParserScalarFun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ExtensionUtil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RegisterFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url_parser_scalar_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With our extension written, we can run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt; to build both DuckDB and the extension. After the build is finished, we
are ready to try out our extension. Since the build process also builds a fresh DuckDB binary with the extension loaded
automatically, all we need to do is run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./build/release/duckdb&lt;/code&gt;, and we can use our newly added scalar function:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;url_scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;https://github.com/duckdb/duckdb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, as we are well-behaved developers, we add some tests by overwriting the default test &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test/sql/url_parser.test&lt;/code&gt;
with:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;require&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url_parser&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Confirm&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extension&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;works&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;url_scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;https://github.com/duckdb/duckdb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;----&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;On&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finding&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;also&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;url_scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;not:\a/valid_url&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;----&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now all that&#39;s left to do is confirm everything works as expected with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make test&lt;/code&gt;, and push these changes to the remote
repository. Then, GitHub Actions will take over and ensure the extension is built for all of DuckDB&#39;s supported
platforms.&lt;/p&gt;

&lt;p&gt;For more details, check out the template repository. Also, the example extension we built in this blog is published
&lt;a href=&quot;https://github.com/samansmink/url-parse-extension&quot;&gt;here&lt;/a&gt;. Note that in the demo, the Wasm and MinGW builds have been
&lt;a href=&quot;https://github.com/samansmink/url-parse-extension/blob/935c4273eea174d99d25be156d4bfea8f55abfa6/.github/workflows/MainDistributionPipeline.yml#L21&quot;&gt;disabled&lt;/a&gt;
due to &lt;a href=&quot;https://github.com/microsoft/vcpkg/issues/35408&quot;&gt;outstanding&lt;/a&gt; &lt;a href=&quot;https://github.com/microsoft/vcpkg/issues/35549&quot;&gt;issues&lt;/a&gt;
with the boost-url dependency for building on these platforms. As these issues are fixed upstream, re-enabling their builds
for the extension is very simple. Of course, as the author of this extension, it could make a lot of sense to fix these compile issues
yourself in vcpkg and fix them not only for this extension, but for the whole open-source community!&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/22/dependency-management.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we&#39;ve explored DuckDB&#39;s journey towards managing dependencies in its extension ecosystem while
upholding its core philosophy of zero external dependencies. By leveraging the power of extensions, DuckDB can maintain
its portability and embeddability while still providing essential features that require external dependencies. To
simplify managing dependencies, Microsoft&#39;s vcpkg is integrated into DuckDB&#39;s extension build systems both for
DuckDB-maintained extension and third-party extensions.&lt;/p&gt;

&lt;p&gt;If this blog post sparked your interest in creating your own DuckDB extension, check out
the &lt;a href=&quot;https://github.com/duckdb/extension-template&quot;&gt;C++ Extension Template&lt;/a&gt;,
the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/overview.html&quot;&gt;DuckDB docs on extensions&lt;/a&gt;,
and the very handy &lt;a href=&quot;https://github.com/mehd-io/duckdb-extension-radar&quot;&gt;duckdb-extension-radar repository&lt;/a&gt; that tracks public DuckDB extensions.
Additionally, DuckDB has a &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Discord server&lt;/a&gt; where you can ask for help on
extensions or anything DuckDB-related in general.&lt;/p&gt;

</description><link>https://duckdb.org/2024/03/22/dependency-management.html</link><guid isPermaLink="false">https://duckdb.org/2024/03/22/dependency-management.html</guid><pubDate>Fri, 22 Mar 2024 00:00:00 GMT</pubDate><author>Sam Ansmink</author></item><item><title>SQL Gymnastics: Bending SQL into Flexible New Shapes</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: Combining multiple features of DuckDB’s &lt;a href=&quot;https://duckdb.org/docs/guides/sql_features/friendly_sql&quot;&gt;friendly SQL&lt;/a&gt; allows for highly flexible queries that can be reused across tables.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duck_gymnast.jpg&quot; alt=&quot;Duck Gymnast&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html&quot;&gt;especially&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html&quot;&gt;friendly&lt;/a&gt; &lt;a href=&quot;https://duckdb.org/docs/stable/sql/dialect/friendly_sql.html&quot;&gt;SQL dialect&lt;/a&gt; simplifies common query operations.
However, these features also unlock new and flexible ways to write advanced SQL! 
In this post we will combine multiple friendly features to both move closer to real-world use cases and stretch your imagination.
These queries are useful in their own right, but their component pieces are even more valuable to have in your toolbox.&lt;/p&gt;

&lt;p&gt;What is the craziest thing you have built with SQL? 
We want to hear about it! 
Tag &lt;a href=&quot;https://twitter.com/duckdb&quot;&gt;DuckDB on X&lt;/a&gt; (the site formerly known as Twitter) or &lt;a href=&quot;https://www.linkedin.com/company/duckdb/mycompany/&quot;&gt;LinkedIn&lt;/a&gt;, and join the &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;DuckDB Discord community&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;traditional-sql-is-too-rigid-to-reuse&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#traditional-sql-is-too-rigid-to-reuse&quot;&gt;Traditional SQL Is Too Rigid to Reuse&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;SQL queries are typically crafted specifically for the unique tables within a database.
This limits reusability. 
For example, have you ever seen a library of high-level SQL helper functions?
SQL as a language typically is not flexible enough to build reusable functions.
Today, we are flying towards a more flexible future!&lt;/p&gt;
      &lt;h2 id=&quot;dynamic-aggregates-macro&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#dynamic-aggregates-macro&quot;&gt;Dynamic Aggregates Macro&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In SQL, typically the columns to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; must be specified individually. 
However, in many business intelligence workloads, groupings and aggregate functions must be easily user-adjustable.
Imagine an interactive charting workflow – first I want to plot total company revenue over time.
Then if I see a dip in revenue in that first plot, I want to adjust the plot to group the revenue by business unit to see which section of the company caused the issue.
This typically requires templated SQL, using a language that compiles down to SQL (like &lt;a href=&quot;https://www.malloydata.dev/&quot;&gt;Malloy&lt;/a&gt;), or building a SQL string using another programming language.
How much we can do with just SQL?&lt;/p&gt;

&lt;p&gt;Let&#39;s have a look at a flexible SQL-only approach and then break down how it is constructed.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
    First we will create an example data table. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;col1&lt;/code&gt; is unique on each row, but the other columns are various groupings of the rows. 
&lt;/summary&gt;

  &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col4&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
&lt;/details&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;col1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;col2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;col3&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;col4&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;creating-the-macro&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#creating-the-macro&quot;&gt;Creating the Macro&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The macro below accepts lists of columns to include or exclude, a list of columns to aggregate, and an aggregate function to apply.
All of these can be passed in as parameters from the host language that is querying the database.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- We use a table macro (or function) for reusability&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dynamic_aggregates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;included_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;excluded_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;aggregated_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;aggregate_function&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;c1&quot;&gt;-- Use a COLUMNS expression to only select the columns&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;-- we include or do not exclude&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;-- If we are not using an input parameter (list is empty),&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;-- ignore it&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list_contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;included_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
             &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;included_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;excluded_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
             &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;excluded_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;-- Use the list_aggregate function to apply an aggregate&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;-- function of our choice&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;list_aggregate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;-- Convert to a list (to enable the use of list_aggregate)&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;-- Use a COLUMNS expression to choose which columns&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;-- to aggregate&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aggregated_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aggregate_function&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- Group by all selected but non-aggregated columns&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- Order by each column from left to right &lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;executing-the-macro&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#executing-the-macro&quot;&gt;Executing the Macro&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Now we can use that macro for many different aggregation operations.
For illustrative purposes, the 3 queries below show different ways to achieve identical results.&lt;/p&gt;

&lt;p&gt;Select col3 and col4, and take the minimum values of col1 and col2:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dynamic_aggregates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;col3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;col4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;col1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;col2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;min&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Select all columns except col1 and col2, and take the minimum values of col1 and col2:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dynamic_aggregates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;col1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;col2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;col1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;col2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;min&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If the same column is in both the included and excluded list, it is excluded (exclusions win ties).
If we include col2, col3, and col4, but we exclude col2, then it is as if we only included col3 and col4:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dynamic_aggregates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;col2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;col3&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;col4&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;col2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;col1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;col2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;min&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Executing either of those queries will return this result:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;col3&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;col4&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;list_aggregate(list(example.col1), &#39;min&#39;)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;list_aggregate(list(example.col2), &#39;min&#39;)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h4 id=&quot;understanding-the-design&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#understanding-the-design&quot;&gt;Understanding the Design&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The first step of our flexible &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_macro.html#table-macros&quot;&gt;table macro&lt;/a&gt; is to choose a specific table using DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#from-first-in-select-statements&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;-first syntax&lt;/a&gt;.
Well that&#39;s not very dynamic!
If we wanted to, we could work around this by creating a copy of this macro for each table we want to expose to our application.
However, we will show another approach in our next example, and completely solve the issue in a follow up blog post with an in-development DuckDB feature.
Stay tuned!&lt;/p&gt;

&lt;p&gt;Then we &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; our grouping columns based on the list parameters that were passed in.
The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/expressions/star.html#columns-expression&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression&lt;/a&gt; will execute a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/lambda.html&quot;&gt;lambda function&lt;/a&gt; to decide which columns meet the criteria to be selected.&lt;/p&gt;

&lt;p&gt;The first portion of the lambda function checks if a column name was passed in within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;included_columns&lt;/code&gt; list.
However, if we choose not to use an inclusion rule (by passing in a blank &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;included_columns&lt;/code&gt; list), we want to ignore that parameter.
If the list is blank, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;len(included_columns) = 0&lt;/code&gt; will evaluate to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;true&lt;/code&gt; and effectively disable the filtering on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;included_columns&lt;/code&gt;.
This is a common pattern for optional filtering that is generically useful across a variety of SQL queries.
(Shout out to my mentor and friend Paul Bloomquist for teaching me this pattern!)&lt;/p&gt;

&lt;p&gt;We repeat that pattern for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;excluded_columns&lt;/code&gt; so that it will be used if populated, but ignored if left blank.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;excluded_columns&lt;/code&gt; list will also win ties, so that if a column is in both lists, it will be excluded.&lt;/p&gt;

&lt;p&gt;Next, we apply our aggregate function to the columns we want to aggregate.
It is easiest to follow the logic of this part of the query by working from the innermost portion outward.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression will acquire the columns that are in our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aggregated_columns&lt;/code&gt; list.
Then, we do a little bit of gymnastics (it had to happen sometime…).&lt;/p&gt;

&lt;p&gt;If we were to apply a typical aggregation function (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;), it would need to be specified statically in our macro.
To pass it in dynamically as a string (potentially all the way from the application code calling this SQL statement), we take advantage of a unique property of the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/nested.html#list-aggregates&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_aggregate&lt;/code&gt; function&lt;/a&gt;.
It accepts the name of a function (as a string) in its second parameter.
So, to use this unique property, we use the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html#general-aggregate-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list&lt;/code&gt; aggregate function&lt;/a&gt; to transform all the values within each group into a list.
Then we use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_aggregate&lt;/code&gt; function to apply the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aggregate_function&lt;/code&gt; we passed into the macro to each list.&lt;/p&gt;

&lt;p&gt;Almost done!
Now &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/groupby.html#group-by-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY ALL&lt;/code&gt;&lt;/a&gt; will automatically choose to group by the columns returned by the first &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression.
The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/orderby.html#order-by-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY ALL&lt;/code&gt;&lt;/a&gt; expression will order each column in ascending order, moving from left to right.&lt;/p&gt;

&lt;p&gt;We made it!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Extra credit! In the next release of DuckDB, version 0.10.1, we will be able to &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10774&quot;&gt;apply a dynamic alias&lt;/a&gt; to the result of a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression.
For example, each new aggregate column could be renamed in the pattern &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;agg_[the original column name]&lt;/code&gt;.
This will unlock the ability to chain together these type of macros, as the naming will be predictable.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h4 id=&quot;takeaways&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#takeaways&quot;&gt;Takeaways&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Several of the approaches used within this macro can be applied in a variety of ways in your SQL workflows.
Using a lambda function in combination with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression can allow you to select any arbitrary list of columns.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OR len(my_list) = 0&lt;/code&gt; trick allows list parameters to be ignored when blank.
Once you have that arbitrary set of columns, you can even apply a dynamically chosen aggregation function to those columns using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_aggregate&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;However, we still had to specify a table at the start.
We are also limited to aggregate functions that are available to be used with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_aggregate&lt;/code&gt;.
Let&#39;s relax those two constraints!&lt;/p&gt;
      &lt;h3 id=&quot;creating-version-2-of-the-macro&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#creating-version-2-of-the-macro&quot;&gt;Creating Version 2 of the Macro&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;This approach takes advantage of two key concepts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Macros can be used to create temporary aggregate functions&lt;/li&gt;
  &lt;li&gt;A macro can query a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/with.html&quot;&gt;Common Table Expression (CTE) / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH&lt;/code&gt; clause&lt;/a&gt; that is in scope during execution&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dynamic_aggregates_any_cte_any_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;included_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;excluded_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;aggregated_columns&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* No more aggregate_function */&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any_cte&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;-- No longer a fixed table!&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list_contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;included_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;included_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; 
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;excluded_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;excluded_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;-- We no longer convert to a list, &lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;-- and we refer to the latest definition of any_func &lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;any_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list_contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aggregated_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;executing-version-2&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#executing-version-2&quot;&gt;Executing Version 2&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;When we call this macro, there is additional complexity.
We no longer execute a single statement, and our logic is no longer completely parameterizable (so some templating or SQL construction will be needed).
However, we can execute this macro against any arbitrary CTE, using any arbitrary aggregation function.
Pretty powerful and very reusable!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- We can define or redefine any_func right before calling the macro &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TEMP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FUNCTION&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;any_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Any table structure is valid for this CTE!&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any_cte&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;another_group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one_big_group&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dynamic_aggregates_any_cte_any_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;another_group&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;one_big_group&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;id&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_group&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;another_group&lt;/th&gt;
      &lt;th&gt;one_big_group&lt;/th&gt;
      &lt;th&gt;any_func(any_cte.id)&lt;/th&gt;
      &lt;th&gt;any_func(any_cte.my_group)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;502.0&lt;/td&gt;
      &lt;td&gt;200.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;490.0&lt;/td&gt;
      &lt;td&gt;200.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h4 id=&quot;understanding-version-2&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#understanding-version-2&quot;&gt;Understanding Version 2&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Instead of querying the very boldly named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;example&lt;/code&gt; table, we query the possibly more generically named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_cte&lt;/code&gt;.
Note that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_cte&lt;/code&gt; has a different schema than our prior example – the columns in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_cte&lt;/code&gt; can be anything!
When the macro is created, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_cte&lt;/code&gt; doesn&#39;t even exist.
When the macro is executed, it searches for a table-like object named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_cte&lt;/code&gt;, and it was defined in the CTE as the macro was called.&lt;/p&gt;

&lt;p&gt;Similarly, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_func&lt;/code&gt; does not exist initially.
It only needs to be created (or recreated) at some point before the macro is executed.
Its only requirements are to be an aggregate function that operates on a single column.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FUNCTION&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MACRO&lt;/code&gt; are synonyms in DuckDB and can be used interchangeably!&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h4 id=&quot;takeaways-from-version-2&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#takeaways-from-version-2&quot;&gt;Takeaways from Version 2&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;A macro can act on any arbitrary table by using a CTE at the time it is called.
This makes our macro far more reusable – it can work on any table!
Not only that, but any custom aggregate function can be used.&lt;/p&gt;

&lt;p&gt;Look how far we have stretched SQL – we have made a truly reusable SQL function!
The table is dynamic, the grouping columns are dynamic, the aggregated columns are dynamic, and so is the aggregate function.
Our daily gymnastics stretches have paid off.
However, stay tuned for a way to achieve similar results with a simpler approach in a future post.&lt;/p&gt;
      &lt;h2 id=&quot;custom-summaries-for-any-dataset&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#custom-summaries-for-any-dataset&quot;&gt;Custom Summaries for Any Dataset&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Next we have a truly production-grade example!
This query powers a portion of the MotherDuck Web UI&#39;s &lt;a href=&quot;https://motherduck.com/blog/introducing-column-explorer/&quot;&gt;Column Explorer&lt;/a&gt; component.
&lt;a href=&quot;https://www.linkedin.com/in/hamilton-ulmer-28b97817/&quot;&gt;Hamilton Ulmer&lt;/a&gt; led the creation of this component and is the author of this query as well!
The purpose of the Column Explorer, and this query, is to get a high-level overview of the data in all columns within a dataset as quickly and easily as possible.&lt;/p&gt;

&lt;p&gt;DuckDB has a built-in &lt;a href=&quot;https://duckdb.org/docs/stable/guides/meta/summarize.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt; keyword&lt;/a&gt; that can calculate similar metrics across an entire table.
However, for larger datasets, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt; can take a couple of seconds to load.
This query provides a custom summarization capability that can be tailored to the properties of your data that you are most interested in.&lt;/p&gt;

&lt;p&gt;Traditionally, databases required that every column be referred to explicitly, and work best when data is arranged in separate columns.
This query takes advantage of DuckDB&#39;s ability to apply functions to all columns at once, its ability to &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/unpivot.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt;&lt;/a&gt; (or stack) columns, and its &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/struct.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt;&lt;/a&gt; data type to store key/value pairs.
The result is a clean, pivoted summary of all the rows and columns in a table.&lt;/p&gt;

&lt;p&gt;Let&#39;s take a look at the entire function, then break it down piece by piece.&lt;/p&gt;

&lt;p&gt;This &lt;a href=&quot;https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset&quot;&gt;example dataset&lt;/a&gt; comes from &lt;a href=&quot;https://huggingface.co/&quot;&gt;Hugging Face&lt;/a&gt;, which hosts &lt;a href=&quot;https://huggingface.co/blog/hub-duckdb&quot;&gt;DuckDB-accessible Parquet files&lt;/a&gt; for many of their datasets.
First, we create a local table populated from this remote Parquet file.&lt;/p&gt;
      &lt;h3 id=&quot;creation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#creation&quot;&gt;Creation&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spotify_tracks&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset/resolve/refs%2Fconvert%2Fparquet/default/train/0000.parquet?download=true&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then we create and execute our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;custom_summarize&lt;/code&gt; macro.
We use the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_cte&lt;/code&gt; trick from above to allow this to be reused on any query result or table.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;custom_summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any_cte&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;typeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;approx_unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;approx_count_distinct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;nulls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stacked_metrics&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;UNPIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stacked_metrics&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;execution&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#execution&quot;&gt;Execution&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spotify_tracks&lt;/code&gt; dataset is effectively renamed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any_cte&lt;/code&gt; and then summarized.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any_cte&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spotify_tracks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;custom_summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result contains one row for every column in the raw dataset, and several columns of summary statistics.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;approx_unique&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;nulls&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Unnamed: 0&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;113999&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;114089&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;track_id&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;7zz7iNGIWhmfFE7zlXkMma&lt;/td&gt;
      &lt;td&gt;0000vdREvCVMxbQTkS888c&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;89815&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;artists&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;龍藏Ryuzo&lt;/td&gt;
      &lt;td&gt;!nvite&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;31545&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;album_name&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;당신이 잠든 사이에 Pt. 4 Original Television Soundtrack&lt;/td&gt;
      &lt;td&gt;! ! ! ! ! Whispers ! ! ! ! !&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;47093&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;track_name&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;행복하길 바래&lt;/td&gt;
      &lt;td&gt;!I&#39;ll Be Back!&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;72745&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;popularity&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;99&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;duration_ms&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;5237295&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;50168&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;explicit&lt;/td&gt;
      &lt;td&gt;BOOLEAN&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;danceability&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.985&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1180&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;energy&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2090&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;key&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;loudness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;4.532&lt;/td&gt;
      &lt;td&gt;-49.531&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19436&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mode&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;speechiness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.965&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1475&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;acousticness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.996&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4976&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;instrumentalness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5302&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;liveness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1717&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;valence&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.995&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1787&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;tempo&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;243.372&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;46221&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;time_signature&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;track_genre&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;world-music&lt;/td&gt;
      &lt;td&gt;acoustic&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;115&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So how was this query constructed? 
Let&#39;s break down each CTE step by step.&lt;/p&gt;
      &lt;h3 id=&quot;step-by-step-breakdown&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#step-by-step-breakdown&quot;&gt;Step by Step Breakdown&lt;/a&gt;
        
      &lt;/h3&gt;
    
      &lt;h4 id=&quot;metrics-cte&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#metrics-cte&quot;&gt;Metrics CTE&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;First let&#39;s have a look at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;metrics&lt;/code&gt; CTE and the shape of the data that is returned:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;any_cte&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;typeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;approx_unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;approx_count_distinct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nulls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;main.struct_pack(&quot;name&quot; := first(alias(subset.&quot;Unnamed: 0&quot;)), …&lt;/th&gt;
      &lt;th&gt;main.struct_pack(&quot;name&quot; := first(alias(subset.track_id)), …&lt;/th&gt;
      &lt;th&gt;…&lt;/th&gt;
      &lt;th&gt;main.struct_pack(&quot;name&quot; := first(alias(subset.time_signature)), …&lt;/th&gt;
      &lt;th&gt;main.struct_pack(&quot;name&quot; := first(alias(subset.track_genre)), …&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;{&#39;name&#39;: Unnamed: 0, &#39;type&#39;: BIGINT, &#39;max&#39;: 113999, &#39;min&#39;: 0, &#39;approx_unique&#39;: 114089, &#39;nulls&#39;: 0}&lt;/td&gt;
      &lt;td&gt;{&#39;name&#39;: track_id, &#39;type&#39;: VARCHAR, &#39;max&#39;: 7zz7iNGIWhmfFE7zlXkMma, &#39;min&#39;: 0000vdREvCVMxbQTkS888c, &#39;approx_unique&#39;: 89815, &#39;nulls&#39;: 0}&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;{&#39;name&#39;: time_signature, &#39;type&#39;: BIGINT, &#39;max&#39;: 5, &#39;min&#39;: 0, &#39;approx_unique&#39;: 5, &#39;nulls&#39;: 0}&lt;/td&gt;
      &lt;td&gt;{&#39;name&#39;: track_genre, &#39;type&#39;: VARCHAR, &#39;max&#39;: world-music, &#39;min&#39;: acoustic, &#39;approx_unique&#39;: 115, &#39;nulls&#39;: 0}&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This intermediate result maintains the same number of columns as the original dataset, but only returns a single row of summary statistics.
The names of the columns are truncated due to their length.
The default naming of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expressions will be improved in DuckDB 0.10.1, so names will be much cleaner!&lt;/p&gt;

&lt;p&gt;The data in each column is organized into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; of key-value pairs. 
You can also see that a clean name of the original column is stored within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; thanks to the use of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alias&lt;/code&gt; function.
While we have calculated the summary statistics, the format of those statistics is difficult to visually interpret.&lt;/p&gt;

&lt;p&gt;The query achieves this structure using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS(*)&lt;/code&gt; expression to apply multiple summary metrics to all columns, and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{...}&lt;/code&gt; syntax to create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt;.
The keys of the struct represent the names of the metrics (and what we want to use as the column names in the final result). 
We use this approach since we want to transpose the columns to rows and then split the summary metrics into their own columns.&lt;/p&gt;
      &lt;h4 id=&quot;stacked_metrics-cte&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#stacked_metrics-cte&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stacked_metrics&lt;/code&gt; CTE&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Next, the data is unpivoted to reshape the table from one row and multiple columns to two columns and multiple rows.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;UNPIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;main.struct_pack(&quot;name&quot; := first(alias(spotify_tracks.&quot;Unnamed: 0&quot;)), …&lt;/td&gt;
      &lt;td&gt;{&#39;name&#39;: Unnamed: 0, &#39;type&#39;: BIGINT, &#39;max&#39;: 113999, &#39;min&#39;: 0, &#39;approx_unique&#39;: 114089, &#39;nulls&#39;: 0}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;main.struct_pack(&quot;name&quot; := first(alias(spotify_tracks.track_id)), …&lt;/td&gt;
      &lt;td&gt;{&#39;name&#39;: track_id, &#39;type&#39;: VARCHAR, &#39;max&#39;: 7zz7iNGIWhmfFE7zlXkMma, &#39;min&#39;: 0000vdREvCVMxbQTkS888c, &#39;approx_unique&#39;: 89815, &#39;nulls&#39;: 0}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;main.struct_pack(&quot;name&quot; := first(alias(spotify_tracks.time_signature)), …&lt;/td&gt;
      &lt;td&gt;{&#39;name&#39;: time_signature, &#39;type&#39;: BIGINT, &#39;max&#39;: 5, &#39;min&#39;: 0, &#39;approx_unique&#39;: 5, &#39;nulls&#39;: 0}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;main.struct_pack(&quot;name&quot; := first(alias(spotify_tracks.track_genre)), …&lt;/td&gt;
      &lt;td&gt;{&#39;name&#39;: track_genre, &#39;type&#39;: VARCHAR, &#39;max&#39;: world-music, &#39;min&#39;: acoustic, &#39;approx_unique&#39;: 115, &#39;nulls&#39;: 0}&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;By unpivoting on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS(*)&lt;/code&gt;, we take all columns and pivot them downward into two columns: one for the auto-generated &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;name&lt;/code&gt; of the column, and one for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value&lt;/code&gt; that was within that column.&lt;/p&gt;
      &lt;h4 id=&quot;return-the-results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#return-the-results&quot;&gt;Return the Results&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The final step is the most gymnastics-like portion of this query.
We explode the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;value&lt;/code&gt; column&#39;s struct format so that each key becomes its own column using the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/struct.html#struct&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT.*&lt;/code&gt; syntax&lt;/a&gt;.
This is another way to make a query less reliant on column names – the split occurs automatically based on the keys in the struct.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stacked_metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We have now split apart the data into multiple columns, so the summary metrics are nice and interpretable.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;approx_unique&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;nulls&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Unnamed: 0&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;113999&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;114089&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;track_id&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;7zz7iNGIWhmfFE7zlXkMma&lt;/td&gt;
      &lt;td&gt;0000vdREvCVMxbQTkS888c&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;89815&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;artists&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;龍藏Ryuzo&lt;/td&gt;
      &lt;td&gt;!nvite&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;31545&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;album_name&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;당신이 잠든 사이에 Pt. 4 Original Television Soundtrack&lt;/td&gt;
      &lt;td&gt;! ! ! ! ! Whispers ! ! ! ! !&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;47093&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;track_name&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;행복하길 바래&lt;/td&gt;
      &lt;td&gt;!I&#39;ll Be Back!&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;72745&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;popularity&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;99&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;duration_ms&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;5237295&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;50168&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;explicit&lt;/td&gt;
      &lt;td&gt;BOOLEAN&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;danceability&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.985&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1180&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;energy&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2090&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;key&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;loudness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;4.532&lt;/td&gt;
      &lt;td&gt;-49.531&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19436&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mode&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;speechiness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.965&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1475&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;acousticness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.996&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4976&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;instrumentalness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5302&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;liveness&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1717&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;valence&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;0.995&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1787&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;tempo&lt;/td&gt;
      &lt;td&gt;DOUBLE&lt;/td&gt;
      &lt;td&gt;243.372&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;46221&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;time_signature&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;track_genre&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;world-music&lt;/td&gt;
      &lt;td&gt;acoustic&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;115&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/03/01/sql-gymnastics.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We have shown that it is now possible to build reusable SQL macros in a highly flexible way. 
You can now build a macro that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Operates on any dataset&lt;/li&gt;
  &lt;li&gt;Selects any columns&lt;/li&gt;
  &lt;li&gt;Groups by any columns&lt;/li&gt;
  &lt;li&gt;Aggregates any number of columns with any function.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Phew!&lt;/p&gt;

&lt;p&gt;Along the way we have covered some useful tricks to have in your toolbox:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Applying a macro to any dataset using a CTE&lt;/li&gt;
  &lt;li&gt;Selecting a dynamic list of columns by combining the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression with a lambda and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_contains&lt;/code&gt; function&lt;/li&gt;
  &lt;li&gt;Passing in an aggregate function as a string using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_aggregate&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Applying any custom aggregation function within a macro&lt;/li&gt;
  &lt;li&gt;Making list parameters optional using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OR len(list_parameter) = 0&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alias&lt;/code&gt; function with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression to store the original name of all columns&lt;/li&gt;
  &lt;li&gt;Summarizing all columns and then transposing that summary using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT.*&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The combination of these friendly SQL features is more powerful than using any one individually.
We hope that we have inspired you to take your SQL to new limits!&lt;/p&gt;

&lt;p&gt;As always, we welcome your feedback and suggestions. 
We also have more flexibility in mind that will be demonstrated in future posts.
Please share the times you have stretched SQL in imaginative ways!&lt;/p&gt;

&lt;p&gt;Happy analyzing!&lt;/p&gt;

</description><link>https://duckdb.org/2024/03/01/sql-gymnastics.html</link><guid isPermaLink="false">https://duckdb.org/2024/03/01/sql-gymnastics.html</guid><pubDate>Fri, 01 Mar 2024 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>Announcing DuckDB 0.10.0</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The DuckDB team is happy to announce the latest DuckDB release (0.10.0). This release is named Fusca after the &lt;a href=&quot;https://en.wikipedia.org/wiki/Velvet_scoter&quot;&gt;Velvet scoter&lt;/a&gt; native to Europe.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/velvet-scoter-duck.jpg&quot; alt=&quot;Image of the Velvet Scoter&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;. The full release notes can be found &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.10.0&quot;&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;whats-new-in-0100&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#whats-new-in-0100&quot;&gt;What&#39;s New in 0.10.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There have been too many changes to discuss them each in detail, but we would like to highlight several particularly exciting features!&lt;/p&gt;

&lt;p&gt;Below is a summary of those new features with examples, starting with a change in our SQL dialect that is designed to produce more intuitive results by default.&lt;/p&gt;
      &lt;h2 id=&quot;breaking-sql-changes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#breaking-sql-changes&quot;&gt;Breaking SQL Changes&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10115&quot;&gt;&lt;strong&gt;Implicit Cast to VARCHAR&lt;/strong&gt;&lt;/a&gt;. Previously, DuckDB would automatically allow any type to be implicitly cast to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; during function binding. As a result it was possible to e.g., compute the substring of an integer without using an implicit cast. Starting with this release, you will need to use an explicit cast here instead.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;No function matches the given name and argument types &#39;substring(...)&#39;.
You might need to add explicit type casts.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To use an explicit cast, run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────┐
│ substr  │
│ varchar │
├─────────┤
│ 4       │
└─────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;old_implicit_casting&lt;/code&gt; setting can be used to revert this behavior, e.g.:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;old_implicit_casting&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────┐
│ substr  │
│ varchar │
├─────────┤
│ 4       │
└─────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10194&quot;&gt;&lt;strong&gt;Literal Typing&lt;/strong&gt;&lt;/a&gt;. Previously, integer and string literals behaved identically to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; types. Starting with this release, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER_LITERAL&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRING_LITERAL&lt;/code&gt; are separate types that have their own binding rules.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER_LITERAL&lt;/code&gt; types can be implicitly converted to any integer type in which the value fits&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRING_LITERAL&lt;/code&gt; types can be implicitly converted to &lt;strong&gt;any&lt;/strong&gt; other type&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This aligns DuckDB with Postgres, and makes operations on literals more intuitive. For example, we can compare string literals with dates – but we cannot compare &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; values with dates.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1992-01-01&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1992-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────┐
│ result  │
│ boolean │
├─────────┤
│ false   │
└─────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1992-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1992-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Binder Error:
Cannot compare values of type DATE and type VARCHAR – an explicit cast is required
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;backward-compatibility&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#backward-compatibility&quot;&gt;Backward Compatibility&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Backward compatibility refers to the ability of a newer DuckDB version to read storage files created by an older DuckDB version. This release is the first release of DuckDB that supports backward compatibility in the storage format. DuckDB v0.10 can read and operate on files created by the previous DuckDB version – DuckDB v0.9. &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8156&quot;&gt;This is made possible by the implementation of a new serialization framework&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Write with v0.9:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;duckdb_092 v092.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Read with v0.10:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;duckdb_0100 v092.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_partkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_comment&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────┬───────────┬─────────────────────────┐
│ l_orderkey │ l_partkey │        l_comment        │
│   int32    │   int32   │         varchar         │
├────────────┼───────────┼─────────────────────────┤
│          1 │    155190 │ to beans x-ray carefull │
└────────────┴───────────┴─────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For future DuckDB versions, our goal is to ensure that any DuckDB version released &lt;strong&gt;after&lt;/strong&gt; can read files created by previous versions, starting from this release. We want to ensure that the file format is fully backward compatible. This allows you to keep data stored in DuckDB files around and guarantees that you will be able to read the files without having to worry about which version the file was written with or having to convert files between versions.&lt;/p&gt;
      &lt;h2 id=&quot;forward-compatibility&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#forward-compatibility&quot;&gt;Forward Compatibility&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Forward compatibility refers to the ability of an older DuckDB version to read storage files produced by a newer DuckDB version. DuckDB v0.9 is &lt;strong&gt;partially&lt;/strong&gt; forward compatible with DuckDB v0.10. Certain files created by DuckDB v0.10 can be read by DuckDB v0.9.&lt;/p&gt;

&lt;p&gt;Write with v0.10:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;duckdb_0100 v010.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Read with v0.9:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;duckdb_092 v010.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_partkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_comment&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────┬───────────┬─────────────────────────┐
│ l_orderkey │ l_partkey │        l_comment        │
│   int32    │   int32   │         varchar         │
├────────────┼───────────┼─────────────────────────┤
│          1 │    155190 │ to beans x-ray carefull │
└────────────┴───────────┴─────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Forward compatibility is provided on a &lt;strong&gt;best effort&lt;/strong&gt; basis. While stability of the storage format is important – there are still many improvements and innovations that we want to make to the storage format in the future. As such, forward compatibility may be (partially) broken on occasion.&lt;/p&gt;

&lt;p&gt;For this release, DuckDB v0.9 is able to read files created by DuckDB v0.10 provided that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The database file does not contain views&lt;/li&gt;
  &lt;li&gt;The database file does not contain new types (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARRAY&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UHUGEINT&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;The database file does not contain indexes (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRIMARY KEY&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FOREIGN KEY&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNIQUE&lt;/code&gt;, explicit indexes)&lt;/li&gt;
  &lt;li&gt;The database file does not contain new compression methods (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALP&lt;/code&gt;). As ALP is automatically used to compress &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt; columns – that means forward compatibility in practice often does not work for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt; columns unless &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALP&lt;/code&gt; is explicitly disabled through configuration.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We expect that as the format stabilizes and matures this will happen less frequently – and we hope to offer better guarantees in allowing DuckDB to read files written by future DuckDB versions.&lt;/p&gt;
      &lt;h2 id=&quot;csv-reader-rework&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#csv-reader-rework&quot;&gt;CSV Reader Rework&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10209&quot;&gt;CSV Reader Rework&lt;/a&gt;.&lt;/strong&gt; The CSV reader has received a major overhaul in this release. The new CSV reader uses efficient state machine transitions to speed through CSV files. This has greatly sped up performance of the CSV reader, particularly in multi-threaded scenarios. In addition, in the case of malformed CSV files, reported error messages should be more clear.&lt;/p&gt;

&lt;p&gt;Below is a benchmark comparing the loading time of 11 million rows of the NYC Taxi dataset from a CSV file on an M1 Max with 10 cores:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Version&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Load time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.9.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.6 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.10.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.2 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Furthermore, many optimizations have been done that make running queries over CSV files directly significantly faster as well. Below is a benchmark comparing the execution time of a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT count(*)&lt;/code&gt; query directly over the NYC Taxi CSV file.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Version&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Query time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.9.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.8 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.10.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.3 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;fixed-length-arrays&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#fixed-length-arrays&quot;&gt;Fixed-Length Arrays&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8983&quot;&gt;Fixed-Length Arrays&lt;/a&gt;.&lt;/strong&gt; This release introduces the fixed-length array type. Fixed-length arrays are similar to lists, however, every value must have the same fixed number of elements in them.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DOUBLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Fixed-length arrays can be operated on faster than variable-length lists as the size of each list element is known ahead of time. This release also introduces specialized functions that operate over these arrays, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cross_product&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_cosine_similarity&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;array_inner_product&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;array_cross_product&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────┐
│      result       │
│     double[3]     │
├───────────────────┤
│ [-1.0, 2.0, -1.0] │
└───────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/array.html&quot;&gt;Array Type page&lt;/a&gt; in the documentation for more information.&lt;/p&gt;
      &lt;h2 id=&quot;multi-database-support&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#multi-database-support&quot;&gt;Multi-Database Support&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB can now attach MySQL, Postgres, and SQLite databases in addition to databases stored in its own format. This allows data to be read into DuckDB and moved between these systems in a convenient manner, as attached databases are fully functional, appear just as regular tables, and can be updated in a safe, transactional manner. More information about multi-database support can be found in our &lt;a href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html&quot;&gt;recent blog post&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sqlite:sakila.db&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;postgres:dbname=postgresscanner&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;mysql:user=root database=mysqlscanner&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;secret-manager&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#secret-manager&quot;&gt;Secret Manager&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB integrates with several cloud storage systems such as S3 that require access credentials to access data. In the current version of DuckDB, authentication information is configured through DuckDB settings, e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SET s3_access_key_id = &#39;...&#39;;&lt;/code&gt;. While this worked, it had several shortcomings. For example, it was not possible to set different credentials for different S3 buckets without modifying the settings between queries. Because settings are not considered secret, it was also possible to query them using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb_settings()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;With this release, DuckDB adds a new &quot;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10042&quot;&gt;Secrets Manager&lt;/a&gt;&quot; to manage secrets in a better way. We now have a unified user interface for secrets across all backends that use them. Secrets can be scoped, so different storage prefixes can have different secrets, allowing, for example, joining across organizations in a single query. Secrets can also be persisted, so that they do not need to be specified every time DuckDB is launched.&lt;/p&gt;

&lt;p&gt;Secrets are typed, their type identifies which service they are for. For example, this release can manage secrets for S3, Google Cloud Storage, Cloudflare R2 and Azure Blob Storage. For each type, there are one or more &quot;secret providers&quot; that specify how the secret is created. Secrets can also have an optional scope, which is a file path prefix that the secret applies to. When fetching a secret for a path, the secret scopes are compared to the path, returning the matching secret for the path. In the case of multiple matching secrets, the longest prefix is chosen.&lt;/p&gt;

&lt;p&gt;Finally, secrets can be temporary or persistent. Temporary secrets are used by default – and are stored in-memory for the life span of the DuckDB instance similar to how settings worked previously. Persistent secrets are stored in unencrypted binary format in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.duckdb/stored_secrets&lt;/code&gt; directory. On startup of DuckDB, persistent secrets are read from this directory and automatically loaded.&lt;/p&gt;

&lt;p&gt;For example, to create a temporary unscoped secret to access S3, we can now use the following syntax:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;AKIAIOSFODNN7EXAMPLE&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;REGION&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;us-east-1&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If two secrets exist for a service type, the scope can be used to decide which one should be used. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;secret1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_key1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_secret1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SCOPE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;my_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;secret2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_key2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_secret2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SCOPE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s3://&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;my_other_bucket&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, if the user queries something from &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;ge&quot;&gt;my_other_bucket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;something&lt;/span&gt;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;secret2&lt;/code&gt; will be chosen automatically for that request.&lt;/p&gt;

&lt;p&gt;Secrets can be listed using the built-in table-producing function, e.g., by using &lt;code class=&quot;language-sql highlight highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duckdb_secrets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;/code&gt;. Sensitive information will be redacted.&lt;/p&gt;

&lt;p&gt;In order to persist secrets between DuckDB database instances, we can now use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE PERSISTENT SECRET&lt;/code&gt; command, e.g.:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PERSISTENT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_persistent_secret&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;KEY_ID&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_key&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SECRET&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_secret&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As mentioned, this will write the secret (unencrypted, so beware) to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.duckdb/stored_secrets&lt;/code&gt; directory.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_secret.html&quot;&gt;Create Secret page&lt;/a&gt; in the documentation for more information.&lt;/p&gt;
      &lt;h2 id=&quot;temporary-memory-manager&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#temporary-memory-manager&quot;&gt;Temporary Memory Manager&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB has support for larger-than-memory operations, which means that memory-hungry operators such as aggregations and joins can offload part of their intermediate results to temporary files on disk should there not be enough memory available.&lt;/p&gt;

&lt;p&gt;Before, those operators started offloading to disk if their memory usage reached around 60% of the available memory (as defined by the memory limit). This works well if there is exactly one of these operations happening at the same time. If multiple memory-intensive operations are happening simultaneously, their combined memory usage may exceed the memory limit, causing DuckDB to throw an error.&lt;/p&gt;

&lt;p&gt;This release introduces the so-called &quot;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10147&quot;&gt;Temporary Memory Manager&lt;/a&gt;&quot;, which manages the temporary memory of concurrent operations. It works as follows: Memory-intensive operations register themselves with the Temporary Manager. Each registration is guaranteed some minimum amount of memory by the manager depending on the number of threads and the current memory limit. Then, the memory-intensive operations communicate how much memory they would currently like to use. The manager can approve this or respond with a reduced allocation. In a case of a reduced allocation, the operator will need to dynamically reduce its memory requirements, for example by switching algorithms.&lt;/p&gt;

&lt;p&gt;For example, a hash join might adapt its operation and perform a partitioned hash join instead of a full in-memory one if not enough memory is available.&lt;/p&gt;

&lt;p&gt;Here is an example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;memory_limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;5GB&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;temp_directory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/tmp/duckdb_temporary_memory_manager&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
       &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that a temporary directory has to be set here, because the operators actually need to offload data to disk to complete this query given this memory limit.&lt;/p&gt;

&lt;p&gt;With the new version 0.10.0, this query completes in ca. 5s on a MacBook, while it would error out on the previous version with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Error: Out of Memory Error: failed to pin block of size ...&lt;/code&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;adaptive-lossless-floating-point-compression-alp&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#adaptive-lossless-floating-point-compression-alp&quot;&gt;Adaptive Lossless Floating-Point Compression (ALP)&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Floating point numbers are notoriously difficult to compress efficiently, both in terms of compression ratio as well as speed of compression and decompression. In the past, DuckDB had support for the then state-of-the-art &quot;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4878&quot;&gt;Chimp&lt;/a&gt;&quot; and the &quot;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5044&quot;&gt;Patas&lt;/a&gt;&quot; compression methods. Turns out, those were not the last word in floating point compression. Researchers &lt;a href=&quot;https://www.cwi.nl/en/people/azim-afroozeh/&quot;&gt;Azim Afroozeh&lt;/a&gt;, &lt;a href=&quot;https://www.cwi.nl/en/people/leonardo-xavier-kuffo-rivero/&quot;&gt;Leonard Kuffo&lt;/a&gt; and (the one and only) &lt;a href=&quot;https://homepages.cwi.nl/~boncz/&quot;&gt;Peter Boncz&lt;/a&gt; have recently published a paper titled &quot;&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/3626717&quot;&gt;ALP: Adaptive Lossless floating-Point Compression&lt;/a&gt;&quot; at SIGMOD, a top-tier academic conference for data management research. In an uncommon yet highly commendable move, they have also sent a &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9635&quot;&gt;pull request&lt;/a&gt; to DuckDB. The new compression scheme replaces Chimp and Patas. Inside DuckDB, ALP is &lt;strong&gt;x2-4 times faster&lt;/strong&gt; than Patas (at decompression) achieving &lt;strong&gt;compression ratios twice as high&lt;/strong&gt; (sometimes even much more).&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Compression&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Load&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Query&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Size&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ALP&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.434 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.020 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;184 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Patas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.603 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.080 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;275 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Uncompressed&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.316 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.012 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;489 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As a user, you don&#39;t have to do anything to make use of the new ALP compression method, DuckDB will automatically decide during checkpointing whether using ALP is beneficial for the specific dataset.&lt;/p&gt;
      &lt;h2 id=&quot;cli-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#cli-improvements&quot;&gt;CLI Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The command-line client has seen a lot of work this release. In particular, multi-line editing has been made the default mode, and has seen many improvements. The query history is now also multi-line. &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/syntax_highlighting.html&quot;&gt;Syntax highlighting has improved&lt;/a&gt; – missing brackets and unclosed quotes are highlighted as errors, and matching brackets are highlighted when the cursor moves over them. Compatibility with read-line has also been &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/editing.html&quot;&gt;greatly extended&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/syntax_highlighting_screenshot.png&quot; alt=&quot;Image showing syntax highlighting in the shell&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;extended CLI docs for more information&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;final-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#final-thoughts&quot;&gt;Final Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;These were a few highlights – but there are many more features and improvements in this release. Below are a few more highlights. The full release notes can be &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.10.0&quot;&gt;found on GitHub&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;new-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#new-features&quot;&gt;New Features&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10372&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COMMENT ON&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9765&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY FROM DATABASE&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8635&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UHUGEINT&lt;/code&gt; type&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9220&quot;&gt;Window &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9754&quot;&gt;Window &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt;&lt;/a&gt; support&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9392&quot;&gt;Parquet encryption support&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8851&quot;&gt;Indexes for Lambda parameters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9636&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCEPT ALL&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERSECT ALL&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10210&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESCRIBE&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SHOW&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt; as subquery&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10357&quot;&gt;Support recursive CTEs in correlated subqueries&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;new-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#new-functions&quot;&gt;New Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9126&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_kv_metadata&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9793&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_file_metadata&lt;/code&gt;&lt;/a&gt; functions&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10376&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_text&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_blob&lt;/code&gt; table functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9909&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_reduce&lt;/code&gt;&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8907&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_where&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_zip&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_select&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_grade_up&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;storage-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#storage-improvements&quot;&gt;Storage Improvements&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9931&quot;&gt;Vacuuming partial deletes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/9999&quot;&gt;Parallel checkpointing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10126&quot;&gt;Checksum WAL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;optimizations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#optimizations&quot;&gt;Optimizations&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10245&quot;&gt;Parallel streaming query result&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10314&quot;&gt;Struct filter pushdown&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/10347&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first(x ORDER BY y)&lt;/code&gt; optimizations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;acknowledgments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/02/13/announcing-duckdb-0100.html#acknowledgments&quot;&gt;Acknowledgments&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We would like to thank all of the contributors for their hard work on improving DuckDB.&lt;/p&gt;

</description><link>https://duckdb.org/2024/02/13/announcing-duckdb-0100.html</link><guid isPermaLink="false">https://duckdb.org/2024/02/13/announcing-duckdb-0100.html</guid><pubDate>Tue, 13 Feb 2024 00:00:00 GMT</pubDate><author>Mark Raasveldt and Hannes Mühleisen</author></item><item><title>Multi-Database Support in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB can attach MySQL, Postgres, and SQLite databases in addition to databases stored in its own format. This allows data to be read into DuckDB and moved between these systems in a convenient manner.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duckdb-multidb-support.png&quot; alt=&quot;DuckDB supports reading and writing to MySQL, Postgres, and SQLite&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;In modern data analysis, data must often be combined from a wide variety of different sources. Data might sit in CSV files on your machine, in Parquet files in a data lake, or in an operational database. DuckDB has strong support for moving data between many different data sources. However, this support has previously been limited to reading data and writing data to files.&lt;/p&gt;

&lt;p&gt;DuckDB supports advanced operations on its own native storage format – such as deleting rows, updating values, or altering the schema of a table. It supports all of these operations using ACID semantics. This guarantees that your database is always left in a sane state – operations are atomic and do not partially complete.&lt;/p&gt;

&lt;p&gt;DuckDB now has a pluggable storage and transactional layer. This flexible layer allows new storage back-ends to be created by DuckDB extensions. These storage back-ends can support all database operations in the same way that DuckDB supports them, including inserting data and even modifying schemas.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/mysql.html&quot;&gt;MySQL&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/postgres.html&quot;&gt;Postgres&lt;/a&gt;, and &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/sqlite.html&quot;&gt;SQLite&lt;/a&gt; extensions implement this new pluggable storage and transactional layer, allowing DuckDB to connect to those systems and operate on them in the same way that it operates on its own native storage engine.&lt;/p&gt;

&lt;p&gt;These extensions enable a number of useful features. For example, using these extensions you can:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Export data from SQLite to JSON&lt;/li&gt;
  &lt;li&gt;Read data from Parquet into Postgres&lt;/li&gt;
  &lt;li&gt;Move data from MySQL to Postgres&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;… and much more.&lt;/p&gt;
      &lt;h2 id=&quot;attaching-databases&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#attaching-databases&quot;&gt;Attaching Databases&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/attach.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; statement&lt;/a&gt; can be used to attach a new database to the system. By default, a native DuckDB file will be attached. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TYPE&lt;/code&gt; parameter can be used to specify a different storage type. Alternatively, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{type}:&lt;/code&gt; prefix can be used.&lt;/p&gt;

&lt;p&gt;For example, using the SQLite extension, we can open &lt;a href=&quot;https://github.com/duckdb/duckdb-sqlite/raw/main/data/db/sakila.db&quot;&gt;a SQLite database file&lt;/a&gt; and query it as we would query a DuckDB database.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sakila.db&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sakila&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;release_year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sakila&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────┬──────────────┬────────┐
│      title       │ release_year │ length │
│     varchar      │   varchar    │ int64  │
├──────────────────┼──────────────┼────────┤
│ ACADEMY DINOSAUR │ 2006         │     86 │
│ ACE GOLDFINGER   │ 2006         │     48 │
│ ADAPTATION HOLES │ 2006         │     50 │
│ AFFAIR PREJUDICE │ 2006         │    117 │
│ AFRICAN EGG      │ 2006         │    130 │
└──────────────────┴──────────────┴────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;USE&lt;/code&gt; command switches the main database.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;USE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sakila&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────┬──────────────┐
│ first_name │  last_name   │
│  varchar   │   varchar    │
├────────────┼──────────────┤
│ PENELOPE   │ GUINESS      │
│ NICK       │ WAHLBERG     │
│ ED         │ CHASE        │
│ JENNIFER   │ DAVIS        │
│ JOHNNY     │ LOLLOBRIGIDA │
└────────────┴──────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The SQLite database can be manipulated as if it were a native DuckDB database. For example, we can create a new table, populate it with values from a Parquet file, delete a few rows from the table and alter the schema of the table.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitem.parquet&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;N&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_comment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb_databases&lt;/code&gt; table contains a list of all attached databases and their types.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;database_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb_databases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────┬───────────┬─────────┐
│ database_name │   path    │  type   │
│    varchar    │  varchar  │ varchar │
├───────────────┼───────────┼─────────┤
│ sakila        │ sakila.db │ sqlite  │
│ memory        │ NULL      │ duckdb  │
└───────────────┴───────────┴─────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;mix-and-match&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#mix-and-match&quot;&gt;Mix and Match&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;While attaching to different database types is useful – it becomes even more powerful when used in combination. For example, we can attach both a SQLite, MySQL and a Postgres database.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sqlite:sakila.db&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;postgres:dbname=postgresscanner&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;mysql:user=root database=mysqlscanner&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we can move data between these attached databases and query them together. Let&#39;s copy the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;film&lt;/code&gt; table to MySQL, and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;actor&lt;/code&gt; table to Postgres:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can now join tables from these three attached databases together. Let&#39;s find all of the actors that starred in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ace Goldfinger&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_name&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film_actor&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;film_actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;film_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;film_actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;ACE GOLDFINGER&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────┬───────────┐
│ first_name │ last_name │
│  varchar   │  varchar  │
├────────────┼───────────┤
│ BOB        │ FAWCETT   │
│ MINNIE     │ ZELLWEGER │
│ SEAN       │ GUINESS   │
│ CHRIS      │ DEPP      │
└────────────┴───────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN&lt;/code&gt; on the query shows how the data from the different engines is combined into the final query result.&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐                                                          
│         PROJECTION        │                                                          
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │                                                          
│         first_name        │                                                          
│         last_name         │                                                          
└─────────────┬─────────────┘                                                          
┌─────────────┴─────────────┐                                                          
│         HASH_JOIN         │                                                          
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │                                                          
│           INNER           │                                                          
│     film_id = film_id     ├───────────────────────────────────────────┐              
└─────────────┬─────────────┘                                           │              
┌─────────────┴─────────────┐                             ┌─────────────┴─────────────┐
│         HASH_JOIN         │                             │           FILTER          │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │                             │   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│           INNER           │                             │ (title = &#39;ACE GOLDFINGER&#39;)│
│    actor_id = actor_id    ├──────────────┐              │                           │
└─────────────┬─────────────┘              │              └─────────────┬─────────────┘
┌─────────────┴─────────────┐┌─────────────┴─────────────┐┌─────────────┴─────────────┐
│        SQLITE_SCAN        ││       POSTGRES_SCAN       ││        MYSQL_SCAN         │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│    sakila.db:film_actor   ││           actor           ││            film           │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│          film_id          ││          actor_id         ││          film_id          │
│          actor_id         ││         first_name        ││           title           │
│                           ││         last_name         ││                           │
└───────────────────────────┘└───────────────────────────┘└───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;transactions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#transactions&quot;&gt;Transactions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;All statements executed within DuckDB are executed within a transaction. If an explicit &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BEGIN TRANSACTION&lt;/code&gt; is not called, every statement will execute in its own transaction. This also applies to queries that are executed over other storage engines. These storage engines also support explicit &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BEGIN&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COMMIT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROLLBACK&lt;/code&gt; statements.&lt;/p&gt;

&lt;p&gt;For example, we can begin a transaction within our attached &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SQLite&lt;/code&gt; database, make a change, and then roll it back. The original data will be restored.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;TRUNCATE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;film&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;release_year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;film&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────┬──────────────┬────────┐
│  title  │ release_year │ length │
│ varchar │   varchar    │ int64  │
├─────────────────────────────────┤
│             0 rows              │
└─────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ROLLBACK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;release_year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;film&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────────────────┬──────────────┬────────┐
│      title       │ release_year │ length │
│     varchar      │   varchar    │ int64  │
├──────────────────┼──────────────┼────────┤
│ ACADEMY DINOSAUR │ 2006         │     86 │
│ ACE GOLDFINGER   │ 2006         │     48 │
│ ADAPTATION HOLES │ 2006         │     50 │
│ AFFAIR PREJUDICE │ 2006         │    117 │
│ AFRICAN EGG      │ 2006         │    130 │
└──────────────────┴──────────────┴────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;multi-database-transactions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#multi-database-transactions&quot;&gt;Multi-Database Transactions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Every storage engine has their own transactions that are stand-alone and managed by the storage engine itself. Opening a transaction in Postgres, for example, calls &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BEGIN TRANSACTION&lt;/code&gt; in the Postgres client. The transaction is managed by Postgres itself. Similarly, when the transaction is committed or rolled back, the storage engine handles this by itself.&lt;/p&gt;

&lt;p&gt;Transactions are used both for &lt;strong&gt;reading&lt;/strong&gt; and for &lt;strong&gt;writing&lt;/strong&gt; data. For reading data, they are used to provide a consistent snapshot of the database. For writing, they are used to ensure all data in a transaction is packed together and written at the same time.&lt;/p&gt;

&lt;p&gt;When executing a transaction that involves multiple attached databases we need to open multiple transactions: one per attached database that is used in the transaction. While this is not a problem when &lt;strong&gt;reading&lt;/strong&gt; from the database, it becomes complicated when &lt;strong&gt;writing&lt;/strong&gt;. In particular, when we want to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COMMIT&lt;/code&gt; a transaction it is challenging to ensure that either (a) every database has successfully committed, or (b) every database has rolled back.&lt;/p&gt;

&lt;p&gt;For that reason, it is currently not supported to &lt;strong&gt;write&lt;/strong&gt; to multiple attached databases in a single transaction. Instead, an error is thrown when this is attempted:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;BEGIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_table&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_table&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Error: Attempting to write to database &quot;mysql&quot; in a transaction that has
already modified database &quot;postgres&quot; – a single transaction can only write
to a single attached database.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;copying-data-between-databases&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#copying-data-between-databases&quot;&gt;Copying Data Between Databases&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE TABLE AS&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT INTO&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; can be used to copy data between different attached databases. The dedicated &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/copy.html#copy-from-database--to&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY FROM DATABASE ... TO&lt;/code&gt;&lt;/a&gt; can be used to copy all data from one database to another. This includes all tables and views that are stored in the source database.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- attach a Postgres database&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;postgres:dbname=postgresscanner&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- attach a DuckDB file&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;database.db&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- export all tables and views from the Postgres database to the DuckDB file&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;postgres&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;directly-opening-a-database&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#directly-opening-a-database&quot;&gt;Directly Opening a Database&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The explicit &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ATTACH&lt;/code&gt; statement is not required to connect to a different database type. When instantiating a DuckDB instance a connection can be made directly to a different database type using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{type}:&lt;/code&gt; prefix. For example, to connect to a SQLite file, use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sqlite:file.db&lt;/code&gt;. To connect to a Postgres instance, use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;postgres:dbname=postgresscanner&lt;/code&gt;. This can be done in any client, including the CLI. For instance:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CLI:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;duckdb &lt;/span&gt;sqlite:file.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Python:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;sqlite:file.db&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is equivalent to attaching the storage engine and running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;USE&lt;/code&gt; afterwards.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s pluggable storage engine architecture enables many use cases. By attaching multiple databases, data can be extracted in a transactionally safe manner for bulk ETL or ELT workloads, as well as for on-the-fly data virtualization workloads. These techniques also work well in combination, for example, by moving data in bulk on a regular cadence, while filling in the last few data points on the fly.&lt;/p&gt;

&lt;p&gt;Pluggable storage engines also unlock new ways to handle concurrent writers in a data platform. Each separate process could write its output to a transactional database, and the results could be combined within DuckDB – all in a transactionally safe manner. Then, data analysis tasks can occur on the centralized DuckDB database for improved performance.&lt;/p&gt;

&lt;p&gt;We look forward to hearing the many creative ways you are able to use this feature!&lt;/p&gt;
      &lt;h2 id=&quot;future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html#future-work&quot;&gt;Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We intend to continue enhancing the performance and capabilities of the existing extensions. In addition, all of these features can be leveraged by the community to connect to other databases.&lt;/p&gt;

</description><link>https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html</link><guid isPermaLink="false">https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html</guid><pubDate>Fri, 26 Jan 2024 00:00:00 GMT</pubDate><author>Mark Raasveldt</author></item><item><title>Extensions for DuckDB-Wasm</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB-Wasm users can now load DuckDB extensions, allowing them to run extensions in the browser.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;In this blog post, we will go over two exciting DuckDB features: the DuckDB-Wasm client and DuckDB extensions. I will discuss how these disjoint features have now been adapted to work together. These features are now available for DuckDB-Wasm users and you can try them out at &lt;a href=&quot;https://shell.duckdb.org/&quot;&gt;shell.duckdb.org&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#duckdb-extensions&quot;&gt;DuckDB Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s philosophy is to have a lean core system to ensure robustness and portability.
However, a competing design goal is to be flexible and allow a wide range of functionality that is necessary to perform advanced analytics.
To accommodate this, DuckDB has an extension mechanism for installing and loading extensions during runtime.&lt;/p&gt;
      &lt;h3 id=&quot;running-duckdb-extensions-locally&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#running-duckdb-extensions-locally&quot;&gt;Running DuckDB Extensions Locally&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For DuckDB, here is a simple end-to-end example using the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;command line interface&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; tpch&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; tpch&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dbgen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tpch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This script first installs the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/tpch.html&quot;&gt;TPC-H extension&lt;/a&gt; from the official extension repository, which implements the popular TPC-H benchmark. It then loads the TPC-H extension, uses it to populate the database with generated data using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dbgen&lt;/code&gt; function. Finally, it runs &lt;a href=&quot;https://github.com/duckdb/duckdb/blob/v0.9.2/extension/tpch/dbgen/queries/q07.sql&quot;&gt;TPC-H query 7&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This example demonstrates a case where we install an extension to complement DuckDB with a new feature (the TPC-H data generator), which is not part of the base DuckDB executable. Instead, it is downloaded from the extension repository, then loaded and executed it locally within the framework of DuckDB.&lt;/p&gt;

&lt;p&gt;Currently, DuckDB has &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/core_extensions.html&quot;&gt;several extensions&lt;/a&gt;. These add support for filesystems, file formats, database and network protocols. Additionally, they implement new functions such as full text search.&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-wasm&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#duckdb-wasm&quot;&gt;DuckDB-Wasm&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In an effort spearheaded by André Kohn, &lt;a href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html&quot;&gt;DuckDB was ported to the WebAssembly platform&lt;/a&gt; in 2021. &lt;a href=&quot;https://webassembly.org/&quot;&gt;WebAssembly&lt;/a&gt;, also known as Wasm, is a W3C standard language developed in recent years. Think of it as a machine-independent binary format that you can execute from within the sandbox of a web browser.&lt;/p&gt;

&lt;p&gt;Thanks to DuckDB-Wasm, anyone has access to a DuckDB instance only a browser tab away, with all computation being executed locally within your browser and no data leaving your device. DuckDB-Wasm is a library that can be used in various deployments (e.g., &lt;a href=&quot;https://observablehq.com/@cmudig/duckdb&quot;&gt;notebooks that run inside your browser without a server&lt;/a&gt;). In this post, we will use the Web shell, where SQL statements are entered by the user line by line, with the behavior modeled after the DuckDB &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;CLI shell&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-extensions-in-duckdb-wasm&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#duckdb-extensions-in-duckdb-wasm&quot;&gt;DuckDB Extensions, in DuckDB-Wasm!&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB-Wasm &lt;a href=&quot;https://duckdb.org/docs/stable/clients/wasm/extensions.html&quot;&gt;now supports DuckDB extensions&lt;/a&gt;. This support comes with four new key features.
First, the DuckDB-Wasm library can be compiled with dynamic extension support.
Second, DuckDB extensions can be compiled to a single WebAssembly module.
Third, users and developers working with DuckDB-Wasm can now select the set of extensions they load.
Finally, the DuckDB-Wasm shell&#39;s features are now much closer to the native &lt;a href=&quot;https://duckdb.org/docs/stable/clients/cli/overview.html&quot;&gt;CLI functionality&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;using-the-tpc-h-extension-in-duckdb-wasm&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#using-the-tpc-h-extension-in-duckdb-wasm&quot;&gt;Using the TPC-H Extension in DuckDB-Wasm&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To demonstrate this, we will again use the &lt;a href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#running-duckdb-extensions-locally&quot;&gt;TPC-H data generation example&lt;/a&gt;.
To run this script in your browser, &lt;a href=&quot;https://shell.duckdb.org/#queries=v0,INSTALL-tpch~,LOAD-tpch~,CALL-dbgen(sf%3D0.1)~,PRAGMA-tpch(7)~&quot;&gt;start an online DuckDB shell that runs these commands&lt;/a&gt;. The script will generate the TPC-H data set at scale factor 0.1, which corresponds to 100 MB in uncompressed CSV format.&lt;/p&gt;

&lt;p&gt;Once the script is finished, you can keep executing queries, or you could even download the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer.parquet&lt;/code&gt; file (1 MB) using the following commands:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;customer.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will first copy the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer.parquet&lt;/code&gt; to the DuckDB-Wasm file system, then download it via your browser.&lt;/p&gt;

&lt;p&gt;In short, your DuckDB instance, which &lt;em&gt;runs entirely within your browser,&lt;/em&gt; first installed and loaded the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/tpch.html&quot;&gt;TPC-H extension&lt;/a&gt;. It then used the extension logic to generate data and convert it to a Parquet file. Finally, you could download the Parquet file as a regular file to your local file system.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://shell.duckdb.org/#queries=v0,INSTALL-tpch~,LOAD-tpch~,CALL-dbgen(sf%3D0.1)~,PRAGMA-tpch(7)~&quot;&gt;
&lt;img src=&quot;https://duckdb.org/images/wasm-blog-post-shell-tpch.png&quot; alt=&quot;Wasm shell using the TPC-H extension&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;h3 id=&quot;using-the-spatial-extension-in-duckdb-wasm&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#using-the-spatial-extension-in-duckdb-wasm&quot;&gt;Using the Spatial Extension in DuckDB-Wasm&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To show the possibilities unlocked by DuckDB-Wasm extensions and test the capabilities of what&#39;s possible, what about using the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;spatial extension&lt;/a&gt; within DuckDB-Wasm?
This extension implements geospatial types and functions that allow it to work with geospatial data and relevant workloads.&lt;/p&gt;

&lt;p&gt;To install and load the spatial extension in DuckDB-Wasm, run:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using the spatial extension, the following query uses the New York taxi dataset, and calculates the area of the taxi zones for each borough:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;borough&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;st_union_agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;full_geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;st_area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full_geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;st_centroid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full_geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centroid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;st_read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;https://raw.githubusercontent.com/duckdb/duckdb-spatial/main/test/data/nyc_taxi/taxi_zones/taxi_zones.shp&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;borough&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;borough&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centroid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Both your local DuckDB client and the &lt;a href=&quot;https://shell.duckdb.org/#queries=v0,INSTALL-spatial~,LOAD-spatial~,CREATE-TABLE-nyc-AS-SELECT-borough%2C-st_union_agg(geom)-AS-full_geom%2C-st_area(full_geom)-AS-area%2C-st_centroid(full_geom)-AS-centroid%2C-count(*)-AS-count-FROM-st_read(&#39;https%3A%2F%2Fraw.githubusercontent.com%2Fduckdb%2Fduckdb-spatial%2Fmain%2Ftest%2Fdata%2Fnyc_taxi%2Ftaxi_zones%2Ftaxi_zones.shp&#39;)-GROUP-BY-borough~,SELECT-borough%2C-area%2C-centroid%3A%3AVARCHAR%2C-count-FROM-nyc~&quot;&gt;online DuckDB shell&lt;/a&gt; will perform the same analysis.&lt;/p&gt;
      &lt;h2 id=&quot;under-the-hood&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#under-the-hood&quot;&gt;Under the Hood&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let&#39;s dig into how this all works.
The following figure shows an overview of DuckDB-Wasm&#39;s architecture.
Both components in the figure run within the web browser.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/wasm-blog-post-overview.png&quot; alt=&quot;Overview of the architecture of DuckDB-Wasm&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;When you load DuckDB-Wasm in your browser, there are two components that will be set up:
(1) A main-thread wrapper library that acts as a bridge between users or code using DuckDB-Wasm and drives the background component. 
(2) A DuckDB engine used to execute queries.
This component lives in a Web Worker and communicates with the main thread component via messages. This component has a JavaScript layer that handles messages and the original DuckDB C++ logic compiled down to a single WebAssembly file.&lt;/p&gt;

&lt;p&gt;What happens when we add extensions to the mix?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/wasm-blog-post-extensions.png&quot; alt=&quot;Overview of the architecture of DuckDB-Wasm with extensions&quot; width=&quot;828&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Extensions for DuckDB-Wasm are composed of a single WebAssembly module. This will encode the logic and data of the extensions, the list of functions that are going to be imported and exported, and a custom section encoding metadata that allows verification of the extension.&lt;/p&gt;

&lt;p&gt;To make extension loading work, the DuckDB engine component blocks, fetches, and validates external WebAssembly code, then links it in, wires together import and export, and then the system will be connected and set to keep executing as if it was a single codebase.&lt;/p&gt;

&lt;p&gt;The central code block that makes this possible is the following:&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;EM_ASM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xhr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XMLHttpRequest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xhr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;GET&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UTF8ToString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xhr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;responseType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;arraybuffer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xhr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uInt8Array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xhr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Check signatures / version compatibility left as an exercise&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;WebAssembly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;validate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uInt8Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// Here we add the uInt8Array to Emscripten&#39;s filesystem,&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// for it to be found by dlopen&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;FS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writeFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UTF8ToString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Uint8Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uInt8Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;basename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lib_hdl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dlopen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RTLD_NOW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RTLD_LOCAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib_hdl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;&quot;Extension &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; could not be loaded: %s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;GetDLError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we rely on two powerful features of &lt;a href=&quot;https://emscripten.org/&quot;&gt;Emscripten&lt;/a&gt;, the compiler toolchain we are using to compile DuckDB to WebAssembly.&lt;/p&gt;

&lt;p&gt;First, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EM_ASM&lt;/code&gt; allows us to inline JavaScript code directly in C++ code. It means that during runtime when we get to that block of code, the WebAssembly component will go back to JavaScript land, perform a blocking &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;XMLHttpRequest&lt;/code&gt; on a URL such as &lt;a href=&quot;https://extensions.duckdb.org/duckdb-wasm/v0.9.2/wasm_eh/tpch.duckdb_extension.wasm&quot;&gt;https://extensions.duckdb.org/…/tpch.duckdb_extension.wasm&lt;/a&gt;,
then validate that the package that has been just fetched is actually a valid WebAssembly module.&lt;/p&gt;

&lt;p&gt;Second, we leverage Emscripten&#39;s &lt;a href=&quot;https://emscripten.org/docs/compiling/Dynamic-Linking.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dlopen&lt;/code&gt; implementation&lt;/a&gt;, which enables compatible WebAssembly modules to be linked together and act as a single composable codebase.&lt;/p&gt;

&lt;p&gt;These enable implementing dynamic loading of extensions, when triggered via the SQL &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LOAD&lt;/code&gt; statement.&lt;/p&gt;
      &lt;h2 id=&quot;developer-guide&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#developer-guide&quot;&gt;Developer Guide&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We see two main groups of developers using extensions with DuckDB-Wasm.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Developers working with DuckDB-Wasm: If you are building a website or a library that wraps DuckDB-Wasm, the new extension support means that there is now a wider range of functionality that can be exposed to your users.&lt;/li&gt;
  &lt;li&gt;Developers working on DuckDB extensions: If you have written a DuckDB extension, or are thinking of doing so, consider porting it to DuckDB-Wasm. The &lt;a href=&quot;https://github.com/duckdb/extension-template&quot;&gt;DuckDB extension template repository&lt;/a&gt; contains the configuration required for compiling to DuckDB-Wasm.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;limitations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#limitations&quot;&gt;Limitations&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB-Wasm extensions have a few inherent limitations. For example, it is not possible to communicate with native executables living on your machine, which is required by some extensions, such as the &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/postgres.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;postgres&lt;/code&gt; scanner extension&lt;/a&gt;.
Moreover, compilation to Wasm may not be currently supported for some libraries you are relying on, or capabilities might not be one-to-one with local executables due to additional requirements imposed on the browser, in particular around &lt;a href=&quot;https://duckdb.org/docs/stable/clients/wasm/extensions.html#httpfs&quot;&gt;non-secure HTTP requests&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;conclusions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html#conclusions&quot;&gt;Conclusions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we explained how DuckDB-Wasm supports extensions, and demonstrated with multiple extensions: &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/tpch.html&quot;&gt;TPC-H&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;Parquet&lt;/a&gt;, and &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html&quot;&gt;spatial&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Thanks to the portability of DuckDB, the scripts shown in this blog post also work on your smartphone:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/wasm-blog-post-ios-shell.png&quot; alt=&quot;Wasm shell using the TPC-H extension on iOS&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;For updates on the latest developments, follow this blog and join the Wasm channel in &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;our Discord&lt;/a&gt;. If you have an example of what&#39;s possible with extensions in DuckDB, let us know!&lt;/p&gt;

</description><link>https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html</link><guid isPermaLink="false">https://duckdb.org/2023/12/18/duckdb-extensions-in-wasm.html</guid><pubDate>Mon, 18 Dec 2023 00:00:00 GMT</pubDate><author>Carlo Piovesan</author></item><item><title>Updates to the H2O.ai db-benchmark!</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The H2O.ai db-benchmark has been updated with new results. In addition, the AWS EC2 instance used for benchmarking has been changed to a c6id.metal for improved repeatability and fairness across libraries. DuckDB is the fastest library for both join and group by queries at almost every data size.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;a href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html#results&quot;&gt;Skip directly to the results&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;the-benchmark-has-been-updated&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html#the-benchmark-has-been-updated&quot;&gt;The Benchmark Has Been Updated!&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In April, DuckDB Labs published a &lt;a href=&quot;https://duckdb.org/2023/04/14/h2oai.html&quot;&gt;blog post reporting updated H2O.ai db-benchmark results&lt;/a&gt;. Since then, the results haven&#39;t been updated. The original plan was to update the results with every DuckDB release. DuckDB 0.9.1 was recently released, and DuckDB Labs has updated the benchmark. While updating the benchmark, however, we noticed that our initial setup did not lend itself to being fair to all solutions. The machine used had network storage and could suffer from noisy neighbors. To avoid these issues, the whole benchmark was re-run on a c6id.metal machine.&lt;/p&gt;
      &lt;h2 id=&quot;new-benchmark-environment-c6idmetal-instance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html#new-benchmark-environment-c6idmetal-instance&quot;&gt;New Benchmark Environment: c6id.metal Instance&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Initially, updating the results to the benchmark showed strange results. Even using the same library versions from the prior update, some solutions regressed and others improved. We believe this variance came from the AWS EC2 instance we chose: an m4.10xlarge. The m4.10xlarge has 40 virtual CPUs and EBS storage. EBS storage is highly available network block storage for EC2 instances. When running compute-heavy benchmarks, a machine like the m4.10xlarge can suffer from the following issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Network storage&lt;/strong&gt; is an issue for benchmarking solutions that interact with storage frequently. For the 500 MB and 5 GB workloads, network storage was not an issue on the m4.10xlarge since all solutions could execute the queries in memory. For the 50 GB workload, however, network storage was an issue for the solutions that could not execute queries in memory. While the m4.10xlarge has dedicated EBS bandwidth, any read/write from storage is still happening over the network, which is usually slower than physically mounted storage. Solutions that frequently read and write to storage for the 50 GB queries end up doing this over the network. This network time becomes a chunk of the execution time of the query. If the network has variable performance, the query performance is then also variable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Noisy neighbors&lt;/strong&gt; is a common issue when benchmarking on virtual CPUs. The previous machine most likely shared its compute hardware with other (neighboring) AWS EC2 instances. If these neighbors are also running compute heavy workloads, the physical CPU caches are repeatedly invalidated/flushed by the neighboring instance and the benchmark instance. When the CPU cache is shared between two workloads on two instances, both workloads require extra reads from memory for data that would already be in CPU cache on a non-virtual machine.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In order to be fair to all solutions, we decided to change the instance type to a metal instance with local storage. Metal instance types negate any noisy neighbor problems because the hardware is physical and not shared with any other AWS users/instances. Network storage problems are also fixed because solutions can read and write data to the local instance storage, which is physically mounted on the hardware.&lt;/p&gt;

&lt;p&gt;Another benefit of the c6id.metal box is that it stresses parallel performance. There are 128 cores on the c6id.metal. Performance differences between solutions that can effectively use every core and solutions that cannot are clearly visible.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html#updated-settings&quot;&gt;updated settings&lt;/a&gt; section on how settings were change for each solution when run on the new machine.&lt;/p&gt;
      &lt;h2 id=&quot;updating-the-benchmark&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html#updating-the-benchmark&quot;&gt;Updating the Benchmark&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Moving forward we will update the benchmark when PRs with new performance numbers are provided. The PR should include a description of the changes to a solution script or a version update and new entries in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time.csv&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;logs.csv&lt;/code&gt; files. These entries will be verified using a different c6id.metal instance, and if there is limited variance, the PR will be merged and the results will be updated!&lt;/p&gt;
      &lt;h3 id=&quot;updated-settings&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html#updated-settings&quot;&gt;Updated Settings&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;ol&gt;
  &lt;li&gt;ClickHouse
    &lt;ul&gt;
      &lt;li&gt;Storage: Any data this gets spilled to disk also needs to be on the NVMe drive. This has been changed in the new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;format_and_mount.sh&lt;/code&gt; script and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;clickhouse/clickhouse-mount-config.xml&lt;/code&gt; file.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Julia (juliadf &amp;amp; juliads)
    &lt;ul&gt;
      &lt;li&gt;Threads: The threads were hardcoded for juliadf/juliads to 20/40 threads. Now the max number of threads are used. No option was given to spill to disk, so this was not changed/researched.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;DuckDB
    &lt;ul&gt;
      &lt;li&gt;Storage: The DuckDB database file was specified to run on the NVMe mount.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Spark
    &lt;ul&gt;
      &lt;li&gt;Storage: There is an option to spill to disk. I was unsure of how to modify the storage location so that it was on the NVMe drive. Open to a PR with storage location changes and improved results!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Many solutions do not spill to disk, so they did not require any modification to use the instance storage. Other solutions use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parallel::ncores()&lt;/code&gt; or default to a maximum number of cores for parallelism. Solution scripts were run in their current form on &lt;a href=&quot;https://github.com/duckdblabs/db-benchmark&quot;&gt;github.com/duckdblabs/db-benchmark&lt;/a&gt;. Please read the &lt;a href=&quot;https://github.com/duckdblabs/db-benchmark#updating-the-benchmark&quot;&gt;Updating the Benchmark&lt;/a&gt; section on how to re-run your solution.&lt;/p&gt;
      &lt;h3 id=&quot;results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html#results&quot;&gt;Results&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The first results you see are the 50 GB group by results. The benchmark runs every query twice per solution, and both runtimes are reported. The &quot;first time&quot; can be considered a cold run, and the &quot;second time&quot; can be considered a hot run. DuckDB and DuckDB-latest perform very well among all dataset sizes and variations.&lt;/p&gt;

&lt;p&gt;The team at DuckDB Labs has been hard at work improving the performance of the out-of-core hash aggregates and joins. The most notable improvement is the performance of query 5 in the advanced group by queries. The cold run is almost an order of magnitude better than every other solution! DuckDB is also one of only two solutions to finish the 50 GB join query. Some solutions are experiencing timeouts on the 50 GB datasets. Solutions running the 50 GB group by queries are killed after running for 180 minutes, meaning all 10 group by queries need to finish within the 180 minutes. Solutions running the 50 GB join queries are killed after running for 360 minutes.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdblabs.github.io/db-benchmark/&quot;&gt;Link to result page&lt;/a&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://duckdblabs.github.io/db-benchmark/&quot; title=&quot;h2oai db benchmmark&quot; height=&quot;500&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/iframe&gt;

</description><link>https://duckdb.org/2023/11/03/db-benchmark-update.html</link><guid isPermaLink="false">https://duckdb.org/2023/11/03/db-benchmark-update.html</guid><pubDate>Fri, 03 Nov 2023 00:00:00 GMT</pubDate><author>Tom Ebergen</author></item><item><title>DuckDB&#39;s CSV Sniffer: Automatic Detection of Types and Dialects</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB is primarily focused on performance, leveraging the capabilities of modern file formats. At the same time, we also pay attention to flexible, non-performance-driven formats like CSV files. To create a nice and pleasant experience when reading from CSV files, DuckDB implements a CSV sniffer that automatically detects CSV dialect options, column types, and even skips dirty data. The sniffing process allows users to efficiently explore CSV files without needing to provide any input about the file format.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/csv-sniffer/ducktetive.jpg&quot; alt=&quot;ducktetive&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are many different file formats that users can choose from when storing their data. For example, there are performance-oriented binary formats like Parquet, where data is stored in a columnar format, partitioned into row groups, and heavily compressed. However, Parquet is known for its rigidity, requiring specialized systems to read and write these files.&lt;/p&gt;

&lt;p&gt;On the other side of the spectrum, there are files with the CSV (comma-separated values) format, which I like to refer to as the &#39;Woodstock of data&#39;. CSV files offer the advantage of flexibility; they are structured as text files, allowing users to manipulate them with any text editor, and nearly any data system can read and execute queries on them.&lt;/p&gt;

&lt;p&gt;However, this flexibility comes at a cost. Reading a CSV file is not a trivial task, as users need a significant amount of prior knowledge about the file. For instance, &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html&quot;&gt;DuckDB&#39;s CSV reader&lt;/a&gt; offers more than 25 configuration options. I&#39;ve found that people tend to think I&#39;m not working hard enough if I don&#39;t introduce at least three new options with each release. &lt;em&gt;Just kidding.&lt;/em&gt; These options include specifying the delimiter, quote and escape characters, determining the number of columns in the CSV file, and identifying whether a header is present while also defining column types. This can slow down an interactive data exploration process, and make analyzing new datasets a cumbersome and less enjoyable task.&lt;/p&gt;

&lt;p&gt;One of the raison d&#39;être of DuckDB is to be pleasant and easy to use, so we don&#39;t want our users to have to fiddle with CSV files and input options manually. Manual input should be reserved only for files with rather unusual choices for their CSV dialect (where a dialect comprises the combination of the delimiter, quote, escape, and newline values used to create that file) or for specifying column types.&lt;/p&gt;

&lt;p&gt;Automatically detecting CSV options can be a daunting process. Not only are there many options to investigate, but their combinations can easily lead to a search space explosion. This is especially the case for CSV files that are not well-structured. Some might argue that CSV files have a &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc4180&quot;&gt;specification&lt;/a&gt;, but the truth of the matter is that the &quot;specification&quot; changes as soon as a single system is capable of reading a flawed file. And, oh boy, I&#39;ve encountered my fair share of semi-broken CSV files that people wanted DuckDB to read in the past few months.&lt;/p&gt;

&lt;p&gt;DuckDB implements a &lt;a href=&quot;https://hannes.muehleisen.org/publications/ssdbm2017-muehleisen-csvs.pdf&quot;&gt;multi-hypothesis CSV sniffer&lt;/a&gt; that automatically detects dialects, headers, date/time formats, column types, and identifies dirty rows to be skipped. Our ultimate goal is to automatically read anything resembling a CSV file, to never give up and never let you down! All of this is achieved without incurring a substantial initial cost when reading CSV files. In the bleeding edge version, the sniffer runs when reading a CSV file by default. Note that the sniffer will always prioritize any options set by the user (e.g., if the user sets &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;,&lt;/code&gt; as the delimiter, the sniffer won&#39;t try any other options and will assume that the user input is correct).&lt;/p&gt;

&lt;p&gt;In this blog post, I will explain how the current implementation works, discuss its performance, and provide insights into what comes next!&lt;/p&gt;
      &lt;h2 id=&quot;duckdbs-automatic-detection&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#duckdbs-automatic-detection&quot;&gt;DuckDB&#39;s Automatic Detection&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The process of parsing CSV files is depicted in the figure below. It currently consists of five different phases, which will be detailed in the next sections.&lt;/p&gt;

&lt;p&gt;The CSV file used in the overview example is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;Name, Height, Vegetarian, Birthday
&quot;Pedro&quot;, 1.73, False, 30-07-92
... imagine 2048 consistent rows ...
&quot;Mark&quot;, 1.72, N/A, 20-09-92
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/csv-sniffer/sniffer.png&quot; alt=&quot;sniffing overview&quot; width=&quot;680&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;In the first phase, we perform &lt;em&gt;Dialect Detection&lt;/em&gt;, where we select the dialect candidates that generate the most per-row columns in the CSV file while maintaining consistency (i.e., not exhibiting significant variations in the number of columns throughout the file). In our example, we can observe that, after this phase, the sniffer successfully detects the necessary options for the delimiter, quotes, escapes, and new line delimiters.&lt;/p&gt;

&lt;p&gt;The second phase, referred to as &lt;em&gt;Type Detection&lt;/em&gt;, involves identifying the data types for each column in our CSV file. In our example, our sniffer recognizes four column types: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOL&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The third step, known as &lt;em&gt;Header Detection&lt;/em&gt;, is employed to ascertain whether our file includes a header. If a header is present, we use it to set the column names; otherwise, we generate them automatically. In our example, there is a header, and each column gets its name defined in there.&lt;/p&gt;

&lt;p&gt;Now that our columns have names, we move on to the fourth, optional phase: &lt;em&gt;Type Replacement&lt;/em&gt;. DuckDB&#39;s CSV reader provides users with the option to specify column types by name. If these types are specified, we replace the detected types with the user&#39;s specifications.&lt;/p&gt;

&lt;p&gt;Finally, we progress to our last phase, &lt;em&gt;Type Refinement&lt;/em&gt;. In this phase, we analyze additional sections of the file to validate the accuracy of the types determined during the initial type detection phase. If necessary, we refine them. In our example, we can see that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vegetarian&lt;/code&gt; column was initially categorized as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOL&lt;/code&gt;. However, upon further examination, it was found to contain the string &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N/A&lt;/code&gt;, leading to an upgrade of the column type to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; to accommodate all possible values.&lt;/p&gt;

&lt;p&gt;The automatic detection is only executed on a sequential sample of the CSV file. By default, the size of the sample is 20,480 tuples (i.e., 10 DuckDB execution chunks). This can be configured via the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sample_size&lt;/code&gt; option, and can be set to -1 in case the user wants to sniff the complete file. Since the same data is repeatedly read with various options, and users can scan the entire file, all CSV buffers generated during sniffing are cached and efficiently managed to ensure high performance.&lt;/p&gt;

&lt;p&gt;Of course, running the CSV Sniffer on very large files will have a drastic impact on the overall performance (see our &lt;a href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#varying-sampling-size&quot;&gt;benchmark section below&lt;/a&gt;). In these cases, the sample size should be kept at a reasonable level.&lt;/p&gt;

&lt;p&gt;In the next subsections, I will describe each phase in detail.&lt;/p&gt;
      &lt;h3 id=&quot;dialect-detection&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#dialect-detection&quot;&gt;Dialect Detection&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In the &lt;em&gt;Dialect Detection&lt;/em&gt;, we identify the delimiter, quotes, escapes, and new line delimiters of a CSV file.&lt;/p&gt;

&lt;p&gt;Our delimiter search space consists of the following delimiters: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;,&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;|&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\t&lt;/code&gt;. If the file has a delimiter outside the search space, it must be provided by the user (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delim=&#39;?&#39;&lt;/code&gt;). Our quote search space is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\0&lt;/code&gt;, where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\0&lt;/code&gt; is a string terminator indicating no quote is present; again, users can provide custom characters outside the search space (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quote=&#39;?&#39;&lt;/code&gt;). The search space of escape values depends on the value of the quote option, but in summary, they are the same as quotes with the addition of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\&lt;/code&gt;, and again, they can also be provided by the user (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;escape=&#39;?&#39;&lt;/code&gt;). Finally, the last detected option is the new line delimiters; they can be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\r&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\n&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\r\n&lt;/code&gt;, and a mix of everything (trust me, I&#39;ve seen a real-world CSV file that used a mix).&lt;/p&gt;

&lt;p&gt;By default, the dialect detection runs on 24 different combinations of dialect configurations. To determine the most promising configuration, we calculate the number of columns each CSV tuple would produce under each of these configurations. The one that results in the most columns with the most consistent rows will be chosen.&lt;/p&gt;

&lt;p&gt;The calculation of consistent rows depends on additional user-defined options. For example, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null_padding&lt;/code&gt; option will pad missing columns with NULL values. Therefore, rows with missing columns will have the missing columns padded with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null_padding&lt;/code&gt; is set to true, CSV files with inconsistent rows will still be considered, but a preference will be given to configurations that minimize the occurrence of padded rows. If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null_padding&lt;/code&gt; is set to false, the dialect detector will skip inconsistent rows at the beginning of the CSV file. As an example, consider the following CSV file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;I like my csv files to have notes to make dialect detection harder
I also like commas like this one : ,
A,B,C
1,2,3
4,5,6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here the sniffer would detect that with the delimiter set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;,&lt;/code&gt; the first row has one column, the second has two, but the remaining rows have 3 columns. Hence, if &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null_padding&lt;/code&gt; is set to false, it would still select &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;,&lt;/code&gt; as a delimiter candidate, by assuming the top rows are dirty notes. (Believe me, CSV notes are a thing!). Resulting in the following table:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;A,B,C
1, 2, 3
4, 5, 6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;null_padding&lt;/code&gt; is set to true, all lines would be accepted, resulting in the following table:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;&#39;I like my csv files to have notes to make dialect detection harder&#39;, None, None
&#39;I also like commas like this one : &#39;, None, None
&#39;A&#39;, &#39;B&#39;, &#39;C&#39;
&#39;1&#39;, &#39;2&#39;, &#39;3&#39;
&#39;4&#39;, &#39;5&#39;, &#39;6&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ignore_errors&lt;/code&gt; option is set, then the configuration that yields the most columns with the least inconsistent rows will be picked.&lt;/p&gt;
      &lt;h3 id=&quot;type-detection&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#type-detection&quot;&gt;Type Detection&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;After deciding the dialect that will be used, we detect the types of each column. Our &lt;em&gt;Type Detection&lt;/em&gt; considers the following types: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SQLNULL&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOLEAN&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;. These types are ordered in specificity, which means we first check if a column is a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SQLNULL&lt;/code&gt;; if not, if it&#39;s a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOLEAN&lt;/code&gt;, and so on, until it can only be a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;. DuckDB has more types than the ones used by default. Users can also define which types the sniffer should consider via the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;auto_type_candidates&lt;/code&gt; option.&lt;/p&gt;

&lt;p&gt;At this phase, the type detection algorithm goes over the first chunk of data (i.e., 2048 tuples). This process starts on the second valid row (i.e., not a note) of the file. The first row is stored separately and not used for type detection. It will be later detected if the first row is a header or not. The type detection runs a per-column, per-value casting trial process to determine the column types. It starts off with a unique, per-column array with all types to be checked. It tries to cast the value of the column to that type; if it fails, it removes the type from the array, attempts to cast with the new type, and continues that process until the whole chunk is finished.&lt;/p&gt;

&lt;p&gt;At this phase, we also determine the format of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt; columns. The following formats are considered for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt; columns:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%m-%d-%Y&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%m-%d-%y&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%d-%m-Y&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%d-%m-%y&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%Y-%m-%d&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%y-%m-%d&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following are considered for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt; columns:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%Y-%m-%dT%H:%M:%S.%f&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%Y-%m-%d %H:%M:%S.%f&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%m-%d-%Y %I:%M:%S %p&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%m-%d-%y %I:%M:%S %p&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%d-%m-%Y %H:%M:%S&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%d-%m-%y %H:%M:%S&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%Y-%m-%d %H:%M:%S&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%y-%m-%d %H:%M:%S&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For columns that use formats outside this search space, they must be defined with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dateformat&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timestampformat&lt;/code&gt; options.&lt;/p&gt;

&lt;p&gt;As an example, let&#39;s consider the following CSV file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;Name, Age
,
Jack Black, 54
Kyle Gass, 63.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first row [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Name&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Age&lt;/code&gt;] will be stored separately for the header detection phase. The second row [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;] will allow us to cast the first and second columns to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SQLNULL&lt;/code&gt;. Therefore, their type candidate arrays will be the same: [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SQLNULL&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOLEAN&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;].&lt;/p&gt;

&lt;p&gt;In the third row [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Jack Black&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;54&lt;/code&gt;], things become more interesting. With &#39;Jack Black,&#39; the type candidate array for column 0 will exclude all values with higher specificity, as &#39;Jack Black&#39; can only be converted to a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;. The second column cannot be converted to either &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SQLNULL&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOOLEAN&lt;/code&gt;, but it will succeed as a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt;. Hence, the type candidate for the second column will be [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;].&lt;/p&gt;

&lt;p&gt;In the fourth row, we have [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Kyle Gass&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;63.2&lt;/code&gt;]. For the first column, there&#39;s no problem since it&#39;s also a valid &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;. However, for the second column, a cast to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt; will fail, but a cast to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt; will succeed. Hence, the new array of candidate types for the second column will be [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;].&lt;/p&gt;
      &lt;h3 id=&quot;header-detection&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#header-detection&quot;&gt;Header Detection&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;em&gt;Header Detection&lt;/em&gt; phase simply obtains the first valid line of the CSV file and attempts to cast it to the candidate types in our columns. If there is a cast mismatch, we consider that row as the header; if not, we treat the first row as actual data and automatically generate a header.&lt;/p&gt;

&lt;p&gt;In our previous example, the first row was [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Name&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Age&lt;/code&gt;], and the column candidate type arrays were [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;] and [&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;]. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Name&lt;/code&gt; is a string and can be converted to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Age&lt;/code&gt; is also a string, and attempting to cast it to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt; will fail. Since the casting fails, the auto-detection algorithm considers the first row as a header, resulting in the first column being named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Name&lt;/code&gt; and the second as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Age&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If a header is not detected, column names will be automatically generated with the pattern &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;column${x}&lt;/code&gt;, where x represents the column&#39;s position (0-based index) in the CSV file.&lt;/p&gt;
      &lt;h3 id=&quot;type-replacement&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#type-replacement&quot;&gt;Type Replacement&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Now that the auto-detection algorithm has discovered the header names, if the user specifies column types, the types detected by the sniffer will be replaced with them in the &lt;em&gt;Type Replacement&lt;/em&gt; phase. For example, we can replace the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Age&lt;/code&gt; type with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FLOAT&lt;/code&gt; by using:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;greatest_band_in_the_world.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Age&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;FLOAT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This phase is optional and will only be triggered if there are manually defined types.&lt;/p&gt;
      &lt;h3 id=&quot;type-refinement&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#type-refinement&quot;&gt;Type Refinement&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;em&gt;Type Refinement&lt;/em&gt; phase performs the same tasks as type detection; the only difference is the granularity of the data on which the casting operator works, which is adjusted for performance reasons. During type detection, we conduct cast checks on a per-column, per-value basis.&lt;/p&gt;

&lt;p&gt;In this phase, we transition to a more efficient vectorized casting algorithm. The validation process remains the same as in type detection, with types from type candidate arrays being eliminated if a cast fails.&lt;/p&gt;
      &lt;h2 id=&quot;how-fast-is-the-sniffing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#how-fast-is-the-sniffing&quot;&gt;How Fast Is the Sniffing?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To analyze the impact of running DuckDB&#39;s automatic detection, we execute the sniffer on the &lt;a href=&quot;https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data/&quot;&gt;NYC taxi dataset&lt;/a&gt;. The file consists of 19 columns, 10,906,858 tuples and is 1.72 GB in size.&lt;/p&gt;

&lt;p&gt;The cost of sniffing the dialect column names and types is approximately 4% of the total cost of loading the data.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Sniffing&lt;/td&gt;
      &lt;td&gt;0.11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Loading&lt;/td&gt;
      &lt;td&gt;2.43&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;varying-sampling-size&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#varying-sampling-size&quot;&gt;Varying Sampling Size&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Sometimes, CSV files can have dialect options or more refined types that appear only later in the CSV file. In those cases, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sample_size&lt;/code&gt; option becomes an important tool for users to ensure that the sniffer examines enough data to make the correct decision. However, increasing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sample_size&lt;/code&gt; also leads to an increase in the total runtime of the sniffer because it uses more data to detect all possible dialects and types.&lt;/p&gt;

&lt;p&gt;Below, you can see how increasing the default sample size by multiplier (see X axis) affects the sniffer&#39;s runtime on the NYC dataset. As expected, the total time spent on sniffing increases linearly with the total sample size.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/csv-sniffer/sample.png&quot; alt=&quot;sample benchmark&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h3 id=&quot;varying-number-of-columns&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#varying-number-of-columns&quot;&gt;Varying Number of Columns&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The other main characteristic of a CSV file that will affect the auto-detection is the number of columns the file has. Here, we test the sniffer against a varying number of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt; type columns in files with 10,906,858 tuples. The results are depicted in the figure below. We can see that from one column to two, we have a steeper increase in runtime. That&#39;s because, for single columns, we have a simplified dialect detection due to the lack of delimiters. For the other columns, as expected, we have a more linear increase in runtime, depending on the number of columns.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/csv-sniffer/columns.png&quot; alt=&quot;sniffer benchmark&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;conclusion--future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/10/27/csv-sniffer.html#conclusion--future-work&quot;&gt;Conclusion &amp;amp; Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;If you have unusual CSV files and want to query, clean up, or normalize them, DuckDB is already one of the top solutions available. It is very easy to get started. To read a CSV file with the sniffer, you can simply:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;path/to/csv_file.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB&#39;s CSV auto-detection algorithm is an important tool to facilitate the exploration of CSV files. With its default options, it has a low impact on the total cost of loading and reading CSV files. Its main goal is to always be capable of reading files, doing a best-effort job even on files that are ill-defined.&lt;/p&gt;

&lt;p&gt;We have a list of points related to the sniffer that we would like to improve in the future.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Advanced Header Detection.&lt;/em&gt; We currently determine if a CSV has a header by identifying a type mismatch between the first valid row and the remainder of the CSV file. However, this can generate false negatives if, for example, all the columns of a CSV are of a type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt;. We plan on enhancing our Header Detection to perform matches with commonly used names for headers.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Adding Accuracy and Speed Benchmarks.&lt;/em&gt; We currently implement many accuracy and regression tests; however, due to the CSV&#39;s inherent flexibility, manually creating test cases is quite daunting. The plan moving forward is to implement a whole accuracy and regression test suite using the &lt;a href=&quot;https://www.vldb.org/pvldb/vol16/p1870-vitagliano.pdf&quot;&gt;Pollock Benchmark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Improved Sampling.&lt;/em&gt; We currently execute the auto-detection algorithm on a sequential sample of data. However, it&#39;s very common that new settings are only introduced later in the file (e.g., quotes might be used only in the last 10% of the file). Hence, being able to execute the sniffer in distinct parts of the file can improve accuracy.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Multi-Table CSV File.&lt;/em&gt; Multiple tables can be present in the same CSV file, which is a common scenario when exporting spreadsheets to CSVs. Therefore, we would like to be able to identify and support these.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Null-String Detection.&lt;/em&gt; We currently do not have an algorithm in place to identify the representation of null strings.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Decimal Precision Detection.&lt;/em&gt; We also don&#39;t automatically detect decimal precision yet. This is something that we aim to tackle in the future.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Parallelization.&lt;/em&gt; Despite DuckDB&#39;s CSV Reader being fully parallelized, the sniffer is still limited to a single thread. Parallelizing it in a similar fashion to what is done with the CSV Reader (description coming in a future blog post) would significantly enhance sniffing performance and enable full-file sniffing.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Sniffer as a stand-alone function.&lt;/em&gt; Currently, users can utilize the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESCRIBE&lt;/code&gt; query to acquire information from the sniffer, but it only returns column names and types. We aim to expose the sniffing algorithm as a stand-alone function that provides the complete results from the sniffer. This will allow users to easily configure files using the exact same options without the need to rerun the sniffer.&lt;/li&gt;
&lt;/ol&gt;

</description><link>https://duckdb.org/2023/10/27/csv-sniffer.html</link><guid isPermaLink="false">https://duckdb.org/2023/10/27/csv-sniffer.html</guid><pubDate>Fri, 27 Oct 2023 00:00:00 GMT</pubDate><author>Pedro Holanda</author></item><item><title>Announcing DuckDB 0.9.0</title><description>&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/yellow-billed-duck.jpg&quot; alt=&quot;Image of the Yellow Billed Duck&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The DuckDB team is happy to announce the latest DuckDB release (0.9.0). This release is named Undulata after the &lt;a href=&quot;https://en.wikipedia.org/wiki/Yellow-billed_duck&quot;&gt;Yellow-billed duck&lt;/a&gt; native to Africa.&lt;/p&gt;

&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;. The full release notes can be found &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.9.0&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;whats-new-in-090&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html#whats-new-in-090&quot;&gt;What&#39;s New in 0.9.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There have been too many changes to discuss them each in detail, but we would like to highlight several particularly exciting features!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Out-of-Core Hash Aggregate&lt;/li&gt;
  &lt;li&gt;Storage Improvements&lt;/li&gt;
  &lt;li&gt;Index Improvements&lt;/li&gt;
  &lt;li&gt;DuckDB-Wasm Extensions&lt;/li&gt;
  &lt;li&gt;Extension Auto-Loading&lt;/li&gt;
  &lt;li&gt;Improved AWS Support&lt;/li&gt;
  &lt;li&gt;Iceberg Support&lt;/li&gt;
  &lt;li&gt;Azure Support&lt;/li&gt;
  &lt;li&gt;PySpark-Compatible API&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is a summary of those new features with examples, starting with a change in our SQL dialect that is designed to produce more intuitive results by default.&lt;/p&gt;
      &lt;h2 id=&quot;breaking-sql-changes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html#breaking-sql-changes&quot;&gt;Breaking SQL Changes&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8942&quot;&gt;&lt;strong&gt;Struct Auto-Casting&lt;/strong&gt;&lt;/a&gt;. Previously the names of struct entries were ignored when determining auto-casting rules. As a result, struct field names could be silently renamed. Starting with this release, this will result in an error instead.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;structs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;STRUCT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;structs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;k&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Mismatch Type Error: Type STRUCT(k INTEGER) does not match with STRUCT(i INTEGER). Cannot cast STRUCTs with different names
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Unnamed structs constructed using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ROW&lt;/code&gt; function can still be inserted into struct fields.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;structs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;core-system-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html#core-system-improvements&quot;&gt;Core System Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7931&quot;&gt;Out-of-Core Hash Aggregates&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8475&quot;&gt;Hash Aggregate Performance Improvements.&lt;/a&gt;&lt;/strong&gt; When working with large data sets, memory management is always a potential pain point. By using a streaming execution engine and buffer manager, DuckDB supports many operations on larger than memory data sets. DuckDB also aims to support queries where &lt;em&gt;intermediate&lt;/em&gt; results do not fit into memory by using disk-spilling techniques.&lt;/p&gt;

&lt;p&gt;In this release, support for disk-spilling techniques is further extended through the support for out-of-core hash aggregates. Now, hash tables constructed during &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; queries or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt; operations that do not fit in memory due to a large number of unique groups will spill data to disk instead of throwing an out-of-memory exception. Due to the clever use of radix partitioning, performance degradation is gradual, and performance cliffs are avoided. Only the subset of the table that does not fit into memory will be spilled to disk.&lt;/p&gt;

&lt;p&gt;The performance of our hash aggregate has also improved in general, especially when there are many groups. For example, we compute the number of unique rows in a data set with 30 million rows and 15 columns by using the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If we keep all the data in memory, the query should use around 6 GB. However, we can still complete the query if less memory is available. In the table below, we can see how the runtime is affected by lowering the memory limit:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;memory limit&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.8.1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.9.0&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.52 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.91 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.52 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.45 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.52 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.45 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.52 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.47 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;OOM&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.41 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;OOM&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.67 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;OOM&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.87 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;OOM&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.20 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;OOM&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.39 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;OOM&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.91 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7644&quot;&gt;Compressed Materialization.&lt;/a&gt;&lt;/strong&gt; DuckDB&#39;s streaming execution engine has a low memory footprint, but more memory is required for operations such as grouped aggregation. The memory footprint of these operations can be reduced by compression. DuckDB already uses &lt;a href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html&quot;&gt;many compression techniques in its storage format&lt;/a&gt;, but many of these techniques are too costly to use during query execution. However, certain lightweight compression techniques are so cheap that the benefit of the reducing memory footprint outweight the cost of (de)compression.&lt;/p&gt;

&lt;p&gt;In this release, we add support for compression of strings and integer types right before data goes into the grouped aggregation and sorting operators. By using statistics, both types are compressed to the smallest possible integer type. For example, if we have the following table:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────┬─────────┐
│  id   │  name   │
│ int32 │ varchar │
├───────┼─────────┤
│   300 │ alice   │
│   301 │ bob     │
│   302 │ eve     │
│   303 │ mallory │
│   304 │ trent   │
└───────┴─────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt; column uses a 32-bit integer. From our statistics we know that the minimum value is 300, and the maximum value is 304. We can subtract 300 and cast to an 8-bit integer instead, reducing the width from 4 bytes down to 1.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;name&lt;/code&gt; column uses our internal string type, which is 16 bytes wide. However, our statistics tell us that the longest string here is only 7 bytes. We can fit this into a 64-bit integer like so:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alice   -&amp;gt; alice005
bob     -&amp;gt; bob00003
eve     -&amp;gt; eve00003
mallory -&amp;gt; mallory7
trent   -&amp;gt; trent005
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This reduces the width from 16 bytes down to 8. To support sorting of compressed strings, we flip the bytes on big-endian machines so that our comparison operators are still correct:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alice005 -&amp;gt; 500ecila
bob00003 -&amp;gt; 30000bob
eve00003 -&amp;gt; 30000eve
mallory7 -&amp;gt; 7yrollam
trent005 -&amp;gt; 500tnert
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By reducing the size of query intermediates, we can prevent/reduce spilling data to disk, reducing the need for costly I/O operations, thereby improving query performance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Window Function Performance Improvements (&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7831&quot;&gt;#7831&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7996&quot;&gt;#7996&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8050&quot;&gt;#8050&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8491&quot;&gt;#8491&lt;/a&gt;).&lt;/strong&gt; This release features many improvements to the performance of Window functions due to improved vectorization of the code, more re-use of partial aggregates and improved parallelism through work stealing of tasks. As a result, performance of &lt;a href=&quot;https://github.com/duckdb/duckdb/issues/7809#issuecomment-1679387022&quot;&gt;Window functions has improved significantly, particularly in scenarios where there are no or few partitions&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;driver_pay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_datetime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tripdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Version&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Run time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;v0.8.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;33.8 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;v0.9.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.8 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;storage-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html#storage-improvements&quot;&gt;Storage Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7794&quot;&gt;&lt;strong&gt;Vacuuming of Deleted Row Groups&lt;/strong&gt;&lt;/a&gt;. Starting with this release, when deleting data using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DELETE&lt;/code&gt; statements, entire row groups that are deleted will be automatically cleaned up. Support is also added to &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7824&quot;&gt;truncate the database file on checkpoint&lt;/a&gt; which allows the database file to be reduced in size after data is deleted. Note that this only occurs if the deleted row groups are located at the end of the file. The system does not yet move around data in order to reduce the size of the file on disk. Instead, free blocks earlier on in the file are re-used to store later data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Index Storage Improvements (&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7930&quot;&gt;#7930&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8112&quot;&gt;#8112&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8437&quot;&gt;#8437&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8703&quot;&gt;#8703&lt;/a&gt;)&lt;/strong&gt;. Many improvements have been made to both the in-memory footprint, and the on-disk footprint of ART indexes. In particular for indexes created to maintain &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRIMARY KEY&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNIQUE&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FOREIGN KEY&lt;/code&gt; constraints the storage and in-memory footprint is drastically reduced.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Version&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Size&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.8.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;278 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.9.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;78 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In addition, due to improvements in the manner in which indexes are stored on disk they can now be written to disk incrementally instead of always requiring a full rewrite. This allows for much quicker checkpointing for tables that have indexes.&lt;/p&gt;
      &lt;h2 id=&quot;extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html#extensions&quot;&gt;Extensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8732&quot;&gt;&lt;strong&gt;Extension Auto-Loading&lt;/strong&gt;&lt;/a&gt;. Starting from this release, DuckDB supports automatically installing and loading of trusted extensions. As many workflows rely on core extensions that are not bundled, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt;, many users found themselves having to remember to load the required extensions up front. With this change, the extensions will instead be automatically loaded (and optionally installed) when used in a query.&lt;/p&gt;

&lt;p&gt;For example, in Python the following code snippet now works without needing to explicitly load the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json&lt;/code&gt; extensions.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;FROM &#39;https://raw.githubusercontent.com/duckdb/duckdb/main/data/json/example_n.ndjson&#39;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The set of autoloadable extensions is limited to official extensions distributed by DuckDB Labs, and can be &lt;a href=&quot;https://github.com/duckdb/duckdb/blob/8feb03d274892db0e7757cd62c145b18dfa930ec/scripts/generate_extensions_function.py#L298&quot;&gt;found here&lt;/a&gt;. The behavior can also be disabled using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;autoinstall_known_extensions&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;autoload_known_extensions&lt;/code&gt; settings, or through the more general &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;enable_external_access&lt;/code&gt; setting. See the &lt;a href=&quot;https://duckdb.org/docs/stable/configuration/overview.html&quot;&gt;configuration options&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb-wasm/pull/1403&quot;&gt;&lt;strong&gt;DuckDB-Wasm Extensions&lt;/strong&gt;&lt;/a&gt;. This release adds support for loadable extensions to DuckDB-Wasm. Previously, any extensions that you wanted to use with the Wasm client had to be baked in. With this release, extensions can be loaded dynamically instead. When an extension is loaded, the Wasm bundle is downloaded and the functionality of the extension is enabled. Give it a try in our &lt;a href=&quot;https://shell.duckdb.org/&quot;&gt;Wasm shell&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; inet&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;127.0.0.1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;INET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb-aws&quot;&gt;&lt;strong&gt;AWS Extension&lt;/strong&gt;&lt;/a&gt;. This release marks the launch of the DuckDB AWS extension. This extension contains AWS related features that rely on the AWS SDK. Currently, the extension contains one function, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LOAD_AWS_CREDENTIALS&lt;/code&gt;, which uses the AWS &lt;a href=&quot;https://docs.aws.amazon.com/sdkref/latest/guide/standardized-credentials.html#credentialProviderChain&quot;&gt;Credential Provider Chain&lt;/a&gt; to automatically fetch and set credentials:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_aws_credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;s3://some-bucket/that/requires/authentication.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/extensions/aws.html&quot;&gt;See the documentation for more information&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb-iceberg&quot;&gt;&lt;strong&gt;Experimental Iceberg Extension&lt;/strong&gt;&lt;/a&gt;. This release marks the launch of the DuckDB Iceberg extension. This extension adds support for reading tables stored in the &lt;a href=&quot;https://iceberg.apache.org/&quot;&gt;Iceberg format&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;iceberg_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;data/iceberg/lineitem_iceberg&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;allow_moved_paths&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/extensions/iceberg/overview.html&quot;&gt;See the documentation for more information&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb-azure&quot;&gt;&lt;strong&gt;Experimental Azure Extension&lt;/strong&gt;&lt;/a&gt;. This release marks the launch of the DuckDB Azure extension. This extension allows for DuckDB to natively read data stored on Azure, in a similar manner to how it can read data stored on S3.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;azure_storage_connection_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;&amp;lt;your_connection_string&amp;gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;azure://&amp;lt;my_container&amp;gt;/*.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/extensions/azure.html&quot;&gt;See the documentation for more information&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;clients&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html#clients&quot;&gt;Clients&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/8083&quot;&gt;&lt;strong&gt;Experimental PySpark API&lt;/strong&gt;&lt;/a&gt;. This release features the addition of an experimental Spark API to the Python client. The API aims to be fully compatible with the PySpark API, allowing you to use the Spark API as you are familiar with but while utilizing the power of DuckDB. All statements are translated to DuckDB&#39;s internal plans using our &lt;a href=&quot;https://duckdb.org/docs/stable/clients/python/relational_api.html&quot;&gt;relational API&lt;/a&gt; and executed using DuckDB&#39;s query engine.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb.experimental.spark.sql&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkSession&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb.experimental.spark.sql.functions&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pandas_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&#39;age&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;56&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&#39;name&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Joan&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Peter&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;John&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Bob&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createDataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;withColumn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&#39;location&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Seattle&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;age&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;location&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#[
#    Row(age=34, location=&#39;Seattle&#39;),
#    Row(age=45, location=&#39;Seattle&#39;),
#    Row(age=23, location=&#39;Seattle&#39;),
#    Row(age=56, location=&#39;Seattle&#39;)
#]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that the API is currently experimental and features are still missing. We are very interested in feedback. Please report any functionality that you are missing, either through Discord or on GitHub.&lt;/p&gt;
      &lt;h2 id=&quot;final-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/26/announcing-duckdb-090.html#final-thoughts&quot;&gt;Final Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The full release notes can be &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.9.0&quot;&gt;found on GitHub&lt;/a&gt;. We would like to thank all of the contributors for their hard work on improving DuckDB.&lt;/p&gt;

</description><link>https://duckdb.org/2023/09/26/announcing-duckdb-090.html</link><guid isPermaLink="false">https://duckdb.org/2023/09/26/announcing-duckdb-090.html</guid><pubDate>Tue, 26 Sep 2023 00:00:00 GMT</pubDate><author>Mark Raasveldt and Hannes Mühleisen</author></item><item><title>DuckDB&#39;s AsOf Joins: Fuzzy Temporal Lookups</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB supports AsOf Joins – a way to match nearby values. They are especially useful for searching event tables for temporal analytics.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Do you have time series data that you want to join,
but the timestamps don&#39;t quite match?
Or do you want to look up a value that changes over time
using the times in another table?
And did you end up writing convoluted (and slow) inequality joins to get your results?
Then this post is for you!&lt;/p&gt;
      &lt;h2 id=&quot;what-is-an-asof-join&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#what-is-an-asof-join&quot;&gt;What Is an AsOf Join?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Time series data is not always perfectly aligned.
Clocks may be slightly off, or there may be a delay between cause and effect.
This can make connecting two sets of ordered data challenging.
AsOf Joins are a tool for solving this and other similar problems.&lt;/p&gt;

&lt;p&gt;One of the problems that AsOf Joins are used to solve is
finding the value of a varying property at a specific point in time.
This use case is so common that it is where the name came from:
&lt;em&gt;Give me the value of the property &lt;strong&gt;as of this time.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;More generally, however, AsOf joins embody some common temporal analytic semantics,
which can be cumbersome and slow to implement in standard SQL.&lt;/p&gt;
      &lt;h3 id=&quot;portfolio-example&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#portfolio-example&quot;&gt;Portfolio Example&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Let&#39;s start with a concrete example.
Suppose we have a table of stock &lt;a href=&quot;https://duckdb.org/data/prices.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prices&lt;/code&gt;&lt;/a&gt; with timestamps:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ticker&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;when&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;price&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MSFT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MSFT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MSFT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We have another table containing portfolio &lt;a href=&quot;https://duckdb.org/data/holdings.csv&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;holdings&lt;/code&gt;&lt;/a&gt; at various points in time:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ticker&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;when&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;shares&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2000-12-31 23:59:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.94&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;24.13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2000-12-31 23:59:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9.33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10.58&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DATA&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2000-12-31 23:59:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.65&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DATA&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.95&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DATA&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18.37&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can compute the value of each holding at that point in time by finding
the most recent price before the holding&#39;s timestamp by using an AsOf Join:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shares&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;holdings&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This attaches the value of the holding at that time to each row:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ticker&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;when&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.94&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;48.26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.16&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;It essentially executes a function defined by looking up nearby values in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prices&lt;/code&gt; table.
Note also that missing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ticker&lt;/code&gt; values do not have a match and don&#39;t appear in the output.&lt;/p&gt;
      &lt;h3 id=&quot;outer-asof-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#outer-asof-joins&quot;&gt;Outer AsOf Joins&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Because AsOf produces at most one match from the right hand side,
the left side table will not grow as a result of the join,
but it could shrink if there are missing times on the right.
To handle this situation, you can use an &lt;em&gt;outer&lt;/em&gt; AsOf Join:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shares&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;holdings&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you might expect, this will produce &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; prices and values instead of dropping left side rows
when there is no ticker or the time is before the prices begin.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ticker&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;when&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2000-12-31 23:59:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.94&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;48.26&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2000-12-31 23:59:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DATA&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2000-12-31 23:59:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DATA&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DATA&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:30&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;windowing-alternative&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#windowing-alternative&quot;&gt;Windowing Alternative&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Standard SQL can implement this kind of join,
but you need to use a window function and an inequality join.
These can both be fairly expensive operations, but the query would look like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;&quot;when&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;when&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;infinity&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;when&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shares&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;holdings&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The default value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;infinity&lt;/code&gt; is used to make sure there is an end value for the last row that can be compared.
Here is what the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;state&lt;/code&gt; CTE looks like for our example:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ticker&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;price&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;when&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;end&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;APPL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;infinity&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GOOG&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;infinity&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MSFT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MSFT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:01:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MSFT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2001-01-01 00:02:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;infinity&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In the case where there is no equality condition, the planner would have to use an inequality join,
which can be very expensive.
And even in the equality condition case, 
the resulting hash join may end up with long chains of identical &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ticker&lt;/code&gt; keys that will all match and need pruning.&lt;/p&gt;
      &lt;h2 id=&quot;why-asof&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#why-asof&quot;&gt;Why AsOf?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;If SQL can compute AsOf joins already, why do we need a new join type?
There are two big reasons: expressibility and performance.
The windowing alternative is more verbose and harder to understand than the AsOf syntax,
so making it easier to say what you are doing helps others (or even you!) understand what is happening.&lt;/p&gt;

&lt;p&gt;The syntax also makes it easier for DuckDB to understand what you want and produce your results faster.
The window and inequality join version loses the valuable information that the intervals do not overlap.
It also prevents the query optimiser from moving the join 
because SQL insists that windowing happens &lt;em&gt;after&lt;/em&gt; joins.
By treating the operation &lt;em&gt;as a join&lt;/em&gt; with &lt;em&gt;known data constraints&lt;/em&gt;,
DuckDB can move the join for performance and use a tailored join algorithm.
The algorithm we use is to sort the right side table and then do a kind of merge join with the left side values.
But unlike a standard merge join, 
AsOf can stop searching when it finds the first match because there is at most one match.&lt;/p&gt;
      &lt;h3 id=&quot;state-tables&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#state-tables&quot;&gt;State Tables&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;You may be wondering why the Common Table Expression in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH&lt;/code&gt; clause was called &lt;em&gt;state&lt;/em&gt;.
This is because the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prices&lt;/code&gt; table is really an example of what in temporal analytics is called an &lt;em&gt;event table&lt;/em&gt; .
The rows of an event table contain timestamps and what happened at that time (i.e., events).
The events in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;prices&lt;/code&gt; table are changes to the price of a stock.
Another common example of an event table is a structured log file:
Each row of the log records when something &quot;happened&quot; – usually a change to a part of the system.&lt;/p&gt;

&lt;p&gt;Event tables are difficult to work with because each fact only has the start time.
In order to know whether the fact is still true (or true at a specific time) you need the end time as well.
A table with both the start and end time is called a &lt;em&gt;state table&lt;/em&gt;.
Converting event tables to state tables is a common temporal data preparation task,
and the windowing CTE above shows how to do it in general using SQL.&lt;/p&gt;
      &lt;h3 id=&quot;sentinel-values&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#sentinel-values&quot;&gt;Sentinel Values&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;One limitation of the windowing approach is that 
the ordering type needs to have sentinel value that can be used if it does not support &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;infinity&lt;/code&gt;,
either an unused value or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Both of these choices are potentially problematic.
In the first case, it may not be easy to determine an upper sentinel value 
(suppose the ordering was a string column?)
In the second case, you would need to write the condition as 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h.when &amp;lt; s.end OR s.end IS NULL&lt;/code&gt;
and using an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OR&lt;/code&gt; like this in a join condition makes comparisons slow and hard to optimise.
Moreover, if the ordering column is already using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; to indicate missing values,
this option is not available.&lt;/p&gt;

&lt;p&gt;For most state tables, there are suitable choices (e.g., large dates) 
but one of the advantages of AsOf is that it can avoid having to design a state table 
if it is not needed for the analytic task.&lt;/p&gt;
      &lt;h3 id=&quot;event-table-variants&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#event-table-variants&quot;&gt;Event Table Variants&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;So far we have been using a standard type of event table 
where the timestamps are assumed to be the start of the state transitions.
But AsOf can now use any inequality, which allows it to handle other types of event tables.&lt;/p&gt;

&lt;p&gt;To explore this, let&#39;s use two very simple tables with no equality conditions.
The build side will just have four integer &quot;timestamps&quot; with alphabetic values:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;d&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The probe table will just be the time values plus the midpoints,
and we can make a table showing what value each probe time matches
for greater than or equal to:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Probe&lt;/th&gt;
      &lt;th&gt;&amp;gt;=&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.0&lt;/td&gt;
      &lt;td&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.5&lt;/td&gt;
      &lt;td&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.0&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.5&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.0&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.5&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.0&lt;/td&gt;
      &lt;td&gt;d&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.5&lt;/td&gt;
      &lt;td&gt;d&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This shows us that the interval a probe value matches is in the half-open interval &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[Tn, Tn+1)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now let&#39;s see what happens if use strictly greater than as the inequality:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Probe&lt;/th&gt;
      &lt;th&gt;&amp;gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.0&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.5&lt;/td&gt;
      &lt;td&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.0&lt;/td&gt;
      &lt;td&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.5&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.0&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.5&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.0&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.5&lt;/td&gt;
      &lt;td&gt;d&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we can see that the interval a probe value matches is in the half-open interval &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Tn, Tn+1]&lt;/code&gt;.
The only difference is that the interval is closed at the end instead of the beginning.
This means that for this inequality type, the time is not part of the interval.&lt;/p&gt;

&lt;p&gt;What if the inequality goes in the other direction, say less than or equal to?&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Probe&lt;/th&gt;
      &lt;th&gt;&amp;lt;=&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5&lt;/td&gt;
      &lt;td&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.0&lt;/td&gt;
      &lt;td&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.5&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.0&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.5&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.0&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.5&lt;/td&gt;
      &lt;td&gt;d&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.0&lt;/td&gt;
      &lt;td&gt;d&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.5&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Again, we have half-open intervals, but this time we are matching the &lt;em&gt;previous&lt;/em&gt; interval &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Tn-1, Tn]&lt;/code&gt;.
One way to interpret this is that the times in the build table are the &lt;em&gt;end&lt;/em&gt; of the interval,
instead of the beginning.
Also, unlike greater than or equal to,
the interval is closed at the end instead of the beginning.
Adding this to what we found for strictly greater than,
we can interpret this as meaning that the lookup times are part of the interval
when non-strict inequalities are used.&lt;/p&gt;

&lt;p&gt;We can check this by looking at the last inequality: strictly less than:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Probe&lt;/th&gt;
      &lt;th&gt;&amp;lt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.5&lt;/td&gt;
      &lt;td&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.0&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.5&lt;/td&gt;
      &lt;td&gt;b&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.0&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.5&lt;/td&gt;
      &lt;td&gt;c&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.0&lt;/td&gt;
      &lt;td&gt;d&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.5&lt;/td&gt;
      &lt;td&gt;d&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.0&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.5&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In this case the matching intervals are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[Tn-1, Tn)&lt;/code&gt;.
This is a strict inequality, so the table time is not in the interval,
and it is a less than, so the time is the end of the interval.&lt;/p&gt;

&lt;p&gt;To sum up, here is the full list:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Inequality&lt;/th&gt;
      &lt;th&gt;Interval&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;(Tn, Tn+1]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&amp;gt;=&lt;/td&gt;
      &lt;td&gt;[Tn, Tn+1)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&amp;lt;=&lt;/td&gt;
      &lt;td&gt;(Tn-1, Tn]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&amp;lt;&lt;/td&gt;
      &lt;td&gt;[Tn-1, Tn)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We now have two natural interpretations of what the inequalities mean:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The greater (resp. less) than inequalities mean the time is the beginning (resp. end) of the interval.&lt;/li&gt;
  &lt;li&gt;The strict (resp. non-strict) inequalities mean the time is excluded from (resp. included in) the interval.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So if we know whether the time marks the start or the end of the event,
and whether the time is include or excluded, we can choose the appropriate AsOf inequality.&lt;/p&gt;
      &lt;h3 id=&quot;usage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#usage&quot;&gt;Usage&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;So far we have been explicit about specifying the conditions for AsOf,
but SQL also has a simplified join condition syntax
for the common case where the column names are the same in both tables.
This syntax uses the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;USING&lt;/code&gt; keyword to list the fields that should be compared for equality.
AsOf also supports this syntax, but with two restrictions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The last field is the inequality&lt;/li&gt;
  &lt;li&gt;The inequality is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;gt;=&lt;/code&gt; (the most common case)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our first query can then be written as:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shares&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;holdings&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;when&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Be aware that if you don&#39;t explicitly list the columns in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;,
the ordering field value will be the probe value, not the build value.
For a natural join, this is not an issue because all the conditions are equalities,
but for AsOf, one side has to be chosen.
Since AsOf can be viewed as a lookup function,
it is more natural to return the &quot;function arguments&quot; than the function internals.&lt;/p&gt;
      &lt;h3 id=&quot;under-the-hood&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#under-the-hood&quot;&gt;Under the Hood&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;What an AsOf Join is really doing is allowing you to treat an event table as a state table for join operations.
By knowing the semantics of the join, it can avoid creating a full state table
and be more efficient than a general inequality join.&lt;/p&gt;

&lt;p&gt;Let&#39;s start by looking at how the windowing version works.
Remember that we used this query to convert the event table to a state table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;price&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;&quot;when&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;when&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;infinity&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;when&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prices&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The state table CTE is created by hash partitioning the table on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ticker&lt;/code&gt;,
sorting on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;when&lt;/code&gt; and then computing another column that is just &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;when&lt;/code&gt; shifted down by one.
The join is then implemented with a hash join on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ticker&lt;/code&gt; and two comparisons on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;when&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If there was no &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ticker&lt;/code&gt; column (e.g., the prices were for a single item)
then the join would be implemented using our inequality join operator,
which would materialise and sort both sides because it doesn&#39;t know that the ranges are disjoint.&lt;/p&gt;

&lt;p&gt;The AsOf operator uses all three operator pipeline APIs to consolidate and collect rows.
During the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sink&lt;/code&gt; phase, AsOf hash partitions and sorts the right hand side to make a temporary state table.
(In fact it uses the same code as Window,
but without unnecessarily materialising the end column.)
During the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;operator&lt;/code&gt; phase, it filters out (or returns) rows that cannot match
because of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values in the predicate expressions,
and then hash partitions and sorts the remaining rows into a cache.
Finally, during the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;source&lt;/code&gt; phase, it matches hash partitions
and then merge joins the sorted values within each hash partition.&lt;/p&gt;
      &lt;h2 id=&quot;benchmarks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#benchmarks&quot;&gt;Benchmarks&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Because AsOf joins can be implemented in various ways using standard SQL queries,
benchmarking is really about comparing the various alternatives.&lt;/p&gt;

&lt;p&gt;One alternative is a debugging &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRAGMA&lt;/code&gt; for AsOf called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;debug_asof_iejoin&lt;/code&gt;, 
which implements the join using Window and IEJoin.
This allows us to easily toggle between the implementations and compare runtimes.&lt;/p&gt;

&lt;p&gt;Other alternatives combine equi-joins and window functions.
The equi-join is used to implement the equality matching conditions,
and the window is used to select the closest inequality.
We will now look at two different windowing techniques and compare their performance.
If you wish to skip this section,
the bottom line is that while they are sometimes a bit faster,
the AsOf join has the most consistent behavior of all the algorithms.&lt;/p&gt;
      &lt;h3 id=&quot;window-as-state-table&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#window-as-state-table&quot;&gt;Window as State Table&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The first benchmark compares a hash join with a state table.
It probes a 5M row table of values
built from 100K timestamps and 50 partitioning keys
using a self-join where only 50% of the keys are present
and the timestamps have been shifted to be halfway between the originals:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2001-01-01 00:00:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MINUTE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECOND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;build&lt;/code&gt; table looks like this:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;k&lt;/th&gt;
      &lt;th&gt;t&lt;/th&gt;
      &lt;th&gt;v&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:00:00&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:01:00&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:02:00&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:03:00&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;and the probe table looks like this (with only even values for k):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;k&lt;/th&gt;
      &lt;th&gt;t&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2000-12-31 23:59:30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:00:30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:01:30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:02:30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2001-01-01 00:03:30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The benchmark just does the join and sums up the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt; column:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The debugging &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRAGMA&lt;/code&gt; does not allow us to use a hash join,
but we can create the state table in a CTE again and use an inner join:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Hash Join implementation&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;infinity&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This works because the planner assumes that equality conditions are more selective
than inequalities and generates a hash join with a filter.&lt;/p&gt;

&lt;p&gt;Running the benchmark, we get results like this:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Algorithm&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Median of 5&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;AsOf&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.425 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;IEJoin&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.522 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;State Join&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;192.460 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The runtime improvement of AsOf over IEJoin here is about 9×.
The horrible performance of the Hash Join is caused by the long (100K) bucket chains in the hash table.&lt;/p&gt;

&lt;p&gt;The second benchmark tests the case where the probe side is about 10× smaller than the build side:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;s1&quot;&gt;&#39;2021-01-01T00:00:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECOND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100_000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
      &lt;span class=&quot;s1&quot;&gt;&#39;2021-01-01T00:00:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SECOND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1_000_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Hash Join Version&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;nf&quot;&gt;lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;infinity&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Algorithm&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Median of 5 runs&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;State Join&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.065 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;AsOf&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.077 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;IEJoin&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;49.508 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now the runtime improvement of AsOf over IEJoin is huge (~500×)
because it can leverage the partitioning to eliminate almost all of the equality mismatches.&lt;/p&gt;

&lt;p&gt;The Hash Join implementation does much better here because 
the optimiser notices that the probe side is smaller and builds the hash table on the &quot;probe&quot; table.
Also, the probe values here are unique, so the hash table chains are minimal.&lt;/p&gt;
      &lt;h3 id=&quot;window-with-ranking&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#window-with-ranking&quot;&gt;Window with Ranking&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Another way to use the window operator is to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Join the tables on the equality predicates&lt;/li&gt;
  &lt;li&gt;Filter to pairs where the build time is before the probe time&lt;/li&gt;
  &lt;li&gt;Partition the result on both the equality keys &lt;em&gt;and&lt;/em&gt; the probe timestamp&lt;/li&gt;
  &lt;li&gt;Sort the partitions on the build timestamp &lt;em&gt;descending&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Filter out all value except rank 1 (i.e., the largest build time &amp;lt;= the probe time)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The query looks like:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;QUALIFY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The advantage of this windowing query is that it does not require sentinel values,
so it can work with any data type.
The disadvantage is that it creates many more partitions 
because it includes both timestamps, which requires more complex sorting.
Moreover, because it applies the window &lt;em&gt;after&lt;/em&gt; the join,
it can produce huge intermediates that can result in external sorting
and expensive out-of-memory operations.&lt;/p&gt;

&lt;p&gt;For this benchmark, we will be using three build tables,
and two probe tables, all containing 10K integer equality keys.
The probe tables have either 1 or 15 timestamps per key:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe15&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
         &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;2022-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;26&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2022-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The build tables are much larger and have approximately
10/100/1000× the number of entries as the 15 element tables:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- 10:1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
         &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;2022-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;59&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;HOUR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- 100:1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
         &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;2022-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;350&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MINUTE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- 1000:1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build1000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;DECIMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
         &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;2022-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MINUTE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The AsOf join queries are:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- AsOf/IEJoin&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Rank&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;QUALIFY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The results are shown here:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/asof-rank.png&quot; alt=&quot;Rank Benchmark Results&quot; width=&quot;760&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;(Median of 5 except for Rank/15/1000).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For all ratios with 15 probes, AsOf is the most performant.&lt;/li&gt;
  &lt;li&gt;For small ratios with 15 probes, Rank beats IEJoin (both with windowing), but by 100:1 it is starting to explode.&lt;/li&gt;
  &lt;li&gt;For single element probes, Rank is most effective, but even there, its edge over AsOf is only about 50% at scale.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This shows that AsOf could be possibly be improved upon, but predicting where that happens would be tricky,
and getting it wrong would have enormous costs.&lt;/p&gt;
      &lt;h2 id=&quot;future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#future-work&quot;&gt;Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB can now execute AsOf joins for all inequality types with reasonable performance.
In some cases, the performance gain is several orders of magnitude over the standard SQL versions –
even with our fast inequality join operator.&lt;/p&gt;

&lt;p&gt;While the current AsOf operator is completely general,
there are a couple of planning optimisations that could be applied here.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When there are selective equality conditions, it is likely that a hash join with filtering against a materialised state table would be significantly faster. If we can detect this and suitable sentinel values are available, the planner could choose to use a hash join instead of the default AsOf implementation.&lt;/li&gt;
  &lt;li&gt;There are also use cases where the probe table is much smaller than the build table, along with equality conditions, and performing a hash join against the &lt;em&gt;probe&lt;/em&gt; table could yield significant performance improvements.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nevertheless, remember that one of the advantages of SQL is that it is a declarative language:&lt;br&gt;
You specify &lt;em&gt;what&lt;/em&gt; you want and leave it up to the database to figure out &lt;em&gt;how&lt;/em&gt;.
Now that we have defined the semantics of the AsOf join,
you the user can write queries saying this is &lt;em&gt;what&lt;/em&gt; you want – and we are free to keep improving the &lt;em&gt;how&lt;/em&gt;!&lt;/p&gt;
      &lt;h2 id=&quot;happy-joining&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html#happy-joining&quot;&gt;Happy Joining!&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;One of the most interesting parts of working on DuckDB is that it stretches the traditional SQL model of unordered data.
DuckDB makes it easy to query &lt;em&gt;ordered&lt;/em&gt; data sets such as data frames and parquet files,
and when you have data like that, you expect to be able to do ordered analysis!
Implementing Fast Sorting, Fast Windowing and Fast AsOf joins is how we are making this expectation a reality.&lt;/p&gt;

</description><link>https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html</link><guid isPermaLink="false">https://duckdb.org/2023/09/15/asof-joins-fuzzy-temporal-lookups.html</guid><pubDate>Fri, 15 Sep 2023 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>Even Friendlier SQL with DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB continues to push the boundaries of SQL syntax to both simplify queries and make more advanced analyses possible. Highlights include dynamic column selection, queries that start with the FROM clause, function chaining, and list comprehensions. We boldly go where no SQL engine has gone before! For more details, see the documentation for &lt;a href=&quot;https://duckdb.org/docs/guides/sql_features/friendly_sql&quot;&gt;friendly SQL features&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ai_generated_star_trek_rubber_duck.png&quot; alt=&quot;Looks like a Duck ready to boldly go where databases have not gone before&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Who says that SQL should stay frozen in time, chained to a 1999 version of the specification? As a comparison, do folks remember what JavaScript felt like before Promises? Those didn’t launch until 2012! It’s clear that innovation at the programming syntax layer can have a profoundly positive impact on an entire language ecosystem.&lt;/p&gt;

&lt;p&gt;We believe there are many valid reasons for innovation in the SQL language, among them opportunities to simplify basic queries and also to make more dynamic analyses possible. Many of these features arose from community suggestions! Please let us know your SQL pain points on &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Discord&lt;/a&gt; or &lt;a href=&quot;https://github.com/duckdb/duckdb/discussions&quot;&gt;GitHub&lt;/a&gt; and join us as we change what it feels like to write SQL!&lt;/p&gt;

&lt;p&gt;If you have not had a chance to read the first installment in this series, please take a quick look to the prior blog post, &lt;a href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html&quot;&gt;“Friendlier SQL with DuckDB”&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;the-future-is-now&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#the-future-is-now&quot;&gt;The Future Is Now&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The first few enhancements in this list were included in the “Ideas for the Future” section of the prior post.&lt;/p&gt;
      &lt;h3 id=&quot;reusable-column-aliases&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#reusable-column-aliases&quot;&gt;Reusable Column Aliases&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;When working with incremental calculated expressions in a select statement, traditional SQL dialects force you to either write out the full expression for each column or create a common table expression (CTE) around each step of the calculation. Now, any column alias can be reused by subsequent columns within the same select statement. Not only that, but these aliases can be used in the where and order by clauses as well.&lt;/p&gt;
      &lt;h4 id=&quot;old-way-1-repeat-yourself&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#old-way-1-repeat-yourself&quot;&gt;Old Way 1: Repeat Yourself&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;s1&quot;&gt;&#39;These are the voyages of the starship Enterprise...&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;instr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;These are the voyages of the starship Enterprise...&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;starship&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship_loc&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;These are the voyages of the starship Enterprise...&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;instr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;These are the voyages of the starship Enterprise...&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;starship&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;starship&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trimmed_intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;old-way-2-all-the-ctes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#old-way-2-all-the-ctes&quot;&gt;Old Way 2: All the CTEs&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intro_cte&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&#39;These are the voyages of the starship Enterprise...&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship_loc_cte&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;instr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;starship&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship_loc&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intro_cte&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;starship_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;starship&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trimmed_intro&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship_loc_cte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;new-way&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#new-way&quot;&gt;New Way&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;s1&quot;&gt;&#39;These are the voyages of the starship Enterprise...&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;nf&quot;&gt;instr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;starship&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;nf&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;starship&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trimmed_intro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;intro&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;starship_loc&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;trimmed_intro&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;These are the voyages of the starship Enterprise…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;30&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Enterprise…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;dynamic-column-selection&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#dynamic-column-selection&quot;&gt;Dynamic Column Selection&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Databases typically prefer strictness in column definitions and flexibility in the number of rows. This can help by enforcing data types and recording column level metadata. However, in data science workflows and elsewhere, it is very common to dynamically generate columns (for example during feature engineering).&lt;/p&gt;

&lt;p&gt;No longer do you need to know all of your column names up front! DuckDB can select and even modify columns based on regular expression pattern matching, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REPLACE&lt;/code&gt; modifiers, and even lambda functions (see the &lt;a href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#list-lambda-functions&quot;&gt;section on lambda functions below&lt;/a&gt; for details!).&lt;/p&gt;

&lt;p&gt;Let’s take a look at some facts gathered about the first season of Star Trek. Using DuckDB’s &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; extension&lt;/a&gt;, we can query a CSV dataset directly from GitHub. It has several columns so let’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESCRIBE&lt;/code&gt; it.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; httpfs&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; httpfs&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://blobs.duckdb.org/data/Star_Trek-Season_1.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;DESCRIBE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;column_name&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;column_type&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;null&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;key&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;default&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;extra&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;season_num&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;episode_num&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;aired_date&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DATE&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_kirk_hookups&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_downed_redshirts&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;bool_aliens_almost_took_over_planet&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;bool_aliens_almost_took_over_enterprise&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_vulcan_nerve_pinch&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_warp_speed_orders&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;highest_warp_speed_issued&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;bool_hand_phasers_fired&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;bool_ship_phasers_fired&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;bool_ship_photon_torpedos_fired&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_transporter_pax&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_damn_it_jim_quote&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_im_givin_her_all_shes_got_quote&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cnt_highly_illogical_quote&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;bool_enterprise_saved_the_day&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BIGINT&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;YES&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h4 id=&quot;columns-with-regular-expressions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#columns-with-regular-expressions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS()&lt;/code&gt; with Regular Expressions&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression can accept a string parameter that is a regular expression and will return all column names that match the pattern. How did warp change over the first season? Let’s examine any column name that contains the word &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;warp&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;episode_num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;.*warp.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;episode_num&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;cnt_warp_speed_orders&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;highest_warp_speed_issued&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;27&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;28&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;29&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression can also be wrapped by other functions to apply those functions to each selected column. Let’s simplify the above query to look at the maximum values across all episodes:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;.*warp.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.cnt_warp_speed_orders)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.highest_warp_speed_issued)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can also create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clause that applies across multiple columns. All columns must match the filter criteria, which is equivalent to combining them with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AND&lt;/code&gt;. Which episodes had at least 2 warp speed orders and at least a warp speed level of 2?&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;episode_num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;.*warp.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;.*warp.*&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- cnt_warp_speed_orders &amp;gt;= 2 &lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- AND &lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;-- highest_warp_speed_issued &amp;gt;= 2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;episode_num&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;cnt_warp_speed_orders&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;highest_warp_speed_issued&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;29&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;columns-with-exclude-and-replace&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#columns-with-exclude-and-replace&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS()&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REPLACE&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Individual columns can also be either excluded or replaced prior to applying calculations on them. For example, since our dataset only includes season 1, we do not need to find the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt; of that column. It would be highly illogical.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;season_num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.&lt;br&gt;episode_num)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.&lt;br&gt;aired_date)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.&lt;br&gt;cnt_kirk_hookups)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;…&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.&lt;br&gt;bool_enterprise_saved_the_day)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;29&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1967-04-13&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REPLACE&lt;/code&gt; syntax is also useful when applied to a dynamic set of columns. In this example, we want to convert the dates into timestamps prior to finding the maximum value in each column. Previously this would have required an entire subquery or CTE to pre-process just that single column!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aired_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timestamp&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aired_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.&lt;br&gt;season_num)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.&lt;br&gt;episode_num)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(aired_date := &lt;br&gt;CAST(aired_date AS TIMESTAMP))&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;…&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;max(trek_facts.&lt;br&gt;bool_enterprise_saved_the_day)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;29&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1967-04-13 00:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;columns-with-lambda-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#columns-with-lambda-functions&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS()&lt;/code&gt; with Lambda Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The most flexible way to query a dynamic set of columns is through a &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/nested.html#lambda-functions&quot;&gt;lambda function&lt;/a&gt;. This allows for any matching criteria to be applied to the names of the columns, not just regular expressions. See more details about lambda functions below.&lt;/p&gt;

&lt;p&gt;For example, if using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; syntax is more comfortable, we can select columns matching a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; pattern rather than with a regular expression.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;episode_num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%warp%&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%warp%&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;episode_num&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;cnt_warp_speed_orders&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;highest_warp_speed_issued&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;29&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;automatic-json-to-nested-types-conversion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#automatic-json-to-nested-types-conversion&quot;&gt;Automatic JSON to Nested Types Conversion&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The first installment in the series mentioned JSON dot notation references as future work. However, the team has gone even further! Instead of referring to JSON-typed columns using dot notation, JSON can now be &lt;a href=&quot;https://duckdb.org/2023/03/03/json.html&quot;&gt;automatically parsed&lt;/a&gt; into DuckDB’s native types for significantly faster performance, compression, as well as that friendly dot notation!&lt;/p&gt;

&lt;p&gt;First, install and load the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json&lt;/code&gt; extensions if they don&#39;t come bundled with the client you are using. Then query a remote JSON file directly as if it were a table!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; httpfs&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; httpfs&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; json&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; json&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;n&quot;&gt;starfleet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starship&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://raw.githubusercontent.com/vlad-saling/star-trek-ipsum/master/src/content/content.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;starship&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;USS Farragut - NCC-1647 - Ship on which James Kirk served as a phaser station operator. Attacked by the Dikironium Cloud Creature, killing half the crew. ad.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now for some new SQL capabilities beyond the ideas from the prior post!&lt;/p&gt;
      &lt;h2 id=&quot;from-first-in-select-statements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#from-first-in-select-statements&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; First in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; Statements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When building a query, the first thing you need to know is where your data is coming &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;. Well then why is that the second clause in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement?? No longer! DuckDB is building SQL as it should have always been – putting the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause first! This addresses one of the longest standing complaints about SQL, and the DuckDB team implemented it in 2 days.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Not only that, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement can be completely removed and DuckDB will assume all columns should be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;ed. Taking a look at a table is now as simple as:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- SELECT * FROM my_table&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Other statements like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COPY&lt;/code&gt; are simplified as well.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trek_facts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;phaser_filled_facts.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This has an additional benefit beyond saving keystrokes and staying in a development flow state: autocomplete will have much more context when you begin to choose columns to query. Give the AI a helping hand!&lt;/p&gt;

&lt;p&gt;Note that this syntax is completely optional, so your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM&lt;/code&gt; keyboard shortcuts are safe, even if they are obsolete… 🙂&lt;/p&gt;
      &lt;h2 id=&quot;function-chaining&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#function-chaining&quot;&gt;Function Chaining&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Many SQL blogs advise the use of CTEs instead of subqueries. Among other benefits, they are much more readable. Operations are compartmentalized into discrete chunks and they can be read in order top to bottom instead of forcing the reader to work their way inside out.&lt;/p&gt;

&lt;p&gt;DuckDB enables the same interpretability improvement for every scalar function! Use the dot operator to chain functions together, just like in Python. The prior expression in the chain is used as the first argument to the subsequent function.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Make it so&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39; &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list_aggr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;string_agg&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;.&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;.&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;im_not_messing_around_number_one&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;im_not_messing_around_number_one&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MAKE.IT.SO.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now compare that with the old way…&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;nf&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;nf&quot;&gt;list_aggr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
               &lt;span class=&quot;nf&quot;&gt;string_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                    &lt;span class=&quot;nf&quot;&gt;upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Make it stop&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
               &lt;span class=&quot;s1&quot;&gt;&#39; &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
          &lt;span class=&quot;s1&quot;&gt;&#39;string_agg&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;.&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
     &lt;span class=&quot;s1&quot;&gt;&#39;.&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;oof&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MAKE.IT.STOP.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;union-by-name&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#union-by-name&quot;&gt;Union by Name&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB aims to blend the best of databases and dataframes. This new syntax is inspired by the &lt;a href=&quot;https://pandas.pydata.org/docs/reference/api/pandas.concat.html&quot;&gt;concat function in Pandas&lt;/a&gt;. Rather than vertically stacking tables based on column position, columns are matched by name and stacked accordingly. Simply replace &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION BY NAME&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION ALL BY NAME&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For example, we had to add some new alien species proverbs in The Next Generation:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proverbs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
          &lt;span class=&quot;s1&quot;&gt;&#39;Revenge is a dish best served cold&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;klingon_proverb&lt;/span&gt; 
     &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt; 
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
          &lt;span class=&quot;s1&quot;&gt;&#39;You will be assimilated&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;borg_proverb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;s1&quot;&gt;&#39;If winning is not important, why keep score?&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;klingon_proverb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proverbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;klingon_proverb&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;borg_proverb&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Revenge is a dish best served cold&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;If winning is not important, why keep score?&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;You will be assimilated&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This approach has additional benefits. As seen above, not only can tables with different column orders be combined, but so can tables with different numbers of columns entirely. This is helpful as schemas migrate, and is particularly useful for DuckDB’s &lt;a href=&quot;https://duckdb.org/docs/stable/data/multiple_files/combining_schemas.html#union-by-name&quot;&gt;multi-file reading capabilities&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;insert-by-name&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#insert-by-name&quot;&gt;Insert by Name&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another common situation where column order is strict in SQL is when inserting data into a table. Either the columns must match the order exactly, or all of the column names must be repeated in two locations within the query.&lt;/p&gt;

&lt;p&gt;Instead, add the keywords &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BY NAME&lt;/code&gt; after the table name when inserting. Any subset of the columns in the table in any order can be inserted.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proverbs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt; 
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Resistance is futile&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;borg_proverb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proverbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;klingon_proverb&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;borg_proverb&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Revenge is a dish best served cold&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;If winning is not important, why keep score?&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;You will be assimilated&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Resistance is futile&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;dynamic-pivot-and-unpivot&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#dynamic-pivot-and-unpivot&quot;&gt;Dynamic &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Historically, databases are not well-suited for pivoting operations. However, DuckDB’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; clauses can create or stack dynamic column names for a truly flexible pivoting capability! In addition to that flexibility, DuckDB also provides both the SQL standard syntax and a friendlier shorthand.&lt;/p&gt;

&lt;p&gt;For example, let’s take a look at some procurement forecast data just as the Earth-Romulan war was beginning:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;purchases&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;purchases&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;phasers&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2155&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1035&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;phasers&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2156&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25039&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;phasers&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2157&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;95000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;photon torpedoes&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2155&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;photon torpedoes&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2156&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;17899&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;photon torpedoes&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2157&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;87492&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;purchases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;item&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;year&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;phasers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2155&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1035&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;phasers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2156&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;25039&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;phasers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2157&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;95000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;photon torpedoes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2155&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;255&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;photon torpedoes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2156&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17899&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;photon torpedoes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2157&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;87492&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;It is easier to compare our phaser needs to our photon torpedo needs if each year’s data is visually close together. Let’s pivot this into a friendlier format! Each year should receive its own column (but each year shouldn’t need to be specified in the query!), we want to sum up the total &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count&lt;/code&gt;, and we still want to keep a separate group (row) for each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;item&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivoted_purchases&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;PIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;purchases&lt;/span&gt; 
          &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; 
          &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
          &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivoted_purchases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;item&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2155&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2156&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;2157&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;phasers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1035&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;25039&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;95000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;photon torpedoes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;255&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17899&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;87492&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Looks like photon torpedoes went on sale…&lt;/p&gt;

&lt;p&gt;Now imagine the reverse situation. Scotty in engineering has been visually analyzing and manually constructing his purchases forecast. He prefers things pivoted so it’s easier to read. Now you need to fit it back into the database! This war may go on for a bit, so you may need to do this again next year. Let’s write an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; query to return to the original format that can handle any year.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression will use all columns except &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;item&lt;/code&gt;. After stacking, the column containing the column names from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pivoted_purchases&lt;/code&gt; should be renamed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;year&lt;/code&gt;, and the values within those columns represent the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count&lt;/code&gt;. The result is the same dataset as the original.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;UNPIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivoted_purchases&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;VALUE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;item&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;year&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;phasers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2155&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1035&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;phasers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2156&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;25039&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;phasers&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2157&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;95000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;photon torpedoes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2155&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;255&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;photon torpedoes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2156&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17899&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;photon torpedoes&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2157&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;87492&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;More examples are included as a part of our &lt;a href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#new-sql-features&quot;&gt;DuckDB 0.8.0 announcement post&lt;/a&gt;, and the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/pivot.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/unpivot.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt;&lt;/a&gt; documentation pages highlight more complex queries.&lt;/p&gt;

&lt;p&gt;Stay tuned for a future post to cover what is happening behind the scenes!&lt;/p&gt;
      &lt;h2 id=&quot;list-lambda-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#list-lambda-functions&quot;&gt;List Lambda Functions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;List lambdas allow for operations to be applied to each item in a list. These do not need to be pre-defined – they are created on the fly within the query.&lt;/p&gt;

&lt;p&gt;In this example, a lambda function is used in combination with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_transform&lt;/code&gt; function to shorten each official ship name.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Enterprise NCC-1701&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Voyager NCC-74656&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Discovery NCC-1031&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39; &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ship_name&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[Enterprise, Voyager, Discovery]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Lambdas can also be used to filter down the items in a list. The lambda returns a list of booleans, which is used by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_filter&lt;/code&gt; function to select specific items. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;contains&lt;/code&gt; function is using the &lt;a href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#function-chaining&quot;&gt;function chaining&lt;/a&gt; described earlier.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Enterprise NCC-1701&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Voyager NCC-74656&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Discovery NCC-1031&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;1701&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the_original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;the_original&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[Enterprise NCC-1701]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;list-comprehensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#list-comprehensions&quot;&gt;List Comprehensions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;What if there was a simple syntax to both modify and filter a list? DuckDB takes inspiration from Python’s approach to list comprehensions to dramatically simplify the above examples. List comprehensions are syntactic sugar – these queries are rewritten into lambda expressions behind the scenes!&lt;/p&gt;

&lt;p&gt;Within brackets, first specify the transformation that is desired, then indicate which list should be iterated over, and finally include the filter criteria.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;string_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39; &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
     &lt;span class=&quot;k&quot;&gt;FOR&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Enterprise NCC-1701&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Voyager NCC-74656&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Discovery NCC-1031&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
     &lt;span class=&quot;k&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contains&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;1701&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ready_to_boldly_go&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ready_to_boldly_go&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[Enterprise]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;exploding-struct&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#exploding-struct&quot;&gt;Exploding Struct.*&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A struct in DuckDB is a set of key/value pairs. Behind the scenes, a struct is stored with a separate column for each key. As a result, it is computationally easy to explode a struct into separate columns, and now it is also syntactically simple as well! This is another example of allowing SQL to handle dynamic column names.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;damage_report&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;gold_casualties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;blue_casualties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;red_casualties&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;casualties&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;damage_report&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;n&quot;&gt;casualties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;gold_casualties&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;blue_casualties&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;red_casualties&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;15&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;automatic-struct-creation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#automatic-struct-creation&quot;&gt;Automatic Struct Creation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB exposes an easy way to convert any table into a single-column struct. Instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;ing column names, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; the table name itself.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;officers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Captain&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Jean-Luc Picard&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; 
     &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; 
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Lieutenant Commander&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Data&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;officers&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;officers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;officers&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;{&#39;rank&#39;: Captain, &#39;name&#39;: Jean-Luc Picard}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;{&#39;rank&#39;: Lieutenant Commander, &#39;name&#39;: Data}&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;union-data-type&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#union-data-type&quot;&gt;Union Data Type&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB utilizes strong typing to provide high performance and enforce data quality. However, DuckDB is also as forgiving as possible using approaches like implicit casting to avoid always having to cast between data types.&lt;/p&gt;

&lt;p&gt;Another way DuckDB enables flexibility is the new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; data type. A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; data type allows for a single column to contain multiple types of values. This can be thought of as an “opt-in” to SQLite’s flexible data typing rules (the opposite direction of SQLite’s recently announced &lt;a href=&quot;https://www.sqlite.org/stricttables.html&quot;&gt;strict tables&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;By default DuckDB will seek the common denominator of data types when combining tables together. The below query results in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; column:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;The Motion Picture&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movie&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;First Contact&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;movie&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The Motion Picture&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;First Contact&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;However, if a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; type is used, each individual row retains its original data type. A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNION&lt;/code&gt; is defined using key-value pairs with the key as a name and the value as the data type. This also allows the specific data types to be pulled out as individual columns:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;movie&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;The Motion Picture&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;First Contact&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;n&quot;&gt;movie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;nf&quot;&gt;union_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;movie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;movie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;movie&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;type&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;name&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;num&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The Motion Picture&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;name&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The Motion Picture&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;num&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;num&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;num&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;num&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;num&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;First Contact&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;name&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;First Contact&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;additional-friendly-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#additional-friendly-features&quot;&gt;Additional Friendly Features&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Several other friendly features are worth mentioning and some are powerful enough to warrant their own blog posts.&lt;/p&gt;

&lt;p&gt;DuckDB takes a nod from the &lt;a href=&quot;https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;describe&lt;/code&gt; function in Pandas&lt;/a&gt; and implements a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt; keyword that will calculate a variety of statistics about each column in a dataset for a quick, high-level overview. Simply prepend &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUMMARIZE&lt;/code&gt; to any table or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement.&lt;/p&gt;

&lt;p&gt;Have a look at the &lt;a href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html&quot;&gt;correlated subqueries post&lt;/a&gt; to see how to use subqueries that refer to each others’ columns. DuckDB’s advanced optimizer improves correlated subquery performance by orders of magnitude, allowing for queries to be expressed as naturally as possible. What was once an anti-pattern for performance reasons can now be used freely!&lt;/p&gt;

&lt;p&gt;DuckDB has added more ways to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JOIN&lt;/code&gt; tables together that make expressing common calculations much easier. Some like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LATERAL&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ASOF&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SEMI&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ANTI&lt;/code&gt; joins are present in other systems, but have high-performance implementations in DuckDB. DuckDB also adds a new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSITIONAL&lt;/code&gt; join that combines by the row numbers in each table to match the commonly used Pandas capability of joining on row number indexes. See the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/from.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JOIN&lt;/code&gt; documentation&lt;/a&gt; for details, and look out for a blog post describing DuckDB’s state of the art &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ASOF&lt;/code&gt; joins!&lt;/p&gt;
      &lt;h2 id=&quot;summary-and-future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/23/even-friendlier-sql.html#summary-and-future-work&quot;&gt;Summary and Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB aims to be the easiest database to use. Fundamental architectural decisions to be in-process, have zero dependencies, and have strong typing contribute to this goal, but the friendliness of its SQL dialect has a strong impact as well. By extending the industry-standard PostgreSQL dialect, DuckDB aims to provide the simplest way to express the data transformations you need. These changes range from altering the ancient clause order of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement to begin with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt;, allowing a fundamentally new way to use functions with chaining, to advanced nested data type calculations like list comprehensions. Each of these features are available in the 0.8.1 release.&lt;/p&gt;

&lt;p&gt;Future work for friendlier SQL includes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lambda functions with more than 1 argument, like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;list_zip&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Underscores as digit separators (Ex: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1_000_000&lt;/code&gt; instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1000000&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Extension user experience, including autoloading&lt;/li&gt;
  &lt;li&gt;Improvements to file globbing&lt;/li&gt;
  &lt;li&gt;Your suggestions!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please let us know what areas of SQL can be improved! We welcome your feedback on &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Discord&lt;/a&gt; or &lt;a href=&quot;https://github.com/duckdb/duckdb/discussions&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Live long and prosper! 🖖&lt;/p&gt;

</description><link>https://duckdb.org/2023/08/23/even-friendlier-sql.html</link><guid isPermaLink="false">https://duckdb.org/2023/08/23/even-friendlier-sql.html</guid><pubDate>Wed, 23 Aug 2023 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>DuckDB ADBC – Zero-Copy Data Transfer via Arrow Database Connectivity</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB has added support for &lt;a href=&quot;https://arrow.apache.org/adbc/0.5.1/index.html&quot;&gt;Arrow Database Connectivity (ADBC)&lt;/a&gt;, an API standard that enables efficient data ingestion and retrieval from database systems, similar to &lt;a href=&quot;https://learn.microsoft.com/en-us/sql/odbc/microsoft-open-database-connectivity-odbc?view=sql-server-ver16&quot;&gt;Open Database Connectivity (ODBC)&lt;/a&gt; interface. However, unlike ODBC, ADBC specifically caters to the columnar storage model, facilitating fast data transfers between a columnar database and an external application.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/adbc/duck-arrow.jpg&quot; alt=&quot;DuckDB-Arrow&quot; width=&quot;100&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Database interface standards allow developers to write application code that is independent of the underlying database management system (DBMS) being used. DuckDB has supported two standards that have gained popularity in the past few decades: &lt;a href=&quot;https://learn.microsoft.com/en-us/sql/odbc/reference/develop-app/interface-conformance-levels?view=sql-server-ver16&quot;&gt;the core interface of ODBC&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Java_Database_Connectivity&quot;&gt;Java Database Connectivity (JDBC)&lt;/a&gt;. Both interfaces are designed to fully support database connectivity and management, with JDBC being catered for the Java environment. With these APIs, developers can query DBMS agnostically, retrieve query results, run prepared statements, and manage connections.&lt;/p&gt;

&lt;p&gt;These interfaces were designed in the early 90s when row-wise database systems reigned supreme. As a result, they were primarily intended for transferring data in a row-wise format. However, in the mid-2000s, columnar-wise database systems started gaining a lot of traction due to their drastic performance advantages for data analysis (you can find myself giving a brief exemplification of this difference &lt;a href=&quot;https://youtu.be/egN4TwVyJss?t=643&quot;&gt;at EuroPython&lt;/a&gt;). This means that these APIs offer no support for transferring data in a columnar-wise format (or, in the case of ODBC, &lt;a href=&quot;https://learn.microsoft.com/en-us/sql/odbc/reference/develop-app/column-wise-binding?view=sql-server-ver16&quot;&gt;some support&lt;/a&gt; with a lot of added complexity). In practice, when analytical, column-wise systems like DuckDB make use of these APIs, &lt;a href=&quot;https://hannes.muehleisen.org/publications/p852-muehleisen.pdf&quot;&gt;converting the data between these representation formats becomes a major bottleneck&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The figure below depicts how a developer can use these APIs to query a DuckDB database. For example, developers can submit SQL queries via the API, which then uses a DuckDB driver to internally call the proper functions. A query result is then produced in DuckDB&#39;s internal columnar representation, and the driver takes care of transforming it to the JDBC or ODBC row-wise result format. This transformation has significant costs for rearranging and copying the data, quickly becoming a major bottleneck.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/adbc/duck-odbc-jdbc.png&quot; alt=&quot;DuckDB-JDBC-ODBC&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;To overcome this transformation cost, ADBC has been proposed, with a generic API to support database operations while using the &lt;a href=&quot;https://arrow.apache.org/&quot;&gt;Apache Arrow memory format&lt;/a&gt; to send data in and out of the DBMS. DuckDB now supports the &lt;a href=&quot;https://arrow.apache.org/adbc/0.5.1/cpp/api/adbc.html&quot;&gt;ADBC specification&lt;/a&gt;. Due to DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html&quot;&gt;zero-copy integration with the Arrow format&lt;/a&gt;, using ADBC as an interface is rather efficient, since there is only a small &lt;em&gt;constant&lt;/em&gt; cost to transform DuckDB query results to the Arrow format.&lt;/p&gt;

&lt;p&gt;The figure below depicts the query execution flow when using ADBC. Note that the main difference between ODBC/JDBC is that the result does not need to be transformed to a row-wise format.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/adbc/duck-adbc.png&quot; alt=&quot;DuckDB-ADBC&quot; width=&quot;700&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;quick-tour&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/04/adbc.html#quick-tour&quot;&gt;Quick Tour&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;For our quick tour, we will illustrate an example of round-tripping data using DuckDB-ADBC via Python. Please note that DuckDB-ADBC can also be utilized with other programming languages. Specifically, you can find C++ DuckDB-ADBC examples and tests in the &lt;a href=&quot;https://github.com/duckdb/duckdb/blob/main/test/api/adbc/test_adbc.cpp&quot;&gt;DuckDB GitHub repository&lt;/a&gt; along with usage examples available in C++.
For convenience, you can also find a ready-to-run version of this tour in a &lt;a href=&quot;https://colab.research.google.com/drive/11CEI62jRMHG5GtK0t_h6xSn6ne8W7dvS?usp=sharing&quot;&gt;Colab notebook&lt;/a&gt;.
If you would like to see a more detailed explanation of the DuckDB-ADBC API or view a C++ example, please refer to our &lt;a href=&quot;https://duckdb.org/docs/stable/clients/adbc.html&quot;&gt;documentation page&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/04/adbc.html#setup&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For this example, you must have a dynamic library from the latest bleeding-edge version of DuckDB, pyarrow, and the &lt;a href=&quot;https://github.com/apache/arrow-adbc/tree/main/python/adbc_driver_manager&quot;&gt;adbc-driver-manager&lt;/a&gt;. The ADBC driver manager is a Python package developed by &lt;a href=&quot;https://voltrondata.com/&quot;&gt;Voltron Data&lt;/a&gt;. The driver manager is compliant with &lt;a href=&quot;https://peps.python.org/pep-0249/&quot;&gt;DB-API 2.0&lt;/a&gt;. It wraps ADBC, making its usage more straightforward. You can find the documentation of the ADBC Driver Manager &lt;a href=&quot;https://arrow.apache.org/adbc/0.5.1/python/api/adbc_driver_manager.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;While DuckDB is already DB-API compliant in Python, what sets ADBC apart is that you do not need a DuckDB module installed and loaded. Additionally, unlike the DB-API, it does not utilize row-wise as its data transfer format of choice.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;pip &lt;/span&gt;install pyarrow
&lt;span class=&quot;nb&quot;&gt;pip &lt;/span&gt;install adbc-driver-manager
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;insert-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/04/adbc.html#insert-data&quot;&gt;Insert Data&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;First, we need to include the necessary libraries that will be used in this tour. Mainly, PyArrow and the DBAPI from the ADBC Driver Manager.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;adbc_driver_manager&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbapi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we can create a connection via ADBC with DuckDB. This connection simply requires the path to DuckDB&#39;s driver and the entrypoint function name. DuckDB&#39;s entrypoint is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb_adbc_init&lt;/code&gt;.
By default, connections are established with an in-memory database. However, if desired, you have the option to specify the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;path&lt;/code&gt; variable and connect to a local duckdb instance, allowing you to store the data on disk.
Note that these are the only variables in ADBC that are not DBMS agnostic; instead, they are set by the user, often through a configuration file.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbapi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path/to/duckdb.lib&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entrypoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;duckdb_adbc_init&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test.db&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To insert the data, we can simply call the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;adbc_ingest&lt;/code&gt; function with a cursor from our connection. It requires the name of the table we want to perform the ingestion to and the Arrow Python object we want to ingest. This function also has two modes: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;append&lt;/code&gt;, where data is appended to an existing table, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;create&lt;/code&gt;, where the table does not exist yet and will be created with the input data. By default, it&#39;s set to create, so we don&#39;t need to define it here.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyarrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Tenacious D&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Backstreet Boys&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Wu Tang Clan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

     &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Albums&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adbc_ingest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Bands&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;adbc_ingest&lt;/code&gt;, the table is created in the DuckDB connection and the data is fully inserted.&lt;/p&gt;
      &lt;h3 id=&quot;read-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/04/adbc.html#read-data&quot;&gt;Read Data&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To read data from DuckDB, one simply needs to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execute&lt;/code&gt; function with a SQL query and then return the cursor&#39;s result to the desired Arrow format, such as a PyArrow Table in this example.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM Bands&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetch_arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;benchmark-adbc-vs-odbc&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/04/adbc.html#benchmark-adbc-vs-odbc&quot;&gt;Benchmark ADBC vs ODBC&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In our benchmark section, we aim to evaluate the differences in data reading from DuckDB via ADBC and ODBC. This benchmark was executed on an Apple M1 Max with 32 GB of RAM and involves outputting and inserting the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; table of TPC-H SF 1. You can find the repository with the code used to run this benchmark &lt;a href=&quot;https://github.com/pdet/connector_benchmark&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;ODBC&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;28.149&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ADBC&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.724&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The time difference between ODBC and ADBC is 38x. This significant contrast results from the extra allocations and copies that exist in ODBC.&lt;/p&gt;
      &lt;h2 id=&quot;conclusions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/08/04/adbc.html#conclusions&quot;&gt;Conclusions&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB now supports the ADBC standard for database connection. ADBC is particularly efficient when combined with DuckDB, thanks to its use of the Arrow zero-copy integration.&lt;/p&gt;

&lt;p&gt;ADBC is particularly interesting because it can drastically decrease interactions between analytic systems compared to ODBC. For example, if software that already support ODBC, e.g., if &lt;a href=&quot;https://www.microsoft.com/en-us/microsoft-365/excel&quot;&gt;MS-Excel&lt;/a&gt; was to implement ADBC, integrations with columnar systems like DuckDB could benefit from this significant difference in performance.&lt;/p&gt;

&lt;p&gt;DuckDB-ADBC is currently supported via the C Interface and through the Python ADBC Driver Manager. We will add more extensive tutorials for other languages to our &lt;a href=&quot;https://duckdb.org/docs/stable/&quot;&gt;documentation webpage&lt;/a&gt;. Please feel free to let us know your preferred language for interacting with DuckDB via ADBC!&lt;/p&gt;

&lt;p&gt;As always, we are happy to hear your thoughts! Feel free to drop us an &lt;a href=&quot;https://duckdb.org/cdn-cgi/l/email-protection#572732332538173322343c33353b3635247934383a&quot;&gt;email&lt;/a&gt; if you have any suggestions, comments or questions!&lt;/p&gt;

&lt;p&gt;Last but not least, if you encounter any problems using ADBC, please open an issue in &lt;a href=&quot;https://github.com/duckdb/duckdb/issues&quot;&gt;DuckDB&#39;s issue tracker&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2023/08/04/adbc.html</link><guid isPermaLink="false">https://duckdb.org/2023/08/04/adbc.html</guid><pubDate>Fri, 04 Aug 2023 00:00:00 GMT</pubDate><author>Pedro Holanda</author></item><item><title>From Waddle to Flying: Quickly Expanding DuckDB&#39;s Functionality with Scalar Python UDFs</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB now supports vectorized Scalar Python User Defined Functions (UDFs). By implementing Python UDFs, users can easily expand the functionality of DuckDB while taking advantage of DuckDB&#39;s fast execution model, SQL and data safety.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/bird-dance.gif&quot; alt=&quot;DuckDB-Waddle-fly&quot; width=&quot;100&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;User Defined Functions (UDFs) enable users to extend the functionality of a Database Management System (DBMS) to perform domain-specific tasks that are not implemented as built-in functions. For instance, users who frequently need to export private data can benefit from an anonymization function that masks the local part of an email while preserving the domain. Ideally, this function would be executed directly in the DBMS. This approach offers several advantages:&lt;/p&gt;

&lt;p&gt;1) &lt;strong&gt;Performance.&lt;/strong&gt; The function could be executed using the same execution model (e.g., streaming results, beyond-memory/out-of-core execution) of the DBMS, and without any unnecessary transformations.&lt;/p&gt;

&lt;p&gt;2) &lt;strong&gt;Easy Use.&lt;/strong&gt; UDFs can be seamlessly integrated into SQL queries, allowing users to leverage the power of SQL to call the functions. This eliminates the need for passing data through a separate database connector and executing external code. The functions can be utilized in various SQL contexts (e.g., subqueries, join conditions).&lt;/p&gt;

&lt;p&gt;3) &lt;strong&gt;Safety.&lt;/strong&gt; The sensitive data never leaves the DBMS process.&lt;/p&gt;

&lt;p&gt;There are two main reasons users often refrain from implementing UDFs. 1) There are security concerns associated with UDFs. Since UDFs are custom code created by users and executed within the DBMS process, there is a potential risk of crashing the server. However, when it comes to DuckDB, an embedded database, this concern is mitigated as each analyst runs their own DuckDB process separately. Therefore, the impact on server stability is not a significant worry. 2) The difficulty of implementation is a common deterrent for users. High-Performance UDFs are typically only supported in low-level languages. UDFs in higher-level languages like Python incur significant performance costs. Consequently many users cannot quickly implement their UDFs without investing a significant amount of time in learning a low-level language and understanding the internal details of the DBMS.&lt;/p&gt;

&lt;p&gt;DuckDB followed a similar approach. As a DBMS tailored for analytical tasks, performance is a key consideration, leading to the implementation of its core in C++. Consequently, the initial focus of extensibility efforts &lt;a href=&quot;https://www.youtube.com/watch?v=UKo_LQyLTko&amp;amp;ab_channel=DuckDBLabs&quot;&gt;was centered around C++&lt;/a&gt;. However, this  duck is not limited to just waddling; it can also fly. So we are delighted to announce the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7171&quot;&gt;recent addition&lt;/a&gt; of Scalar Python UDFs to DuckDB.&lt;/p&gt;

&lt;p&gt;DuckDB provides support for two distinct types of Python UDFs, differing in the Python object used for communication between &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/overview.html&quot;&gt;DuckDB&#39;s native data types&lt;/a&gt; and the Python process. These communication layers include support for &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/overview.html&quot;&gt;Python built-in types&lt;/a&gt; and &lt;a href=&quot;https://arrow.apache.org/docs/python/generated/pyarrow.Table.html&quot;&gt;PyArrow Tables&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The two approaches exhibit two key differences:&lt;/p&gt;

&lt;p&gt;1) &lt;strong&gt;Zero-Copy.&lt;/strong&gt; PyArrow Tables leverage our &lt;a href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html&quot;&gt;zero-copy integration with Arrow&lt;/a&gt;, enabling efficient translation of data types to Python-Land with zero-copy cost.&lt;/p&gt;

&lt;p&gt;2) &lt;strong&gt;Vectorization.&lt;/strong&gt; PyArrow Table functions operate on a chunk level, processing chunks of data containing up to 2048 rows. This approach maximizes cache locality and leverages vectorization. On the other hand, the built-in types UDF implementation operates on a per-row basis.&lt;/p&gt;

&lt;p&gt;This blog post aims to demonstrate how you can extend DuckDB using Python UDFs, with a particular emphasis on PyArrow-powered UDFs. In our quick-tour section, we will provide examples using the PyArrow UDF types. For those interested in benchmarks, you can jump ahead to the &lt;a href=&quot;https://duckdb.org/2023/07/07/python-udf.html#benchmarks&quot;&gt;benchmark section below&lt;/a&gt;. If you want to see a detailed description of the Python UDF API, please refer to our &lt;a href=&quot;https://duckdb.org/docs/stable/clients/python/function.html&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;python-udfs&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#python-udfs&quot;&gt;Python UDFs&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This section depicts several practical examples of using Python UDFs. Each example uses a different type of Python UDF.&lt;/p&gt;
      &lt;h3 id=&quot;quick-tour&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#quick-tour&quot;&gt;Quick-Tour&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To demonstrate the usage of Python UDFs in DuckDB, let&#39;s consider the following example. We have a dictionary called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;world_cup_titles&lt;/code&gt; that maps countries to the number of World Cups they have won. We want to create a Python UDF that takes a country name as input, searches for the corresponding value in the dictionary, and returns the number of World Cups won by that country. If the country is not found in the dictionary, the UDF will return &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here&#39;s an example implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb.typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Dictionary that maps countries and world cups they won
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;world_cup_titles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Brazil&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Germany&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Italy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Argentina&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Uruguay&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;France&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;England&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;Spain&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Function that will be registered as an UDF, simply does a lookup in the python dictionary
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;world_cups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;world_cup_titles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# We register the function
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;wc_titles&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;world_cups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That&#39;s it, the function is then registered and ready to be called through SQL.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Let&#39;s create an example countries table with the countries we are interested in using
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CREATE TABLE countries (country VARCHAR)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;INSERT INTO countries VALUES (&#39;Brazil&#39;), (&#39;Germany&#39;), (&#39;Italy&#39;), (&#39;Argentina&#39;), (&#39;Uruguay&#39;), (&#39;France&#39;), (&#39;England&#39;), (&#39;Spain&#39;), (&#39;Netherlands&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# We can simply call the function through SQL, and even use the function return to eliminate the countries that never won a world cup
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT country, wc_titles(country) AS world_cups FROM countries&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [(&#39;Brazil&#39;, 5), (&#39;Germany&#39;, 4), (&#39;Italy&#39;, 4), (&#39;Argentina&#39;, 2), (&#39;Uruguay&#39;, 2), (&#39;France&#39;, 2), (&#39;England&#39;, 1), (&#39;Spain&#39;, 1), (&#39;Netherlands&#39;, None)]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;generating-fake-data-with-faker-built-in-type-udf&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#generating-fake-data-with-faker-built-in-type-udf&quot;&gt;Generating Fake Data with Faker (Built-In Type UDF)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Here is an example that demonstrates the usage of the &lt;a href=&quot;https://faker.readthedocs.io/en/master/&quot;&gt;Faker library&lt;/a&gt;  to generate a scalar function in DuckDB, which returns randomly generated dates. The function, named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random_date&lt;/code&gt;, does not require any inputs and outputs a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt; column. Since Faker utilizes built-in Python types, the function directly returns them.
One important thing to notice is that a function that is not deterministic based on its input must be marked as having &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;side_effects&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# By importing duckdb.typing we can specify DuckDB Types directly without using strings
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb.typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;faker&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Faker&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Our Python UDF generates a random date every time it&#39;s called
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Faker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_between&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We then have to register the Python function in DuckDB using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;create_function&lt;/code&gt;. Since our function doesn&#39;t require any inputs, we can pass an empty list as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;argument_type_list&lt;/code&gt;. As the function returns a date, we specify &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt; from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb.typing&lt;/code&gt; as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;return_type&lt;/code&gt;. Note that since our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random_date()&lt;/code&gt; function returns a built-in Python type (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;datetime.date&lt;/code&gt;), we don&#39;t need to specify the UDF type.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# To exemplify the effect of side-effect, let&#39;s first run the function without marking it.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;random_date&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# After registration, we can use the function directly via SQL
# Notice that without side_effect=True, it&#39;s not guaranteed that the function will be re-evaluated.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT random_date() FROM range (3)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [(datetime.date(2003, 8, 3),), (datetime.date(2003, 8, 3),), (datetime.date(2003, 8, 3),)]
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Now let&#39;s re-add the function with side-effects marked as true.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remove_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;random_date&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;random_date&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;side_effects&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT random_date() FROM range (3)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [(datetime.date(2020, 11, 29),), (datetime.date(2009, 5, 18),), (datetime.date(2018, 5, 24),)]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;swap-string-case-pyarrow-type-udf&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#swap-string-case-pyarrow-type-udf&quot;&gt;Swap String Case (PyArrow Type UDF)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;One issue with using built-in types is that you don&#39;t benefit from zero-copy, vectorization and cache locality. Using PyArrow as a UDF type should be favored to leverage these optimizations.&lt;/p&gt;

&lt;p&gt;To demonstrate a PyArrow function, let&#39;s consider a simple example where we want to transform lowercase characters to uppercase and uppercase characters to lowercase. Fortunately, PyArrow already has a function for this in the compute engine, and it&#39;s as simple as calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pc.utf8_swapcase(x)&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# By importing duckdb.typing we can specify DuckDB Types directly without using strings
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb.typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow.compute&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pc&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swap_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;# Swap the case of the &#39;column&#39; using utf8_swapcase and return the result
&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utf8_swapcase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# To register the function, we must define it&#39;s type to be &#39;arrow&#39;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;swap_case&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;swap_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;arrow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT swap_case(&#39;PEDRO HOLANDA&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [(&#39;pedro holanda&#39;,)]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;predicting-taxi-fare-costs-ibis--pyarrow-udf&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#predicting-taxi-fare-costs-ibis--pyarrow-udf&quot;&gt;Predicting Taxi Fare Costs (Ibis + PyArrow UDF)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Python UDFs offer significant power as they enable users to leverage the extensive Python ecosystem and tools, including libraries like &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt; and &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;Tensorflow&lt;/a&gt; that efficiently implement machine learning operations.&lt;/p&gt;

&lt;p&gt;Additionally the &lt;a href=&quot;https://ibis-project.org/&quot;&gt;Ibis project&lt;/a&gt; offers a DataFrame API with great DuckDB integration and supports both of DuckDB&#39;s native Python and PyArrow UDFs.&lt;/p&gt;

&lt;p&gt;In this example, we demonstrate the usage of a pre-built PyTorch model to estimate taxi fare costs based on the traveled distance. You can find a complete example &lt;a href=&quot;https://ibis-project.org/blog/rendered/torch/&quot;&gt;in this blog post by the Ibis team&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ibis&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ibis.expr.datatypes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ibis.expr.operations&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;udf&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# The code to generate the model is not specified in this snippet, please refer to the provided link for more information
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Function that uses the model and a traveled distance input tensor to predict values, please refer to the provided link for more information
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict_linear_regression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Indicate to ibis that this is a scalar user-defined function whose input format is pyarrow
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;udf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scalar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyarrow&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict_fare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# `x` is a pyarrow.ChunkedArray; the `dt.float64` annotation indicate the element type of the ChunkedArray.
&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Transform the data from PyArrow to the required torch tensor format and dimension.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[:,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Call the actual prediction function, which also returns a torch tensor.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_linear_regression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Execute a query on the NYC Taxi parquet file to showcase our model&#39;s predictions, the actual fare amount, and the distance.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ibis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;yellow_tripdata_2016-02.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;fare_amount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;trip_distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;predicted_fare&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_fare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By utilizing Python UDFs in DuckDB with Ibis, you can seamlessly incorporate machine learning models and perform predictions directly within your Ibis code and SQL queries. The example demonstrates how to predict taxi fare costs based on distance using a PyTorch model, showcasing the integration of machine learning capabilities within DuckDB&#39;s SQL environment driven by Ibis.&lt;/p&gt;
      &lt;h2 id=&quot;benchmarks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#benchmarks&quot;&gt;Benchmarks&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this section, we will perform simple benchmark comparisons to demonstrate the performance differences between two different types of Python UDFs. The benchmark will measure the execution time, and peak memory consumption. The benchmarks are executed 5 times, and the median value is considered. The benchmark is conducted on a Mac Apple M1 with 16 GB of RAM.&lt;/p&gt;
      &lt;h3 id=&quot;built-in-python-vs-pyarrow&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#built-in-python-vs-pyarrow&quot;&gt;Built-In Python vs. PyArrow&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To benchmark these UDF types, we create UDFs that take an integral column as input, add one to each value, and return the result. The code used for this benchmark section can be found &lt;a href=&quot;https://gist.github.com/pdet/ebd201475581756c29e4533a8fa4106e&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow.compute&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pc&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Built-In UDF
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_built_in_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Arrow UDF
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_arrow_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Registration
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;built_in_types&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add_built_in_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;BIGINT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;BIGINT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;native&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;add_arrow_type&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add_arrow_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;BIGINT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;BIGINT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;arrow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Integer View with 10,000,000 elements.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
     SELECT i
     FROM range(10000000) tbl(i);
&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;numbers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Calls for both UDFs
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;native_res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT sum(add_built_in_type(i)) FROM numbers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;arrow_res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT sum(add_arrow_type(i)) FROM numbers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Built-In&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.37&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PyArrow&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.35&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can observe a performance difference of more than one order of magnitude between the two UDFs. The difference in performance is primarily due to three factors:&lt;/p&gt;

&lt;p&gt;1) In Python, object construction and general use is rather slow. This is due to several reasons, including automatic memory management, interpretation, and dynamic typing.
2) The PyArrow UDF does not require any data copying.
3) The PyArrow UDF is executed in a vectorized fashion, processing chunks of data instead of individual rows.&lt;/p&gt;
      &lt;h3 id=&quot;python-udfs-vs-external-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#python-udfs-vs-external-functions&quot;&gt;Python UDFs vs. External Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Here we compare the usage of a Python UDF with an external function. In this case, we have a function that calculates the sum of the lengths of all strings in a column. You can find the code used for this benchmark section &lt;a href=&quot;https://gist.github.com/pdet/2907290725539d390df7981e799ed593&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Function used in UDF
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;string_length_arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;tuples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tuples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Same Function but external to the database
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;exec_external&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT i FROM strings tbl(i)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;arrow_column&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;i&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;tuples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arrow_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tuples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;arrow_tbl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_arrays&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;i&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT sum(i) FROM arrow_tbl&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;strlen_arrow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string_length_arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;VARCHAR&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;arrow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
     SELECT
          CASE WHEN i != 0 AND i % 42 = 0
          THEN
               NULL
          ELSE
               repeat(chr((65 + (i % 26))::INTEGER), (4 + (i % 12))) END
          FROM range(10000000) tbl(i);
&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;strings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT sum(strlen_arrow(i)) FROM strings tbl(i)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;exec_external&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Peak memory consumption (MB)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;External&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.65&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;584.032&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;UDF&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.63&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;112.848&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here we can see that there is no significant regression in performance when utilizing UDFs. However, you still have the benefits of safer execution and the utilization of SQL. In our example, we can also notice that the external function materializes the entire query, resulting in a 5× higher peak memory consumption compared to the UDF approach.&lt;/p&gt;
      &lt;h2 id=&quot;conclusions-and-further-development&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/07/07/python-udf.html#conclusions-and-further-development&quot;&gt;Conclusions and Further Development&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Scalar Python UDFs are now supported in DuckDB, marking a significant milestone in extending the functionality of the database. This enhancement empowers users to perform complex computations using a high-level language. Additionally, Python UDFs can leverage DuckDB&#39;s zero-copy integration with Arrow, eliminating data transfer costs and ensuring efficient query execution.&lt;/p&gt;

&lt;p&gt;While the introduction of Python UDFs is a major step forward, our work in this area is ongoing. Our roadmap includes the following focus areas:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Aggregate/Table-Producing UDFs&lt;/strong&gt;: Currently, users can create Scalar UDFs, but we are actively working on supporting Aggregation Functions (which perform calculations on a set of values and return a single result) and Table-Producing Functions (which return tables without limitations on the number of columns and rows).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Types&lt;/strong&gt;: Scalar Python UDFs currently support most DuckDB types, with the exception of ENUM types and BIT types. We are working towards expanding the type support to ensure comprehensive functionality.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As always, we are happy to hear your thoughts! Feel free to drop us an &lt;a href=&quot;https://duckdb.org/cdn-cgi/l/email-protection#5a2a3f3e28351a3e2f39313e38363b382974393537612e323330291a3e2f39313e38363b382974393537&quot;&gt;email&lt;/a&gt; if you have any suggestions, comments or questions.&lt;/p&gt;

&lt;p&gt;Last but not least, if you encounter any problems using our Python UDFs, please open an issue in &lt;a href=&quot;https://github.com/duckdb/duckdb/issues&quot;&gt;DuckDB&#39;s issue tracker&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2023/07/07/python-udf.html</link><guid isPermaLink="false">https://duckdb.org/2023/07/07/python-udf.html</guid><pubDate>Fri, 07 Jul 2023 00:00:00 GMT</pubDate><author>Pedro Holanda, Thijs Bruineman and Phillip Cloud</author></item><item><title>Correlated Subqueries in SQL</title><description>&lt;p&gt;Subqueries in SQL are a powerful abstraction that allow simple queries to be used as composable building blocks. They allow you to break down complex problems into smaller parts, and subsequently make it easier to write, understand and maintain large and complex queries.&lt;/p&gt;

&lt;p&gt;DuckDB uses a state-of-the-art subquery decorrelation optimizer that allows subqueries to be executed very efficiently. As a result, users can freely use subqueries to create expressive queries without having to worry about manually rewriting subqueries into joins. For more information, skip to the &lt;a href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#performance&quot;&gt;Performance&lt;/a&gt; section.&lt;/p&gt;
      &lt;h2 id=&quot;types-of-subqueries&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#types-of-subqueries&quot;&gt;Types of Subqueries&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;SQL subqueries exist in two main forms: subqueries as &lt;em&gt;expressions&lt;/em&gt; and subqueries as &lt;em&gt;tables&lt;/em&gt;. Subqueries that are used as expressions can be used in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clauses. Subqueries that are used as tables can be used in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause. In this blog post we will focus on subqueries used as &lt;em&gt;expressions&lt;/em&gt;. A future blog post will discuss subqueries as &lt;em&gt;tables&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Subqueries as expressions exist in three forms.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scalar subqueries&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXISTS&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ANY&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALL&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of the subqueries can be either &lt;em&gt;correlated&lt;/em&gt; or &lt;em&gt;uncorrelated&lt;/em&gt;. An uncorrelated subquery is a query that is independent from the outer query. A correlated subquery is a subquery that contains expressions from the outer query. Correlated subqueries can be seen as &lt;em&gt;parameterized subqueries&lt;/em&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;uncorrelated-scalar-subqueries&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#uncorrelated-scalar-subqueries&quot;&gt;Uncorrelated Scalar Subqueries&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Uncorrelated scalar subqueries can only return &lt;em&gt;a single value&lt;/em&gt;. That constant value is then substituted and used in the query. As an example of why this is useful – imagine that we want to select all of the shortest flights in our dataset. We could run the following query to obtain the shortest flight distance:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;min(distance)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;31.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We could manually take this distance and use it in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clause to obtain all flights on this route.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;31.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;uniquecarrier&lt;/th&gt;
      &lt;th&gt;origincityname&lt;/th&gt;
      &lt;th&gt;destcityname&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;flightdate&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AS&lt;/td&gt;
      &lt;td&gt;Petersburg, AK&lt;/td&gt;
      &lt;td&gt;Wrangell, AK&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2017-01-15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AS&lt;/td&gt;
      &lt;td&gt;Wrangell, AK&lt;/td&gt;
      &lt;td&gt;Petersburg, AK&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2017-01-15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AS&lt;/td&gt;
      &lt;td&gt;Petersburg, AK&lt;/td&gt;
      &lt;td&gt;Wrangell, AK&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2017-01-16&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;However – this requires us to hardcode the constant inside the query. By using the first query as a &lt;em&gt;subquery&lt;/em&gt; we can compute the minimum distance as part of the query.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;correlated-scalar-subqueries&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#correlated-scalar-subqueries&quot;&gt;Correlated Scalar Subqueries&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;While uncorrelated subqueries are powerful, they come with a hard restriction: only a &lt;em&gt;single value&lt;/em&gt; can be returned. Often, what we want to do is &lt;em&gt;parameterize&lt;/em&gt; the query, so that we can return different values per row.&lt;/p&gt;

&lt;p&gt;For example, suppose that we want to find all of the shortest flights &lt;em&gt;for each carrier&lt;/em&gt;. We can find the shortest flight for a &lt;em&gt;specific carrier&lt;/em&gt; using the following parameterized query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PREPARE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_distance_per_carrier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can execute this prepared statement to obtain the minimum distance for a specific carrier.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;EXECUTE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_distance_per_carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;UA&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;min(distance)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;67.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If we want to use this parameterized query as a subquery, we need to use a &lt;em&gt;correlated subquery&lt;/em&gt;. Correlated subqueries allow us to use parameterized queries as scalar subqueries by referencing columns from &lt;em&gt;the outer query&lt;/em&gt;. We can obtain the set of shortest flights per carrier using the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;uniquecarrier&lt;/th&gt;
      &lt;th&gt;origincityname&lt;/th&gt;
      &lt;th&gt;destcityname&lt;/th&gt;
      &lt;th&gt;flightdate&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;distance&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AS&lt;/td&gt;
      &lt;td&gt;Wrangell, AK&lt;/td&gt;
      &lt;td&gt;Petersburg, AK&lt;/td&gt;
      &lt;td&gt;2017-01-01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;31.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NK&lt;/td&gt;
      &lt;td&gt;Fort Lauderdale, FL&lt;/td&gt;
      &lt;td&gt;Orlando, FL&lt;/td&gt;
      &lt;td&gt;2017-01-01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;177.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;VX&lt;/td&gt;
      &lt;td&gt;Las Vegas, NV&lt;/td&gt;
      &lt;td&gt;Los Angeles, CA&lt;/td&gt;
      &lt;td&gt;2017-01-01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;236.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Notice how the column from the &lt;em&gt;outer&lt;/em&gt; relation (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ontime_outer&lt;/code&gt;) is used &lt;em&gt;inside&lt;/em&gt; the query. This is what turns the subquery into a &lt;em&gt;correlated subquery&lt;/em&gt;. The column from the outer relation (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ontime_outer.uniquecarrier&lt;/code&gt;) is a &lt;em&gt;parameter&lt;/em&gt; for the subquery. Logically the subquery is executed once for every row that is present in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ontime&lt;/code&gt;, where the value for the column at that row is substituted as a parameter.&lt;/p&gt;

&lt;p&gt;In order to make it more clear that the correlated subquery is in essence a &lt;em&gt;parameterized query&lt;/em&gt;, we can create a scalar macro that contains the query using DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/create_macro.html&quot;&gt;macros&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;MACRO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_distance_per_carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can then use the macro in our original query as if it is a function.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_distance_per_carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This gives us the same result as placing the correlated subquery inside of the query, but is cleaner as we can decompose the query into multiple segments more effectively.&lt;/p&gt;
      &lt;h3 id=&quot;exists&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#exists&quot;&gt;EXISTS&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXISTS&lt;/code&gt; can be used to check if a given subquery has any results. This is powerful when used as a correlated subquery. For example, we can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXISTS&lt;/code&gt; if we want to obtain the &lt;em&gt;last flight that has been flown on each route&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;We can obtain a list of all flights on a given route past a certain date using the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PREPARE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flights_after_date&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;EXECUTE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flights_after_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;LAX&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;JFK&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2017-05-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;uniquecarrier&lt;/th&gt;
      &lt;th&gt;origincityname&lt;/th&gt;
      &lt;th&gt;destcityname&lt;/th&gt;
      &lt;th&gt;flightdate&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;distance&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AA&lt;/td&gt;
      &lt;td&gt;Los Angeles, CA&lt;/td&gt;
      &lt;td&gt;New York, NY&lt;/td&gt;
      &lt;td&gt;2017-08-01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2475.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AA&lt;/td&gt;
      &lt;td&gt;Los Angeles, CA&lt;/td&gt;
      &lt;td&gt;New York, NY&lt;/td&gt;
      &lt;td&gt;2017-08-02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2475.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AA&lt;/td&gt;
      &lt;td&gt;Los Angeles, CA&lt;/td&gt;
      &lt;td&gt;New York, NY&lt;/td&gt;
      &lt;td&gt;2017-08-03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2475.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now in order to obtain the &lt;em&gt;last flight on a route&lt;/em&gt;, we need to find flights &lt;em&gt;for which no later flight exists&lt;/em&gt;.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;uniquecarrier&lt;/th&gt;
      &lt;th&gt;origincityname&lt;/th&gt;
      &lt;th&gt;destcityname&lt;/th&gt;
      &lt;th&gt;flightdate&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;distance&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AA&lt;/td&gt;
      &lt;td&gt;Daytona Beach, FL&lt;/td&gt;
      &lt;td&gt;Charlotte, NC&lt;/td&gt;
      &lt;td&gt;2017-02-27&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;416.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;EV&lt;/td&gt;
      &lt;td&gt;Abilene, TX&lt;/td&gt;
      &lt;td&gt;Dallas/Fort Worth, TX&lt;/td&gt;
      &lt;td&gt;2017-02-15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;158.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;EV&lt;/td&gt;
      &lt;td&gt;Dallas/Fort Worth, TX&lt;/td&gt;
      &lt;td&gt;Durango, CO&lt;/td&gt;
      &lt;td&gt;2017-02-13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;674.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;in--any--all&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#in--any--all&quot;&gt;IN / ANY / ALL&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; can be used to check if a &lt;em&gt;given value&lt;/em&gt; exists within the result returned by the subquery. For example, we can obtain a list of all carriers that have performed more than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;250 000&lt;/code&gt; flights in the dataset using the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;HAVING&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;250000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can then use an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; clause to obtain all flights performed by those carriers.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;HAVING&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;250000&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A correlated subquery can be useful here if we want to not count the total amount of flights performed by each carrier, but count the total amount of flights &lt;em&gt;for the given route&lt;/em&gt;. We can select all flights performed by carriers that have performed &lt;em&gt;at least 1000 flights on a given route&lt;/em&gt; using the following query.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;HAVING&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ANY&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALL&lt;/code&gt; are generalizations of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt;. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; checks if the value is present in the set returned by the subquery. This is equivalent to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;= ANY(...)&lt;/code&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ANY&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALL&lt;/code&gt; operators can be used to perform other comparison operators (such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;gt;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;&amp;gt;&lt;/code&gt;). The above query can be rewritten to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ANY&lt;/code&gt; in the following form.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ANY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;HAVING&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;performance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#performance&quot;&gt;Performance&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Whereas scalar subqueries are logically executed &lt;em&gt;once&lt;/em&gt;, correlated subqueries are logically executed &lt;em&gt;once per row&lt;/em&gt;. As such, it is natural to think that correlated subqueries are very expensive and should be avoided for performance reasons.&lt;/p&gt;

&lt;p&gt;While that is true in many SQL systems, it is not the case in DuckDB. In DuckDB, subqueries are &lt;strong&gt;always&lt;/strong&gt; &lt;em&gt;decorrelated&lt;/em&gt;. DuckDB uses a state-of-the-art subquery decorrelation algorithm as described in the &lt;a href=&quot;https://cs.emis.de/LNI/Proceedings/Proceedings241/383.pdf&quot;&gt;Unnesting Arbitrary Queries&lt;/a&gt; paper. This allows all subqueries to be decorrelated and executed as a single, much more efficient, query.&lt;/p&gt;

&lt;p&gt;In DuckDB, correlation does not imply performance degradation.&lt;/p&gt;

&lt;p&gt;If we look at the query plan for the correlated scalar subquery using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXPLAIN&lt;/code&gt;, we can see that the query has been transformed into a hash aggregate followed by a hash join. This allows the query to be executed very efficiently.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;EXPLAIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime_outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────────────────────┐
│         HASH_JOIN         │ 
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │ 
│      uniquecarrier =      │ 
│       uniquecarrier       ├──────────────┐
└─────────────┬─────────────┘              │
┌─────────────┴─────────────┐┌─────────────┴─────────────┐
│         SEQ_SCAN          ││       HASH_GROUP_BY       │
│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   ││   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
│           ontime          ││       uniquecarrier       │
└───────────────────────────┘│       min(distance)       │
                             └─────────────┬─────────────┘
                             ┌─────────────┴─────────────┐
                             │         SEQ_SCAN          │
                             │   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │
                             │           ontime          │
                             └───────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can see the drastic performance difference that subquery decorrelation has when we compare the run-time of this query in DuckDB with the run-time in Postgres and SQLite. When running the above query on the &lt;a href=&quot;https://www.transtats.bts.gov/Homepage.asp&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ontime&lt;/code&gt; dataset&lt;/a&gt; for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2017&lt;/code&gt; with roughly &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~4 million&lt;/code&gt; rows, we get the following performance results:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;DuckDB&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Postgres&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;SQLite&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.06 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;gt;48 hours&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;gt;48 hours&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As Postgres and SQLite do not de-correlate the subquery, the query is not just &lt;em&gt;logically&lt;/em&gt;, but &lt;em&gt;actually&lt;/em&gt; executed once for every row. As a result, the subquery is executed &lt;em&gt;4 million times&lt;/em&gt; in those systems, which takes an immense amount of time.&lt;/p&gt;

&lt;p&gt;In this case, it is possible to manually decorrelate the query and generate the following SQL:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origincityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;destcityname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_distance&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subquery&lt;/span&gt; 
  &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subquery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniquecarrier&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By performing the de-correlation manually, the performance of SQLite and Postgres improves significantly. However, both systems remain over 30× slower than DuckDB.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;DuckDB&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Postgres&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;SQLite&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.06 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.98 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.81 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Note that while it is possible to manually decorrelate certain subqueries by rewriting the SQL, it is not always possible to do so. As described in the &lt;a href=&quot;https://cs.emis.de/LNI/Proceedings/Proceedings241/383.pdf&quot;&gt;Unnesting Arbitrary Queries paper&lt;/a&gt;, special join types that are not present in SQL are necessary to decorrelate arbitrary queries.&lt;/p&gt;

&lt;p&gt;In DuckDB, these special join types will be automatically generated by the system to decorrelate all subqueries. In fact, DuckDB does not have support for executing subqueries that are not decorrelated. All subqueries will be decorrelated before DuckDB executes them.&lt;/p&gt;
      &lt;h3 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Subqueries are a very powerful tool that allow you to take arbitrary queries and convert them into ad-hoc functions. When used in combination with DuckDB&#39;s powerful subquery decorrelation, they can be executed extremely efficiently, making previously intractable queries not only possible, but fast.&lt;/p&gt;

</description><link>https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html</link><guid isPermaLink="false">https://duckdb.org/2023/05/26/correlated-subqueries-in-sql.html</guid><pubDate>Fri, 26 May 2023 00:00:00 GMT</pubDate><author>Mark Raasveldt</author></item><item><title>Announcing DuckDB 0.8.0</title><description>&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/mottled_duck.jpg&quot; alt=&quot;Image of the Mottled Duck&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The DuckDB team is happy to announce the latest DuckDB release (0.8.0). This release is named “Fulvigula” after the &lt;a href=&quot;https://en.wikipedia.org/wiki/Mottled_duck&quot;&gt;Mottled Duck&lt;/a&gt; (Anas Fulvigula) native to the Gulf of Mexico.&lt;/p&gt;

&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;. The full release notes can be found &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.8.0&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;whats-new-in-080&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#whats-new-in-080&quot;&gt;What&#39;s New in 0.8.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There have been too many changes to discuss them each in detail, but we would like to highlight several particularly exciting features!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;New pivot and unpivot statements&lt;/li&gt;
  &lt;li&gt;Improvements to parallel data import/export&lt;/li&gt;
  &lt;li&gt;Time series joins&lt;/li&gt;
  &lt;li&gt;Recursive globbing&lt;/li&gt;
  &lt;li&gt;Lazy-loading of storage metadata for faster startup times&lt;/li&gt;
  &lt;li&gt;User-defined functions for Python&lt;/li&gt;
  &lt;li&gt;Arrow Database Connectivity (ADBC) support&lt;/li&gt;
  &lt;li&gt;New Swift integration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below is a summary of those new features with examples, starting with two breaking changes in our SQL dialect that are designed to produce more intuitive results by default.&lt;/p&gt;
      &lt;h2 id=&quot;breaking-sql-changes&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#breaking-sql-changes&quot;&gt;Breaking SQL Changes&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This release includes two breaking changes to the SQL dialect: The &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7082&quot;&gt;division operator uses floating point division by default&lt;/a&gt;, and the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7174&quot;&gt;default null sort order is changed from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS FIRST&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS LAST&lt;/code&gt;&lt;/a&gt;. While DuckDB is stil in Beta, we recognize that many DuckDB queries are already used in production. So, the old behavior can be restored using the following settings:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;integer_division&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;default_null_order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;NULLS_FIRST&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7082&quot;&gt;&lt;strong&gt;Division Operator&lt;/strong&gt;&lt;/a&gt;. The division operator &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&lt;/code&gt; will now always perform a floating point division even with integer parameters. The new operator &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;//&lt;/code&gt; retains the old semantics and can be used to perform integer division. This makes DuckDB&#39;s division operator less error prone for beginners, and consistent with the division operator in Python 3 and other systems in the OLAP space like Spark, Snowflake and BigQuery.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;(42 / 5)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;(42 // 5)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7174&quot;&gt;&lt;strong&gt;Default Null Sort Order&lt;/strong&gt;&lt;/a&gt;. The default null sort order is changed from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS FIRST&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS LAST&lt;/code&gt;. The reason for this change is that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS LAST&lt;/code&gt; sort-order is more intuitive when combined with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt;. With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS FIRST&lt;/code&gt;, Top-N queries always return the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values first. With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS LAST&lt;/code&gt;, the actual Top-N values are returned instead.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bigdata&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bigdata&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;43&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bigdata&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.7.1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.8.0&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;42&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;43&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;new-sql-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#new-sql-features&quot;&gt;New SQL Features&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/6387&quot;&gt;&lt;strong&gt;Pivot and Unpivot&lt;/strong&gt;&lt;/a&gt;. There are many shapes and sizes of data, and we do not always have control over the process in which data is generated. While SQL is well-suited for reshaping datasets, turning columns into rows or rows into columns is tedious in vanilla SQL. With this release, DuckDB introduces the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PIVOT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPIVOT&lt;/code&gt; statements that allow reshaping data sets so that rows are turned into columns or vice versa. A key advantage of DuckDB&#39;s syntax is that the column names to pivot or unpivot can be automatically deduced. Here is a short example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;amount&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2021&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2022&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2021&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;PIVOT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2021&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;2022&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;84&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/pivot.html&quot;&gt;documentation contains more examples&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/6719&quot;&gt;&lt;strong&gt;ASOF Joins for Time Series&lt;/strong&gt;&lt;/a&gt;. When joining time series data with background fact tables, the timestamps often do not exactly match. In this case it is often desirable to join rows so that the timestamp is joined with the &lt;em&gt;nearest timestamp&lt;/em&gt;. The ASOF join can be used for this purpose – it performs a fuzzy join to find the closest join partner for each row instead of requiring an exact match.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-05-15 10:31:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-05-15 11:31:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-05-15 10:30:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2023-05-15 11:30:00&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASOF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;a.ts&lt;/th&gt;
      &lt;th&gt;b.ts&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;2023-05-15 10:31:00&lt;/td&gt;
      &lt;td&gt;2023-05-15 10:30:00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2023-05-15 11:31:00&lt;/td&gt;
      &lt;td&gt;2023-05-15 11:30:00&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Please &lt;a href=&quot;https://duckdb.org/docs/stable/guides/sql_features/asof_join.html&quot;&gt;refer to the documentation&lt;/a&gt; for a more in-depth explanation.&lt;/p&gt;
      &lt;h2 id=&quot;data-integration-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#data-integration-improvements&quot;&gt;Data Integration Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/6977&quot;&gt;&lt;strong&gt;Default Parallel CSV Reader&lt;/strong&gt;&lt;/a&gt;. In this release, the parallel CSV reader has been vastly improved and is now the default CSV reader. We would like to thank everyone that has tried out the experimental reader for their valuable feedback and reports. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;experimental_parallel_csv&lt;/code&gt; flag has been deprecated and is no longer required. The parallel CSV reader enables much more efficient reading of large CSV files.&lt;/p&gt;

&lt;!-- Would it be possible to include the data size and hardware used? --&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.7.1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.8.0&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.1 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.2 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Parallel &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7375&quot;&gt;Parquet&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7368&quot;&gt;CSV and JSON Writing&lt;/a&gt;&lt;/strong&gt;. This release includes support for parallel &lt;em&gt;order-preserving&lt;/em&gt; writing of Parquet, CSV and JSON files. As a result, writing to these file formats is parallel by default, also without disabling insertion order preservation, and writing to these formats is greatly sped up.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitem.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitem.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitem.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Format&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.7.1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.8.0&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CSV&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.9 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.6 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.1 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.2 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;JSON&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.4 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.1 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/6627&quot;&gt;&lt;strong&gt;Recursive File Globbing using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;**&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;. This release adds support for recursive globbing where an arbitrary number of subdirectories can be matched using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;**&lt;/code&gt; operator (double-star).&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;data/glob/crawl/stackoverflow/**/*.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/docs/stable/data/multiple_files/overview.html&quot;&gt;The documentation has been updated&lt;/a&gt; with various examples of this syntax.&lt;/p&gt;
      &lt;h2 id=&quot;storage-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#storage-improvements&quot;&gt;Storage Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/6715&quot;&gt;&lt;strong&gt;Lazy-Loading Table Metadata&lt;/strong&gt;&lt;/a&gt;. DuckDB’s internal storage format stores metadata for every row group in a table, such as min-max indexes and where in the file every row group is stored. In the past, DuckDB would load this metadata immediately once the database was opened. However, once the data gets very big, the metadata can also get quite large, leading to a noticeable delay on database startup. In this release, we have optimized the metadata handling of DuckDB to only read table metadata as its being accessed. As a result, startup is near-instantaneous even for large databases, and metadata is only loaded for columns that are actually used in queries. The benchmarks below are for a database file containing a single large TPC-H &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; table (120× SF1) with ~770 million rows and 16 columns:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Query&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.6.1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.7.1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;v0.8.0&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Parquet&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT 42&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.60 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.31 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.02 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM lineitem LIMIT 1&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.62 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.32 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.27 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;clients&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#clients&quot;&gt;Clients&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7171&quot;&gt;&lt;strong&gt;User-Defined Scalar Functions for Python&lt;/strong&gt;&lt;/a&gt;. Arbitrary Python functions can now be registered as scalar functions within SQL queries. This will only work when using DuckDB from Python, because it uses the actual Python runtime that DuckDB is running within. While plain Python values can be passed to the function, there is also a vectorized variant that uses PyArrow under the hood for higher efficiency and better parallelism.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb.typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;faker&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Faker&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Faker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_between&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;random_date&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT random_date()&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [(datetime.date(2019, 5, 15),)]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/docs/stable/clients/python/function.html&quot;&gt;documentation&lt;/a&gt; for more information.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/duckdb/duckdb/pull/7086&quot;&gt;&lt;strong&gt;Arrow Database Connectivity Support (ADBC)&lt;/strong&gt;&lt;/a&gt;. ADBC is a database API standard for database access libraries that uses Apache Arrow to transfer query result sets and to ingest data. Using Arrow for this is particularly beneficial for columnar data management systems which traditionally suffered a performance hit by emulating row-based APIs such as JDBC/ODBC. From this release, DuckDB natively supports ADBC. We’re happy to be one of the first systems to offer native support, and DuckDB’s in-process design fits nicely with ADBC.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://duckdb.org/2023/04/21/swift.html&quot;&gt;&lt;strong&gt;Swift Integration&lt;/strong&gt;&lt;/a&gt;. DuckDB has gained another official language integration: Swift. Swift is a language developed by Apple that most notably is used to create Apps for Apple devices, but also increasingly used for server-side development. The DuckDB Swift API allows developers on all swift platforms to harness DuckDB using a native Swift interface with support for Swift features like strong typing and concurrency.&lt;/p&gt;
      &lt;h2 id=&quot;final-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/05/17/announcing-duckdb-080.html#final-thoughts&quot;&gt;Final Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The full release notes can be &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.8.0&quot;&gt;found on GitHub&lt;/a&gt;. We would like to thank all of the contributors for their hard work on improving DuckDB.&lt;/p&gt;

</description><link>https://duckdb.org/2023/05/17/announcing-duckdb-080.html</link><guid isPermaLink="false">https://duckdb.org/2023/05/17/announcing-duckdb-080.html</guid><pubDate>Wed, 17 May 2023 00:00:00 GMT</pubDate><author>Mark Raasveldt and Hannes Mühleisen</author></item><item><title>10 000 Stars on GitHub</title><description>&lt;p&gt;Today, DuckDB reached 10 000 stars on &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;GitHub&lt;/a&gt;. We would like to pause for a second to express our gratitude to &lt;a href=&quot;https://github.com/duckdb/duckdb/graphs/contributors&quot;&gt;everyone who contributed&lt;/a&gt; to DuckDB and of course all its users. When we started working on DuckDB back in 2018, we would have never dreamt of getting this kind of adoption in such a short time.&lt;/p&gt;

&lt;p&gt;From those brave souls who were early adopters of DuckDB back in 2019 to the many today, we are happy you&#39;re part of our community. Thank you for your feedback, feature requests and for your enthusiasm in adopting new features and integrations. Thank you for helping each other on our &lt;a href=&quot;http://discord.duckdb.org/&quot;&gt;Discord server&lt;/a&gt; or in &lt;a href=&quot;https://github.com/duckdb/duckdb/discussions&quot;&gt;GitHub Discussions&lt;/a&gt;. Thank you for spreading the word, too.&lt;/p&gt;

&lt;p&gt;We also would like to extend special thanks to the &lt;a href=&quot;https://duckdb.org/foundation/&quot;&gt;DuckDB foundation supporters&lt;/a&gt;, who through their generous donations keep DuckDB independent.&lt;/p&gt;

&lt;p&gt;For us, the maintainers of DuckDB, the past few years have also been quite eventful: We spun off from the &lt;a href=&quot;https://www.cwi.nl/en/groups/database-architectures/&quot;&gt;research group where DuckDB originated&lt;/a&gt; to a &lt;a href=&quot;https://duckdblabs.com/&quot;&gt;successful company&lt;/a&gt; with close to 20 employees and many excellent partnerships.&lt;/p&gt;

&lt;p&gt;We are very much looking forward to what the future will hold for DuckDB. Things are looking bright!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/wilbur-the-duck.jpg&quot; alt=&quot;Wilbur the duck approves of all those stars&quot; width=&quot;400&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

</description><link>https://duckdb.org/2023/05/12/github-10k-stars.html</link><guid isPermaLink="false">https://duckdb.org/2023/05/12/github-10k-stars.html</guid><pubDate>Fri, 12 May 2023 00:00:00 GMT</pubDate><author>Mark Raasveldt and Hannes Mühleisen</author></item><item><title>PostGEESE? Introducing The DuckDB Spatial Extension</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB now has an official &lt;a href=&quot;https://github.com/duckdb/duckdb-spatial&quot;&gt;Spatial extension&lt;/a&gt; to enable geospatial processing.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Geospatial data has become increasingly important and prevalent in modern-day applications and data engineering workflows, with use-cases ranging from location-based services to environmental monitoring.&lt;/p&gt;

&lt;p&gt;While there are many great and specialized tools for working with geospatial data, integrating geospatial capabilities directly into DuckDB has multiple advantages. For one, you get to operate, transform and join your geospatial data alongside your regular, unstructured or time-series data using DuckDBs rich type system and extensions like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JSON&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ICU&lt;/code&gt;. Secondly, spatial queries involving geometric predicates and relations translate surprisingly well to SQL, which is all about expressing relations after all! Not to mention all the other benefits provided by DuckDB such as transactional semantics, high performance multi-threaded vectorized execution and larger-than-memory data processing.&lt;/p&gt;

&lt;p&gt;Therefore, we&#39;re very excited to announce that DuckDB now has a &lt;a href=&quot;https://github.com/duckdb/duckdb-spatial&quot;&gt;Spatial extension&lt;/a&gt; packed with features easily installable from the DuckDB CLI and other DuckDB clients. Simply execute:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And you&#39;re good to go!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;No, we&#39;re not calling it GeoDuck either, &lt;a href=&quot;https://en.wikipedia.org/wiki/Geoduck&quot;&gt;that&#39;s just gross&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
      &lt;h2 id=&quot;whats-in-it&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/28/spatial.html#whats-in-it&quot;&gt;What&#39;s in It?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The core of the extension is a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOMETRY&lt;/code&gt; type based on the &quot;Simple Features&quot; geometry model and accompanying functions such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_Area&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_Intersects&lt;/code&gt;. It also provides methods for reading and writing geospatial data formats and converting between coordinate reference systems (details later in the post!). While we&#39;re not ready to commit to full compliance with the OGC Simple Feature Access and SQL/MM Standards yet, if you&#39;ve worked with geospatial functionality in other database systems such as &lt;a href=&quot;https://postgis.net/&quot;&gt;PostGIS&lt;/a&gt; or &lt;a href=&quot;https://www.gaia-gis.it/fossil/libspatialite/index&quot;&gt;SpatiaLite&lt;/a&gt;, you should feel right at home.&lt;/p&gt;

&lt;p&gt;Most of the implemented functions are based on the trifecta of foundational geospatial libraries, &lt;a href=&quot;https://libgeos.org/&quot;&gt;GEOS&lt;/a&gt;, &lt;a href=&quot;https://gdal.org/&quot;&gt;GDAL&lt;/a&gt; and &lt;a href=&quot;https://proj.org/&quot;&gt;PROJ&lt;/a&gt;, which provide algorithms, format conversions and coordinate reference system transformations respectively. In particular, we leverage GDAL to provide a set of table and copy functions that enable import and export of tables from and to 50+ different geospatial data formats (so far!), including the most common ones such as Shapefiles, GeoJSON, GeoPackage, KML, GML, WKT, WKB, etc.&lt;/p&gt;

&lt;p&gt;Check for yourself by running:&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM st_drivers();&lt;/code&gt;
&lt;/summary&gt;

  &lt;table&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;short_name&lt;/th&gt;
        &lt;th&gt;long_name&lt;/th&gt;
        &lt;th&gt;can_create&lt;/th&gt;
        &lt;th&gt;can_copy&lt;/th&gt;
        &lt;th&gt;can_open&lt;/th&gt;
        &lt;th&gt;help_url&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;ESRI Shapefile&lt;/td&gt;
        &lt;td&gt;ESRI Shapefile&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/shapefile.html&quot;&gt;https://gdal.org/drivers/vector/shapefile.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;MapInfo File&lt;/td&gt;
        &lt;td&gt;MapInfo File&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/mitab.html&quot;&gt;https://gdal.org/drivers/vector/mitab.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;UK .NTF&lt;/td&gt;
        &lt;td&gt;UK .NTF&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/ntf.html&quot;&gt;https://gdal.org/drivers/vector/ntf.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;LVBAG&lt;/td&gt;
        &lt;td&gt;Kadaster LV BAG Extract 2.0&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/lvbag.html&quot;&gt;https://gdal.org/drivers/vector/lvbag.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;S57&lt;/td&gt;
        &lt;td&gt;IHO S-57 (ENC)&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/s57.html&quot;&gt;https://gdal.org/drivers/vector/s57.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;DGN&lt;/td&gt;
        &lt;td&gt;Microstation DGN&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/dgn.html&quot;&gt;https://gdal.org/drivers/vector/dgn.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;OGR_VRT&lt;/td&gt;
        &lt;td&gt;VRT - Virtual Datasource&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/vrt.html&quot;&gt;https://gdal.org/drivers/vector/vrt.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Memory&lt;/td&gt;
        &lt;td&gt;Memory&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;CSV&lt;/td&gt;
        &lt;td&gt;Comma Separated Value (.csv)&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/csv.html&quot;&gt;https://gdal.org/drivers/vector/csv.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;GML&lt;/td&gt;
        &lt;td&gt;Geography Markup Language (GML)&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/gml.html&quot;&gt;https://gdal.org/drivers/vector/gml.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;GPX&lt;/td&gt;
        &lt;td&gt;GPX&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/gpx.html&quot;&gt;https://gdal.org/drivers/vector/gpx.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;KML&lt;/td&gt;
        &lt;td&gt;Keyhole Markup Language (KML)&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/kml.html&quot;&gt;https://gdal.org/drivers/vector/kml.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;GeoJSON&lt;/td&gt;
        &lt;td&gt;GeoJSON&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/geojson.html&quot;&gt;https://gdal.org/drivers/vector/geojson.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;GeoJSONSeq&lt;/td&gt;
        &lt;td&gt;GeoJSON Sequence&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/geojsonseq.html&quot;&gt;https://gdal.org/drivers/vector/geojsonseq.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;ESRIJSON&lt;/td&gt;
        &lt;td&gt;ESRIJSON&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/esrijson.html&quot;&gt;https://gdal.org/drivers/vector/esrijson.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;TopoJSON&lt;/td&gt;
        &lt;td&gt;TopoJSON&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/topojson.html&quot;&gt;https://gdal.org/drivers/vector/topojson.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;OGR_GMT&lt;/td&gt;
        &lt;td&gt;GMT ASCII Vectors (.gmt)&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/gmt.html&quot;&gt;https://gdal.org/drivers/vector/gmt.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;GPKG&lt;/td&gt;
        &lt;td&gt;GeoPackage&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/gpkg.html&quot;&gt;https://gdal.org/drivers/vector/gpkg.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;SQLite&lt;/td&gt;
        &lt;td&gt;SQLite / Spatialite&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/sqlite.html&quot;&gt;https://gdal.org/drivers/vector/sqlite.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;WAsP&lt;/td&gt;
        &lt;td&gt;WAsP .map format&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/wasp.html&quot;&gt;https://gdal.org/drivers/vector/wasp.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;OpenFileGDB&lt;/td&gt;
        &lt;td&gt;ESRI FileGDB&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/openfilegdb.html&quot;&gt;https://gdal.org/drivers/vector/openfilegdb.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;DXF&lt;/td&gt;
        &lt;td&gt;AutoCAD DXF&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/dxf.html&quot;&gt;https://gdal.org/drivers/vector/dxf.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;CAD&lt;/td&gt;
        &lt;td&gt;AutoCAD Driver&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/cad.html&quot;&gt;https://gdal.org/drivers/vector/cad.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;FlatGeobuf&lt;/td&gt;
        &lt;td&gt;FlatGeobuf&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/flatgeobuf.html&quot;&gt;https://gdal.org/drivers/vector/flatgeobuf.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Geoconcept&lt;/td&gt;
        &lt;td&gt;Geoconcept&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;GeoRSS&lt;/td&gt;
        &lt;td&gt;GeoRSS&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/georss.html&quot;&gt;https://gdal.org/drivers/vector/georss.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VFK&lt;/td&gt;
        &lt;td&gt;Czech Cadastral Exchange Data Format&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/vfk.html&quot;&gt;https://gdal.org/drivers/vector/vfk.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;PGDUMP&lt;/td&gt;
        &lt;td&gt;PostgreSQL SQL dump&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/pgdump.html&quot;&gt;https://gdal.org/drivers/vector/pgdump.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;OSM&lt;/td&gt;
        &lt;td&gt;OpenStreetMap XML and PBF&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/osm.html&quot;&gt;https://gdal.org/drivers/vector/osm.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;GPSBabel&lt;/td&gt;
        &lt;td&gt;GPSBabel&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/gpsbabel.html&quot;&gt;https://gdal.org/drivers/vector/gpsbabel.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;WFS&lt;/td&gt;
        &lt;td&gt;OGC WFS (Web Feature Service)&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/wfs.html&quot;&gt;https://gdal.org/drivers/vector/wfs.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;OAPIF&lt;/td&gt;
        &lt;td&gt;OGC API - Features&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/oapif.html&quot;&gt;https://gdal.org/drivers/vector/oapif.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;EDIGEO&lt;/td&gt;
        &lt;td&gt;French EDIGEO exchange format&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/edigeo.html&quot;&gt;https://gdal.org/drivers/vector/edigeo.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;SVG&lt;/td&gt;
        &lt;td&gt;Scalable Vector Graphics&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/svg.html&quot;&gt;https://gdal.org/drivers/vector/svg.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;ODS&lt;/td&gt;
        &lt;td&gt;Open Document/ LibreOffice / OpenOffice Spreadsheet&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/ods.html&quot;&gt;https://gdal.org/drivers/vector/ods.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;XLSX&lt;/td&gt;
        &lt;td&gt;MS Office Open XML spreadsheet&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/xlsx.html&quot;&gt;https://gdal.org/drivers/vector/xlsx.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Elasticsearch&lt;/td&gt;
        &lt;td&gt;Elastic Search&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/elasticsearch.html&quot;&gt;https://gdal.org/drivers/vector/elasticsearch.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Carto&lt;/td&gt;
        &lt;td&gt;Carto&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/carto.html&quot;&gt;https://gdal.org/drivers/vector/carto.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;AmigoCloud&lt;/td&gt;
        &lt;td&gt;AmigoCloud&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/amigocloud.html&quot;&gt;https://gdal.org/drivers/vector/amigocloud.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;SXF&lt;/td&gt;
        &lt;td&gt;Storage and eXchange Format&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/sxf.html&quot;&gt;https://gdal.org/drivers/vector/sxf.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Selafin&lt;/td&gt;
        &lt;td&gt;Selafin&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/selafin.html&quot;&gt;https://gdal.org/drivers/vector/selafin.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;JML&lt;/td&gt;
        &lt;td&gt;OpenJUMP JML&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/jml.html&quot;&gt;https://gdal.org/drivers/vector/jml.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;PLSCENES&lt;/td&gt;
        &lt;td&gt;Planet Labs Scenes API&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/plscenes.html&quot;&gt;https://gdal.org/drivers/vector/plscenes.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;CSW&lt;/td&gt;
        &lt;td&gt;OGC CSW (Catalog  Service for the Web)&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/csw.html&quot;&gt;https://gdal.org/drivers/vector/csw.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VDV&lt;/td&gt;
        &lt;td&gt;VDV-451/VDV-452/INTREST Data Format&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/vdv.html&quot;&gt;https://gdal.org/drivers/vector/vdv.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;MVT&lt;/td&gt;
        &lt;td&gt;Mapbox Vector Tiles&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/mvt.html&quot;&gt;https://gdal.org/drivers/vector/mvt.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;NGW&lt;/td&gt;
        &lt;td&gt;NextGIS Web&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/ngw.html&quot;&gt;https://gdal.org/drivers/vector/ngw.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;MapML&lt;/td&gt;
        &lt;td&gt;MapML&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/mapml.html&quot;&gt;https://gdal.org/drivers/vector/mapml.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;TIGER&lt;/td&gt;
        &lt;td&gt;U.S. Census TIGER/Line&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/tiger.html&quot;&gt;https://gdal.org/drivers/vector/tiger.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;AVCBin&lt;/td&gt;
        &lt;td&gt;Arc/Info Binary Coverage&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/avcbin.html&quot;&gt;https://gdal.org/drivers/vector/avcbin.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;AVCE00&lt;/td&gt;
        &lt;td&gt;Arc/Info E00 (ASCII) Coverage&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;false&lt;/td&gt;
        &lt;td&gt;true&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;https://gdal.org/drivers/vector/avce00.html&quot;&gt;https://gdal.org/drivers/vector/avce00.html&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;

&lt;/details&gt;

&lt;p&gt;Initially we have prioritized providing a breadth of capabilities by wrapping existing libraries. We&#39;re planning to implement more of the core functions and algorithms natively in the future to enable faster performance and more efficient memory management.&lt;/p&gt;

&lt;p&gt;As an initial step in this direction, we provide a set of non-standard specialized columnar DuckDB native geometry types such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POINT_2D&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOX_2D&lt;/code&gt;, etc. that should provide better compression and faster execution in exchange for some flexibility, but work around these are still very much experimental.&lt;/p&gt;
      &lt;h2 id=&quot;example-usage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/28/spatial.html#example-usage&quot;&gt;Example Usage&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The following demonstrates how you can use the spatial extension to read and export multiple geospatial data formats, transform geometries between different coordinate reference systems and work with spatial property and predicate functions. While this example may be slightly contrived, we want to showcase the power of the currently available features.
You can find the datasets used in this example in the &lt;a href=&quot;https://github.com/duckdb/duckdb-spatial/tree/main/test/data/nyc_taxi&quot;&gt;spatial extension repository&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&#39;s import the NYC taxi ride data provided in Parquet format as well as the accompanying taxi zone data from a shapefile, using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_Read&lt;/code&gt; table function provided by the spatial extension. These taxi zones break NYC into polygons that represent regions, for example the Newark Airport. We then create a table for the rides and a table for the zones. Note that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_Read&lt;/code&gt; produces a table with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wkb_geometry&lt;/code&gt; column that contains the geometry data encoded as a WKB (Well-Known Binary) blob, which we then convert to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOMETRY&lt;/code&gt; type using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_GeomFromWKB&lt;/code&gt; function.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This may all seem a bit much if you are not familiar with the geospatial ecosystem, but rest assured this is all you really need to get started. In short:
– &lt;a href=&quot;https://en.wikipedia.org/wiki/Shapefile&quot;&gt;Shapefile&lt;/a&gt; (.shp, .shx, .dbf) is a common format for storing geometry vector data and auxiliary metadata such as indexes and attributes.
– &lt;a href=&quot;https://libgeos.org/specifications/wkb/&quot;&gt;WKB (Well Known Binary)&lt;/a&gt;, while not really a file format in itself, is a common binary encoding of vector geometry data, used in e.g., GeoParquet. Comes in multiple flavors, but we&#39;re only concerned with &quot;standard&quot; WKB for now.
– &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOMETRY&lt;/code&gt; is a DuckDB type that represents a &lt;a href=&quot;https://en.wikipedia.org/wiki/Simple_Features&quot;&gt;Simple Features&lt;/a&gt; geometry object, which is based on a set of standards modeling vector geometry data as points, linestrings, polygons or collections of such. This is the core data type used by the spatial extension, and what most of the provided functions take and return.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; spatial&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rides&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;yellow_tripdata_2010-01-limit1mil.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Load the NYC taxi zone data from a shapefile using the gdal-based ST_Read function&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zones&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LocationId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;borough&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ST_Read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;taxi_zones/taxi_zones.shx&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let&#39;s compare the trip distance to the linear distance between the pickup and dropoff points to figure out how efficient the taxi drivers are (or how dirty the data is, since some diffs seem to be negative). We transform the coordinates from &quot;WGS84&quot; (given by the identifier EPSG:4326), also commonly known as simply latitude/longitude to the &quot;NAD83 / New York Long Island ftUS&quot; (identified as ESRI:102718) coordinate reference system which is a projection with minimal distortion around New York. We then calculate the distance using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_Distance&lt;/code&gt; function. In This case we get the distance in feet since we&#39;ve converted the coordinates to NAD83 but we can easily convert it into to miles (5280 ft/mile) which is the unit used in the rides dataset so we can compare them correctly.&lt;/p&gt;

&lt;details&gt;
  &lt;summary&gt;
Wait, what&#39;s all this about coordinate reference systems and projections?
&lt;/summary&gt;
  &lt;blockquote&gt;
    &lt;p&gt;The earth is not flat, but sometimes it is useful to pretend it is for the sake of simplicity by &quot;projecting&quot; the coordinates onto a flat surface. The &quot;parameters&quot; of a projection – e.g., where the &quot;origin&quot; is located, what unit coordinates are in, or how the earth&#39;s shape is approximated – are encapsulated by a &quot;Spatial Reference System&quot; or &quot;Coordinate Reference System&quot; (CRS) which is usually referenced by a shorthand identifier composed of an authority and a code, e.g., &quot;EPSG:4326&quot; or &quot;ESRI:102718&quot;. Projections are always lossy, so its important to use a CRS that is well suited for the &quot;area of interest&quot; your data is in. The spatial extension uses the &lt;a href=&quot;https://proj.org/&quot;&gt;PROJ&lt;/a&gt; library to handle coordinate reference systems and projections.&lt;/p&gt;
  &lt;/blockquote&gt;

&lt;/details&gt;

&lt;p&gt;Trips with a distance shorter than the aerial distance are likely to be erroneous, so we use this query to filter out some bad data. The query below takes advantage of DuckDB&#39;s ability to refer to column aliases defined within the same select statement. This is a small example of how DuckDB&#39;s rich SQL dialect can simplify geospatial analysis.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaned_rides&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;nf&quot;&gt;ST_Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pickup_latitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_longitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;ST_Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropoff_latitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_longitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dropoff_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;ST_Distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;ST_Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pickup_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;EPSG:4326&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;ESRI:102718&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
            &lt;span class=&quot;nf&quot;&gt;ST_Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropoff_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;EPSG:4326&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;ESRI:102718&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5280&lt;/span&gt; 
            &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aerial_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aerial_distance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rides&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM rides LIMIT 10;&lt;/code&gt;
&lt;/summary&gt;

  &lt;table&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;vendor_id&lt;/th&gt;
        &lt;th&gt;pickup_datetime&lt;/th&gt;
        &lt;th&gt;dropoff_datetime&lt;/th&gt;
        &lt;th&gt;passenger_count&lt;/th&gt;
        &lt;th&gt;trip_distance&lt;/th&gt;
        &lt;th&gt;pickup_longitude&lt;/th&gt;
        &lt;th&gt;pickup_latitude&lt;/th&gt;
        &lt;th&gt;rate_code&lt;/th&gt;
        &lt;th&gt;store_and_fwd_flag&lt;/th&gt;
        &lt;th&gt;dropoff_longitude&lt;/th&gt;
        &lt;th&gt;dropoff_latitude&lt;/th&gt;
        &lt;th&gt;payment_type&lt;/th&gt;
        &lt;th&gt;fare_amount&lt;/th&gt;
        &lt;th&gt;surcharge&lt;/th&gt;
        &lt;th&gt;mta_tax&lt;/th&gt;
        &lt;th&gt;tip_amount&lt;/th&gt;
        &lt;th&gt;tolls_amount&lt;/th&gt;
        &lt;th&gt;total_amount&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;VTS&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:17&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:17&lt;/td&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;-73.87105699999998&lt;/td&gt;
        &lt;td&gt;40.773522&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
        &lt;td&gt;-73.871048&lt;/td&gt;
        &lt;td&gt;40.773545&lt;/td&gt;
        &lt;td&gt;CAS&lt;/td&gt;
        &lt;td&gt;45.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;45.5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VTS&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:20&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:20&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.05&lt;/td&gt;
        &lt;td&gt;-73.97512999999998&lt;/td&gt;
        &lt;td&gt;40.789973&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
        &lt;td&gt;-73.97498799999998&lt;/td&gt;
        &lt;td&gt;40.790598&lt;/td&gt;
        &lt;td&gt;CAS&lt;/td&gt;
        &lt;td&gt;2.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;3.5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;CMT&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:23&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:25&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;-73.999431&lt;/td&gt;
        &lt;td&gt;40.71216&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
        &lt;td&gt;-73.99915799999998&lt;/td&gt;
        &lt;td&gt;40.712421&lt;/td&gt;
        &lt;td&gt;No&lt;/td&gt;
        &lt;td&gt;2.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;3.5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;CMT&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:33&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:55&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;-73.97721699999998&lt;/td&gt;
        &lt;td&gt;40.749633&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
        &lt;td&gt;-73.97732899999998&lt;/td&gt;
        &lt;td&gt;40.749629&lt;/td&gt;
        &lt;td&gt;Cas&lt;/td&gt;
        &lt;td&gt;2.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;3.5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VTS&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:00&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:00&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;-73.942313&lt;/td&gt;
        &lt;td&gt;40.784332&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
        &lt;td&gt;-73.942313&lt;/td&gt;
        &lt;td&gt;40.784332&lt;/td&gt;
        &lt;td&gt;Cre&lt;/td&gt;
        &lt;td&gt;10.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;2.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;12.5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VTS&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:06&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:06&lt;/td&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;0.38&lt;/td&gt;
        &lt;td&gt;-73.97463&lt;/td&gt;
        &lt;td&gt;40.756687&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
        &lt;td&gt;-73.979872&lt;/td&gt;
        &lt;td&gt;40.759143&lt;/td&gt;
        &lt;td&gt;CAS&lt;/td&gt;
        &lt;td&gt;3.7&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;4.7&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VTS&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:07&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:07&lt;/td&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;0.23&lt;/td&gt;
        &lt;td&gt;-73.987358&lt;/td&gt;
        &lt;td&gt;40.718475&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
        &lt;td&gt;-73.98518&lt;/td&gt;
        &lt;td&gt;40.720468&lt;/td&gt;
        &lt;td&gt;CAS&lt;/td&gt;
        &lt;td&gt;2.9&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;3.9&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;CMT&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:00:02&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:08&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.1&lt;/td&gt;
        &lt;td&gt;-73.992807&lt;/td&gt;
        &lt;td&gt;40.741418&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0&lt;/td&gt;
        &lt;td&gt;-73.995799&lt;/td&gt;
        &lt;td&gt;40.742596&lt;/td&gt;
        &lt;td&gt;No&lt;/td&gt;
        &lt;td&gt;2.9&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;3.9&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VTS&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:23&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:23&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.6099999999999999&lt;/td&gt;
        &lt;td&gt;-73.98003799999998&lt;/td&gt;
        &lt;td&gt;40.74306&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
        &lt;td&gt;-73.974862&lt;/td&gt;
        &lt;td&gt;40.750387&lt;/td&gt;
        &lt;td&gt;CAS&lt;/td&gt;
        &lt;td&gt;3.7&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;4.7&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;VTS&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:34&lt;/td&gt;
        &lt;td&gt;2010-01-01 00:01:34&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;0.02&lt;/td&gt;
        &lt;td&gt;-73.954122&lt;/td&gt;
        &lt;td&gt;40.801173&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;&amp;nbsp;&lt;/td&gt;
        &lt;td&gt;-73.95431499999998&lt;/td&gt;
        &lt;td&gt;40.800897&lt;/td&gt;
        &lt;td&gt;CAS&lt;/td&gt;
        &lt;td&gt;45.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.5&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;0.0&lt;/td&gt;
        &lt;td&gt;45.5&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;

&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM zones LIMIT 10;&lt;/code&gt;
&lt;/summary&gt;

  &lt;table&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;zone&lt;/th&gt;
        &lt;th&gt;LocationID&lt;/th&gt;
        &lt;th&gt;borough&lt;/th&gt;
        &lt;th&gt;geom&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;Newark Airport&lt;/td&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;EWR&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Jamaica Bay&lt;/td&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;Queens&lt;/td&gt;
        &lt;td&gt;MULTIPOLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Allerton/Pelham Gardens&lt;/td&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;Bronx&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Alphabet City&lt;/td&gt;
        &lt;td&gt;4&lt;/td&gt;
        &lt;td&gt;Manhattan&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Arden Heights&lt;/td&gt;
        &lt;td&gt;5&lt;/td&gt;
        &lt;td&gt;Staten Island&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Arrochar/Fort Wadsworth&lt;/td&gt;
        &lt;td&gt;6&lt;/td&gt;
        &lt;td&gt;Staten Island&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Astoria&lt;/td&gt;
        &lt;td&gt;7&lt;/td&gt;
        &lt;td&gt;Queens&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Astoria Park&lt;/td&gt;
        &lt;td&gt;8&lt;/td&gt;
        &lt;td&gt;Queens&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Auburndale&lt;/td&gt;
        &lt;td&gt;9&lt;/td&gt;
        &lt;td&gt;Queens&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Baisley Park&lt;/td&gt;
        &lt;td&gt;10&lt;/td&gt;
        &lt;td&gt;Queens&lt;/td&gt;
        &lt;td&gt;POLYGON (…)&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;

&lt;/details&gt;

&lt;blockquote&gt;
  &lt;p&gt;It should be noted that this is not entirely accurate since the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_Distance&lt;/code&gt; function we use does not take into account the curvature of the earth. However, we&#39;ll accept it as a good enough approximation for our purposes. Spherical and geodesic distance calculations are on the roadmap!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let&#39;s join the taxi rides with the taxi zones to get the start and end zone for each ride. We use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_Within&lt;/code&gt; function as our join condition to check if a pickup or dropoff point is within a taxi zone polygon. Again we need to transform the coordinates from WGS84 to the NAD83 since the taxi zone data also use that projection. Spatial joins like these are the bread and butter of geospatial data processing, but we don&#39;t currently have any optimizations in place (such as spatial indexes) to speed up these queries, which is why we only use a subset of the data for the following step.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Since we don&#39;t have spatial indexes yet, use a smaller dataset for the join.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DELETE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaned_rides&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;joined&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;pickup_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dropoff_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;start_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;end_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zone&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaned_rides&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zones&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_zone&lt;/span&gt; 
      &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ST_Within&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ST_Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pickup_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;EPSG:4326&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;ESRI:102718&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zones&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_zone&lt;/span&gt; 
      &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ST_Within&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ST_Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropoff_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;EPSG:4326&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;ESRI:102718&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM joined USING SAMPLE 10 ROWS;&lt;/code&gt;
&lt;/summary&gt;

  &lt;table&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;pickup_point&lt;/th&gt;
        &lt;th&gt;dropoff_point&lt;/th&gt;
        &lt;th&gt;start_zone&lt;/th&gt;
        &lt;th&gt;end_zone&lt;/th&gt;
        &lt;th&gt;trip_distance&lt;/th&gt;
        &lt;th&gt;time&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.722223 -73.98385299999998)&lt;/td&gt;
        &lt;td&gt;POINT (40.715507 -73.992438)&lt;/td&gt;
        &lt;td&gt;East Village&lt;/td&gt;
        &lt;td&gt;Lower East Side&lt;/td&gt;
        &lt;td&gt;10.3&lt;/td&gt;
        &lt;td&gt;00:19:16&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.648687 -73.783522)&lt;/td&gt;
        &lt;td&gt;POINT (40.649567 -74.005812)&lt;/td&gt;
        &lt;td&gt;JFK Airport&lt;/td&gt;
        &lt;td&gt;Sunset Park West&lt;/td&gt;
        &lt;td&gt;23.57&lt;/td&gt;
        &lt;td&gt;00:28:00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.761603 -73.96661299999998)&lt;/td&gt;
        &lt;td&gt;POINT (40.760232 -73.96344499999998)&lt;/td&gt;
        &lt;td&gt;Upper East Side South&lt;/td&gt;
        &lt;td&gt;Sutton Place/Turtle Bay North&lt;/td&gt;
        &lt;td&gt;17.6&lt;/td&gt;
        &lt;td&gt;00:27:05&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.697212 -73.937495)&lt;/td&gt;
        &lt;td&gt;POINT (40.652377 -73.93983299999998)&lt;/td&gt;
        &lt;td&gt;Stuyvesant Heights&lt;/td&gt;
        &lt;td&gt;East Flatbush/Farragut&lt;/td&gt;
        &lt;td&gt;13.55&lt;/td&gt;
        &lt;td&gt;00:24:00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.721462 -73.993583)&lt;/td&gt;
        &lt;td&gt;POINT (40.774205 -73.90441699999998)&lt;/td&gt;
        &lt;td&gt;Lower East Side&lt;/td&gt;
        &lt;td&gt;Steinway&lt;/td&gt;
        &lt;td&gt;28.75&lt;/td&gt;
        &lt;td&gt;01:03:00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.716955 -74.004328)&lt;/td&gt;
        &lt;td&gt;POINT (40.754688 -73.991612)&lt;/td&gt;
        &lt;td&gt;TriBeCa/Civic Center&lt;/td&gt;
        &lt;td&gt;Garment District&lt;/td&gt;
        &lt;td&gt;18.4&lt;/td&gt;
        &lt;td&gt;00:46:12&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.740052 -73.994918)&lt;/td&gt;
        &lt;td&gt;POINT (40.75439 -73.98587499999998)&lt;/td&gt;
        &lt;td&gt;Flatiron&lt;/td&gt;
        &lt;td&gt;Garment District&lt;/td&gt;
        &lt;td&gt;24.2&lt;/td&gt;
        &lt;td&gt;00:35:25&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.763017 -73.95949199999998)&lt;/td&gt;
        &lt;td&gt;POINT (40.763615 -73.959182)&lt;/td&gt;
        &lt;td&gt;Lenox Hill East&lt;/td&gt;
        &lt;td&gt;Lenox Hill West&lt;/td&gt;
        &lt;td&gt;18.4&lt;/td&gt;
        &lt;td&gt;00:33:46&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.865663 -73.927458)&lt;/td&gt;
        &lt;td&gt;POINT (40.86537 -73.927352)&lt;/td&gt;
        &lt;td&gt;Washington Heights North&lt;/td&gt;
        &lt;td&gt;Washington Heights North&lt;/td&gt;
        &lt;td&gt;10.47&lt;/td&gt;
        &lt;td&gt;00:27:00&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;POINT (40.738408 -73.980345)&lt;/td&gt;
        &lt;td&gt;POINT (40.696038 -73.955493)&lt;/td&gt;
        &lt;td&gt;Gramercy&lt;/td&gt;
        &lt;td&gt;Bedford&lt;/td&gt;
        &lt;td&gt;16.4&lt;/td&gt;
        &lt;td&gt;00:21:47&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;

&lt;/details&gt;

&lt;p&gt;We can export the joined table to a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GeoJSONSeq&lt;/code&gt; file using the GDAL copy function, passing in a GDAL layer creation option. Since &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GeoJSON&lt;/code&gt; only supports a single &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOMETRY&lt;/code&gt; per record, we use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_MakeLine&lt;/code&gt; function to combine the pickup and dropoff points into a single line geometry. The default coordinate reference system for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GeoJSON&lt;/code&gt; is WGS84, but the coordinate pairs are expected to be in longitude/latitude, so we need to flip the geometry using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ST_FlipCoordinates&lt;/code&gt; function.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
        &lt;span class=&quot;nf&quot;&gt;ST_MakeLine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pickup_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropoff_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ST_FlipCoordinates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ST_AsWKB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wkb_geometry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;start_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;end_zone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_time&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;joined&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;joined.geojsonseq&#39;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;gdal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;DRIVER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;GeoJSONSeq&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;LAYER_CREATION_OPTIONS&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;WRITE_BBOX=YES&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;details&gt;
  &lt;summary&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;head -n 10 joined.geojsonseq&lt;/code&gt;
&lt;/summary&gt;

  &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:52:00&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.789923&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.643515&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.97608&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.680395&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:35:00&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.776445&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.645422&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.98427&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.670782&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:45:42&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.776878&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.645065&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.992153&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.662571&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:36:00&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.788028&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.641508&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.97584&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.670927&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:47:58&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.781855&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.644749&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.980129&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.663663&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:32:10&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.787494&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.641559&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.974694&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.673479&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:36:59&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.790138&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.643342&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.982721&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.662379&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:32:00&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.786952&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.641248&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.97421&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.676237&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:33:21&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.783892&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.648514&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.979283&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.669721&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Feature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;start_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;JFK Airport&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;end_zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Park Slope&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;trip_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;00:35:45&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;geometry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LineString&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.776643&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.645272&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;-73.978873&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;40.66723&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/details&gt;

&lt;p&gt;And there we have it! We pulled tabular data from Parquet, combined it with geospatial data in a shapefile, cleaned and analyzed that combined data, and output it to a human readable geospatial format. The full set of currently supported functions and their implementation status can be found over at the docs in &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/spatial/overview.html#spatial-scalar-functions&quot;&gt;this table&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;whats-next&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/28/spatial.html#whats-next&quot;&gt;What&#39;s Next?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;While it&#39;s probably going to take a while for us to catch up to the full set of functions provided by e.g., PostGIS, we believe that DuckDB&#39;s vectorized execution model and columnar storage format will enable a whole new class of optimizations for geospatial processing that we&#39;ve just begun exploring. Improving the performance of spatial joins and predicates is therefore high on our list of priorities.&lt;/p&gt;

&lt;p&gt;There are also some limitations with our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOMETRY&lt;/code&gt; type that we would eventually like to tackle, such as the fact that we don&#39;t support additional Z and M dimensions, or don&#39;t support the full range of geometry sub-types that are mandated by the OGC standard, like curves or polyhedral surfaces.&lt;/p&gt;

&lt;p&gt;We&#39;re also interested in supporting spherical and ellipsoidal calculations in the near future, perhaps in the form of a dedicated &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOGRAPHY&lt;/code&gt; type.&lt;/p&gt;

&lt;p&gt;Wasm builds are also just around the corner!&lt;/p&gt;

&lt;p&gt;Please take a look at the &lt;a href=&quot;https://github.com/duckdb/duckdb-spatial&quot;&gt;GitHub repository&lt;/a&gt; for the full roadmap and to see what we&#39;re currently working on. If you would like to help build this capability, please reach out on GitHub!&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/28/spatial.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The DuckDB Spatial extension is another step towards making DuckDB a swiss army knife for data engineering and analytics. This extension provides a flexible and familiar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GEOMETRY&lt;/code&gt; type, reprojectable between thousands of coordinate reference systems, coupled with the capability to export and import geospatial data between more than 50 different data sources. All embedded into a single extension with minimal runtime dependencies. This enables DuckDB to fit seamlessly into your existing GIS workflows regardless of which geospatial data formats or projections you&#39;re working with.&lt;/p&gt;

&lt;p&gt;We are excited to hear what you make of the DuckDB spatial extension. It&#39;s still early days but we hope to have a lot more to share in the future as we continue making progress! If you have any questions, suggestions, ideas or issues, please don&#39;t hesitate to reach out to us on Discord or GitHub!&lt;/p&gt;

</description><link>https://duckdb.org/2023/04/28/spatial.html</link><guid isPermaLink="false">https://duckdb.org/2023/04/28/spatial.html</guid><pubDate>Fri, 28 Apr 2023 00:00:00 GMT</pubDate><author>Max Gabrielsson</author></item><item><title>Introducing DuckDB for Swift</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB now has a native Swift API. DuckDB on mobile here we go!&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Today we’re excited to announce the &lt;a href=&quot;https://github.com/duckdb/duckdb-swift&quot;&gt;DuckDB API for Swift&lt;/a&gt;. It enables developers on Swift platforms to harness the full power of DuckDB using a native Swift interface with support for great Swift features such as strong typing and concurrency. The API is available not only on Apple platforms, but on Linux too, opening up new opportunities for the growing Swift on Server ecosystem.&lt;/p&gt;
      &lt;h2 id=&quot;whats-included&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/21/swift.html#whats-included&quot;&gt;What’s Included&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB is designed to be fast, reliable and easy to use, and it’s this philosophy that also guided the creation of our new Swift API.&lt;/p&gt;

&lt;p&gt;This initial release supports many of the great features of DuckDB right out of the box, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Queries via DuckDB’s enhanced SQL dialect: In addition to basic SQL, DuckDB supports arbitrary and nested correlated subqueries, window functions, collations, complex types (Swift arrays and structs), and more.&lt;/li&gt;
  &lt;li&gt;Import and export of JSON, CSV, and Parquet files: Beyond its built-in and super-efficient native file format, DuckDB supports reading in, and exporting out to, JSON, CSV, and Parquet files.&lt;/li&gt;
  &lt;li&gt;Strongly typed result sets: DuckDB’s strongly typed result sets are a natural fit for Swift. It’s simple to cast DuckDB columns to their native Swift equivalents, ready for presentation using SwiftUI or as part of an existing TabularData workflow.&lt;/li&gt;
  &lt;li&gt;Swift concurrency support: by virtue of their &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Sendable&lt;/code&gt; conformance, many of DuckDB’s core underlying types can be safely passed across concurrency contexts, easing the process of designing parallel processing workflows and ensuring responsive UIs.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;usage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/21/swift.html#usage&quot;&gt;Usage&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To demonstrate just how well DuckDB works together with Swift, we’ve created an example project that uses raw data from &lt;a href=&quot;https://exoplanetarchive.ipac.caltech.edu/&quot;&gt;NASA’s Exoplanet Archive&lt;/a&gt; loaded directly into DuckDB.&lt;/p&gt;

&lt;p&gt;You’ll see how to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Instantiate a DuckDB in-memory Database and Connection&lt;/li&gt;
  &lt;li&gt;Populate a DuckDB table with the contents of a remote CSV&lt;/li&gt;
  &lt;li&gt;Query a DuckDB database and prepare the results for presentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finally, we’ll present our analysis with the help of Apple’s &lt;a href=&quot;https://developer.apple.com/documentation/tabulardata&quot;&gt;TabularData Framework&lt;/a&gt; and &lt;a href=&quot;https://developer.apple.com/documentation/charts&quot;&gt;Swift Charts&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;instantiating-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/21/swift.html#instantiating-duckdb&quot;&gt;Instantiating DuckDB&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB supports both file-based and in-memory databases. In this example, as we don’t intend to persist the results of our Exoplanet analysis to disk, we’ll opt for an in-memory Database.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;database&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;store&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inMemory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, we can’t issue queries just yet. Much like other RDMSs, queries must be issued through a &lt;em&gt;database connection&lt;/em&gt;. DuckDB supports multiple connections per database. This can be useful to support parallel processing, for example. In our project, we’ll need just the one connection that we’ll eventually access asynchronously.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;connection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, we’ll create an app-specific type that we’ll use to house our database and connection and through which we’ll eventually define our app-specific queries.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DuckDB&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExoplanetStore&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Database&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Connection&lt;/span&gt;

    &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;database&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;populating-duckdb-with-a-remote-csv-file&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/21/swift.html#populating-duckdb-with-a-remote-csv-file&quot;&gt;Populating DuckDB with a Remote CSV File&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;One problem with our current &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExoplanetStore&lt;/code&gt; type is that it doesn’t yet contain any data to query. To fix that, we’ll load it with the data of every Exoplanet discovered to date from &lt;a href=&quot;https://exoplanetarchive.ipac.caltech.edu/&quot;&gt;NASA’s Exoplanet Archive&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are hundreds of configuration options for this incredible resource, but today we want each exoplanet’s name and its discovery year packaged as a CSV. &lt;a href=&quot;https://exoplanetarchive.ipac.caltech.edu/docs/API_PS_columns.html&quot;&gt;Checking the docs&lt;/a&gt; gives us the following endpoint:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://exoplanetarchive.ipac.caltech.edu/TAP/sync?query=select+pl_name+,+disc_year+from+pscomppars&amp;amp;format=csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once we have our CSV downloaded locally, we can use the following SQL command to load it as a new table within our DuckDB in-memory database. DuckDB’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv_auto&lt;/code&gt; command automatically infers our table schema and the data is immediately available for analysis.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exoplanets&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_csv_auto&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;downloaded_exoplanets.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let’s package this up as a new asynchronous factory method on our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ExoplanetStore&lt;/code&gt; type:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DuckDB&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Foundation&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExoplanetStore&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Factory method to create and prepare a new ExoplanetStore&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExoplanetStore&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Create our database and connection as described above&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;database&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;store&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inMemory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;connection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Download the CSV from the exoplanet archive&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;csvFileURL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;URLSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://exoplanetarchive.ipac.caltech.edu/TAP/sync?query=select+pl_name+,+disc_year+from+pscomppars&amp;amp;format=csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Issue our first query to DuckDB&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
            CREATE TABLE exoplanets AS (
                SELECT * FROM read_csv_auto(&#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csvFileURL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;)
            );
            &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Create our pre-populated ExoplanetStore instance&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExoplanetStore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;nv&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Let&#39;s make the initializer we defined previously &lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// private. This prevents anyone accidentally instantiating&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// the store without having pre-loaded our Exoplanet CSV&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// into the database&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Database&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// ...&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;querying-the-database&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/21/swift.html#querying-the-database&quot;&gt;Querying the Database&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Now that the database is populated with data, it’s ready to be analyzed. Let’s create a query which we can use to plot a chart of the number of exoplanets discovered by year.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disc_year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exoplanets&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_year&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Issuing the query to DuckDB  from within Swift is simple. We’ll again make use of an async function from which to issue our query. This means the callee won’t be blocked while the query is executing. We’ll then cast the result columns to Swift native types using DuckDB’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResultSet&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cast(to:)&lt;/code&gt; family of methods, before finally wrapping them up in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt; from the TabularData framework ready for presentation in the UI.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TabularData&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;extension&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExoplanetStore&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Retrieves the number of exoplanets discovered by year  &lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;groupedByDiscoveryYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DataFrame&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Issue the query we described above&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
            SELECT disc_year, count(disc_year) AS Count
            FROM exoplanets
            GROUP BY disc_year
            ORDER BY disc_year
            &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Cast our DuckDB columns to their native Swift&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// equivalent types&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;discoveryYearColumn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;countColumn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// Use our DuckDB columns to instantiate TabularData&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;// columns and populate a TabularData DataFrame&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;TabularData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;discoveryYearColumn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eraseToAnyColumn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;TabularData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;countColumn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eraseToAnyColumn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;visualizing-the-results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/21/swift.html#visualizing-the-results&quot;&gt;Visualizing the Results&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In just a few lines of code, our database has been created, populated and analyzed – all that’s left to do now is present the results.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/iphone-simulator-screen-shot.png&quot; alt=&quot;&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;And I have a feeling that we’re just getting started…&lt;/p&gt;

&lt;p&gt;For the complete example project – including the SwiftUI views and Chart definitions used to create the screenshot above –&amp;nbsp;clone &lt;a href=&quot;https://github.com/duckdb/duckdb-swift&quot;&gt;the DuckDB Swift repo&lt;/a&gt; and open up the runnable app project located in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Examples/SwiftUI/ExoplanetExplorer.xcodeproj&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We encourage you to modify the code, explore the Exoplanet Archive and DuckDB, and make some discoveries of your own – interplanetary or otherwise!&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/21/swift.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this article we’ve introduced the brand new Swift API for DuckDB and demonstrated how quickly you can get up and running analyzing data.&lt;/p&gt;

&lt;p&gt;With DuckDB’s incredible performance and analysis capabilities and Swift’s vibrant eco-system and platform support, there’s never been a better time to begin exploring analytical datasets in Swift.&lt;/p&gt;

&lt;p&gt;We can’t wait to see what you do with it. Feel free to reach out on our &lt;a href=&quot;https://discord.duckdb.org/&quot;&gt;Discord&lt;/a&gt; if you have any questions!&lt;/p&gt;&lt;hr&gt;

&lt;p&gt;The Swift API for DuckDB is packaged using Swift Package Manager and lives in a new top-level repository available at &lt;a href=&quot;https://github.com/duckdb/duckdb-swift&quot;&gt;https://github.com/duckdb/duckdb-swift&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2023/04/21/swift.html</link><guid isPermaLink="false">https://duckdb.org/2023/04/21/swift.html</guid><pubDate>Fri, 21 Apr 2023 00:00:00 GMT</pubDate><author>Tristan Celder</author></item><item><title>The Return of the H2O.ai Database-like Ops Benchmark</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We&#39;ve resurrected the H2O.ai database-like ops benchmark with up to date libraries and plan to keep re-running it.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;a href=&quot;https://duckdb.org/2023/04/14/h2oai.html#results&quot;&gt;Skip directly to the results&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We published a new blog post on the H2O.ai benchmark in November 2023 and improved the benchmark setup for reproducibility.
For details, see the new post: &lt;a href=&quot;https://duckdb.org/2023/11/03/db-benchmark-update.html&quot;&gt;&quot;Updates to the H2O.ai db-benchmark!&quot;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The H2O.ai &lt;a href=&quot;https://h2oai.github.io/db-benchmark/&quot;&gt;Database-like Ops Benchmark&lt;/a&gt; is a well-known benchmark in the data analytics and R community. The benchmark measures the groupby and join performance of various analytical tools like data.table, Polars, dplyr, ClickHouse, DuckDB and more. Since July 2nd 2021, the benchmark has been dormant, with no result updates or maintenance. Many of the analytical systems measured in the benchmark have since undergone substantial improvements, leaving many of the maintainers curious as to where their analytical tool ranks on the benchmark.&lt;/p&gt;

&lt;p&gt;DuckDB has decided to give the H2O.ai benchmark new life and maintain it for the foreseeable future. One reason the DuckDB project has decided to maintain the benchmark is because DuckDB has had 10 new minor releases since the most recent published results on July 2nd, 2021. After managing to run parts of the benchmark on a r3-8xlarge AWS box, DuckDB ranked as a top performer on the benchmark. Additionally, the DuckDB project wants to demonstrate it&#39;s commitment to performance by consistently comparing DuckDB with other analytical systems. While DuckDB delivers differentiated ease of use, raw performance and scalability are critically important for solving tough problems fast. Plus, just like many of our fellow data folks, we have a need for speed. Therefore, the decision was made to fork the benchmark, modernize underlying dependencies and run the benchmark on the latest versions of the included systems. You can find the repository &lt;a href=&quot;https://github.com/duckdblabs/db-benchmark&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The results of the new benchmark are very interesting, but first a quick summary of the benchmark and what updates took place.&lt;/p&gt;
      &lt;h2 id=&quot;the-h2oai-database-like-ops-benchmark&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/14/h2oai.html#the-h2oai-database-like-ops-benchmark&quot;&gt;The H2O.ai Database-like Ops Benchmark&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are 5 basic grouping tests and 5 advanced grouping tests. The 10 grouping queries all focus on a combination of the following&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Low cardinality (a few big groups)&lt;/li&gt;
  &lt;li&gt;High cardinality (lots of very small groups)&lt;/li&gt;
  &lt;li&gt;Grouping integer types&lt;/li&gt;
  &lt;li&gt;Grouping string types&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each query is run only twice with both results being reported. This way we can see the performance of a cold run and any effects data caching may have. The idea is to avoid reporting any potential &quot;best&quot; results on a hot system. Data analysts only need to run a query once to get their answer. No one drives to the store a second time to get another litre of milk faster.&lt;/p&gt;

&lt;p&gt;The time reported is the sum of the time it takes to run all 5 queries twice.&lt;/p&gt;

&lt;p&gt;More information about the specific queries can be found below.&lt;/p&gt;
      &lt;h3 id=&quot;the-data-and-queries&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/14/h2oai.html#the-data-and-queries&quot;&gt;The Data and Queries&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The queries have not changed since the benchmark went dormant. The data is generated in a rather simple manner. Inspecting the datagen files you can see that the columns are generated with small, medium, and large groups of char and int values. Similar generation logic applies to the join data generation.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Query&lt;/th&gt;
      &lt;th&gt;SQL&lt;/th&gt;
      &lt;th&gt;Objective&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;groupby #1&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id1, sum(v1) AS v1 FROM tbl GROUP BY id1&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Sum over large cardinality groups, grouped by varchar&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;groupby #2&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id1, id2, sum(v1) AS v1 FROM tbl GROUP BY id1, id2&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Sum over medium cardinality groups, grouped by varchars&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;groupby #3&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id3, sum(v1) AS v1, mean(v3) AS v3 FROM tbl GROUP BY id3&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Sum and mean over many small cardinality groups, grouped by varchar&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;groupby #4&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id4, mean(v1) AS v1, mean(v2) AS v2, mean(v3) AS v3 FROM tbl GROUP BY id4&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Mean over many large cardinality groups, grouped by integer&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;groupby #5&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id6, sum(v1) AS v1, sum(v2) AS v2, sum(v3) AS v3 FROM tbl GROUP BY id6&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Sum over many small groups, grouped by integer&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;advanced groupby #1&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id4, id5, quantile_cont(v3, 0.5) AS median_v3, stddev(v3) AS sd_v3 FROM tbl GROUP BY id4, id5&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile_cont&lt;/code&gt; over medium cardinality group, grouped by integers&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;advanced groupby #2&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id3, max(v1)-min(v2) AS range_v1_v2 FROM tbl GROUP BY id3&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Range selection over small cardinality groups, grouped by integer&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;advanced groupby #3&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id6, v3 AS largest2_v3 FROM (SELECT id6, v3, row_number() OVER (PARTITION BY id6 ORDER BY v3 DESC) AS order_v3 FROM x WHERE v3 IS NOT NULL) sub_query WHERE order_v3 &amp;lt;= 2&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Advanced group by query&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;advanced groupby #4&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id2, id4, pow(corr(v1, v2), 2) AS r2 FROM tbl GROUP BY id2, id4&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Arithmetic over medium sized groups, grouped by varchar, integer.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;advanced groupby #5&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT id1, id2, id3, id4, id5, id6, sum(v3) AS v3, count(*) AS count FROM tbl GROUP BY id1, id2, id3, id4, id5, id6&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Many small groups, the number of groups is the cardinality of the dataset&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;join #1&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT x.*, small.id4 AS small_id4, v2 FROM x JOIN small USING (id1)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Joining a large table (x) with a small-sized table on integer type&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;join #2&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT x.*, medium.id1 AS medium_id1, medium.id4 AS medium_id4, medium.id5 AS medium_id5, v2 FROM x JOIN medium USING (id2)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Joining a large table (x) with a medium-sized table on integer type&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;join #3&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT x.*, medium.id1 AS medium_id1, medium.id4 AS medium_id4, medium.id5 AS medium_id5, v2 FROM x LEFT JOIN medium USING (id2)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Left join a large table (x) with a medium-sized table on integer type&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;join #4&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT x.*, medium.id1 AS medium_id1, medium.id2 AS medium_id2, medium.id4 AS medium_id4, v2 FROM x JOIN medium USING (id5)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Join a large table (x) with a medium table on varchar type&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;join #5&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT x.*, big.id1 AS big_id1, big.id2 AS big_id2, big.id4 AS big_id4, big.id5 AS big_id5, big.id6 AS big_id6, v2 FROM x JOIN big USING (id3)&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Join a large table (x) with a large table on integer type.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You can find more information about the queries in the &lt;a href=&quot;https://jangorecki.gitlab.io/r-talks/2019-12-26_Mumbai_Efficiency-in-data-processing/Efficiency-in-data-processing.pdf&quot;&gt;Efficiency of Data Processing&lt;/a&gt; slides.&lt;/p&gt;
      &lt;h3 id=&quot;modifications-to-the-benchmark--hardware&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/14/h2oai.html#modifications-to-the-benchmark--hardware&quot;&gt;Modifications to the Benchmark &amp;amp; Hardware&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;No modifications have been made to the queries or the data generation. Some scripts required minor modifications so that the current version of the library could be run. The hardware used is slightly different as the exact AWS offering the benchmark previously used is no longer available. Base libraries have been updated as well. GPU libraries were not tested.&lt;/p&gt;

&lt;p&gt;AWS is a &lt;a href=&quot;https://aws.amazon.com/ec2/instance-types/&quot;&gt;m4.10xlarge&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU model: Intel(R) Xeon(R) CPU E5-2676 v3 @ 2.40 GHz&lt;/li&gt;
  &lt;li&gt;CPU cores: 40&lt;/li&gt;
  &lt;li&gt;RAM model: Unknown&lt;/li&gt;
  &lt;li&gt;Memory: 160 GB&lt;/li&gt;
  &lt;li&gt;NO GPU specifications&lt;/li&gt;
  &lt;li&gt;R upgraded, 4.0.0 -&amp;gt; 4.2.2&lt;/li&gt;
  &lt;li&gt;Python upgraded 3.[6|7] -&amp;gt; 3.10&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;changes-made-to-install-scripts-of-other-systems&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/14/h2oai.html#changes-made-to-install-scripts-of-other-systems&quot;&gt;Changes Made to Install Scripts of Other Systems&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Pandas, Polars, Dask, and ClickHouse required changes to their setup/install scripts. The changes were relatively minor consisting mostly of syntax updates and data ingestion updates. Data ingestion did not affect the reporting timing results.&lt;/p&gt;
      &lt;h2 id=&quot;results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/14/h2oai.html#results&quot;&gt;Results&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;div style=&quot;position:relative; padding-bottom:10%; width: 100%; height:600px&quot;&gt;
    &lt;iframe src=&quot;https://duckdblabs.github.io/db-benchmark/&quot; title=&quot;h2o db benchmmark&quot; style=&quot;width: 100%; height:100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;You can also look at the results &lt;a href=&quot;https://duckdblabs.github.io/db-benchmark/&quot;&gt;here&lt;/a&gt;. DuckDB&#39;s timings have improved significantly since v0.2.7 (released over two years ago). A major contributor to our increased performance is &lt;a href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html&quot;&gt;parallel grouped aggregation&lt;/a&gt;, merged in March 2022, and &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/3700&quot;&gt;parallel result set materialization&lt;/a&gt;. In addition, DuckDB now supports &lt;a href=&quot;https://duckdb.org/2021/11/26/duck-enum.html&quot;&gt;enum types&lt;/a&gt;, which makes DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;group by&lt;/code&gt; aggregation even faster. &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4970&quot;&gt;Improvements to the out-of-core hash join&lt;/a&gt; were merged as well, further improving the performance of our joins.&lt;/p&gt;
      &lt;h2 id=&quot;questions-about-certain-results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/14/h2oai.html#questions-about-certain-results&quot;&gt;Questions about Certain Results?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Some solutions may report internal errors for some queries. Feel free to investigate the errors by using the &lt;a href=&quot;https://github.com/duckdblabs/db-benchmark/blob/main/_setup_utils/repro.sh&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;repro.sh&lt;/code&gt; scripts&lt;/a&gt; and file a GitHub issue to resolve any confusion. In addition, there are many areas in the code where certain query results are automatically nullified. If you believe that is the case for a query for your system or if you have any other questions, you can create a GitHub issue to discuss.&lt;/p&gt;
      &lt;h2 id=&quot;maintenance-plan&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/04/14/h2oai.html#maintenance-plan&quot;&gt;Maintenance Plan&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB will continue to maintain this benchmark for the forseeable future. The process for re-running the benchmarks with updated library versions must still be decided.&lt;/p&gt;

&lt;p&gt;Do you have any other questions? Would you like to have your system added to the benchmark? Please feel free to read the README in the &lt;a href=&quot;https://github.com/duckdblabs/db-benchmark&quot;&gt;repository&lt;/a&gt;, and if you still have questions, you can reach out to me at &lt;a href=&quot;https://duckdb.org/cdn-cgi/l/email-protection#cdb9a2a08da9b8aea6a9afa1acafbee3aea2a0&quot;&gt;&lt;span class=&quot;__cf_email__&quot; data-cfemail=&quot;d5a1bab895b1a0b6beb1b7b9b4b7a6fbb6bab8&quot;&gt;[email&amp;nbsp;protected]&lt;/span&gt;&lt;/a&gt; or on our &lt;a href=&quot;https://discord.com/invite/tcvwpjfnZx&quot;&gt;Discord&lt;/a&gt;!&lt;/p&gt;

</description><link>https://duckdb.org/2023/04/14/h2oai.html</link><guid isPermaLink="false">https://duckdb.org/2023/04/14/h2oai.html</guid><pubDate>Fri, 14 Apr 2023 00:00:00 GMT</pubDate><author>Tom Ebergen</author></item><item><title>Shredding Deeply Nested JSON, One Vector at a Time</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: We recently improved DuckDB&#39;s JSON extension so JSON files can be directly queried as if they were tables.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
  &lt;p&gt;We updated this blog post in December 2024 to reflect the changes in DuckDB&#39;s JSON syntax.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/jason-duck.jpg&quot; alt=&quot;JSON is not scary anymore! Jason IS scary though, even as a duck.&quot; width=&quot;180&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;DuckDB has a &lt;a href=&quot;https://duckdb.org/docs/stable/data/json/overview.html&quot;&gt;JSON extension&lt;/a&gt; that can be installed and loaded through SQL:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The JSON extension supports various functions to create, read, and manipulate JSON strings.
These functions are similar to the JSON functionality provided by other databases such as &lt;a href=&quot;https://www.postgresql.org/docs/current/functions-json.html&quot;&gt;PostgreSQL&lt;/a&gt; and &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/json.html&quot;&gt;MySQL&lt;/a&gt;.
DuckDB uses &lt;a href=&quot;https://github.com/ibireme/yyjson&quot;&gt;yyjson&lt;/a&gt; internally to parse JSON, a high-performance JSON library written in ANSI C. Many thanks to the yyjson authors and contributors!&lt;/p&gt;

&lt;p&gt;Besides these functions, DuckDB is now able to read JSON directly!
This is done by automatically detecting the types and column names, then converting the values within the JSON to DuckDB&#39;s vectors.
The automated schema detection dramatically simplifies working with JSON data and subsequent queries on DuckDB&#39;s vectors are significantly faster!&lt;/p&gt;
      &lt;h2 id=&quot;reading-json-automatically-with-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#reading-json-automatically-with-duckdb&quot;&gt;Reading JSON Automatically with DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Since &lt;a href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html&quot;&gt;version 0.7.0&lt;/a&gt;, DuckDB supports JSON table functions.
To demonstrate these, we will read &lt;a href=&quot;https://duckdb.org/data/json/todos.json&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;todos.json&lt;/code&gt;&lt;/a&gt;, a &lt;a href=&quot;https://jsonplaceholder.typicode.com/todos&quot;&gt;fake TODO list&lt;/a&gt; containing 200 fake TODO items (only the first two items are shown):&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;delectus aut autem&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;completed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;quis ut nam facilis et officia qui&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;completed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Each TODO item is an entry in the JSON array, but in DuckDB, we&#39;d like a table where each entry is a row.
This is as easy as:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;todos.json&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;userId&lt;/th&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;completed&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;delectus aut autem&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;quis ut nam facilis et officia qui&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;fugiat veniam minus&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;et porro tempora&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;laboriosam mollitia et enim quasi adipisci quia provident illum&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Finding out which user completed the most TODO items is as simple as:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;completed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_completed&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;todos.json&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;userId&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_completed&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;userId&lt;/th&gt;
      &lt;th&gt;total_completed&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Under the hood, DuckDB recognizes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.json&lt;/code&gt; file extension in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;todos.json&#39;&lt;/code&gt;, and calls &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json(&#39;todos.json&#39;)&lt;/code&gt; instead.
This function is similar to our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt; function, which &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/auto_detection.html&quot;&gt;automatically infers column names and types for CSV files&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Like our other table functions, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt; supports reading multiple files by passing a list, e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json([&#39;file1.json&#39;, &#39;file2.json&#39;])&lt;/code&gt;, but also globbing, e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json(&#39;file*.json&#39;)&lt;/code&gt;.
DuckDB will read multiple files in parallel.&lt;/p&gt;
      &lt;h2 id=&quot;newline-delimited-json&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#newline-delimited-json&quot;&gt;Newline Delimited JSON&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Not all JSON adheres to the format used in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;todos.json&lt;/code&gt;, which is an array of &#39;records&#39;.
Newline-delimited JSON, or &lt;a href=&quot;https://github.com/ndjson/ndjson-spec&quot;&gt;NDJSON&lt;/a&gt;, stores each row on a new line.
DuckDB also supports reading (and writing!) this format.
First, let&#39;s write our TODO list as NDJSON:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;todos.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;todos2.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Again, DuckDB recognizes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.json&lt;/code&gt; suffix in the output file and automatically infers that we mean to use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(FORMAT json)&lt;/code&gt;.
The created file looks like this (only the first two records are shown):&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;delectus aut autem&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;completed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;userId&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;quis ut nam facilis et officia qui&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;completed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB can read this file in exactly the same way as the original one:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;todos2.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If your JSON file is newline-delimited, DuckDB can parallelize reading.
This can be specified by calling &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_ndjson&lt;/code&gt; or passing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;records = true&lt;/code&gt; parameter to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_ndjson&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;todos2.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;todos2.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can also set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;records = auto&lt;/code&gt; to auto-detect whether the JSON file is newline-delimited.&lt;/p&gt;
      &lt;h2 id=&quot;other-json-formats&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#other-json-formats&quot;&gt;Other JSON Formats&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt; function is used directly, the format of the JSON can be specified using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;format&lt;/code&gt; parameter.
This parameter defaults to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;auto&#39;&lt;/code&gt;, which tells DuckDB to infer what kind of JSON we are dealing with.
The first &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;format&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;array&#39;&lt;/code&gt;, while the second is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;nd&#39;&lt;/code&gt;.
This can be specified like so:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;todos.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;array&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;todos2.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;nd&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another supported format is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unstructured&lt;/code&gt;. With this format, records are not required to be a JSON object but can also be a JSON array, string, or anything supported in JSON.&lt;/p&gt;
      &lt;h2 id=&quot;manual-schemas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#manual-schemas&quot;&gt;Manual Schemas&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;What you may also have noticed is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;auto_detect&lt;/code&gt; parameter.
This parameter tells DuckDB to infer the schema, i.e., determine the names and types of the returned columns.
These can manually be specified like so:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;todos.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;INTEGER&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;INTEGER&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;VARCHAR&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;completed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BOOLEAN&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;array&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You don&#39;t have to specify all fields, just the ones you&#39;re interested in:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;todos.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;INTEGER&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;completed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BOOLEAN&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;array&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now that we know how to use the new DuckDB JSON table functions let&#39;s dive into some analytics!&lt;/p&gt;
      &lt;h2 id=&quot;github-archive-examples&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#github-archive-examples&quot;&gt;GitHub Archive Examples&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;a href=&quot;https://www.gharchive.org/&quot;&gt;GH Archive&lt;/a&gt; is a project to record the public GitHub timeline, archive it, and make it easily accessible for further analysis.
Every hour, a GZIP compressed, newline-delimited JSON file containing all public events on GitHub is uploaded.
I downloaded a whole day (2023-02-08) of activity using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wget&lt;/code&gt; and stored the 24 files (starting with &lt;a href=&quot;https://data.gharchive.org/2023-02-08-0.json.gz&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2023-02-08-0.json.gz&lt;/code&gt;&lt;/a&gt;) in a directory called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gharchive_gz&lt;/code&gt;.
You can get the full day&#39;s archive as &lt;a href=&quot;https://blobs.duckdb.org/data/gharchive-2023-02-08.zip&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gharchive-2023-02-08.zip&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;Keep in mind that the data is compressed:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;du&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-sh&lt;/span&gt; gharchive_gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2.3G  gharchive_gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Decompressed, one day&#39;s worth of GitHub activity amounts to more than 18 GB of JSON.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;gunzip&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-dc&lt;/span&gt; gharchive_gz/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;wc&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;18396198934
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To get a feel of what the data looks like, we run the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;json_group_structure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_ndjson_objects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;gharchive_gz/*.json.gz&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here, we use our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_ndjson_objects&lt;/code&gt; function, which reads the JSON objects in the file as raw JSON, i.e., as strings.
The query reads the first 2048 records of JSON from the JSON files &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gharchive_gz&lt;/code&gt; directory and describes the structure.
You can also directly query the JSON files from GH Archive using DuckDB&#39;s &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;httpfs&lt;/code&gt; extension&lt;/a&gt;, but we will be querying the files multiple times, so it is better to download them in this case.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tip In the CLI client, you can use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.mode line&lt;/code&gt; to make the output easier to read.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I formatted the result using &lt;a href=&quot;https://jsonformatter.curiousconcept.com/&quot;&gt;an online JSON formatter &amp;amp; validator&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;actor&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;login&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;display_login&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;gravatar_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;avatar_url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;repo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;payload&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;public&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BOOLEAN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;created_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;org&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;login&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;gravatar_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;avatar_url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I left &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; out because it consists of deeply nested JSON, and its formatted structure takes up more than 1000 lines!&lt;/p&gt;

&lt;p&gt;So, how many records are we dealing with exactly? Let&#39;s count it using DuckDB:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;gharchive_gz/*.json.gz&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4434953&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;That&#39;s around 4.4M daily events, which amounts to almost 200K events per hour.
This query takes around 7.3 seconds on my laptop, a 2020 MacBook Pro with an M1 chip and 16 GB of memory.
This is the time it takes to decompress the GZIP compression and parse every JSON record.&lt;/p&gt;

&lt;p&gt;To see how much time is spent decompressing GZIP in the query, I also created a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gharchive&lt;/code&gt; directory containing the same data but uncompressed.
Running the same query on the uncompressed data takes around 5.4 seconds, almost 2 seconds faster.
We got faster, but we also read more than 18 GB of data from storage, as opposed to 2.3 GB when it was compressed.
So, this comparison really depends on the speed of your storage.
I prefer to keep the data compressed.&lt;/p&gt;

&lt;p&gt;As a side note, the speed of this query really shows how fast yyjson is!&lt;/p&gt;

&lt;p&gt;So, what kind of events are in the GitHub data?&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;gharchive_gz/*.json.gz&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;PushEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2359096&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CreateEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;624062&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PullRequestEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;366090&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IssueCommentEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;238660&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;WatchEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;231486&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DeleteEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;154383&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PullRequestReviewEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;131107&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IssuesEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;88917&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PullRequestReviewCommentEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;79540&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ForkEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64233&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CommitCommentEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;36823&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ReleaseEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MemberEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14872&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PublicEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GollumEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8180&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This query takes around 7.4 seconds, not much more than the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count(*)&lt;/code&gt; query.
So as we can see, data analysis is very fast once everything has been decompressed and parsed.&lt;/p&gt;

&lt;p&gt;The most common event type is the &lt;a href=&quot;https://docs.github.com/en/developers/webhooks-and-events/events/github-event-types#pushevent&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PushEvent&lt;/code&gt;&lt;/a&gt;, taking up more than half of all events, unsurprisingly, which is people pushing their committed code to GitHub.
The least common event type is the &lt;a href=&quot;https://docs.github.com/en/developers/webhooks-and-events/events/github-event-types#gollumevent&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GollumEvent&lt;/code&gt;&lt;/a&gt;, taking up less than 1% of all events, which is a creation or update of a wiki page.&lt;/p&gt;

&lt;p&gt;If we want to analyze the same data multiple times, decompressing and parsing every time is redundant and slows down the analysis.
Instead, we can create a DuckDB table like so:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;gharchive_gz/*.json.gz&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This takes around 9 seconds if you&#39;re using an in-memory database.
If you&#39;re using an on-disk database, this takes around 13 seconds and results in a database size of 444 MB.
When using an on-disk database, DuckDB ensures the table is persistent and performs &lt;a href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html&quot;&gt;all kinds of compression&lt;/a&gt;.
Note that we have temporarily ignored the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;payload&lt;/code&gt; field using the convenient &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; clause.&lt;/p&gt;

&lt;p&gt;To get a feel of what we&#39;ve read, we can ask DuckDB to describe the table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DESCRIBE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This gives us the following:&lt;/p&gt;

&lt;div class=&quot;monospace_table&quot;&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;cid&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;notnull&lt;/th&gt;
      &lt;th&gt;dflt_value&lt;/th&gt;
      &lt;th&gt;pk&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;id&lt;/td&gt;
      &lt;td&gt;BIGINT&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;type&lt;/td&gt;
      &lt;td&gt;VARCHAR&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;actor&lt;/td&gt;
      &lt;td&gt;STRUCT(id UBIGINT, login VARCHAR, display_login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;repo&lt;/td&gt;
      &lt;td&gt;STRUCT(id UBIGINT, name VARCHAR, url VARCHAR)&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;public&lt;/td&gt;
      &lt;td&gt;BOOLEAN&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;created_at&lt;/td&gt;
      &lt;td&gt;TIMESTAMP&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;org&lt;/td&gt;
      &lt;td&gt;STRUCT(id UBIGINT, login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As we can see, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;actor&quot;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;repo&quot;&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;org&quot;&lt;/code&gt; fields, which are JSON objects, have been converted to DuckDB structs.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;id&quot;&lt;/code&gt; column was a string in the original JSON but has been converted to a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt; by DuckDB&#39;s automatic type detection.
DuckDB can also detect a few different &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt; formats within JSON strings, as well as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UUID&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now that we created the table, we can analyze it like any other DuckDB table!
Let&#39;s see how much activity there was in the &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;duckdb/duckdb&lt;/code&gt; GitHub repository&lt;/a&gt; on this specific day:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;duckdb/duckdb&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;PullRequestEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;35&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IssueCommentEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;WatchEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PushEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PullRequestReviewEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IssuesEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PullRequestReviewCommentEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ForkEvent&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;That&#39;s a lot of pull request activity!
Note that this doesn&#39;t mean that 35 pull requests were opened on this day, activity within a pull request is also counted.
If we &lt;a href=&quot;https://github.com/duckdb/duckdb/pulls?q=is%3Apr+created%3A2023-02-08+&quot;&gt;search through the pull requests for that day&lt;/a&gt;, we see that there are only 15.
This is more activity than normal because most of the DuckDB developers were busy fixing bugs for the 0.7.0 release.&lt;/p&gt;

&lt;p&gt;Now, let&#39;s see who was the most active:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;login&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;duckdb/duckdb&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;PullRequestEvent&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;login&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;desc&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;login&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Mytherin&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mause&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;carlopi&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Tmonster&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lnkuiper&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As expected, Mark Raasveldt (Mytherin, co-founder of DuckDB Labs) was the most active!
My activity (lnkuiper, software engineer at DuckDB Labs) also shows up.&lt;/p&gt;
      &lt;h2 id=&quot;handling-inconsistent-json-schemas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#handling-inconsistent-json-schemas&quot;&gt;Handling Inconsistent JSON Schemas&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;So far, we have ignored the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; of the events.
We ignored it because the contents of this field are different based on the type of event.
We can see how they differ with the following query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;json_group_structure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;structure&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&#39;gharchive_gz/*.json.gz&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BIGINT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;VARCHAR&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT,
                          login VARCHAR,
                          display_login VARCHAR,
                          gravatar_id VARCHAR,
                          url VARCHAR,
                          avatar_url VARCHAR)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;repo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT, name VARCHAR, url VARCHAR)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;JSON&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BOOLEAN&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;created_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;TIMESTAMP&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT, login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)&#39;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;WatchEvent&#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;monospace_table&quot;&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;structure&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;{&quot;action&quot;:&quot;VARCHAR&quot;}&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; field is simple for events of type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WatchEvent&lt;/code&gt;.
However, if we change the type to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PullRequestEvent&lt;/code&gt;, we get a JSON structure of more than 500 lines when formatted with a JSON formatter.
We don&#39;t want to look through all those fields, so we cannot use our automatic schema detection, which will try to get them all.
Instead, we can manually supply the structure of the fields we&#39;re interested in.
DuckDB will skip reading the other fields.
Another approach is to store the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; field as DuckDB&#39;s JSON data type and parse it at query time (see the example later in this post!).&lt;/p&gt;

&lt;p&gt;I stripped down the JSON structure for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; of events with the type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PullRequestEvent&lt;/code&gt; to the things I&#39;m actually interested in:&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;action&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;number&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;pull_request&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;user&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;login&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;body&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;created_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;TIMESTAMP&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;updated_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;TIMESTAMP&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;assignee&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;login&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;assignees&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;login&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;VARCHAR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UBIGINT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is technically not valid JSON because there are trailing commas.
However, we try to &lt;a href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#trailing-commas&quot;&gt;allow trailing commas wherever possible&lt;/a&gt; in DuckDB, including JSON!&lt;/p&gt;

&lt;p&gt;We can now plug this into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;columns&lt;/code&gt; parameter of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt;, but we need to convert it to a DuckDB type first.
I&#39;m lazy, so I prefer to let DuckDB do this for me:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;typeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;json_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;{}&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;{
        &quot;action&quot;:&quot;VARCHAR&quot;,
        &quot;number&quot;:&quot;UBIGINT&quot;,
        &quot;pull_request&quot;:{
          &quot;url&quot;:&quot;VARCHAR&quot;,
          &quot;id&quot;:&quot;UBIGINT&quot;,
          &quot;title&quot;:&quot;VARCHAR&quot;,
          &quot;user&quot;:{
              &quot;login&quot;:&quot;VARCHAR&quot;,
              &quot;id&quot;:&quot;UBIGINT&quot;,
          },
          &quot;body&quot;:&quot;VARCHAR&quot;,
          &quot;created_at&quot;:&quot;TIMESTAMP&quot;,
          &quot;updated_at&quot;:&quot;TIMESTAMP&quot;,
          &quot;assignee&quot;:{
              &quot;login&quot;:&quot;VARCHAR&quot;,
              &quot;id&quot;:&quot;UBIGINT&quot;,
          },
          &quot;assignees&quot;:[
              {
                &quot;login&quot;:&quot;VARCHAR&quot;,
                &quot;id&quot;:&quot;UBIGINT&quot;,
              }
          ],
        }
    }&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This gives us back a DuckDB type that we can plug the type into our function!
Note that because we are not auto-detecting the schema, we have to supply &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timestampformat&lt;/code&gt; to be able to parse the timestamps correctly.
The key &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;user&quot;&lt;/code&gt; must be surrounded by quotes because it is a reserved keyword in SQL:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pr_events&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&#39;gharchive_gz/*.json.gz&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BIGINT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;VARCHAR&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT,
                          login VARCHAR,
                          display_login VARCHAR,
                          gravatar_id VARCHAR,
                          url VARCHAR,
                          avatar_url VARCHAR)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;repo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT, name VARCHAR, url VARCHAR)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(
                        action VARCHAR,
                        number UBIGINT,
                        pull_request STRUCT(
                          url VARCHAR,
                          id UBIGINT,
                          title VARCHAR,
                          &quot;user&quot; STRUCT(
                            login VARCHAR,
                            id UBIGINT
                          ),
                          body VARCHAR,
                          created_at TIMESTAMP,
                          updated_at TIMESTAMP,
                          assignee STRUCT(login VARCHAR, id UBIGINT),
                          assignees STRUCT(login VARCHAR, id UBIGINT)[]
                        )
                      )&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BOOLEAN&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;created_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;TIMESTAMP&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT, login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)&#39;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;newline_delimited&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;timestampformat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%Y-%m-%dT%H:%M:%SZ&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;PullRequestEvent&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query completes in around 36 seconds with an on-disk database (resulting size is 478 MB) and 9 seconds with an in-memory database.
If you don&#39;t care about preserving insertion order, you can speed the query up with this setting:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;preserve_insertion_order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With this setting, the query completes in around 27 seconds with an on-disk database and 8.5 seconds with an in-memory database.
The difference between the on-disk and in-memory case is quite substantial here because DuckDB has to compress and persist much more data.&lt;/p&gt;

&lt;p&gt;Now we can analyze pull request events! Let&#39;s see what the maximum number of assignees is:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pull_request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;assignees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_assignees&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pr_events&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;max_assignees&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;That&#39;s a lot of people reviewing a single pull request!&lt;/p&gt;

&lt;p&gt;We can check who was assigned the most:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignees&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pull_request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;assignee&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;login&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignee&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pr_events&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;unnest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pull_request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;assignees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;login&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignee&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pr_events&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignee&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignees&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignee&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignee&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;assignee&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;poad&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;494&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;vinayakkulkarni&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;268&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;tmtmtmtm&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;198&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fisker&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;98&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;icemac&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;84&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;That&#39;s a lot of assignments – although I suspect there are duplicates in here.&lt;/p&gt;
      &lt;h2 id=&quot;storing-as-json-to-parse-at-query-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#storing-as-json-to-parse-at-query-time&quot;&gt;Storing as JSON to Parse at Query Time&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Specifying the JSON schema of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; field was helpful because it allowed us to directly analyze what is there, and subsequent queries are much faster.
Still, it can also be quite cumbersome if the schema is complex.
If you don&#39;t want to specify the schema of a field, you can set the type as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;JSON&#39;&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pr_events&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&#39;gharchive_gz/*.json.gz&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BIGINT&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;VARCHAR&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT,
                          login VARCHAR,
                          display_login VARCHAR,
                          gravatar_id VARCHAR,
                          url VARCHAR,
                          avatar_url VARCHAR)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;repo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT, name VARCHAR, url VARCHAR)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;JSON&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;BOOLEAN&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;created_at&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;TIMESTAMP&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;STRUCT(id UBIGINT, login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)&#39;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;newline_delimited&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;timestampformat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;%Y-%m-%dT%H:%M:%SZ&#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;PullRequestEvent&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will load the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; field as a JSON string, and we can use DuckDB&#39;s JSON functions to analyze it when querying.
For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;payload&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;action&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pr_events&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-&amp;gt;&amp;gt;&lt;/code&gt; arrow is short-hand for our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json_extract_string&lt;/code&gt; function.
Creating the entire &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;payload&quot;&lt;/code&gt; field as a column with type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JSON&lt;/code&gt; is not the most efficient way to get just the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;action&quot;&lt;/code&gt; field, but this example is just to show the flexibility of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt;.
The query results in the following table:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;action&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;opened&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;189096&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;closed&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;174914&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;reopened&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2080&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As we can see, only a few pull requests have been reopened.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/03/03/json.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB tries to be an easy-to-use tool that can read all kinds of data formats.
In the 0.7.0 release, we have added support for reading JSON.
JSON comes in many formats and all kinds of schemas.
DuckDB&#39;s rich support for nested types (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt;) allows it to fully “shred” the JSON to a columnar format for more efficient analysis.&lt;/p&gt;

&lt;p&gt;We are excited to hear what you think about our new JSON functionality.
If you have any questions or suggestions, please reach out to us on &lt;a href=&quot;https://discord.com/invite/tcvwpjfnZx&quot;&gt;Discord&lt;/a&gt; or &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;GitHub&lt;/a&gt;!&lt;/p&gt;

</description><link>https://duckdb.org/2023/03/03/json.html</link><guid isPermaLink="false">https://duckdb.org/2023/03/03/json.html</guid><pubDate>Fri, 03 Mar 2023 00:00:00 GMT</pubDate><author>Laurens Kuiper</author></item><item><title>JupySQL Plotting with DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: &lt;a href=&quot;https://github.com/ploomber/jupysql&quot;&gt;JupySQL&lt;/a&gt; provides a seamless SQL experience in Jupyter and uses DuckDB to visualize larger than memory datasets in matplotlib.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/24/jupysql.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Data visualization is essential for every data practitioner since it allows us to find patterns that otherwise would be hard to see. The typical approach for plotting tabular datasets involves Pandas and Matplotlib. However, this technique quickly falls short as our data grows, given that Pandas introduces a significant memory overhead, making it challenging even to plot a medium-sized dataset.&lt;/p&gt;

&lt;p&gt;In this blog post, we&#39;ll use &lt;a href=&quot;https://github.com/ploomber/jupysql&quot;&gt;JupySQL&lt;/a&gt; and DuckDB to efficiently plot &lt;em&gt;larger-than-memory&lt;/em&gt; datasets in our laptops. JupySQL is a fork of ipython-sql, which adds SQL cells to Jupyter, that is being actively maintained and enhanced by the team at Ploomber.&lt;/p&gt;

&lt;p&gt;Combining JupySQL with DuckDB enables a powerful and user friendly local SQL processing experience, especially when combined with JupySQL&#39;s new plotting capabilities. There is no need to get beefy (and expensive!) EC2 machines or configure complex distributed frameworks! Get started with JupySQL and DuckDB with our &lt;a href=&quot;https://duckdb.org/docs/stable/guides/python/jupyter.html&quot;&gt;Jupyter Notebook guide&lt;/a&gt;, or go directly to an example &lt;a href=&quot;https://colab.research.google.com/drive/1eOA2FYHqEfZWLYssbUxdIpSL3PFxWVjk?usp=sharing&quot;&gt;collab notebook&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;We want JupySQL to offer the best SQL experience in Jupyter, so if you have any feedback, please open an issue on &lt;a href=&quot;https://github.com/ploomber/jupysql/issues/new&quot;&gt;GitHub!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
      &lt;h2 id=&quot;the-problem&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/24/jupysql.html#the-problem&quot;&gt;The Problem&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;One significant limitation when using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt; for data visualization is that we need to load all our data into memory, making it difficult to plot &lt;em&gt;larger-than-memory&lt;/em&gt; datasets. Furthermore, given the overhead that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt; introduces, we might be unable to visualize some smaller datasets that we might think &quot;fit&quot; into memory.&lt;/p&gt;

&lt;p&gt;Let&#39;s load a sample &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.parquet&lt;/code&gt; dataset using pandas to show the memory overhead:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib.request&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urlretrieve&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urlretrieve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                &lt;span class=&quot;s&quot;&gt;&quot;yellow_tripdata_2022-01.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The downloaded &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.parquet&lt;/code&gt; file takes 36 MB of disk space:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;-rw-r--r--  1 eduardo  staff    36M Jan 18 14:45 yellow_tripdata_2022-01.parquet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;Now let&#39;s load the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.parquet&lt;/code&gt; as a data frame and see how much memory it takes:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;yellow_tripdata_2022-01.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df_mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory_usage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Data frame takes &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_mb&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; MB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Data frame takes 357 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;As you can see, we&#39;re using almost 10× as much memory as the file size. Given this overhead, we must be much more conservative about what &lt;em&gt;larger-than-memory&lt;/em&gt; means, as &quot;medium&quot; files might not fit into memory once loaded. But this is just the beginning of our memory problems.&lt;/p&gt;

&lt;p&gt;When plotting data, we often need to preprocess it before it&#39;s suitable for visualization. However, if we&#39;re not careful, these preprocessing steps will copy our data, dramatically increasing memory. Let&#39;s show a practical example.&lt;/p&gt;

&lt;p&gt;Our sample dataset contains an observation for each NYC yellow cab trip in January 2022. Let&#39;s create a boxplot for the trip&#39;s distance:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Trip distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/jupysql/serialized/8-0.png&quot; alt=&quot;8-0&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;!-- #endregion --&gt;&lt;/p&gt;

&lt;p&gt;Wow! It looks like some new yorkers really like taxi rides! Let&#39;s put the taxi fans aside to improve the visualization and compute the 99th percentile to use it as the cutoff value:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cutoff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.99&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cutoff&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;19.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;Now, we need to filter out observations larger than the cutoff value; but before we do it, let&#39;s create a utility function to capture memory usage:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;psutil&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;memory_used&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Returns memory used in MB&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;psutil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory_full_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Memory used: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; MB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;memory_used&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Memory used: 941 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;Let&#39;s now filter out the observations:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cutoff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Plot the histogram:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Trip distance (top 1% observations removed)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/jupysql/serialized/16-0.png&quot; alt=&quot;16-0&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;!-- #endregion --&gt;&lt;/p&gt;

&lt;p&gt;We now see more reasonable numbers with the top 1% outliers removed. There are a few trips over 10 miles (perhaps some uptown new yorkers going to Brooklyn for some &lt;a href=&quot;https://en.wikipedia.org/wiki/Juliana%27s_Pizza&quot;&gt;delicious pizza?&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;How much memory are we using now?&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;memory_used&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Memory used: 1321 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;380 MB more! Loading a 36 MB Parquet file turned into &amp;gt;700 MB in memory after loading and applying one preprocessing step!&lt;/p&gt;

&lt;p&gt;So, in reality, when we use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt;, what fits in memory is much smaller than we think, and even with a laptop equipped with 16 GB of RAM, we&#39;ll be extremely limited in terms of what size of a dataset we process. Of course, we could save a lot of memory by exclusively loading the column we plotted and deleting unneeded data copies; however, let&#39;s face it, &lt;em&gt;this never happens in practice&lt;/em&gt;. When exploring data, we rarely know ahead of time which columns we&#39;ll need; furthermore, our time is better spent analyzing and visualizing the data than manually deleting data copies.&lt;/p&gt;

&lt;p&gt;When facing this challenge, we might consider using a distributed framework; however, this adds so much complexity to the process, and it only partially solves the problem since we&#39;d need to write code to compute the statistics in a distributed fashion. Alternatively, we might consider getting a larger machine, a relatively straightforward (but expensive!) approach if we can access cloud resources. However, this still requires us to move our data, set up a new environment, etc. Fortunately for us, there&#39;s DuckDB!&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-a-highly-scalable-backend-for-statistical-visualizations&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/24/jupysql.html#duckdb-a-highly-scalable-backend-for-statistical-visualizations&quot;&gt;DuckDB: A Highly Scalable Backend for Statistical Visualizations&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When using functions such as &lt;a href=&quot;https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hist&lt;/code&gt;&lt;/a&gt; (histogram) or &lt;a href=&quot;https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boxplot&lt;/code&gt;&lt;/a&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt; performs two steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute summary statistics&lt;/li&gt;
  &lt;li&gt;Plot data&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boxplot&lt;/code&gt; calls another function called &lt;a href=&quot;https://matplotlib.org/stable/api/cbook_api.html#matplotlib.cbook.boxplot_stats&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boxplot_stats&lt;/code&gt;&lt;/a&gt; that returns the statistics required to draw the plot. To create a boxplot, we need several summary statistics, such as the 25th percentile, 50th percentile, and 75th percentile. The following diagram shows a boxplot along with the labels for each part:&lt;/p&gt;

&lt;!-- ![boxplot-labels](/images/blog/jupysql/boxplot-labels.png | width=550) --&gt;
&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/jupysql/boxplot-labels.png&quot; width=&quot;550&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The bottleneck in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt; + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt; approach is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boxplot_stats&lt;/code&gt; function since it requires a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;numpy.array&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas.Series&lt;/code&gt; as an input, forcing us to load all our data into memory. However, we can implement a new version of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boxplot_stats&lt;/code&gt; that pushes the data aggregation step to another analytical engine.&lt;/p&gt;

&lt;p&gt;We chose DuckDB because it&#39;s extremely powerful and easy to use. There is no need to spin up a server or manage complex configurations: install it with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install&lt;/code&gt;, point it to your data files, and that&#39;s it; you can start aggregating millions and millions of data points in no time!&lt;/p&gt;

&lt;p&gt;You can see the full &lt;a href=&quot;https://github.com/ploomber/jupysql/blob/6c081823e0d5f9e55a07ec617f5b6188af7a1e58/src/sql/plot.py#L125&quot;&gt;implementation here&lt;/a&gt;; essentially, we translated matplotlib&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boxplot_stats&lt;/code&gt; from Python into SQL. For example, the following query will compute the three percentiles we need: 25th, 50th (median), and 75th:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_ext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- We calculate the percentiles all at once and &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- then convert from list format into separate columns&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- (Improving performance by reducing duplicate work)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;percentile_disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITHIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; 
      &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;trip_distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percentiles&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;yellow_tripdata_2022-01.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;percentiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;percentiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;median&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;percentiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;
        &lt;th&gt;q1&lt;/th&gt;
        &lt;th&gt;median&lt;/th&gt;
        &lt;th&gt;q3&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;1.04&lt;/td&gt;
        &lt;td&gt;1.74&lt;/td&gt;
        &lt;td&gt;3.13&lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;!-- #endregion --&gt;

&lt;p&gt;Once we compute all the statistics, we call the &lt;a href=&quot;https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.bxp.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bxp&lt;/code&gt;&lt;/a&gt; function, which draws the boxplot from the input statistics.&lt;/p&gt;

&lt;p&gt;This process is already implemented in JupySQL, and you can create a boxplot with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%sqlplot boxplot&lt;/code&gt; command. Let&#39;s see how. But first, let&#39;s check how much memory we&#39;re using, so we can compare it to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt; version:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;memory_used&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;!-- #region --&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Memory used: 1351 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;Let&#39;s create the boxplot:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlplot&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxplot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yellow_tripdata_2022&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;01.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/jupysql/serialized/26-1.png&quot; alt=&quot;26-1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;!-- #endregion --&gt;&lt;/p&gt;

&lt;p&gt;Again, we see all these outliers. Let&#39;s compute the cutoff value:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;percentile_disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.99&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITHIN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;yellow_tripdata_2022-01.parquet&#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;table&gt;
    &lt;tbody&gt;&lt;tr&gt;
        &lt;th&gt;quantile_disc(0.99 ORDER BY trip_distance)&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;19.7&lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;!-- #endregion --&gt;

&lt;p&gt;Let&#39;s define a query that filters out the top 1% of observations. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--save&lt;/code&gt; option allows us to store this SQL expression and we choose not to execute it.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;--save no-outliers --no-execute&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;yellow_tripdata_2022-01.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;19.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;We can now use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;no-outliers&lt;/code&gt; in our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%sqlplot boxplot&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlplot&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxplot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outliers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outliers&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/jupysql/serialized/32-1.png&quot; alt=&quot;32-1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;!-- #endregion --&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;memory_used&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Memory used: 1375 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #endregion --&gt;

&lt;p&gt;Memory usage remained pretty much the same (23 MB difference, mostly due to the newly imported modules). Since we&#39;re relying on DuckDB for the data aggregation step, the SQL engine takes care of loading, aggregating, and freeing up memory as soon as we&#39;re done; this is much more efficient than loading all our data at the same time and keeping unwanted data copies!&lt;/p&gt;

&lt;!-- #region --&gt;
      &lt;h2 id=&quot;using-duckdb-to-compute-histogram-statistics&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/24/jupysql.html#using-duckdb-to-compute-histogram-statistics&quot;&gt;Using DuckDB to Compute Histogram Statistics&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We can extend our recipe to other statistical visualizations, such as histograms.&lt;/p&gt;

&lt;p&gt;A histogram allows us to visualize the distribution of a dataset, enabling us to find patterns such as modality, outliers, range of values, etc. Like with the boxplot, when using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt; + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt;, creating a histogram involves loading all our data at once into memory; then, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt; aggregates and plots it.&lt;/p&gt;

&lt;p&gt;In our case, we&#39;ll push the aggregation to DuckDB, which will compute the bin positions (X-axis) and heights (Y-axis), then we&#39;ll pass this to maptlotlib&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bar&lt;/code&gt; function to create the histogram.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/ploomber/jupysql/blob/6c081823e0d5f9e55a07ec617f5b6188af7a1e58/src/sql/plot.py#L283&quot;&gt;implementation&lt;/a&gt;  involves two steps.&lt;/p&gt;

&lt;p&gt;First, given the number of bins chosen by the user (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N_BINS&lt;/code&gt;), we compute the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIN_SIZE&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N_BINS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;yellow_tripdata_2022-01.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIN_SIZE&lt;/code&gt;, we find the number of observations that fall into each bin:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;trip_distance&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIN_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIN_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;yellow_tripdata_2022-01.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;!-- #endregion --&gt;

&lt;p&gt;The intuition for the second query is as follows: given that we have &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N_BINS&lt;/code&gt;, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;floor(&quot;trip_distance&quot; / BIN_SIZE)&lt;/code&gt; portion will assign each observation to their corresponding bin (1, 2, …, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N_BINS&lt;/code&gt;), then, we multiply by the bin size to get the value in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X&lt;/code&gt; axis, while the count represents the value in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Y&lt;/code&gt; axis. Once we have that, we call the &lt;a href=&quot;https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bar&lt;/code&gt;&lt;/a&gt; plotting function.&lt;/p&gt;

&lt;p&gt;All these steps are implemented in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%sqplot histogram&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlplot&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;histogram&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outliers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outliers&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/jupysql/serialized/37-1.png&quot; alt=&quot;37-1&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;!-- #endregion --&gt;&lt;/p&gt;
      &lt;h2 id=&quot;final-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/24/jupysql.html#final-thoughts&quot;&gt;Final Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;This blog post demonstrated a powerful approach for plotting large datasets powered using JupySQL and DuckDB. If you need to visualize large datasets, DuckDB offers unmatched simplicity and flexibility!&lt;/p&gt;

&lt;p&gt;At &lt;a href=&quot;https://ploomber.io/&quot;&gt;Ploomber&lt;/a&gt;, we&#39;re working on building a full-fledged SQL client for Jupyter! Exciting features like automated dataset profiling, autocompletion, and more are coming! So &lt;a href=&quot;https://twitter.com/ploomber&quot;&gt;keep an eye&lt;/a&gt; on &lt;a href=&quot;https://www.linkedin.com/company/ploomber&quot;&gt;updates!&lt;/a&gt; If there are features you think we should add to offer the best SQL experience in Jupyter, please &lt;a href=&quot;https://github.com/ploomber/jupysql/issues/new&quot;&gt;open an issue!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;JupySQL is an actively maintained fork of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ipython-sql&lt;/code&gt;, and it keeps full compatibility with it. If you want to learn more, check out the &lt;a href=&quot;https://github.com/ploomber/jupysql&quot;&gt;GitHub repository&lt;/a&gt; and the &lt;a href=&quot;https://jupysql.readthedocs.io/en/latest&quot;&gt;documentation.&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;try-it-out&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/24/jupysql.html#try-it-out&quot;&gt;Try It Out&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To try it yourself, check out this &lt;a href=&quot;https://colab.research.google.com/drive/1FpNKAZ_fCNtjStd2aA15aaBZYRELa9Wp?usp=sharing&quot;&gt;collab notebook&lt;/a&gt;, or here&#39;s a snippet you can paste into Jupyter:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib.request&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;urlretrieve&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;urlretrieve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;s&quot;&gt;&quot;yellow_tripdata_2022-01.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jupysql&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quiet&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_ext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlplot&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxplot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yellow_tripdata_2022&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;01.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parquet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- #region --&gt;

&lt;p&gt;Note: the commands that begin with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%%&lt;/code&gt; will only work on Jupyter/IPython. If you want to try this in a regular Python session, check out the &lt;a href=&quot;https://jupysql.readthedocs.io/en/latest/api/python.html#sql-plot&quot;&gt;Python API&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2023/02/24/jupysql.html</link><guid isPermaLink="false">https://duckdb.org/2023/02/24/jupysql.html</guid><pubDate>Fri, 24 Feb 2023 00:00:00 GMT</pubDate><author>Guest post by Eduardo Blancas</author></item><item><title>Announcing DuckDB 0.7.0</title><description>&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/labrador_duck.png&quot; alt=&quot;Image of the labrador duck&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The DuckDB team is happy to announce the latest DuckDB version (0.7.0) has been released. This release of DuckDB is named &quot;Labradorius&quot; after the &lt;a href=&quot;https://en.wikipedia.org/wiki/Labrador_duck&quot;&gt;Labrador Duck (Camptorhynchus labradorius)&lt;/a&gt; that was native to North America.&lt;/p&gt;

&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;. The full release notes can be found &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.7.0&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;whats-in-070&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html#whats-in-070&quot;&gt;What&#39;s in 0.7.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The new release contains many improvements to the JSON support, new SQL features, improvements to data ingestion and export, and other new features. Below is a summary of the most impactful changes, together with the linked PRs that implement the features.&lt;/p&gt;
      &lt;h2 id=&quot;data-ingestionexport-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html#data-ingestionexport-improvements&quot;&gt;Data Ingestion/Export Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;JSON Ingestion.&lt;/strong&gt; This version introduces the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5992&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json_auto&lt;/code&gt;&lt;/a&gt; methods. These can be used to ingest JSON files into a tabular format. Similar to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_csv&lt;/code&gt;, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json&lt;/code&gt; method requires a schema to be specified, while the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_json_auto&lt;/code&gt; automatically infers the schema of the JSON from the file using sampling. Both &lt;a href=&quot;https://github.com/ndjson/ndjson-spec&quot;&gt;new-line delimited JSON&lt;/a&gt; and regular JSON are supported.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;data/json/with_list.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;[O, Brother,, Where, Art, Thou?]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;[Home, for, the, Holidays]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;[The, Firm]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;[Broadcast, News]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;[Raising, Arizona]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Partitioned Parquet/CSV Export.&lt;/strong&gt; DuckDB has been able to ingest &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/httpfs/overview.html#hive-partitioning&quot;&gt;Hive-partitioned Parquet and CSV files&lt;/a&gt; for a while. After this release &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5964&quot;&gt;DuckDB will also be able to &lt;em&gt;write&lt;/em&gt; Hive-partitioned data&lt;/a&gt; using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PARTITION_BY&lt;/code&gt; clause. These files can be exported locally or remotely to S3 compatible storage. Here is a local example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;orders&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PARTITION_BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will cause the Parquet files to be written in the following directory structure:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;orders
├── year=2021
│    ├── month=1
│    │   ├── file1.parquet
│    │   └── file2.parquet
│    └── month=2
│        └── file3.parquet
└── year=2022
     ├── month=11
     │   ├── file4.parquet
     │   └── file5.parquet
     └── month=12
         └── file6.parquet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Parallel Parquet/CSV Writing.&lt;/strong&gt; Parquet and CSV writing are sped up tremendously this release with the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5756&quot;&gt;parallel Parquet and CSV writer support&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Format&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Old&lt;/th&gt;
      &lt;th&gt;New (8T)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CSV&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.6s&lt;/td&gt;
      &lt;td&gt;0.4s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parquet&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.5s&lt;/td&gt;
      &lt;td&gt;1.3s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Note that currently the parallel writing is currently limited to non-insertion order preserving – which can be toggled by setting the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;preserve_insertion_order&lt;/code&gt; setting to false. In a future release we aim to alleviate this restriction and order parallel insertion order preserving writes as well.&lt;/p&gt;
      &lt;h2 id=&quot;multi-database-support&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html#multi-database-support&quot;&gt;Multi-Database Support&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;Attach Functionality.&lt;/strong&gt; This release adds support for &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5764&quot;&gt;attaching multiple databases&lt;/a&gt; to the same DuckDB instance. This easily allows data to be transferred between separate DuckDB database files, and also allows data from separate database files to be combined together in individual queries. Remote DuckDB instances (stored on a network accessible location like GitHub, for example) may also be attached.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;new_db.db&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DETACH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/attach.html&quot;&gt;documentation for more information&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SQLite Storage Back-End.&lt;/strong&gt; In addition to adding support for attaching DuckDB databases – this release also adds support for &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/6066&quot;&gt;&lt;em&gt;pluggable database engines&lt;/em&gt;&lt;/a&gt;. This allows extensions to define their own database and catalog engines that can be attached to the system. Once attached, an engine can support both reads and writes. The &lt;a href=&quot;https://github.com/duckdb/duckdb-sqlite&quot;&gt;SQLite extension&lt;/a&gt; makes use of this to add native read/write support for SQLite database files to DuckDB.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ATTACH&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;sqlite_file.db&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sqlite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Using this, SQLite database files can be attached, queried and modified as if they are native DuckDB database files. This allows data to be quickly transferred between SQLite and DuckDB – and allows you to use DuckDB&#39;s rich SQL dialect to query data stored in SQLite tables.&lt;/p&gt;
      &lt;h2 id=&quot;new-sql-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html#new-sql-features&quot;&gt;New SQL Features&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;Upsert Support.&lt;/strong&gt; &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5866&quot;&gt;Upsert support&lt;/a&gt; is added with this release using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ON CONFLICT&lt;/code&gt; clause, as well as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SQLite&lt;/code&gt; compatible &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT OR REPLACE&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT OR IGNORE&lt;/code&gt; syntax.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;A New Hope&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;A New Hope&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;The Phantom Menace&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;The Phantom Menace&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;See the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/insert.html#on-conflict-clause&quot;&gt;documentation for more information&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lateral Joins.&lt;/strong&gt; Support for &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5393&quot;&gt;lateral joins&lt;/a&gt; is added in this release. Lateral joins are a more flexible variant of correlated subqueries that make working with nested data easier, as they allow &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5485&quot;&gt;easier unnesting&lt;/a&gt; of nested data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Positional Joins.&lt;/strong&gt; While SQL formally models unordered sets, in practice the order of datasets does frequently have a meaning. DuckDB offers guarantees around maintaining the order of rows when loading data into tables or when exporting data back out to a file – as well as when executing queries such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt; without a corresponding &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause.&lt;/p&gt;

&lt;p&gt;To improve support for this use case – this release &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5867&quot;&gt;introduces the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSITIONAL JOIN&lt;/code&gt;&lt;/a&gt;. Rather than joining on the values of rows – this new join type joins rows based on their position in the table.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;POSITIONAL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;i&lt;/th&gt;
      &lt;th&gt;k&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;python-api-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html#python-api-improvements&quot;&gt;Python API Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;Query Building.&lt;/strong&gt; This release introduces easier incremental query building using the Python API by allowing relations to be queried. This allows you to decompose long SQL queries into multiple smaller SQL queries, and allows you to easily inspect query intermediates.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;FROM lineitem.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────┬───────────┬───────────┬───┬───────────────────┬────────────┬──────────────────────┐
│ l_orderkey │ l_partkey │ l_suppkey │ … │  l_shipinstruct   │ l_shipmode │      l_comment       │
│   int32    │   int32   │   int32   │   │      varchar      │  varchar   │       varchar        │
├────────────┼───────────┼───────────┼───┼───────────────────┼────────────┼──────────────────────┤
│          1 │    155190 │      7706 │ … │ DELIVER IN PERSON │ TRUCK      │ egular courts abov…  │
│          1 │     67310 │      7311 │ … │ TAKE BACK RETURN  │ MAIL       │ ly final dependenc…  │
│          1 │     63700 │      3701 │ … │ TAKE BACK RETURN  │ REG AIR    │ riously. regular, …  │
├────────────┴───────────┴───────────┴───┴───────────────────┴────────────┴──────────────────────┤
│ 3 rows                                                                    16 columns (6 shown) │
└────────────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;FROM lineitem WHERE l_orderkey&amp;gt;5000&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_filtered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────┬───────────┬───────────┬───┬────────────────┬────────────┬──────────────────────┐
│ l_orderkey │ l_partkey │ l_suppkey │ … │ l_shipinstruct │ l_shipmode │      l_comment       │
│   int32    │   int32   │   int32   │   │    varchar     │  varchar   │       varchar        │
├────────────┼───────────┼───────────┼───┼────────────────┼────────────┼──────────────────────┤
│       5024 │    165411 │       444 │ … │ NONE           │ AIR        │  to the expre        │
│       5024 │     57578 │        84 │ … │ COLLECT COD    │ REG AIR    │ osits hinder caref…  │
│       5024 │    111009 │      3521 │ … │ NONE           │ MAIL       │ zle carefully saut…  │
├────────────┴───────────┴───────────┴───┴────────────────┴────────────┴──────────────────────┤
│ 3 rows                                                                 16 columns (6 shown) │
└─────────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT min(l_orderkey), max(l_orderkey) FROM lineitem_filtered&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────────┬─────────────────┐
│ min(l_orderkey) │ max(l_orderkey) │
│      int32      │      int32      │
├─────────────────┼─────────────────┤
│            5024 │         6000000 │
└─────────────────┴─────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that everything is lazily evaluated. The Parquet file is not read from disk until the final query is executed – and queries are optimized in their entirety. Executing the decomposed query will be just as fast as executing the long SQL query all at once.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Python Ingestion APIs.&lt;/strong&gt; This release adds several &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/6015&quot;&gt;familiar data ingestion and export APIs&lt;/a&gt; that follow standard conventions used by other libraries. These functions emit relations as well – which can be directly queried again.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;lineitem.csv&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌────────────┬───────────┬───────────┬───┬───────────────────┬────────────┬──────────────────────┐
│ l_orderkey │ l_partkey │ l_suppkey │ … │  l_shipinstruct   │ l_shipmode │      l_comment       │
│   int32    │   int32   │   int32   │   │      varchar      │  varchar   │       varchar        │
├────────────┼───────────┼───────────┼───┼───────────────────┼────────────┼──────────────────────┤
│          1 │    155190 │      7706 │ … │ DELIVER IN PERSON │ TRUCK      │ egular courts abov…  │
│          1 │     67310 │      7311 │ … │ TAKE BACK RETURN  │ MAIL       │ ly final dependenc…  │
│          1 │     63700 │      3701 │ … │ TAKE BACK RETURN  │ REG AIR    │ riously. regular, …  │
├────────────┴───────────┴───────────┴───┴───────────────────┴────────────┴──────────────────────┤
│ 3 rows                                                                    16 columns (6 shown) │
└────────────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT min(l_orderkey) FROM lineitem&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────────┐
│ min(l_orderkey) │
│      int32      │
├─────────────────┤
│               1 │
└─────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Polars Integration.&lt;/strong&gt; This release adds support for tight integration with the &lt;a href=&quot;https://github.com/pola-rs/polars&quot;&gt;Polars DataFrame library&lt;/a&gt;, similar to our integration with Pandas DataFrames. Results can be converted to Polars DataFrames using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.pl()&lt;/code&gt; function.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT 42&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;shape: (1, 1)
┌─────┐
│ 42  │
│ --- │
│ i32 │
╞═════╡
│ 42  │
└─────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In addition, Polars DataFrames can be directly queried using the SQL interface.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;polars&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;a&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT * FROM df&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;shape: (1, 1)
┌─────┐
│ a   │
│ --- │
│ i64 │
╞═════╡
│ 42  │
└─────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;fsspec Filesystem Support.&lt;/strong&gt; This release adds support for the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5829&quot;&gt;fsspec filesystem API&lt;/a&gt;. &lt;a href=&quot;https://filesystem-spec.readthedocs.io/en/latest/&quot;&gt;fsspec&lt;/a&gt; allows users to define their own filesystem that they can pass to DuckDB. DuckDB will then use this file system to read and write data to and from. This enables support for storage back-ends that may not be natively supported by DuckDB yet, such as FTP.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fsspec&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filesystem&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;register_filesystem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filesystem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;gcs&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM read_csv_auto(&#39;gcs:///bucket/file.csv&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Have a look at the &lt;a href=&quot;https://duckdb.org/docs/stable/guides/python/filesystems.html&quot;&gt;guide&lt;/a&gt; for more information&lt;/p&gt;
      &lt;h2 id=&quot;storage-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html#storage-improvements&quot;&gt;Storage Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;Delta Compression.&lt;/strong&gt; Compression of numeric values in the storage is improved using the new &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5491&quot;&gt;delta and delta-constant compression&lt;/a&gt;. This compression method is particularly effective when compressing values that are equally spaced out. For example, sequences of numbers (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1, 2, 3, ...&lt;/code&gt;) or timestamps with a fixed interval between them (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;12:00:01, 12:00:02, 12:00:03, ...&lt;/code&gt;).&lt;/p&gt;
      &lt;h2 id=&quot;final-thoughts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2023/02/13/announcing-duckdb-070.html#final-thoughts&quot;&gt;Final Thoughts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The full release notes can be &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.7.0&quot;&gt;found on GitHub&lt;/a&gt;. We would like to thank all of the contributors for their hard work on improving DuckDB.&lt;/p&gt;

</description><link>https://duckdb.org/2023/02/13/announcing-duckdb-070.html</link><guid isPermaLink="false">https://duckdb.org/2023/02/13/announcing-duckdb-070.html</guid><pubDate>Mon, 13 Feb 2023 00:00:00 GMT</pubDate><author>Mark Raasveldt</author></item><item><title>Announcing DuckDB 0.6.0</title><description>&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/white-headed-duck.jpeg&quot; alt=&quot;Image of white-headed duck&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The DuckDB team is happy to announce the latest DuckDB version (0.6.0) has been released. This release of DuckDB is named &quot;Oxyura&quot; after the &lt;a href=&quot;https://en.wikipedia.org/wiki/White-headed_duck&quot;&gt;White-headed duck (Oxyura leucocephala)&lt;/a&gt; which is an endangered species native to Eurasia.&lt;/p&gt;

&lt;p&gt;To install the new version, please visit the &lt;a href=&quot;https://duckdb.org/docs/installation/&quot;&gt;installation guide&lt;/a&gt;. Note that the release is still being rolled out, so not all artifacts may be published yet. The full release notes can be found &lt;a href=&quot;https://github.com/duckdb/duckdb/releases/tag/v0.6.0&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;whats-in-060&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/11/14/announcing-duckdb-060.html#whats-in-060&quot;&gt;What&#39;s in 0.6.0&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The new release contains many improvements to the storage system, general performance improvements, memory management improvements and new features. Below is a summary of the most impactful changes, together with the linked PRs that implement the features.&lt;/p&gt;
      &lt;h2 id=&quot;storage-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/11/14/announcing-duckdb-060.html#storage-improvements&quot;&gt;Storage Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;As we are working towards stabilizing the storage format and moving towards version 1.0, we have been actively working on improving our storage format, including many &lt;a href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html&quot;&gt;compression improvements&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Optimistic writing to disk.&lt;/strong&gt; In previous DuckDB versions, the data of a single transaction was first loaded into memory, and would only be written to disk on a commit. While this works fine when data is loaded in batches that fit in memory, it does not work well when loading a lot of data in a single transaction, such as when ingesting one very large file into the system.&lt;/p&gt;

&lt;p&gt;This version introduces &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4996&quot;&gt;optimistic writing to disk&lt;/a&gt;. When loading large data sets in a single transaction, data is compressed and streamed to the database file, even before the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COMMIT&lt;/code&gt; has occurred. When the transaction is committed, the data will already have been written to disk, and no further writing has to happen. On a rollback, any optimistically written data is reclaimed by the system.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parallel data loading&lt;/strong&gt;. In addition to optimistically writing data to disk, this release includes support for parallel data loading into individual tables. This greatly improves performance of data loading on machines that have multiple cores (i.e., all modern machines).&lt;/p&gt;

&lt;p&gt;Below is a benchmark comparing loading time of 150 million rows of the Taxi dataset from a Parquet file on an M1 Max with 10 cores:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Version&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Load time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.5.1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;91.4 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.6.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.2 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;DuckDB supports two modes – the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5082&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;order-preserving&lt;/code&gt;&lt;/a&gt; and the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5033&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-order-preserving&lt;/code&gt;&lt;/a&gt; parallel data load.&lt;/p&gt;

&lt;p&gt;The order-preserving load preserves the insertion order so that e.g., the first line in your CSV file is the first line in the DuckDB table. The non-order-preserving load does not offer such guarantees – and instead might re-order the data on load. By default the order-preserving load is used, which involves some extra book-keeping. The preservation of insertion order can be disabled using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SET preserve_insertion_order = false&lt;/code&gt; statement.&lt;/p&gt;
      &lt;h2 id=&quot;compression-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/11/14/announcing-duckdb-060.html#compression-improvements&quot;&gt;Compression Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;strong&gt;FSST&lt;/strong&gt;. The &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4366&quot;&gt;Fast Static Symbol Table&lt;/a&gt; compression algorithm is introduced in this version. This state-of-the-art compression algorithm compresses data &lt;em&gt;inside&lt;/em&gt; strings using a dictionary, while maintaining support for efficient scans and random look-ups. This greatly increases the compression ratio of strings that have many unique values but with common elements, such as e-mail addresses or URLs.&lt;/p&gt;

&lt;p&gt;The compression ratio improvements of the TPC-H SF1 dataset are shown below:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Compression&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Size&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Uncompressed&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;761 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Dictionary&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;510 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;FSST + Dictionary&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;251 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Chimp&lt;/strong&gt;. The &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4878&quot;&gt;Chimp compression algorithm&lt;/a&gt; is included, which is the state-of-the-art in lightweight floating point compression. Chimp is an improved version of Gorillas, that achieves both a better compression ratio as well as faster decompression speed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Patas&lt;/strong&gt;. &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5044&quot;&gt;Patas&lt;/a&gt; is a novel floating point compression method that iterates upon the Chimp algorithm by optimizing for a single case in the Chimp algorithm. While Patas generally has a slightly lower compression ratio than Chimp, it has significantly faster decompression speed, almost matching uncompressed data in read speed.&lt;/p&gt;

&lt;p&gt;The compression ratio of a dataset containing temperatures of cities stored as double (8-byte floating point numbers) is shown below:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Compression&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Size&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Uncompressed&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25.4 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Chimp&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9.7 MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Patas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10.2 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;performance-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/11/14/announcing-duckdb-060.html#performance-improvements&quot;&gt;Performance Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB aims to have very high performance for a wide variety of workloads. As such, we are always working to improve performance for various workloads. This release is no different.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parallel CSV Loading (Experimental)&lt;/strong&gt;. In this release we are launching &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5194&quot;&gt;a new experimental parallel CSV reader&lt;/a&gt;. This greatly improves the ingestion speed of large CSV files into the system. While we have done our best to make the parallel CSV reader robust – CSV parsing is a minefield as there is such a wide variety of different files out there – so we have marked the reader as experimental for now.&lt;/p&gt;

&lt;p&gt;The parallel CSV reader can be enabled by setting the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;experimental_parallel_csv&lt;/code&gt; flag to true. We aim to make the parallel CSV reader the default reader in future DuckDB versions.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;experimental_parallel_csv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Below is the load time of a 720 MB CSV file containing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; table from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TPC-H&lt;/code&gt; benchmark,&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Variant&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Load time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Single Threaded&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.5s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parallel&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.6s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Parallel CREATE INDEX &amp;amp; Index Memory Management Improvements&lt;/strong&gt;. Index creation is also sped up significantly in this release, as &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4655&quot;&gt;the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE INDEX&lt;/code&gt; statement can now be executed fully in parallel&lt;/a&gt;. In addition, the number of memory allocations done by the ART is greatly reduced through &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5292&quot;&gt;inlining of small structures&lt;/a&gt; which both reduces memory size and further improves performance.&lt;/p&gt;

&lt;p&gt;The timings of creating an index on a single column with 16 million values is shown below.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Version&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Create index time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.5.1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.92 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;v0.6.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.38 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Parallel count(DISTINCT)&lt;/strong&gt;. Aggregates containing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT&lt;/code&gt; aggregates, most commonly used for exact distinct count computation (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count(DISTINCT col)&lt;/code&gt;) previously had to be executed in single-threaded mode. Starting with v0.6.0, &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5146&quot;&gt;DuckDB can execute these queries in parallel&lt;/a&gt;, leading to large speed-ups.&lt;/p&gt;
      &lt;h2 id=&quot;sql-syntax-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/11/14/announcing-duckdb-060.html#sql-syntax-improvements&quot;&gt;SQL Syntax Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;SQL is the primary way of interfacing with DuckDB – and DuckDB &lt;a href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html&quot;&gt;tries to have an easy to use SQL dialect&lt;/a&gt;. This release contains further improvements to the SQL dialect.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UNION Type&lt;/strong&gt;. This release introduces the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4966&quot;&gt;UNION type&lt;/a&gt;, which allows sum types to be stored and queried in DuckDB. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UNION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;oh my globs&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;messages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────┐
│      u      │
├─────────────┤
│ 42          │
│ oh my globs │
└─────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Sum types are strongly typed – but they allow a single value in a table to be represented as one of various types. The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/union.html&quot;&gt;union page&lt;/a&gt; in the documentation contains more information on how to use this new composite type.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FROM-first&lt;/strong&gt;. Starting with this release, DuckDB supports starting queries with the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5076&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FROM&lt;/code&gt; clause&lt;/a&gt; instead of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause. In fact, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause is fully optional now, and defaults to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT *&lt;/code&gt;. That means the following queries are now valid in DuckDB:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- SELECT clause is optional, SELECT * is implied (if not included)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- first 5 rows of the table&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- SELECT can be used after the FROM&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- insert all data from tbl1 into tbl2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;COLUMNS Expression&lt;/strong&gt;. This release adds support for &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5120&quot;&gt;the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression&lt;/a&gt;, inspired by &lt;a href=&quot;https://clickhouse.com/docs/en/sql-reference/statements/select/#columns-expression&quot;&gt;the ClickHouse syntax&lt;/a&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression allows you to execute expressions or functions on multiple columns without having to duplicate the full expression.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val1&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val2&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌─────────────┬───────────────┬───────────────┬──────────────┐
│ min(obs.id) │ min(obs.val1) │ min(obs.val2) │ count_star() │
├─────────────┼───────────────┼───────────────┼──────────────┤
│ 1           │ 10            │ 100           │ 3            │
└─────────────┴───────────────┴───────────────┴──────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression supports all star expressions, including &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/select.html&quot;&gt;the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REPLACE&lt;/code&gt; syntax&lt;/a&gt;. In addition, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression can take a regular expression as parameter:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;COLUMNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;val[0-9]+&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌──────┬──────┐
│ val1 │ val2 │
├──────┼──────┤
│ 10   │ 100  │
│ 20   │ NULL │
│ NULL │ 300  │
└──────┴──────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;List comprehension support&lt;/strong&gt;. List comprehension is an elegant and powerful way of defining operations on lists. DuckDB now also supports &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4926&quot;&gt;list comprehension&lt;/a&gt; as part of its SQL dialect. For example, the query below now works:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────┐
│     l     │
├───────────┤
│ [2, 3, 4] │
└───────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Nested types and structures are very efficiently implemented in DuckDB, and are now also more elegant to work with.&lt;/p&gt;
      &lt;h2 id=&quot;memory-management-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/11/14/announcing-duckdb-060.html#memory-management-improvements&quot;&gt;Memory Management Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When working with large data sets, memory management is always a potential pain point. By using a streaming execution engine and buffer manager, DuckDB supports many operations on larger than memory data sets. DuckDB also aims to support queries where &lt;em&gt;intermediate&lt;/em&gt; results do not fit into memory by using disk-spilling techniques, and has support for an &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html&quot;&gt;efficient out-of-core sort&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/2021/10/13/windowing.html&quot;&gt;out-of-core window functions&lt;/a&gt; and &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4189&quot;&gt;an out-of-core hash join&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This release further improves on that by greatly optimizing the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4970&quot;&gt;out-of-core hash join&lt;/a&gt;, resulting in a much more graceful degradation in performance as the data exceeds the memory limit.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Memory limit (GB)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Old time (s)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;New time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.97&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.96&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.97&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.97&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.23&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.22&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.23&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.44&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.27&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.27&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.81&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.60&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.69&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.28&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.73&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.35&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;jemalloc&lt;/strong&gt;. In addition, this release bundles the &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4971&quot;&gt;jemalloc allocator&lt;/a&gt; with the Linux version of DuckDB by default, which fixes an outstanding issue where the standard &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GLIBC&lt;/code&gt; allocator would not return blocks to the operating system, unnecessarily leading to out-of-memory errors on the Linux version. Note that this problem does not occur on macOS or Windows, and as such we continue using the standard allocators there (at least for now).&lt;/p&gt;
      &lt;h2 id=&quot;shell-improvements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/11/14/announcing-duckdb-060.html#shell-improvements&quot;&gt;Shell Improvements&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB has a command-line interface that is adapted from SQLite&#39;s command line interface, and therefore supports an extremely similar interface to SQLite. All of the tables in this blog post have been generated using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.mode markdown&lt;/code&gt; in the CLI.&lt;/p&gt;

&lt;p&gt;The DuckDB shell also offers several improvements over the SQLite shell, such as syntax highlighting, and this release includes a few new goodies.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DuckBox Rendering&lt;/strong&gt;. This release includes a &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5140&quot;&gt;new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.mode duckbox&lt;/code&gt; rendering&lt;/a&gt; that is used by default. This box rendering adapts to the size of the shell, and leaves out columns and rows to provide a better overview of a result. It very quickly renders large result sets by leaving out rows in the middle. That way, typing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM tbl&lt;/code&gt; in the shell no longer blows it up. In fact, this can now be used to quickly get a good feel of a dataset instead.&lt;/p&gt;

&lt;p&gt;The number of rows that are rendered can be changed by using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.maxrows X&lt;/code&gt; setting, and you can switch back to the old rendering using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.mode box&lt;/code&gt; command.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;~/Data/nyctaxi/nyc-taxi/2014/04/data.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;┌───────────┬─────────────────────┬─────────────────────┬───┬────────────┬──────────────┬──────────────┐
│ vendor_id │      pickup_at      │     dropoff_at      │ … │ tip_amount │ tolls_amount │ total_amount │
│  varchar  │      timestamp      │      timestamp      │   │   float    │    float     │    float     │
├───────────┼─────────────────────┼─────────────────────┼───┼────────────┼──────────────┼──────────────┤
│ CMT       │ 2014-04-08 08:59:39 │ 2014-04-08 09:28:57 │ … │        3.7 │          0.0 │         22.2 │
│ CMT       │ 2014-04-08 14:59:22 │ 2014-04-08 15:04:52 │ … │        1.3 │          0.0 │          7.8 │
│ CMT       │ 2014-04-08 08:45:28 │ 2014-04-08 08:50:41 │ … │        1.2 │          0.0 │          7.2 │
│ CMT       │ 2014-04-08 08:00:20 │ 2014-04-08 08:11:31 │ … │        1.7 │          0.0 │         10.2 │
│ CMT       │ 2014-04-08 08:38:36 │ 2014-04-08 08:44:37 │ … │        1.2 │          0.0 │          7.2 │
│ CMT       │ 2014-04-08 07:52:53 │ 2014-04-08 07:59:12 │ … │        1.3 │          0.0 │          7.8 │
│ CMT       │ 2014-04-08 16:08:16 │ 2014-04-08 16:12:38 │ … │        1.4 │          0.0 │          8.4 │
│ CMT       │ 2014-04-08 12:04:09 │ 2014-04-08 12:14:30 │ … │        1.7 │          0.0 │         10.2 │
│ CMT       │ 2014-04-08 16:18:38 │ 2014-04-08 16:37:04 │ … │        2.5 │          0.0 │         17.5 │
│ CMT       │ 2014-04-08 15:28:00 │ 2014-04-08 15:34:44 │ … │        1.4 │          0.0 │          8.4 │
│  ·        │          ·          │          ·          │ · │         ·  │           ·  │           ·  │
│  ·        │          ·          │          ·          │ · │         ·  │           ·  │           ·  │
│  ·        │          ·          │          ·          │ · │         ·  │           ·  │           ·  │
│ CMT       │ 2014-04-25 00:09:34 │ 2014-04-25 00:14:52 │ … │        2.5 │          0.0 │         10.0 │
│ CMT       │ 2014-04-25 01:59:39 │ 2014-04-25 02:16:07 │ … │        3.5 │          0.0 │         21.0 │
│ CMT       │ 2014-04-24 23:02:08 │ 2014-04-24 23:47:10 │ … │        8.8 │          0.0 │         52.8 │
│ CMT       │ 2014-04-25 01:27:11 │ 2014-04-25 01:56:53 │ … │        4.6 │          0.0 │         27.6 │
│ CMT       │ 2014-04-25 00:15:46 │ 2014-04-25 00:25:37 │ … │        1.0 │          0.0 │         11.5 │
│ CMT       │ 2014-04-25 00:17:53 │ 2014-04-25 00:22:52 │ … │        1.3 │          0.0 │          7.8 │
│ CMT       │ 2014-04-25 03:13:19 │ 2014-04-25 03:21:50 │ … │        2.1 │          0.0 │         12.6 │
│ CMT       │ 2014-04-24 23:53:03 │ 2014-04-25 00:16:01 │ … │       2.85 │          0.0 │        31.35 │
│ CMT       │ 2014-04-25 00:26:08 │ 2014-04-25 00:31:25 │ … │        1.4 │          0.0 │          8.4 │
│ CMT       │ 2014-04-24 23:21:39 │ 2014-04-24 23:33:57 │ … │        1.0 │          0.0 │         11.5 │
├───────────┴─────────────────────┴─────────────────────┴───┴────────────┴──────────────┴──────────────┤
│ 14618759 rows (20 shown)                                                        18 columns (6 shown) │
└──────────────────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Context-Aware Auto-Complete&lt;/strong&gt;. The shell now also ships with &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/4921&quot;&gt;context-aware auto-complete&lt;/a&gt;. Auto-complete is triggered by pressing the tab character. The shell auto-completes four different groups: (1) keywords, (2) table names + table functions, (3) column names + scalar functions, and (4) file names. The shell looks at the position in the SQL statement to determine which of these auto-completions to trigger. For example:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;student_id&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;student_id&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;student_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grades&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;student_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;d -&amp;gt; data/

SELECT student_id FROM &#39;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grades&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;csv&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Progress Bars&lt;/strong&gt;. DuckDB has &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/1432&quot;&gt;supported progress bars in queries for a while now&lt;/a&gt;, but they have always been opt-in. In this release we have &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/5187&quot;&gt;prettied up the progress bar&lt;/a&gt; and enabled it by default in the shell. The progress bar will pop up when a query is run that takes more than 2 seconds, and display an estimated time-to-completion for the query.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitem-big.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   32% ▕███████████████████▏                                        ▏ 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the future we aim to enable the progress bar by default in other clients. For now, this can be done manually by running the following SQL queries:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;enable_progress_bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;enable_print_progress_bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description><link>https://duckdb.org/2022/11/14/announcing-duckdb-060.html</link><guid isPermaLink="false">https://duckdb.org/2022/11/14/announcing-duckdb-060.html</guid><pubDate>Mon, 14 Nov 2022 00:00:00 GMT</pubDate><author>Mark Raasveldt</author></item><item><title>Lightweight Compression in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB supports efficient lightweight compression that is automatically used to keep data size down without incurring high costs for compression and decompression.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/matroshka-duck.png&quot; alt=&quot;Matroshka Ducks (ducks going from big to small)&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;When working with large amounts of data, compression is critical for reducing storage size and egress costs. Compression algorithms typically reduce data set size by &lt;strong&gt;75-95%&lt;/strong&gt;, depending on how compressible the data is. Compression not only reduces the storage footprint of a data set, but also often &lt;strong&gt;improves performance&lt;/strong&gt; as less data has to be read from disk or over a network connection.&lt;/p&gt;

&lt;p&gt;Column store formats, such as DuckDB&#39;s native file format or &lt;a href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html&quot;&gt;Parquet&lt;/a&gt;, benefit especially from compression. That is because data within an individual column is generally very similar, which can be exploited effectively by compression algorithms. Storing data in row-wise format results in interleaving of data of different columns, leading to lower compression rates.&lt;/p&gt;

&lt;p&gt;DuckDB added support for compression &lt;a href=&quot;https://github.com/duckdb/duckdb/pull/2099&quot;&gt;at the end of last year&lt;/a&gt;. As shown in the table below, the compression ratio of DuckDB has continuously improved since then and is still actively being improved. In this blog post, we discuss how compression in DuckDB works, and the design choices and various trade-offs that we have made while implementing compression for DuckDB&#39;s storage format.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Version&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Taxi&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;On&amp;nbsp;Time&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Notes&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB v0.2.8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15.3 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.73 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.85 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Uncompressed&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;July 2021&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB v0.2.9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.2 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.25 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.79 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;RLE + Constant&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;September 2021&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB v0.3.2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10.8 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.98 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.56 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Bitpacking&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;February 2022&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB v0.3.3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.9 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.23 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.32 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Dictionary&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;April 2022&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB v0.5.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.6 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.21 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.29 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FOR&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;September 2022&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB dev&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.8 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.21 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.17 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FSST + Chimp&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;now()&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CSV&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17.0 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.11 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.72 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Parquet (Uncompressed)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.5 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.12 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.31 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Parquet (Snappy)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.2 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.11 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.18 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Parquet (ZSTD)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.6 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.08 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.15 GB&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;compression-intro&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#compression-intro&quot;&gt;Compression Intro&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;At its core, compression algorithms try to find patterns in a data set in order to store it more cleverly. &lt;strong&gt;Compressibility&lt;/strong&gt; of a data set is therefore dependent on whether or not such patterns can be found, and whether they exist in the first place. Data that follows a fixed pattern can be compressed significantly. Data that does not have any patterns, such as random noise, cannot be compressed. Formally, the compressibility of a dataset is known as its &lt;a href=&quot;https://en.wikipedia.org/wiki/Entropy_(information_theory)&quot;&gt;entropy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As an example of this concept, let us consider the following two data sets.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/exampledata.png&quot; alt=&quot;Example data set with predictable and noisy data&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The constant data set can be compressed by simply storing the value of the pattern and how many times the pattern repeats (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1x8&lt;/code&gt;). The random noise, on the other hand, has no pattern, and is therefore not compressible.&lt;/p&gt;
      &lt;h2 id=&quot;general-purpose-compression-algorithms&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#general-purpose-compression-algorithms&quot;&gt;General Purpose Compression Algorithms&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The compression algorithms that most people are familiar with are &lt;em&gt;general purpose compression algorithms&lt;/em&gt;, such as &lt;em&gt;zip&lt;/em&gt;, &lt;em&gt;gzip&lt;/em&gt; or &lt;em&gt;zstd&lt;/em&gt;. General purpose compression algorithms work by finding patterns in bits. They are therefore agnostic to data types, and can be used on any stream of bits. They can be used to compress files, but they can also be applied to arbitrary data sent over a socket connection.&lt;/p&gt;

&lt;p&gt;General purpose compression is flexible and very easy to set up. There are a number of high quality libraries available (such as zstd, snappy or lz4) that provide compression, and they can be applied to any data set stored in any manner.&lt;/p&gt;

&lt;p&gt;The downside of general purpose compression is that (de)compression is generally expensive. While this does not matter if we are reading and writing from a hard disk or over a slow internet connection, the speed of (de)compression can become a bottleneck when data is stored in RAM.&lt;/p&gt;

&lt;p&gt;Another downside is that these libraries operate as a &lt;em&gt;black box&lt;/em&gt;. They operate on streams of bits, and do not reveal information of their internal state to the user. While that is not a problem if you are only looking to decrease the size of your data, it prevents the system from taking advantage of the patterns found by the compression algorithm during execution.&lt;/p&gt;

&lt;p&gt;Finally, general purpose compression algorithms work better when compressing large chunks of data. As illustrated in the table below, compression ratios suffer significantly when compressing small amounts of data. To achieve a good compression ratio, blocks of at least &lt;strong&gt;256 kB&lt;/strong&gt; must be used.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Compression&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;1 kB&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;4 kB&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;16 kB&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;64 kB&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;256 kB&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;1 MB&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;zstd&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.72&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.21&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.41&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.54&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.73&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lz4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.29&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.52&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.58&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.62&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.64&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;gzip&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.28&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.49&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.62&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.67&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This is relevant because the block size is the minimum amount of data that must be decompressed when reading a single row from disk. Worse, as DuckDB compresses data on a per-column basis, the block size would be the minimum amount of data that must be decompressed per column. With a block size of 256 kB, fetching a single row could require decompressing multiple megabytes of data. This can cause queries that fetch a low number of rows, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM tbl LIMIT 5&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM tbl WHERE id = 42&lt;/code&gt; to incur significant costs, despite appearing to be very cheap on the surface.&lt;/p&gt;
      &lt;h2 id=&quot;lightweight-compression-algorithms&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#lightweight-compression-algorithms&quot;&gt;Lightweight Compression Algorithms&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another option for achieving compression is to use specialized lightweight compression algorithms. These algorithms also operate by finding patterns in data. However, unlike general purpose compression, they do not attempt to find generic patterns in bitstreams. Instead, they operate by finding &lt;strong&gt;specific patterns&lt;/strong&gt; in data sets.&lt;/p&gt;

&lt;p&gt;By detecting specific patterns, specialized compression algorithms can be significantly more lightweight, providing much faster compression and decompression. In addition, they can be effective on much smaller data sizes. This allows us to decompress a few rows at a time, rather than requiring large blocks of data to be decompressed at once. These specialized compression algorithms can also offer efficient support for random seeks, making data access through an index significantly faster.&lt;/p&gt;

&lt;p&gt;Lightweight compression algorithms also provide us with more fine-grained control over the compression process. This is especially relevant for us as DuckDB&#39;s file format uses fixed-size blocks in order to avoid fragmentation for workloads involving deletes and updates. The fine-grained control allows us to fill these blocks more effectively, and avoid having to guess how much compressed data will fit into a buffer.&lt;/p&gt;

&lt;p&gt;On the flip side, these algorithms are ineffective if the specific patterns they are designed for do not occur in the data. As a result, individually, these lightweight compression algorithms are no replacement for general purpose algorithms. Instead, multiple specialized algorithms must be combined in order to capture many different common patterns in data sets.&lt;/p&gt;
      &lt;h2 id=&quot;compression-framework&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#compression-framework&quot;&gt;Compression Framework&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Because of the advantages described above, DuckDB uses only specialized lightweight compression algorithms. As each of these algorithms work optimally on different patterns in the data, DuckDB&#39;s compression framework must first decide on which algorithm to use to store the data of each column.&lt;/p&gt;

&lt;p&gt;DuckDB&#39;s storage splits tables into &lt;em&gt;Row Groups&lt;/em&gt;. These are groups of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;120K&lt;/code&gt; rows, stored in columnar chunks called &lt;em&gt;Column Segments&lt;/em&gt;. This storage layout is similar to &lt;a href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html&quot;&gt;Parquet&lt;/a&gt; – but with an important difference: columns are split into blocks of a fixed-size. This design decision was made because DuckDB&#39;s storage format supports in-place ACID modifications to the storage format, including deleting and updating rows, and adding and dropping columns. By partitioning data into fixed size blocks the blocks can be easily reused after they are no longer required and fragmentation is avoided.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/storageformat.png&quot; alt=&quot;Visualization of the storage format of DuckDB&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The compression framework operates within the context of the individual &lt;em&gt;Column Segments&lt;/em&gt;. It operates in two phases. First, the data in the column segment is &lt;em&gt;analyzed&lt;/em&gt;. In this phase, we scan the data in the segment and find out the best compression algorithm for that particular segment. After that, the &lt;em&gt;compression&lt;/em&gt; is performed, and the compressed data is written to the blocks on disk.&lt;/p&gt;

&lt;p&gt;While this approach requires two passes over the data within a segment, this does not incur a significant cost, as the amount of data stored in one segment is generally small enough to fit in the CPU caches. A sampling approach for the analyze step could also be considered, but in general we value choosing the best compression algorithm and reducing file size over a minor increase in compression speed.&lt;/p&gt;
      &lt;h2 id=&quot;compression-algorithms&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#compression-algorithms&quot;&gt;Compression Algorithms&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB implements several lightweight compression algorithms, and we are in the process of adding more to the system. We will go over a few of these compression algorithms and how they work in the following sections.&lt;/p&gt;
      &lt;h3 id=&quot;constant-encoding&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#constant-encoding&quot;&gt;Constant Encoding&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Constant encoding is the most straightforward compression algorithm in DuckDB. Constant encoding is used when every single value in a column segment is the same value. In that case, we store only that single value. This encoding is visualized below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/constant.png&quot; alt=&quot;Data set stored both uncompressed and with constant compression&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;When applicable, this encoding technique leads to tremendous space savings. While it might seem like this technique is rarely applicable – in practice it occurs relatively frequently. Columns might be filled with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values, or have values that rarely change (such as e.g., a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;year&lt;/code&gt; column in a stream of sensor data). Because of this compression algorithm, such columns take up almost no space in DuckDB.&lt;/p&gt;
      &lt;h3 id=&quot;run-length-encoding-rle&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#run-length-encoding-rle&quot;&gt;Run-Length Encoding (RLE)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Run-length_encoding&quot;&gt;Run-length encoding&lt;/a&gt; (RLE) is a compression algorithm that takes advantage of repeated values in a dataset. Rather than storing individual values, the data set is decomposed into a pair of (value, count) tuples, where the count represents how often the value is repeated. This encoding is visualized below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/rle.png&quot; alt=&quot;Data set stored both uncompressed and with RLE compression&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;RLE is powerful when there are many repeating values in the data. This might occur when data is sorted or partitioned on a particular attribute. It is also useful for columns that have many missing (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;) values.&lt;/p&gt;
      &lt;h3 id=&quot;bit-packing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#bit-packing&quot;&gt;Bit Packing&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Bit Packing is a compression technique that takes advantage of the fact that integral values rarely span the full range of their data type. For example, four-byte integer values can store values from negative two billion to positive two billion. Frequently the full range of this data type is not used, and instead only small numbers are stored. Bit packing takes advantage of this by removing all of the unnecessary leading zeros when storing values. An example (in decimal) is provided below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/bitpacking.png&quot; alt=&quot;Data set stored both uncompressed and with bitpacking compression&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;For bit packing compression, we keep track of the maximum value for every &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1024&lt;/code&gt; values. The maximum value determines the bit packing width, which is the number of bits necessary to store that value. For example, when storing a set of values with a maximum value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;32&lt;/code&gt;, the bit packing width is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;5&lt;/code&gt; bits, down from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;32&lt;/code&gt; bits per value that would be required to store uncompressed four-byte integers.&lt;/p&gt;

&lt;p&gt;Bit packing is very powerful in practice. It is also convenient to users – as due to this technique there are no storage size differences between using the various integer types. A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt; column will be stored in the exact same amount of space as an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt; column. That relieves the user from having to worry about which integer type to choose.&lt;/p&gt;
      &lt;h3 id=&quot;frame-of-reference&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#frame-of-reference&quot;&gt;Frame of Reference&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Frame of Reference encoding is an extension of bit packing, where we also include a frame. The frame is the minimum value found in the set of values. The values are stored as the offset from this frame. An example of this is given below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/for.png&quot; alt=&quot;Data set stored both uncompressed and with FOR compression&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;While this might not seem particularly useful at a first glance, it is very powerful when storing dates and timestamps. That is because dates and timestamps are stored as Unix Timestamps in DuckDB, i.e., the offset since &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1970-01-01&lt;/code&gt; in either days (for dates) or microseconds (for timestamps). When we have a set of date or timestamp values, the absolute numbers might be very high, but the numbers are all very close together. By applying a frame before bit packing, we can often improve our compression ratio tremendously.&lt;/p&gt;
      &lt;h3 id=&quot;dictionary-encoding&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#dictionary-encoding&quot;&gt;Dictionary Encoding&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Dictionary encoding works by extracting common values into a separate dictionary, and then replacing the original values with references to said dictionary. An example is provided below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/dictionary.png&quot; alt=&quot;Data set stored both uncompressed and with Dictionary compression&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Dictionary encoding is particularly efficient when storing text columns with many duplicate entries. The much larger text values can be replaced by small numbers, which can in turn be efficiently bit packed together.&lt;/p&gt;
      &lt;h3 id=&quot;fsst&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#fsst&quot;&gt;FSST&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://www.vldb.org/pvldb/vol13/p2649-boncz.pdf&quot;&gt;Fast Static Symbol Table&lt;/a&gt; compression is an extension to dictionary compression, that not only extracts repetitions of entire strings, but also extracts repetitions &lt;em&gt;within&lt;/em&gt; strings. This is effective when storing strings that are themselves unique, but have a lot of repetition within the strings, such as URLs or e-mail addresses. An image illustrating how this works is shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/compression/fsst.png&quot; alt=&quot;Data set stored both uncompressed and with FSST compression&quot; width=&quot;100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;For those interested in learning more, watch the talk by &lt;a href=&quot;https://www.youtube.com/watch?v=uJ1KO_UMrQk&quot;&gt;Peter Boncz here&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;chimp--patas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#chimp--patas&quot;&gt;Chimp &amp;amp; Patas&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;&lt;a href=&quot;https://www.vldb.org/pvldb/vol15/p3058-liakos.pdf&quot;&gt;Chimp&lt;/a&gt; is a very new compression algorithm that is designed to compress floating point values. It is based on &lt;a href=&quot;https://www.vldb.org/pvldb/vol8/p1816-teller.pdf&quot;&gt;Gorilla compression&lt;/a&gt;. The core idea behind Gorilla and Chimp is that floating point values, when XOR&#39;d together, seem to produce small values with many trailing and leading zeros. These algorithms then work on finding an efficient way of storing the trailing and leading zeros.&lt;/p&gt;

&lt;p&gt;After implementing Chimp, we have been inspired and worked on implementing Patas, which uses many of the same ideas but optimizes further for higher decompression speed. Expect a future blog post explaining these in more detail soon!&lt;/p&gt;
      &lt;h2 id=&quot;inspecting-compression&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#inspecting-compression&quot;&gt;Inspecting Compression&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRAGMA storage_info&lt;/code&gt; can be used to inspect the storage layout of tables and columns. This can be used to inspect which compression algorithm has been chosen by DuckDB to compress specific columns of a table.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;segment_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;persistent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block_offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has_updates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pragma_storage_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;taxi&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SAMPLE&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_group_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;row_group_id&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;column_name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;column_id&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;segment_type&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;compression&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;extra&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FLOAT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Chimp&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;tip_amount&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FLOAT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Chimp&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;26&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;pickup_latitude&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;VALIDITY&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Constant&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;46&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;tolls_amount&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FLOAT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;RLE&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;73&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;store_and_fwd_flag&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;VALIDITY&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Uncompressed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;96&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;total_amount&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;VALIDITY&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Constant&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;111&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;total_amount&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;VALIDITY&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Constant&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;141&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;pickup_at&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;TIMESTAMP&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;52224&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BitPacking&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;201&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;pickup_longitude&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;VALIDITY&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Constant&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;209&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;passenger_count&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;TINYINT&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65536&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BitPacking&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;conclusion--future-goals&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/28/lightweight-compression.html#conclusion--future-goals&quot;&gt;Conclusion &amp;amp; Future Goals&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Compression has been tremendously successful in DuckDB, and we have made great strides in reducing the storage requirements of the system. We are still actively working on extending compression within DuckDB, and are looking to improve the compression ratio of the system even further, both by improving our existing techniques and implementing several others. Our goal is to achieve compression on par with Parquet with Snappy, while using only lightweight specialized compression techniques that are very fast to operate on.&lt;/p&gt;

</description><link>https://duckdb.org/2022/10/28/lightweight-compression.html</link><guid isPermaLink="false">https://duckdb.org/2022/10/28/lightweight-compression.html</guid><pubDate>Fri, 28 Oct 2022 00:00:00 GMT</pubDate><author>Mark Raasveldt</author></item><item><title>Modern Data Stack in a Box with DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: A fast, free, and open-source Modern Data Stack (MDS) can now be fully deployed on your laptop or to a single machine using the combination of &lt;a href=&quot;https://duckdb.org/&quot;&gt;DuckDB&lt;/a&gt;, &lt;a href=&quot;https://meltano.com/&quot;&gt;Meltano&lt;/a&gt;, &lt;a href=&quot;https://www.getdbt.com/&quot;&gt;dbt&lt;/a&gt;, and &lt;a href=&quot;https://superset.apache.org/&quot;&gt;Apache Superset&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;!-- https://www.ebay.com/itm/185408133658 --&gt;
&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/mds_in_a_box/rubber_duck_on_a_box.jpg&quot; alt=&quot;Duck on a box&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;This post is a collaboration with Jacob Matson and cross-posted on &lt;a href=&quot;https://www.dataduel.co/modern-data-stack-in-a-box-with-duckdb/&quot;&gt;dataduel.co&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;summary&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#summary&quot;&gt;Summary&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There is a large volume of literature (&lt;a href=&quot;https://www.startdataengineering.com/post/scale-data-pipelines/&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;https://www.databricks.com/session_na21/scaling-your-data-pipelines-with-apache-spark-on-kubernetes&quot;&gt;2&lt;/a&gt;, &lt;a href=&quot;https://towardsdatascience.com/scaling-data-products-delivery-using-domain-oriented-data-pipelines-869ca9461892&quot;&gt;3&lt;/a&gt;) about scaling data pipelines. “Use Kafka! Build a lake house! Don&#39;t build a lake house, use Snowflake! Don&#39;t use Snowflake, use XYZ!” However, with advances in hardware and the rapid maturation of data software, there is a simpler approach. This article will light up the path to highly performant single node analytics with an MDS-in-a-box open source stack: Meltano, DuckDB, dbt, &amp;amp; Apache Superset on Windows using Windows Subsystem for Linux (WSL). There are many options within the MDS, so if you are using another stack to build an MDS-in-a-box, please share it with the community on the DuckDB &lt;a href=&quot;https://twitter.com/duckdb?s=20&amp;amp;t=yBKUNLGHVZGEj1jL-P_PsQ&quot;&gt;Twitter&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/discussions&quot;&gt;GitHub&lt;/a&gt;, or &lt;a href=&quot;https://discord.com/invite/tcvwpjfnZx&quot;&gt;Discord&lt;/a&gt;, or the &lt;a href=&quot;https://www.getdbt.com/community/join-the-community/&quot;&gt;dbt slack&lt;/a&gt;! Or just stop by for a friendly debate about our choice of tools!&lt;/p&gt;
      &lt;h2 id=&quot;motivation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#motivation&quot;&gt;Motivation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;What is the Modern Data Stack, and why use it? The MDS can mean many things (see examples &lt;a href=&quot;https://www.moderndatastack.xyz/stacks&quot;&gt;here&lt;/a&gt; and a &lt;a href=&quot;https://www.getdbt.com/blog/future-of-the-modern-data-stack/&quot;&gt;historical perspective here&lt;/a&gt;), but fundamentally it is a return to using SQL for data transformations by combining multiple best-in-class software tools to form a stack. A typical stack would include (at least!) a tool to extract data from sources and load it into a data warehouse, dbt to transform and analyze that data in the warehouse, and a business intelligence tool. The MDS leverages the accessibility of SQL in combination with software development best practices like git to enable analysts to scale their impact across their companies.&lt;/p&gt;

&lt;p&gt;Why build a bundled Modern Data Stack on a single machine, rather than on multiple machines and on a data warehouse? There are many advantages!&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Simplify for higher developer productivity&lt;/li&gt;
  &lt;li&gt;Reduce costs by removing the data warehouse&lt;/li&gt;
  &lt;li&gt;Deploy with ease either locally, on-premise, in the cloud, or all 3&lt;/li&gt;
  &lt;li&gt;Eliminate software expenses with a fully free and open-source stack&lt;/li&gt;
  &lt;li&gt;Maintain high performance with modern software like DuckDB and increasingly powerful single-node compute instances&lt;/li&gt;
  &lt;li&gt;Achieve self-sufficiency by completing an end-to-end proof of concept on your laptop&lt;/li&gt;
  &lt;li&gt;Enable development best practices by integrating with GitHub&lt;/li&gt;
  &lt;li&gt;Enhance security by (optionally) running entirely locally or on-premise&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you contribute to an open-source community or provide a product within the Modern Data Stack, there is an additional benefit!&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Increase adoption of your tool by providing a free and self-contained example stack
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/dagster-io/dagster/blob/master/examples/project_fully_featured/README.md&quot;&gt;Dagster&#39;s example project&lt;/a&gt; uses DuckDB for this already!&lt;/li&gt;
      &lt;li&gt;Reach out on the DuckDB &lt;a href=&quot;https://twitter.com/duckdb?s=20&amp;amp;t=yBKUNLGHVZGEj1jL-P_PsQ&quot;&gt;Twitter&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb/discussions&quot;&gt;GitHub&lt;/a&gt;, or &lt;a href=&quot;https://discord.com/invite/tcvwpjfnZx&quot;&gt;Discord&lt;/a&gt;, or the &lt;a href=&quot;https://www.getdbt.com/community/join-the-community/&quot;&gt;dbt slack&lt;/a&gt; to share an example using your tool with the community!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;trade-offs&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#trade-offs&quot;&gt;Trade-offs&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;One key component of the MDS is the unlimited scalability of compute. How does that align with the MDS-in-a-box approach? Today, cloud computing instances can vertically scale significantly more than in the past (for example, &lt;a href=&quot;https://aws.amazon.com/ec2/instance-types/high-memory/&quot;&gt;224 cores and 24 TB of RAM on AWS&lt;/a&gt;!). Laptops are more powerful than ever. Now that new OLAP tools like DuckDB can take better advantage of that compute, horizontal scaling is no longer necessary for many analyses! Also, this MDS-in-a-box can be duplicated with ease to as many boxes as needed if partitioned by data subject area. So, while infinite compute is sacrificed, significant scale is still easily achievable.&lt;/p&gt;

&lt;p&gt;Due to this tradeoff, this approach is more of an “Open Source Analytics Stack in a box” than a traditional MDS. It sacrifices infinite scale for significant simplification and the other benefits above.&lt;/p&gt;
      &lt;h2 id=&quot;choosing-a-problem&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#choosing-a-problem&quot;&gt;Choosing a Problem&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Given that the NBA season is starting soon, a monte carlo type simulation of the season is both topical and well-suited for analytical SQL. This is a particularly great scenario to test the limits of DuckDB because it only requires simple inputs and easily scales out to massive numbers of records. This entire project is held in a GitHub repo, which you can find &lt;a href=&quot;https://www.github.com/matsonj/nba-monte-carlo&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;building-the-environment&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#building-the-environment&quot;&gt;Building the Environment&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The detailed steps to build the project can be found in the repo, but the high-level steps will be repeated here. As a note, Windows Subsystem for Linux (WSL) was chosen to support Apache Superset, but the other components of this stack can run directly on any operating system. Thankfully, using Linux on Windows has become very straightforward.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Install Ubuntu 20.04 on WSL.&lt;/li&gt;
  &lt;li&gt;Upgrade your packages (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo apt update&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;Install python.&lt;/li&gt;
  &lt;li&gt;Clone the git repo.&lt;/li&gt;
  &lt;li&gt;Run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make build&lt;/code&gt; and then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make run&lt;/code&gt; in the terminal.&lt;/li&gt;
  &lt;li&gt;Create super admin user for Superset in the terminal, then login and configure the database.&lt;/li&gt;
  &lt;li&gt;Run test queries in superset to check your work.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;meltano-as-a-wrapper-for-pipeline-plugins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#meltano-as-a-wrapper-for-pipeline-plugins&quot;&gt;Meltano as a Wrapper for Pipeline Plugins&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this example, &lt;a href=&quot;https://meltano.com/&quot;&gt;Meltano&lt;/a&gt; pulls together multiple bits and pieces to allow the pipeline to be run with a single statement. The first part is the tap (extractor) which is &#39;&lt;a href=&quot;https://hub.meltano.com/extractors/tap-spreadsheets-anywhere/&quot;&gt;tap-spreadsheets-anywhere&lt;/a&gt;&#39;. This tap allows us to get flat data files from various sources. It should be noted that DuckDB can consume directly from flat files (locally and over the network), or SQLite and PostgreSQL databases. However, this tap was chosen to provide a clear example of getting static data into your database that can easily be configured in the meltano.yml file. Meltano also becomes more beneficial as the complexity of your data sources increases.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;extractors&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;tap-spreadsheets-anywhere&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ets&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pip_url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;git+https://github.com/ets/tap-spreadsheets-anywhere.git&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# data sources are configured inside of this extractor&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The next bit is the target (loader), &#39;&lt;a href=&quot;https://github.com/jwills/target-duckdb&quot;&gt;target-duckdb&lt;/a&gt;&#39;. This target can take data from any Meltano tap and load it into DuckDB. Part of the beauty of this approach is that you don&#39;t have to mess with all the extra complexity that comes with a typical database. DuckDB can be dropped in and is ready to go with zero configuration or ongoing maintenance. Furthermore, because the components and the data are co-located, networking is not a consideration and further reduces complexity.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;na&quot;&gt;loaders&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;target-duckdb&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jwills&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pip_url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;target-duckdb~=0.4&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;filepath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/tmp/mdsbox.db&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;default_target_schema&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;main&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next is the transformer: &#39;&lt;a href=&quot;https://github.com/jwills/dbt-duckdb&quot;&gt;dbt-duckdb&lt;/a&gt;&#39;. dbt enables transformations using a combination of SQL and Jinja templating for approachable SQL-based analytics engineering. The dbt adapter for DuckDB now supports parallel execution across threads, which makes the MDS-in-a-box run even faster. Since the bulk of the work is happening inside of dbt, this portion will be described in detail later in the post.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;na&quot;&gt;transformers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;dbt-duckdb&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jwills&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pip_url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;dbt-core~=1.2.0 dbt-duckdb~=1.2.0&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/tmp/mdsbox.db&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lastly, &lt;a href=&quot;https://superset.apache.org/&quot;&gt;Apache Superset&lt;/a&gt; is included as a &lt;a href=&quot;https://hub.meltano.com/utilities/superset/&quot;&gt;Meltano utility&lt;/a&gt; to enable some data querying and visualization. Superset leverages DuckDB&#39;s SQLAlchemy driver, &lt;a href=&quot;https://github.com/Mause/duckdb_engine&quot;&gt;duckdb_engine&lt;/a&gt;, so it can query DuckDB directly as well.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;na&quot;&gt;utilities&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;superset&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apache&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;pip_url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apache-superset==1.5.0 markupsafe==2.0.1 duckdb-engine==0.6.4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With Superset, the engine needs to be configured to open DuckDB in “read-only” mode. Otherwise, only one query can run at a time (simultaneous queries will cause locks). This also prevents refreshing the Superset dashboard while the pipeline is running. In this case, the pipeline runs in under 8 seconds!&lt;/p&gt;
      &lt;h2 id=&quot;wrangling-the-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#wrangling-the-data&quot;&gt;Wrangling the Data&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The NBA schedule was downloaded from basketball-reference.com, and the Draft Kings win totals from Sept 27th were used for win totals. The schedule and win totals make up the entirety of the data required as inputs for this project. Once converted into CSV format, they were uploaded to the GitHub project, and the meltano.yml file was updated to reference the file locations.&lt;/p&gt;
      &lt;h2 id=&quot;loading-sources&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#loading-sources&quot;&gt;Loading Sources&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Once the data is on the web inside of GitHub, Meltano can pull a copy down into DuckDB. With the command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;meltano run tap-spreadsheets-anywhere target-duckdb&lt;/code&gt;, the data is loaded into DuckDB, and ready for transformation inside of dbt.&lt;/p&gt;
      &lt;h2 id=&quot;building-dbt-models&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#building-dbt-models&quot;&gt;Building dbt Models&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;After the sources are loaded, the data is transformed with dbt. First, the source models are created as well as the scenario generator. Then the random numbers for that simulation run are generated – it should be noted that the random numbers are recorded as a table, not a view, in order to allow subsequent re-runs of the downstream models with the graph operators for troubleshooting purposes (i.e. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dbt run -s random_num_gen+&lt;/code&gt;). Once the underlying data is laid out, the simulation begins, first by simulating the regular season, then the play-in games, and lastly the playoffs. Since each round of games has a dependency on the previous round, parallelization is limited in this model, which is reflected in the &lt;a href=&quot;https://matsonj.github.io/nba-monte-carlo/#!/overview/nba_monte_carlo?g_v=1&quot;&gt;dbt DAG&lt;/a&gt;, in this case conveniently hosted on GitHub Pages.&lt;/p&gt;

&lt;p&gt;There are a few more design choices worth calling out:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Simulation tables and summary tables were split into separate models for ease of use / transparency. So each round of the simulation has a sim model and an end model – this allows visibility into the correct parameters (conference, team, elo rating) to be passed into each subsequent round.&lt;/li&gt;
  &lt;li&gt;To prevent overly deep queries, &#39;reg_season_end&#39; and &#39;playoff_sim_r1&#39; have been materialized as tables. While it is slightly slower on build, the performance gains when querying summary tables (i.e. &#39;season_summary&#39;) are more than worth the slowdown. However, it should be noted that even for only 10k sims, the database takes up about 150 MB in disk space. Running at 100k simulations easily expands it to a few GB.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;connecting-superset&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#connecting-superset&quot;&gt;Connecting Superset&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Once the dbt models are built, the data visualization can begin. An admin user must be created in superset in order to log in. The instructions for connecting the database can be found in the GitHub project, as well as a note on how to connect it in &#39;read only mode&#39;.&lt;/p&gt;

&lt;p&gt;There are 2 models designed for analysis, although any number of them can be used. &#39;season_summary&#39; contains various summary statistics for the season, and &#39;reg_season_sim&#39; contains all simulated game results. This second data set produces an interesting histogram chart. In order to build data visualizations in superset, the dataset must be defined first, the chart built, and lastly, the chart assigned to a dashboard.&lt;/p&gt;

&lt;p&gt;Below is an example Superset dashboard containing several charts based on this data. Superset is able to clearly summarize the data as well as display the level of variability within the monte carlo simulation. The duckdb_engine queries can be refreshed quickly when new simulations are run.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/mds_in_a_box/mds_in_a_box_superset_1.png&quot; alt=&quot;mds_in_a_box_superset_1&quot; width=&quot;680&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/mds_in_a_box/mds_in_a_box_superset_2.png&quot; alt=&quot;mds_in_a_box_superset_2&quot; width=&quot;680&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The ecosystem around DuckDB has grown such that it integrates well with the Modern Data Stack. The MDS-in-a-box is a viable approach for smaller data projects, and would work especially well for read-heavy analytics. There were a few other learnings from this experiment. Superset dashboards are easy to construct, but they are not scriptable and must be built in the GUI (the paid hosted version, Preset, does support exporting as YAML). Also, while you can do monte carlo analysis in SQL, it may be easier to do in another language. However, this shows how far you can stretch the capabilities of SQL!&lt;/p&gt;
      &lt;h2 id=&quot;next-steps&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html#next-steps&quot;&gt;Next Steps&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are additional directions to take this project. One next step could be to Dockerize this workflow for even easier deployments. If you want to put together a Docker example, please reach out! Another adjustment to the approach could be to land the final outputs in parquet files, and to read them with in-memory DuckDB connections. Those files could even be landed in an S3-compatible object store (and still read by DuckDB), although that adds complexity compared with the in-a-box approach! Additional MDS components could also be integrated for data quality monitoring, lineage tracking, etc.&lt;/p&gt;

&lt;p&gt;Josh Wills is also in the process of making &lt;a href=&quot;https://github.com/jwills/dbt-duckdb/pull/22&quot;&gt;an interesting enhancement to dbt-duckdb&lt;/a&gt;! Using the &lt;a href=&quot;https://github.com/tobymao/sqlglot&quot;&gt;sqlglot&lt;/a&gt; library, dbt-duckdb would be able to automatically transpile dbt models written using the SQL dialect of other databases (including Snowflake and BigQuery) to DuckDB. Imagine if you could test out your queries locally before pushing to production… Join the DuckDB channel of the &lt;a href=&quot;https://www.getdbt.com/community/join-the-community/&quot;&gt;dbt slack&lt;/a&gt; to discuss the possibilities!&lt;/p&gt;

&lt;p&gt;Please reach out if you use this or another approach to build an MDS-in-a-box! Also, if you are interested in writing a guest post for the DuckDB blog, please reach out on &lt;a href=&quot;https://discord.com/invite/tcvwpjfnZx&quot;&gt;Discord&lt;/a&gt;!&lt;/p&gt;

</description><link>https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html</link><guid isPermaLink="false">https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html</guid><pubDate>Wed, 12 Oct 2022 00:00:00 GMT</pubDate><author>Guest post by Jacob Matson</author></item><item><title>Querying Postgres Tables Directly from DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB can now directly query tables stored in PostgreSQL and speed up complex analytical queries without duplicating data.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/elephant-duck.jpg&quot; alt=&quot;DuckDB goes Postgres&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;PostgreSQL is the world&#39;s most advanced open source database (&lt;a href=&quot;https://www.postgresql.org/&quot;&gt;self-proclaimed&lt;/a&gt;). From its &lt;a href=&quot;https://dsf.berkeley.edu/papers/ERL-M90-34.pdf&quot;&gt;interesting beginnings as an academic DBMS&lt;/a&gt;, it has evolved over the past 30 years into a fundamental workhorse of our digital environment.&lt;/p&gt;

&lt;p&gt;PostgreSQL is designed for traditional &lt;a href=&quot;https://en.wikipedia.org/wiki/Online_transaction_processing&quot;&gt;transactional use cases, &quot;OLTP&quot;&lt;/a&gt;, where rows in tables are created, updated and removed concurrently, and it excels at this. But this design decision makes PostgreSQL far less suitable for &lt;a href=&quot;https://en.wikipedia.org/wiki/Online_analytical_processing&quot;&gt;analytical use cases, &quot;OLAP&quot;&lt;/a&gt;, where large chunks of tables are read to create summaries of the stored data. Yet there are many use cases where both transactional and analytical use cases are important, for example when trying to gain the latest business intelligence insights into transactional data.&lt;/p&gt;

&lt;p&gt;There have been &lt;a href=&quot;https://en.wikipedia.org/wiki/Hybrid_transactional/analytical_processing&quot;&gt;some attempts to build database management systems that do well on both workloads, &quot;HTAP&quot;&lt;/a&gt;, but in general many design decisions between OLTP and OLAP systems are hard trade-offs, making this endeavour difficult. Accepting that &lt;a href=&quot;https://cs.brown.edu/~ugur/fits_all.pdf&quot;&gt;one size does not fit all after all&lt;/a&gt;, systems are often separated, with the transactional application data living in a purpose-built system like PostgreSQL, and a copy of the data being stored in an entirely different DBMS. Using a purpose-built analytical system speeds up analytical queries by several orders of magnitude.&lt;/p&gt;

&lt;p&gt;Unfortunately, maintaining a copy of the data for analytical purposes can be problematic: The copy will immediately be outdated as new transactions are processed, requiring a complex and non-trivial synchronization setup. Storing two copies of the database also will require twice the storage space. For example, OLTP systems like PostgreSQL traditionally use a row-based data representation, and OLAP systems tend to favor a chunked-columnar data representation. You can&#39;t have both without maintaining a copy of the data with all the issues that brings with it. Also, the SQL syntaxes between whatever OLAP system you&#39;re using and Postgres may differ quite significantly.&lt;/p&gt;

&lt;p&gt;But the design space is not as black and white as it seems. For example, the OLAP performance in systems like DuckDB does not only come from a chunked-columnar on-disk data representation. Much of DuckDB&#39;s performance comes from its vectorized query processing engine that is custom-tuned for analytical queries. What if DuckDB was able to somehow &lt;em&gt;read data stored in PostgreSQL&lt;/em&gt;? While it seems daunting, we have embarked on a quest to make just this possible.&lt;/p&gt;

&lt;p&gt;To allow for fast and consistent analytical reads of Postgres databases, we designed and implemented the &quot;Postgres Scanner&quot;. This scanner leverages the &lt;em&gt;binary transfer mode&lt;/em&gt; of the Postgres client-server protocol (See the &lt;a href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#implementation&quot;&gt;Implementation Section&lt;/a&gt; for more details.), allowing us to efficiently transform and use the data directly in DuckDB.&lt;/p&gt;

&lt;p&gt;Among other things, DuckDB&#39;s design is different from conventional data management systems because DuckDB&#39;s query processing engine can run on nearly arbitrary data sources without needing to copy the data into its own storage format. For example, DuckDB can currently directly run queries on &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;Parquet files&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/data/csv/overview.html&quot;&gt;CSV files&lt;/a&gt;, &lt;a href=&quot;https://github.com/duckdb/duckdb-sqlite&quot;&gt;SQLite files&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/guides/python/sql_on_pandas.html&quot;&gt;Pandas&lt;/a&gt;, &lt;a href=&quot;https://duckdb.org/docs/stable/clients/r.html#efficient-transfer&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;https://duckdb.org/docs/stable/clients/julia.html#scanning-dataframes&quot;&gt;Julia&lt;/a&gt; data frames as well as &lt;a href=&quot;https://duckdb.org/docs/stable/guides/python/sql_on_arrow.html&quot;&gt;Apache Arrow sources&lt;/a&gt;. This new extension adds the capability to directly query PostgreSQL tables from DuckDB.&lt;/p&gt;
      &lt;h2 id=&quot;usage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#usage&quot;&gt;Usage&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The Postgres Scanner DuckDB extension source code &lt;a href=&quot;https://github.com/duckdb/duckdb-postgres&quot;&gt;is available on GitHub&lt;/a&gt;, but it is directly installable through DuckDB&#39;s new binary extension installation mechanism. To install, just run the following SQL query once:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSTALL&lt;/span&gt; postgres_scanner&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, whenever you want to use the extension, you need to first load it:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; postgres_scanner&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To make a Postgres database accessible to DuckDB, use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSTGRES_ATTACH&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CALL&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;postgres_attach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;dbname=myshinydb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;postgres_attach&lt;/code&gt; takes a single required string parameter, which is the &lt;a href=&quot;https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;libpq&lt;/code&gt; connection string&lt;/a&gt;. For example you can pass &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;dbname=myshinydb&#39;&lt;/code&gt; to select a different database name. In the simplest case, the parameter is just &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&#39;&#39;&lt;/code&gt;. There are three additional named parameters to the function:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;source_schema&lt;/code&gt; the name of a non-standard schema name in Postgres to get tables from. Default is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;public&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;overwrite&lt;/code&gt; whether we should overwrite existing views in the target schema, default is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter_pushdown&lt;/code&gt; whether filter predicates that DuckDB derives from the query should be forwarded to Postgres, defaults to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt;. See below for a discussion of what this parameter controls.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The tables in the database are registered as views in DuckDB, you can list them with&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;show_tables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then you can query those views normally using SQL. Again, no data is being copied, this is just a virtual view on the tables in your Postgres database.&lt;/p&gt;

&lt;p&gt;If you prefer to not attach all tables, but just query a single table, that is possible using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSTGRES_SCAN&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;POSTGRES_SCAN_PUSHDOWN&lt;/code&gt; table-producing functions directly, e.g.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;postgres_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;dbname=myshinydb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;public&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;mytable&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;postgres_scan_pushdown&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;dbname=myshinydb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;public&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;mytable&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Both functions takes three unnamed string parameters, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;libpq&lt;/code&gt; connection string (see above), a Postgres schema name and a table name. The schema name is often &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;public&lt;/code&gt;. As the name suggest, the variant with &quot;pushdown&quot; in the name will perform selection pushdown as described below.&lt;/p&gt;

&lt;p&gt;The Postgres scanner will only be able to read actual tables, views are not supported. However, you can of course recreate such views within DuckDB, the syntax should be exactly the same!&lt;/p&gt;
      &lt;h2 id=&quot;implementation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#implementation&quot;&gt;Implementation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;From an architectural perspective, the Postgres Scanner is implemented as a plug-in extension for DuckDB that provides a so-called table scan function (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;postgres_scan&lt;/code&gt;) in DuckDB. There are many such functions in DuckDB and in extensions, such as the Parquet and CSV readers, Arrow readers etc.&lt;/p&gt;

&lt;p&gt;The Postgres Scanner uses the standard &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;libpq&lt;/code&gt; library, which it statically links in. Ironically, this makes the Postgres Scanner easier to install than the other Postgres clients. However, Postgres&#39; normal client-server protocol is &lt;a href=&quot;https://ir.cwi.nl/pub/26415/p852-muehleisen.pdf&quot;&gt;quite slow&lt;/a&gt;, so we spent quite some time optimizing this. As a note, DuckDB&#39;s &lt;a href=&quot;https://github.com/duckdb/sqlite_scanner&quot;&gt;SQLite Scanner&lt;/a&gt; does not face this issue, as SQLite is also an in-process database.&lt;/p&gt;

&lt;p&gt;We actually implemented a prototype direct reader for Postgres&#39; database files, but while performance was great, there is the issue that committed but not yet checkpointed data would not be stored in the heap files yet. In addition, if a checkpoint was currently running, our reader would frequently overtake the checkpointer, causing additional inconsistencies. We abandoned that approach since we want to be able to query an actively used Postgres database and believe that consistency is important. Another architectural option would have been to implement a DuckDB Foreign Data Wrapper (FDW) for Postgres similar to &lt;a href=&quot;https://github.com/alitrack/duckdb_fdw&quot;&gt;duckdb_fdw&lt;/a&gt; but while this could improve the protocol situation, deployment of a postgres extension is quite risky on production servers so we expect few people will be able to do so.&lt;/p&gt;

&lt;p&gt;Instead, we use the rarely-used &lt;em&gt;binary transfer mode&lt;/em&gt; of the Postgres client-server protocol. This format is quite similar to the on-disk representation of Postgres data files and avoids some of the otherwise expensive to-string and from-string conversions. For example, to read a normal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int32&lt;/code&gt; from the protocol message, all we need to do is to swap byte order (&lt;a href=&quot;https://linux.die.net/man/3/ntohl&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ntohl&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The Postgres scanner connects to PostgreSQL and issues a query to read a particular table using the binary protocol. In the simplest case (see optimizations below), to read a table called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt;, we internally run the query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;STDOUT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query will start reading the contents of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; and write them directly to the protocol stream in binary format.&lt;/p&gt;
      &lt;h3 id=&quot;parallelization&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#parallelization&quot;&gt;Parallelization&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB supports automatic intra-query parallelization through pipeline parallelism, so we also want to parallelize scans on Postgres tables: Our scan operator opens multiple connections to Postgres, and reads subsets of the table from each. To efficiently split up reading the table, we use Postgres&#39; rather obscure &lt;em&gt;TID Scan&lt;/em&gt; (Tuple ID) operator, which allows a query to surgically read a specified range of tuple IDs from a table. The Tuple IDs have the form &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(page, tuple)&lt;/code&gt;. We parallelize our scan of a Postgres table based on database page ranges expressed in TIDs. Each scan task reads 1000 pages currently. For example, to read a table consisting of 2500 pages, we would start three scan tasks with TID ranges &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[(0,0),(999,0)]&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[(1000,0),(1999,0)]&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[(2000,0),(UINT32_MAX,0)]&lt;/code&gt;. Having an open bound for the last range is important because the number of pages (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relpages&lt;/code&gt;) in a table in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pg_class&lt;/code&gt; table is merely an estimate. For a given page range (P_MIN, P_MAX), our query from above is thus extended to look like this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
     &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
   &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; 
   &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; 
     &lt;span class=&quot;n&quot;&gt;ctid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;(P_MIN,0)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;(P_MAX,0)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt;
   &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;STDOUT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This way, we can efficiently scan the table in parallel while not relying on the schema in any way. Because page size is fixed in Postgres, this also has the added bonus of equalizing the effort to read a subset of the page independent of the number of columns in each row.&lt;/p&gt;

&lt;p&gt;&quot;But wait!&quot;, you will say, according to the documentation the tuple ID is not stable and may be changed by operations such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VACUUM ALL&lt;/code&gt;. How can you use it for synchronizing parallel scans? This is true, and could be problematic, but we found a solution:&lt;/p&gt;
      &lt;h3 id=&quot;transactional-synchronization&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#transactional-synchronization&quot;&gt;Transactional Synchronization&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Of course a transactional database such as Postgres is expected to run transactions while we run our table scans for analytical purposes. Therefore we need to address concurrent changes to the table we are scanning in parallel. We solve this by first creating a new read-only transaction in DuckDB&#39;s bind phase, where query planning happens. We leave this transaction running until we are completely done reading the table. We use yet another little-known Postgres feature, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pg_export_snapshot()&lt;/code&gt;, which allows us to get the current transaction context in one connection, and then import it into our parallel read connections using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SET TRANSACTION SNAPSHOT ...&lt;/code&gt;. This way, all connections related to one single table scan will see the table state exactly as it appeared at the very beginning of our scan throughout the potentially lengthy read process.&lt;/p&gt;
      &lt;h3 id=&quot;projection-and-selection-push-down&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#projection-and-selection-push-down&quot;&gt;Projection and Selection Push-Down&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;DuckDB&#39;s query optimizer moves selections (filters on rows) and projections (removal of unused columns) as low as possible in the query plan (push down), and even instructs the lowermost scan operators to perform those operations if they support them. For the Postgres scanner, we have implemented both push down variants. Projections are rather straightforward – we can immediately instruct Postgres to only retrieve the columns the query is using. This of course also reduces the number of bytes that need to be transferred, which speeds up queries. For selections, we construct a SQL filter expression from the pushed down filters. For example, if we run a query like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT l_returnflag, l_linestatus FROM lineitem WHERE l_shipdate &amp;lt; &#39;1998-09-02&#39;&lt;/code&gt; through the Postgres scanner, it would run the following queries:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;nv&quot;&gt;&quot;l_returnflag&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;&quot;l_linestatus&quot;&lt;/span&gt; 
  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;public&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;lineitem&quot;&lt;/span&gt; 
  &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;ctid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;(0,0)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;(1000,0)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;l_shipdate&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1998-09-02&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;l_shipdate&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;IS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;STDOUT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;BINARY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- and so on&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see, the projection and selection pushdown has expanded the queries ran against Postgres accordingly. Using the selection push-down is optional. There may be cases where running a filter in Postgres is actually slower than transferring the data and running the filter in DuckDB, for example when filters are not very selective (many rows match).&lt;/p&gt;
      &lt;h2 id=&quot;performance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#performance&quot;&gt;Performance&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To investigate the performance of the Postgres Scanner, we ran the well-known TPC-H benchmark on DuckDB using its internal storage format, on Postgres also using its internal format and with DuckDB reading from Postgres using the new Postgres Scanner. We used DuckDB 0.5.1 and Postgres 14.5, all experiments were run on a MacBook Pro with an M1 Max CPU. The experiment script &lt;a href=&quot;https://gist.github.com/hannes/d2f0914a8e0ed0fb235040b9981c58a7&quot;&gt;is available&lt;/a&gt;. We run &quot;scale factor&quot; 1 of TPCH, creating a dataset of roughly 1 GB with ca. 6 M rows in the biggest table, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt;. Each of the 22 TPC-H benchmark queries was run 5 times, and we report the median run time in seconds. The time breakdown is given in the following table.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;query&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;duckdb&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;duckdb/postgres&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;postgres&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.74&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.20&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.18&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.55&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.52&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.70&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.24&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.56&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.74&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.18&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.34&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.61&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.41&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.35&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.27&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.36&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.18&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.01&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.19&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.36&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.46&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;16&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.09&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;17&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.75&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;gt; 60.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.08&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.97&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;19&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.32&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.37&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;gt; 60.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;21&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.09&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.53&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.35&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;22&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.15&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.15&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Stock Postgres is not able to finish queries 17 and 20 within a one-minute timeout because of correlated subqueries containing a query on the lineitem table. For the other queries, we can see that DuckDB with the Postgres Scanner not only finished all queries, it also was faster than stock Postgres on roughly half of them, which is astonishing given that DuckDB has to read its input data from Postgres through the client/server protocol as described above. Of course, stock DuckDB is still 10× faster with its own storage, but as discussed at the very beginning of this post this requires the data to be imported there first.&lt;/p&gt;
      &lt;h2 id=&quot;other-use-cases&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#other-use-cases&quot;&gt;Other Use Cases&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The Postgres Scanner can also be used to combine live Postgres data with pre-cached data in creative ways. This is especially effective when dealing with an append only table, but could also be used if a modified date column is present. Consider the following SQL template:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table_duckdb_cache&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;postgres_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;dbname=myshinydb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;public&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;my_table&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;incrementing_id_column&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;incrementing_id_column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table_duckdb_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_table_duckdb_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This provides faster query performance with fully up to date query results, at the cost of data duplication. It also avoids complex data replication technologies.&lt;/p&gt;

&lt;p&gt;DuckDB has built-in support to write query results to Parquet files. The Postgres scanner provides a rather simple way to write Postgres tables to Parquet files, it can even directly write to S3 if desired. For example,&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;postgres_scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;dbname=myshinydb&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;public&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitem&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitem.parquet&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;FORMAT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/09/30/postgres-scanner.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s new Postgres Scanner extension can read PostgreSQL&#39;s tables while PostgreSQL is running and compute the answers to complex OLAP SQL queries often faster than PostgreSQL itself can without the need to duplicate data. The Postgres Scanner is currently in preview and we are curious to hear what you think.
If you find any issues with the Postgres Scanner, please &lt;a href=&quot;https://github.com/duckdb/duckdb-postgres/issues&quot;&gt;report them&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2022/09/30/postgres-scanner.html</link><guid isPermaLink="false">https://duckdb.org/2022/09/30/postgres-scanner.html</guid><pubDate>Fri, 30 Sep 2022 00:00:00 GMT</pubDate><author>Hannes Mühleisen</author></item><item><title>Persistent Storage of Adaptive Radix Trees in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB uses Adaptive Radix Tree (ART) Indexes to enforce constraints and to speed up query filters. Up to this point, indexes were not persisted, causing issues like loss of indexing information and high reload times for tables with data constraints. We now persist ART Indexes to disk, drastically diminishing database loading times (up to orders of magnitude), and we no longer lose track of existing indexes. This blog post contains a deep dive into the implementation of ART storage, benchmarks, and future work. Finally, to better understand how our indexes are used, I&#39;m asking you to answer the following &lt;a href=&quot;https://forms.gle/eSboTEp9qpP7ybz98&quot;&gt;survey&lt;/a&gt;. It will guide us when defining our future roadmap.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/pedro-art.jpg&quot; alt=&quot;DuckDB ART&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;DuckDB uses &lt;a href=&quot;https://db.in.tum.de/~leis/papers/ART.pdf&quot;&gt;ART Indexes&lt;/a&gt; to keep primary key (PK), foreign key (FK), and unique constraints. They also speed up point-queries, range queries (with high selectivity), and joins. Before the bleeding edge version (or V0.4.1, depending on when you are reading this post), DuckDB did not persist ART indexes on disk. When storing a database file, only the information about existing PKs and FKs would be stored, with all other indexes being transient and non-existing when restarting the database. For PKs and FKs, they would be fully reconstructed when reloading the database, creating the inconvenience of high-loading times.&lt;/p&gt;

&lt;p&gt;A lot of scientific work has been published regarding ART Indexes, most notably on &lt;a href=&quot;https://db.in.tum.de/~leis/papers/artsync.pdf&quot;&gt;synchronization&lt;/a&gt;, &lt;a href=&quot;https://dbis.uibk.ac.at/sites/default/files/2018-06/hot-height-optimized.pdf&quot;&gt;cache-efficiency&lt;/a&gt;, and &lt;a href=&quot;https://bigdata.uni-saarland.de/publications/ARCD15.pdf&quot;&gt;evaluation&lt;/a&gt;. However, up to this point, no public work exists on serializing and buffer managing an ART Tree. &lt;a href=&quot;https://twitter.com/muehlbau/status/1548024479971807233&quot;&gt;Some say&lt;/a&gt; that Hyper, the database in Tableau, persists ART indexes, but again, there is no public information on how that is done.&lt;/p&gt;

&lt;p&gt;This blog post will describe how DuckDB stores and loads ART indexes. In particular, how the index is lazily loaded (i.e., an ART node is only loaded into memory when necessary). In the &lt;a href=&quot;https://duckdb.org/2022/07/27/art-storage.html#art-index&quot;&gt;ART Index Section&lt;/a&gt;, we go through what an ART Index is, how it works, and some examples. In the &lt;a href=&quot;https://duckdb.org/2022/07/27/art-storage.html#art-in-duckdb&quot;&gt;ART in DuckDB Section&lt;/a&gt;, we explain why we decided to use an ART index in DuckDB where it is used and discuss the problems of not persisting ART indexes. In the &lt;a href=&quot;https://duckdb.org/2022/07/27/art-storage.html#art-storage&quot;&gt;ART Storage Section&lt;/a&gt;, we explain how we serialize and buffer manage ART Indexes in DuckDB. In the &lt;a href=&quot;https://duckdb.org/2022/07/27/art-storage.html#benchmarks&quot;&gt;Benchmarks Section&lt;/a&gt;, we compare DuckDB v0.4.0 (before ART Storage) with the bleeding edge version of DuckDB. We demonstrate the difference in the loading costs of PKs and FKs in both versions and the differences between lazily loading an ART index and accessing a fully loaded ART Index. Finally, in the &lt;a href=&quot;https://duckdb.org/2022/07/27/art-storage.html#roadmap&quot;&gt;Road Map section&lt;/a&gt;, we discuss the drawbacks of our current implementations and the plans on the list of ART index goodies for the future.&lt;/p&gt;
      &lt;h2 id=&quot;art-index&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#art-index&quot;&gt;ART Index&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Adaptive Radix Trees are, in essence, &lt;a href=&quot;https://en.wikipedia.org/wiki/Trie&quot;&gt;Tries&lt;/a&gt; that apply vertical and horizontal compression to create compact index structures.&lt;/p&gt;
      &lt;h3 id=&quot;trie&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#trie&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Trie&quot;&gt;Trie&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Tries are tree data structures, where each tree level holds information on part of the dataset. They are commonly exemplified with strings. In the figure below, you can see a Trie representation of a table containing the strings &quot;pedro&quot;, &quot;paulo&quot; and &quot;peri&quot; The root node represents the first character &quot;p&quot; with children &quot;a&quot; (from paulo) and &quot;e&quot; (from pedro and peri), and so on.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/string-trie.png&quot; alt=&quot;String Trie&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;To perform lookups on a Trie, you must match each character of the key to the current level of the Trie. For example, if you search for pedro, you must check the root contains the letter p. If it does, you check if any of its children contains the letter e, up to the point you reach a leaf node containing the pointer to the tuple that holds this string. (See figure below).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/lookup-trie.png&quot; alt=&quot;Lookup Trie&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The main advantage of Tries is that they have O(k) lookups, meaning that in the worst case, the lookup cost will equal the length of the strings.&lt;/p&gt;

&lt;p&gt;In reality, Tries can also be used for numeric data types. However, storing them character by character-like strings would be wasteful. Take, for example, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UBIGINT&lt;/code&gt; data type. In reality, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UBIGINT&lt;/code&gt; is a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;uint64_t&lt;/code&gt; which takes 64 bits (i.e., 8 bytes) of space. The maximum value of a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;uint64_t&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;18,446,744,073,709,551,615&lt;/code&gt;. Hence if we represented it, like in the example above, we would need 17 levels on the Trie. In practice, Tries are created on a bit fan-out, which tells how many bits are represented per level of the Trie. A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;uint64_t&lt;/code&gt; Trie with 8-bit fan-out would have a maximum of 8 levels, each representing a byte.&lt;/p&gt;

&lt;p&gt;To have more realistic examples, from this point onwards, all depictions in this post will be with bit representations. In DuckDB, the fan-out is always 8 bits. However, for simplicity, the following examples in this blog post will have a fan-out of 2 bits.&lt;/p&gt;

&lt;p&gt;In the example below, we have a Trie that indexes the values 7, 10, and 12. You can also see the binary representation of each value on the table next to them. Each node consists of the bits 0 and 1, with a pointer next to them. This pointer can either be set (represented by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt;) or null (represented by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ø&lt;/code&gt;). Similar to the string Trie we had before, each level of the Trie will represent two bits, with the pointer next to these bits pointing to their children. Finally, the leaves point to the actual data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/2-bit-trie.png&quot; alt=&quot;2-bit Trie&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;One can quickly notice that this Trie representation is wasteful on two different fronts. First, many nodes only have one child (i.e., one path), which could be collapsed by vertical compression (i.e., Radix Tree). Second, many nodes have null pointers, storing space without any information in them, which could be resolved with horizontal compression.&lt;/p&gt;
      &lt;h3 id=&quot;vertical-compression-ie-radix-trees&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#vertical-compression-ie-radix-trees&quot;&gt;Vertical Compression (i.e., &lt;/a&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Radix_tree&quot;&gt;Radix Trees&lt;/a&gt;)
        
      &lt;/h3&gt;
    

&lt;p&gt;The basic idea of vertical compression is that we collapse paths with nodes that only have one child. To support this, nodes store a prefix variable containing the collapsed path to that node. You can see a representation of this in the figure below. For example, one can see that the first four nodes have only one child. These nodes can be collapsed to the third node (i.e., the first one that bifurcates) as a prefix path. When performing lookups, the key must match all values included in the prefix path.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/2-bit-collapse-trie.png&quot; alt=&quot;2-bit Radix Tree (Collapsing)&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Below you can see the resulting Trie after vertical compression. This Trie variant is commonly known as a Radix Tree. Although a lot of wasted space has already been saved with this Trie variant, we still have many nodes with unset pointers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/2-bit-collapse-trie-result.png&quot; alt=&quot;2-bit Radix Tree&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h3 id=&quot;horizontal-compression-ie-art&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#horizontal-compression-ie-art&quot;&gt;Horizontal Compression (i.e., ART)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To fully understand the design decisions behind ART indexes, we must first extend the 2-bit fan-out to 8-bits, the commonly found fan-out for database systems.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/8-bit-radix-tree.png&quot; alt=&quot;8-bit Radix Tree&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Below you can see the same nodes as before in a TRIE node of 8 bits. In reality, these nodes will store (2^8) 256 pointers, with the key being the array position of the pointer. In the case depicted by this example, we have a node with (256 pointers * 8 bytes) 2048 byte size while only actually utilizing  24 bytes (3 pointers * 8 bytes), which means that 2016 bytes are entirely wasted. To avoid this situation. ART indexes are composed of 4 different node types that depend on how full the current node is. Below I quickly describe each node with a graphical representation of them. In the graphical representation, I present a conceptual visualization of the node and an example with keys 0,4 and 255.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Node 4&lt;/strong&gt;: Node 4 holds up to 4 different keys. Each key is stored in a one-byte array, with one pointer per key. With its total size being 40 bytes (4*1 + 4*8). Note that the pointer array is aligned with the key array (e.g., key 0 is in position 0 of the keys array, hence its pointer is in position 0 of the pointers array)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/art-4.png&quot; alt=&quot;Art Node 4&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Node 16&lt;/strong&gt; : Node 16 holds up to 16 different keys. Like node 4, each key is stored in a one-byte array, with one pointer per key. With its total size being 144 bytes (16*1 + 16*8). Like Node 4, the pointer array is aligned with the key array.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/art-16.png&quot; alt=&quot;Art Node 16&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Node 48&lt;/strong&gt; : Node 48 holds up to 48 different keys. When a key is present in this node, the one-byte array position representing that key will hold an index into the pointer array that points to the child of that key. Its total size is 640 bytes (256*1 + 48*8). Note that the pointer array and the key array are not aligned anymore. The key array points to the position in the pointer array where the pointer of that key is stored (e.g., the key 255 in the key array is set to 2 because the position 2 of the pointer array points to the child pertinent to that key).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/art-48.png&quot; alt=&quot;Art Node 48&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Node 256&lt;/strong&gt;: Node 256 holds up to 256 different keys, hence all possible values in the distribution. It only has a pointer vector, if the pointer is set, the key exists, and it points to its child. Its total size is 2048 bytes (256 pointers * 8 bytes).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/art-256.png&quot; alt=&quot;Art Node 256&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;For the example in the previous section, we could use a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Node 4&lt;/code&gt; instead of a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Node 256&lt;/code&gt; to store the keys, since we only have 3 keys present. Hence it would look like the following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/art-index-example.png&quot; alt=&quot;Art Index Example&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;art-in-duckdb&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#art-in-duckdb&quot;&gt;ART in DuckDB&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When considering which index structure to implement in DuckDB, we wanted a structure that could be used to keep PK/FK/Unique constraints while also being able to speed up range queries and Joins. Database systems commonly implement &lt;a href=&quot;https://en.wikipedia.org/wiki/Hash_table&quot;&gt;Hash-Tables&lt;/a&gt; for constraint checks and &lt;a href=&quot;https://en.wikipedia.org/wiki/B%2B_tree&quot;&gt;BP-Trees&lt;/a&gt; for range queries. However, we saw in ART Indexes an opportunity to diminish the code complexity by having one data structures for two use cases. The main characteristics that ART Index provides that we take advantage of are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Compact Structure. Since the ART internal nodes are rather small, they can fit in CPU caches, being a more cache-conscious structure than BP-Trees.&lt;/li&gt;
  &lt;li&gt;Fast Point Queries. The worst case for an ART point query is O(k), which is sufficiently fast for constraint checking.&lt;/li&gt;
  &lt;li&gt;No dramatic regression on insertions. Many Hash-Table variants must be rebuilt when they reach a certain size. In practice, one insert might cause a significant regression in time, with a query suddenly taking orders of magnitude more time to complete, with no apparent reason for the user. In the ART, inserts might cause node growths (e.g., a Node 4 might grow to a Node 16), but these are inexpensive.&lt;/li&gt;
  &lt;li&gt;Ability to run range queries. Although the ART does not run range queries as fast as BP-Trees since it must perform tree traversals, where the BP-Tree can scan leaf nodes sequentially, it still presents an advantage over hash tables since these types of queries can be done (Some might argue that you can use Hash Tables for range queries, but meh). This allows us to efficiently use ART for highly selective range queries and index joins.&lt;/li&gt;
  &lt;li&gt;Maintainability. Using one structure for both constraint checks and range queries instead of two is more code efficient and maintainable.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h3 id=&quot;what-is-it-used-for&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#what-is-it-used-for&quot;&gt;What Is It Used For?&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As said previously, ART indexes are mainly used in DuckDB on three fronts.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Data Constraints. Primary key, Foreign Keys, and Unique constraints are all maintained by an ART Index. When inserting data in a tuple with a constraint, this will effectively try to perform an insertion in the ART index and fail if the tuple already exists.&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Insert unique values into ART&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Insert conflicting value in ART will fail&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fk_integers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOREIGN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REFERENCES&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- This insert works normally&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fk_integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- This fails after checking the ART in integers&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fk_integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Range Queries. Highly selective range queries on indexed columns will also use the ART index underneath.&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Insert unique values into ART&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Range queries (if highly selective) will also use the ART index&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Joins. Joins with a small number of matches will also utilize existing ART indexes.&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Optionally you can always force index joins with the following pragma&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;PRAGMA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;force_index_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Insert unique values into ART&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Joins will also use the ART index&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Indexes over expressions. ART indexes can also be used to quickly look up expressions.&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Creates index over the i + j expression&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_index&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USING&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ART&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Uses ART index point query&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integers&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;art-storage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#art-storage&quot;&gt;ART Storage&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are two main constraints when storing ART indexes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The index must be stored in an order that allows for lazy-loading. Otherwise, we would have to fully load the index, including nodes that might be unnecessary to queries that would be executed in that session.&lt;/li&gt;
  &lt;li&gt;It must not increase the node size. Otherwise, we diminish the cache-conscious effectiveness of the ART index.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h3 id=&quot;post-order-traversal&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#post-order-traversal&quot;&gt;Post-Order Traversal&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To allow for lazy loading, we must store all children of a node, collect the information of where each child is stored, and then, when storing the actual node, we store the disk information of each of its children. To perform this type of operation, we do a post-order traversal.&lt;/p&gt;

&lt;p&gt;The post-order traversal is shown in the figure below. The circles in red represent the numeric order where the nodes will be stored. If we start from the root node (i.e., Node 4 with storage order 10), we must first store both children (i.e., Node 16 with storage order 8 and the Leaf with storage order 9). This goes on recursively for each of its children.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/serialization-order.png&quot; alt=&quot;Post Order Traversal Example&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The figure below shows an actual representation of what this would look like in DuckDB&#39;s block format. In DuckDB, data is stored in 256 kB contiguous blocks, with some blocks reserved for metadata and some for actual data. Each block is represented by an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt;. To allow for navigation within a block, they are partitioned by byte offsets hence each block contains 256,000 different offsets&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/block-storage.png&quot; alt=&quot;DuckDB Block Serialization&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;In this example, we have &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Block 0&lt;/code&gt; that stored some of our database metadata. In particular, between offsets 100,000 and 100,200 we store information pertinent to one ART index. This will store information on the index (e.g., name, constraints, expression) and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;Block,Offset&amp;gt;&lt;/code&gt; position of its root node.&lt;/p&gt;

&lt;p&gt;For example, let&#39;s assume we are doing a lookup of the key with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row_ids&lt;/code&gt; stored in the Leaf with storage order 1. We would start by loading the Art Root node on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;Block:2, Offset:220&amp;gt;&lt;/code&gt;, by checking the keys stored in that Node, we would then see we must load the Node 16 at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;Block:2, Offset:140&amp;gt;&lt;/code&gt;, and then finally our Leaf at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;Block:0, Offset:0&amp;gt;&lt;/code&gt;. That means that for this lookup, only these 3 nodes were loaded into memory. Subsequent access to these nodes would only require memory access, while access to different nodes (e.g., Leaf storage order 2) would still result in disk access.&lt;/p&gt;

&lt;p&gt;One major problem with implementing this (de)serialization process is that now we not only have to keep information about the memory address of pointers but also if they are already in memory and if not, what&#39;s the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;Block,Offset&amp;gt;&lt;/code&gt; position they are stored.&lt;/p&gt;

&lt;p&gt;If we stored the Block Id and Offset in new variables, it would dramatically increase the ART node sizes, diminishing its effectiveness as a cache-conscious data structure.&lt;/p&gt;

&lt;p&gt;Take Node 256 as an example. The cost of holding 256 pointers is 2048 bytes (256 pointers * 8 bytes). Let&#39;s say we decide to store the Block Information on a new array like the following:&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BlockPointer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; 
    &lt;span class=&quot;kt&quot;&gt;uint32_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;uint32_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Node256&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Pointers to the child nodes&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;BlockPointer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Node 256 would increase 2048 bytes (256 * (4+4)), causing it to double its current size to 4096 bytes.&lt;/p&gt;
      &lt;h3 id=&quot;pointer-swizzling&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#pointer-swizzling&quot;&gt;Pointer Swizzling&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To avoid the increase in sizes of ART nodes, we decided to implement &lt;a href=&quot;https://en.wikipedia.org/wiki/Pointer_swizzling&quot;&gt;Swizzlable Pointers&lt;/a&gt; and use them instead of regular pointers.&lt;/p&gt;

&lt;p&gt;The idea is that we don&#39;t need all 64 bits (i.e., 48 bits give you an address space of 256 terabyte, supporting any of the current architectures, more &lt;a href=&quot;https://stackoverflow.com/questions/6716946/why-do-x86-64-systems-have-only-a-48-bit-virtual-address-space&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/64-bit_computing&quot;&gt;here&lt;/a&gt;.) in a pointer to point to a memory address (. Hence we can use the most significant bit as a flag (i.e., the Swizzle Flag). 
If the swizzle flag is set, the value in our Swizzlable Pointer is a memory address for the Node. Otherwise, the variable stores the Block Information of where the Node is stored. In the latter case, we use the following 31 bits to store the Block ID and the remaining 32 bits to store the offset.&lt;/p&gt;

&lt;p&gt;In the following figure, you can see a visual representation of DuckDB&#39;s Swizzlable Pointer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/pointer-swizzling.png&quot; alt=&quot;Pointer Swizzling&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;
      &lt;h2 id=&quot;benchmarks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#benchmarks&quot;&gt;Benchmarks&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To evaluate the benefits and disadvantages of our current storage implementation, we run a benchmark (Available at this &lt;a href=&quot;https://colab.research.google.com/drive/1lidiFNswQfxdmYlsufXUT80IFpyluEF3?usp=sharing&quot;&gt;Colab Link&lt;/a&gt;), where we create a table containing 50,000,000 integral elements with a primary key constraint on top of them.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;vault.db&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CREATE TABLE integers (x INTEGER PRIMARY KEY)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;INSERT INTO integers SELECT * FROM range(50000000)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We run this benchmark on two different versions of DuckDB, one where the index is not stored (i.e., v0.4.0), which means it is always in memory and fully reconstructed at a database restart, and another one where the index is stored (i.e., bleeding-edge version), using the lazy-loading technique described previously.&lt;/p&gt;
      &lt;h3 id=&quot;storing-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#storing-time&quot;&gt;Storing Time&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We first measure the additional cost of serializing our index.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Storage time: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Storage Time&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Reconstruction&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.99&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Storage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18.97&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see storing the index is 2x more expensive than not storing the index. The reason is that our table consists of one column with 50,000,000 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int32_t&lt;/code&gt; values. However, when storing the ART, we also store 50,000,000 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int64_t&lt;/code&gt; values for their respective &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row_ids&lt;/code&gt; in the leaves. This increase in the elements is the main reason for the additional storage cost.&lt;/p&gt;
      &lt;h3 id=&quot;load-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#load-time&quot;&gt;Load Time&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We now measure the loading time of restarting our database.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;vault.db&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Load time: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Reconstruction&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Storage&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.06&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here we can see a two-order magnitude difference in the times of loading the database. This difference is basically due to the complete reconstruction of the ART index during loading. In contrast, in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Storage&lt;/code&gt; version, only the metadata information about the ART index is loaded at this point.&lt;/p&gt;
      &lt;h3 id=&quot;query-time-cold&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#query-time-cold&quot;&gt;Query Time (Cold)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We now measure the cold query time (i.e., the Database has just been restarted, which means that in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Storage&lt;/code&gt; version, the index does not exist in memory yet.) of running point queries on our index. We run 5000 point queries, equally spaced on 10000 elements in our distribution. We use this value to always force the point queries to load a large number of unused nodes.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;times&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT x FROM integers WHERE x = &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/cold-run.png&quot; alt=&quot;Cold Run&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;In general, each query is 3x more expensive in the persisted storage format. This is due to two main reasons:
1) Creating the nodes. In the storage version, we do create the nodes lazily, which means that, for each node, all parameters must be allocated, and values like keys and prefixes are loaded. 
2) Block Pinning. At every node, we must pin and unpin the blocks where they are stored.&lt;/p&gt;
      &lt;h3 id=&quot;query-time-hot&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#query-time-hot&quot;&gt;Query Time (Hot)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In this experiment, we execute the same queries as in the previous section.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/hot-run.png&quot; alt=&quot;Hot Run&quot; width=&quot;800&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The times in both versions are comparable since all the nodes in the storage version are already set in memory.
In conclusion, when stored indexes are in active use, they present similar performance to fully in-memory indexes.&lt;/p&gt;
      &lt;h2 id=&quot;future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#future-work&quot;&gt;Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;ART index storage has been a long-standing issue in DuckDB, with multiple users claiming it a missing feature that created an impediment for them to use DuckDB. Although now storing and lazily loading ART indexes is possible, there are many future paths we can still pursue to make the ART-Index more performant. Here I list what I believe are the most important next steps:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Caching Pinned Blocks. In our current implementation, blocks are constantly pinned and unpinned, even though blocks can store multiple nodes and are most likely reused continuously through lookups. Smartly caching them will result in drastic savings for queries that trigger node loading.&lt;/li&gt;
  &lt;li&gt;Bulk Loading. Our ART-Index currently does not support bulk loading. This means that nodes will be constantly resized when creating an index over a column since elements will be inserted one by one. If we bulk-load the data, we can know exactly which Nodes we must create for that dataset, hence avoiding these frequent resizes.&lt;/li&gt;
  &lt;li&gt;Bulk Insertion. When performing bulk insertion, a similar problem as bulk-loading would happen. A possible solution would be to create a new ART index with Bulk-Loading and then merge it with the existing Art Index&lt;/li&gt;
  &lt;li&gt;Vectorized Lookups/Inserts. DuckDB utilized a vectorized execution engine. However, both our ART lookups and inserts still follow a tuple-at-a-time model.&lt;/li&gt;
  &lt;li&gt;Updatable Index Storage. In our current implementation, ART-Indexes are fully invalidated from disk and stored again. This causes an unnecessary increase in storage time on subsequent storage. Updating nodes directly into disk instead of entirely rewriting the index could drastically decrease future storage costs. In other words, indexes are constantly completely stored at every checkpoint.&lt;/li&gt;
  &lt;li&gt;Combined Pointer/Row Id Leaves. Our current leaf node format allows for storing values that are repeated over multiple tuples. However, since ART indexes are commonly used to keep unique key constraints (e.g., Primary Keys), and a unique &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row_id&lt;/code&gt; fits in the same pointer size space, a lot of space can be saved by using the child pointers to point to the actual &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row_id&lt;/code&gt; instead of creating an actual leaf node that only stores one &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row_id&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;roadmap&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/07/27/art-storage.html#roadmap&quot;&gt;Roadmap&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;blockquote&gt;
  &lt;p&gt;It&#39;s tough to make predictions, especially about the future&lt;br&gt;
– Yogi Berra&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Art Indexes are a core part of both constraint enforcement and keeping access speed up in DuckDB. And as depicted in the previous section, there are many distinct paths we can take in our bag of ART goodies, with advantages for completely different use cases.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/ART/want.jpeg&quot; alt=&quot;We want you&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;To better understand how our indexes are used, it would be extremely helpful if you could answer the following &lt;a href=&quot;https://forms.gle/eSboTEp9qpP7ybz98&quot;&gt;survey&lt;/a&gt; created by one of our MSc students.&lt;/p&gt;

</description><link>https://duckdb.org/2022/07/27/art-storage.html</link><guid isPermaLink="false">https://duckdb.org/2022/07/27/art-storage.html</guid><pubDate>Wed, 27 Jul 2022 00:00:00 GMT</pubDate><author>Pedro Holanda</author></item><item><title>Range Joins in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB has fully parallelized range joins that can efficiently join millions of range predicates.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Range intersection joins are an important operation in areas such as
&lt;a href=&quot;https://www2.cs.arizona.edu/~rts/tdbbook.pdf&quot;&gt;temporal analytics&lt;/a&gt;,
and occur when two inequality conditions are present in a join predicate.
Database implementations often rely on slow &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N^2)&lt;/code&gt; algorithms that compare every pair of rows
for these operations.
Instead, DuckDB leverages its fast sorting logic to implement two highly optimized parallel join operators
for these kinds of range predicates, resulting in 20-30× faster queries.
With these operators, DuckDB can be used effectively in more time-series-oriented use cases.&lt;/p&gt;
      &lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Joining tables row-wise is one of the fundamental and distinguishing operations of the relational model.
A join connects two tables horizontally using some Boolean condition called a &lt;em&gt;predicate&lt;/em&gt;.
This sounds straightforward, but how fast the join can be performed depends on the expressions in the predicate.
This has lead to the creation of different join algorithms that are optimized for different predicate types.&lt;/p&gt;

&lt;p&gt;In this post, we will explain several join algorithms and their capabilities.
In particular, we will describe a newly added &quot;range join&quot; algorithm
that makes connecting tables on overlapping time intervals or multiple ordering conditions much faster.&lt;/p&gt;
      &lt;h3 id=&quot;flight-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#flight-data&quot;&gt;Flight Data&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;No, this part isn&#39;t about ducks, but about air group flight statistics from the Battlestar Galactica reboot.
We have a couple of tables we will be using: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pilots&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Crafts&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Missions&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Battles&lt;/code&gt;.
Some data was lost when the fleet dispersed, but hopefully this is enough to provide some &quot;real life&quot; examples!&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pilots&lt;/code&gt; table contains the pilots and their data that does not change (name, call sign, serial number):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;id&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;callsign&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;serial&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Apollo&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Lee Adama&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;234567&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Starbuck&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Kara Thrace&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;462753&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boomer&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Sharon Valeri&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;312743&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Kat&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Louanne Katraine&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;244977&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Hotdog&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Brendan Costanza&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;304871&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Husker&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;William Adama&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;204971&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Crafts&lt;/code&gt; table contains all the various fighting craft
(ignoring the &lt;a href=&quot;https://en.wikipedia.org/wiki/Ship_of_Theseus&quot;&gt;&quot;Ship Of Theseus&quot;&lt;/a&gt; problem of recycled parts!):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;id&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;type&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;tailno&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Viper&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;N7242C&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Viper&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2794NC&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Raptor&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;312&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Blackbird&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;N9999C&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Missions&lt;/code&gt; table contains all the missions flown by pilots.
Missions have a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;begin&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;end&lt;/code&gt; time logged with the flight deck.
We will use some common pairings
(and an unusual mission at the end where Commander Adama flew his old Viper):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;pid&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;cid&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;begin&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;end&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 13:22:12&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 15:05:49&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 10:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 18:19:12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 13:33:52&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-05 19:12:21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3008-03-20 08:14:37&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3008-03-20 10:21:15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Battles&lt;/code&gt; table contains the time window of each
&lt;a href=&quot;https://en.battlestarwikiclone.org/wiki/Colonial_battles_chronology_(RDM)&quot;&gt;battle with the Cylons&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;battle&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;begin&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;end&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Fall of the Colonies&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 13:21:45&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-05 02:47:16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Red Moon&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-28 07:55:27&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-28 08:12:19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Tylium Asteroid&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-06-09 09:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-06-09 11:14:29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Resurrection Ship&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-10-28 22:00:00&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-10-28 23:47:05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;These last two tables (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Missions&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Battles&lt;/code&gt;) are examples of &lt;em&gt;state tables&lt;/em&gt;.
An object in a state table has a state that runs between two time points.
For the battles, the state is just yes/no.
For the missions, the state is a pilot/craft combination.&lt;/p&gt;
      &lt;h3 id=&quot;equality-predicates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#equality-predicates&quot;&gt;Equality Predicates&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The most common type of join involves comparing one or more pairs of expressions for equality,
often a primary key and a foreign key.
For example, if we want a list of the craft flown by the pilots,
we can join the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pilots&lt;/code&gt; table to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Craft&lt;/code&gt; table through the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Missions&lt;/code&gt; table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;callsign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tailno&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pilots&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Missions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Crafts&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will give us a table like:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;callsign&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count(*)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;tailno&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Starbuck&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;127&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2794NC&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boomer&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;55&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;R1234V&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Apollo&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;N7242C&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Husker&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;N7242C&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;range-predicates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#range-predicates&quot;&gt;Range Predicates&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The thing to notice in this example is that the conditions joining the tables are equalities connected with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AND&lt;/code&gt;s.
But relational joins can be defined using &lt;em&gt;any&lt;/em&gt; Boolean predicate – even ones without equality or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AND&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One common operation in temporal databases is intersecting two state tables.
Suppose we want to find the time intervals when each pilot was engaged in combat
so we can compute combat hours for seniority?
Vipers are launched quickly, but not before the battle has started,
and there can be malfunctions or pilots may be delayed getting to the flight deck.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;callsign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;battle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;greatest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;least&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pilots&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Missions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Crafts&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Battles&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This join creates a set of records containing the call sign and period in combat for each pilot.
It handles the case where a pilot returns for a new craft, excludes patrol flights,
and even handles the situation when a patrol flight turns into combat!
This is because intersecting state tables this way produces a &lt;em&gt;joint state table&lt;/em&gt; -
an important temporal database operation.
Here are a few rows from the result:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;callsign&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;battle&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;begin&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;end&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Starbuck&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Fall of the Colonies&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 13:22:12&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 15:05:49&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Apollo&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Fall of the Colonies&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 13:21:45&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 18:19:12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boomer&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Fall of the Colonies&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-04 13:33:52&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3004-05-05 02:47:16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;…&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Apollo was already in flight when the first Cylon attack came,
so the query puts his &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;begin&lt;/code&gt; time for the battle at the start of the battle,
not when he launched for the decomissioning flyby.
Starbuck and Boomer were scrambled after the battle started,
but Boomer did not return until after the battle was effectively over,
so her &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;end&lt;/code&gt; time is moved back to the official end of the battle.&lt;/p&gt;

&lt;p&gt;What is important here is that the join condition between the pilot/mission/craft relation
and the battle table has no equalities in it.
This kind of join is traditionally very expensive to compute,
but as we will see, there are ways of speeding it up.&lt;/p&gt;
      &lt;h3 id=&quot;infinite-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#infinite-time&quot;&gt;Infinite Time&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;One common problem with populating state tables is how to represent the open edges.
For example, the begin time for the first state might not be known,
or the current state may not have ended yet.&lt;/p&gt;

&lt;p&gt;Often such values are represented by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;s, 
but this complicates the intersection query because comparing with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; yields &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;.
This issue can be worked around by using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coalese(end, &amp;lt;large timestamp&amp;gt;)&lt;/code&gt;, 
but that adds a computation to every row, most of which don&#39;t need it.
Another approach is to just use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;large timestamp&amp;gt;&lt;/code&gt; directly instead of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;,
which solves the expression computation problem but introduces an arbitrary time value.
This value may give strange results when used in computations.&lt;/p&gt;

&lt;p&gt;DuckDB provides a third alterantive from Postgres that can be used for these situations: 
&lt;a href=&quot;https://www.postgresql.org/docs/14/datatype-datetime.html#DATATYPE-DATETIME-SPECIAL-TABLE&quot;&gt;infinite time values&lt;/a&gt;.
Infinite time values will compare as expected, but arithmetic with them will produce &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;s or infinities, 
indicating that the computation is not well defined.&lt;/p&gt;
      &lt;h2 id=&quot;common-join-algorithms&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#common-join-algorithms&quot;&gt;Common Join Algorithms&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To see why these joins can be expensive, let&#39;s start by looking at the two most common join algorithms.&lt;/p&gt;
      &lt;h3 id=&quot;hash-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#hash-joins&quot;&gt;Hash Joins&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Joins with at least one equality condition &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AND&lt;/code&gt;ed to the rest of the conditions are called &lt;em&gt;equi-joins&lt;/em&gt;.
They are usually implemented using a hash table like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hashes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hashes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hashes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The expressions from one side (the &lt;em&gt;build&lt;/em&gt; side) are computed and hashed,
then the corresponding expressions from the other side (the &lt;em&gt;probe&lt;/em&gt; side)
are looked up in the hash table and checked for a match.&lt;/p&gt;

&lt;p&gt;We can modify this a bit when only &lt;em&gt;some&lt;/em&gt; of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AND&lt;/code&gt;ed conditions are equalities
by checking the other conditions once we find the equalities in the hash table.
The important point is that we can use a hash table to make the join run time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N)&lt;/code&gt;.
This modification is a general technique that can be used with any join algorithm which reduces the possible matches.&lt;/p&gt;
      &lt;h3 id=&quot;nested-loop-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#nested-loop-joins&quot;&gt;Nested Loop Joins&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Since relational joins can be defined using &lt;em&gt;any&lt;/em&gt; Boolean predicate – even one without equality or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AND&lt;/code&gt;,
hash joins do not always work.
The join algorithm of last resort in these situations is called a &lt;em&gt;Nested Loop Join&lt;/em&gt; (or NLJ for short),
and consists of just comparing every row from the probe side with every row from the build side:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(M x N)&lt;/code&gt; in the number of rows, which can be very slow if the tables are large.
Even worse, most practical analytic queries (such as the combat hours example above)
will not return anything like this many results, so a lot of effort may be wasted.
But without an algorithm that is tuned for a kind of predicate,
this is what we would have to use.&lt;/p&gt;
      &lt;h2 id=&quot;range-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#range-joins&quot;&gt;Range Joins&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When we have a range comparison (one of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;=&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;gt;&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;gt;=&lt;/code&gt;) as one of the join conditions,
we can take advantage of the ordering it implies by sorting the input relations on some of the join conditions.
Sorting is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N log N)&lt;/code&gt;, which suggests that this could be faster than an NLJ,
and indeed this turns out to be the case.&lt;/p&gt;
      &lt;h3 id=&quot;piecewise-merge-join&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#piecewise-merge-join&quot;&gt;Piecewise Merge Join&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Before the advent of hash joins, databases would often sort the join inputs to find matches.
For equi-joins, a repeated binary search would then find the matching values on the build side in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(M log N)&lt;/code&gt; time.
This is called a &lt;em&gt;Merge Join&lt;/em&gt;, and it runs faster than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(M x N)&lt;/code&gt;, but not as fast as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N)&lt;/code&gt; time of a hash join.
Still, in the case where we have a single range comparison,
the binary search lets us find the first match for a probe value.
We can then find all the remaining matches by looking after the first one.&lt;/p&gt;

&lt;p&gt;If we also sort the probe side, we can even know where to start the search for the next probe value
because it will be after where we found the previous value.
This is how &lt;em&gt;Piecewise Merge Join&lt;/em&gt; (PWMJ) works:
We sort the build side so that the values are ordered by the predicate (either &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ASC&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESC&lt;/code&gt;),
then sort each probe chunk the same way so we can quickly scan through sets of values to find possible matches.
This can be significantly faster than NLJ for these types of queries.
If there are more join conditions, we can then check the generated matches to make sure all conditions are met
because once again the sorting has significantly reduced the number of checks that have to be made.&lt;/p&gt;
      &lt;h3 id=&quot;inequality-join-iejoin&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#inequality-join-iejoin&quot;&gt;Inequality Join (IEJoin)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For two range conditions (like the combat pay query), there are even faster algorithms available.
We have recently added a new join called &lt;a href=&quot;https://vldb.org/pvldb/vol8/p2074-khayyat.pdf&quot;&gt;IEJoin&lt;/a&gt;,
which sorts on two predicates to really speed things up.&lt;/p&gt;

&lt;p&gt;The way that IEJoin works is to first sort both tables on the values for the first condition
and merge the two sort keys into a combined table that tracks the two input tables&#39; row numbers.
Next, it sorts the positions in the combined table on the second range condition.
It can then quickly scan for matches that pass both conditions.
And just like for hash joins, we can check any remaining conditions
because we have hopefully significantly reduced the number pairs we have to test.&lt;/p&gt;
      &lt;h4 id=&quot;walk-through&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#walk-through&quot;&gt;Walk Through&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Because the algorithm is a bit tricky, let&#39;s step through a small example.
(If you are reading the paper, this is a simplified version of the &quot;Union Arrays&quot; optimisation from §4.3,
but I find this version of the algorithm is much easier to understand than the version in §3.1.)
We are going to look at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Qp&lt;/code&gt; from the paper, which is a self join on the table &quot;West&quot;:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;West&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;t_id&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;time&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;cost&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;cores&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;s1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;404&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;s2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;498&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;140&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;s3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;676&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;s4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;742&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We are looking for pairs of billing ids where the second id had a shorter time than the first,
but a higher cost:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t_id2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;west&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;west&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are two pairs that meet this criteria:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;t_id&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;t_id2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;404&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;676&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;742&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;676&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;(This is an example of another kind of double range query where we are looking for anomalies.)&lt;/p&gt;

&lt;p&gt;First, we sort both input tables on the first condition key (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt;).
(We sort &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESC&lt;/code&gt; because we want the values to satisfy the join condition (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;gt;&lt;/code&gt;) from left to right.)&lt;/p&gt;

&lt;p&gt;Because they are sorted the same way,
we can merge the condition keys from the sorted tables into a new table called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt;
after marking each row with the table it came from (using negative row numbers to indicate the right table):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;L1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s4&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s4&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s3&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;time&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;140&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;140&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cost&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;rid&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;-4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rid&lt;/code&gt; column lets us map rows in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; back to the original table.&lt;/p&gt;

&lt;p&gt;Next, we build a second table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2&lt;/code&gt; with the second condition key (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt;) and the row positions (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P&lt;/code&gt;) of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt;
(not the row numbers from the original tables!)
We sort &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2&lt;/code&gt; on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DESC&lt;/code&gt; again this time because now we want the join condition to hold from right to left):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;L2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s3&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s3&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s1&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s4&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;s4&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;cost&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;P&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The sorted column of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; row positions is called the &lt;em&gt;permutation array&lt;/em&gt;,
and we can use it to find the corresponding position of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt; value for a given &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;At this point we have two tables (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2&lt;/code&gt;),
each sorted on one of the join conditions and pointing back to the tables it was derived from.
Moreover, the sort orders have been chosen so that the condition holds from left to right
(resp. right to left).
Since the conditions are transitive,
this means that whenever we have a value that satisfies a condition at a point in the table,
it also satisfies it for everything to the right (resp. left)!&lt;/p&gt;

&lt;p&gt;With this setup, we can scan &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2&lt;/code&gt; from left to right
looking for rows that match both conditions using two indexes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; iterates across &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2&lt;/code&gt; from left to right;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;off2&lt;/code&gt; tracks &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; and is used to identify &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;costs&lt;/code&gt; that satisfy the join condition compared to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;. (Note that for loose inequalities, this could be to the right of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;);&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We use a bitmap &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; to track which rows in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2&lt;/code&gt; scan
has already identified as satisfying the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; condition compared to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L2&lt;/code&gt; scan position &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Because we only want matches between one left and one right row, we can skip matches where the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rid&lt;/code&gt;s have different signs.
To leverage this observation, we only process values of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; that are in the left hand table (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rid[P[i]]&lt;/code&gt; is positive),
and we only mark bits for rows in the right hand table (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rid[P[i]]&lt;/code&gt; is negative).
In this example, the right side rows are the odd numbered values in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P&lt;/code&gt; (which are conveniently also the odd values of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;),
which makes them easy to track in the example.&lt;/p&gt;

&lt;p&gt;For the other rows, here is what happens:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;i&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;off2&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;cost[i]&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;cost[off2]&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;P[i]&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;rid[P[i]]&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;B&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Result&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;00000000&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0..2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11..10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;01000000&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2..4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10..6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;01000001&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[{s4, s3}]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4..6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6..5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;01010001&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[{s1, s3}]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Whenever we find &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt;s that satisfy the condition to the left of the scan location (between &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;off2&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt;),
we use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P[off2]&lt;/code&gt; to mark the bits in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; corresponding to those positions in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; that reference right side rows.
This records that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; condition is satisfied for those rows.
Then whenever we have a position &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P[i]&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt;,
we can scan &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; to the right to find values that also satisfy the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; condition.
This works because everything to the right of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P[i]&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; satisfies the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;price&lt;/code&gt; condition
thanks the sort order of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; and the transitivity of the comparison operations.&lt;/p&gt;

&lt;p&gt;In more detail:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;off2&lt;/code&gt; are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; condition &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;&lt;/code&gt; is not satisfied, so nothing happens;&lt;/li&gt;
  &lt;li&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;, we are looking at a row from the right side of the join, so we skip it and move on;&lt;/li&gt;
  &lt;li&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&lt;/code&gt;, we are now looking at a row from the left side, so we bring &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;off2&lt;/code&gt; forward until the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; condition fails, marking &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; where it succeeds at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P[1] = [1]&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;We then scan the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt; values in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; right from  position &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P[i=2] = 6&lt;/code&gt; and find no matches in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4&lt;/code&gt;, we bring &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;off2&lt;/code&gt; forward again, marking &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P[3] = [7]&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;We then scan &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt; from position &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&lt;/code&gt; and find matches at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[6,7]&lt;/code&gt;, one of which (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;6&lt;/code&gt;) is from the right side table;&lt;/li&gt;
  &lt;li&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;6&lt;/code&gt;, we bring &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;off2&lt;/code&gt; forward again, marking &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P[5] = [3]&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;We then scan &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt; from position &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4&lt;/code&gt; and again find matches at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[6,7]&lt;/code&gt;;&lt;/li&gt;
  &lt;li&gt;Finally, when &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; runs off the end, we have no new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cost&lt;/code&gt; values, so nothing happens;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;What makes this fast is that we only have to check a few bits to find the matches.
When we do need to perform comparisons, we can use the fast radix comparison code from our sorting code,
which doesn&#39;t require special templated versions for every data type.
This not only reduces the code size and complexity, it &quot;future-proofs&quot; it against new data types.&lt;/p&gt;
      &lt;h4 id=&quot;further-details&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#further-details&quot;&gt;Further Details&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;That walk through is a slightly simplified, single threaded version of the actual algorithm.
There are a few more details that may be of interest:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Scanning large, mostly empty bit maps can be slow, so we use the Bloom filter optimisation from §4.2.&lt;/li&gt;
  &lt;li&gt;The published algorithm assumes that there are no duplicate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; values in either table. To handle the general case, we use an &lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_search&quot;&gt;exponential search&lt;/a&gt; to find the first &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; value that satisfies the predicate with respect to the current position and scan right from that point;&lt;/li&gt;
  &lt;li&gt;We also adapted the distributed Algorithm 3 from §5 by joining pairs of the sorted blocks generated by the sort code on separate threads. This allows us to fully parallelize the operator by first using parallel sorting and then by breaking up the join into independent pieces;&lt;/li&gt;
  &lt;li&gt;Breaking up the pieces for parallel execution also allows us to spool join blocks that are not being processed to disk, making the join scalable.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;special-joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#special-joins&quot;&gt;Special Joins&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;One of the nice things about IEJoin is that it is very general and implements a number of more specialized join types reasonably efficiently.
For example, the state intersection query above is an example of an &lt;em&gt;interval join&lt;/em&gt; 
where we are looking to join on the intersection of two intervals.&lt;/p&gt;

&lt;p&gt;Another specialized join that can be accelerated with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IEJoin&lt;/code&gt; is a &lt;em&gt;band join&lt;/em&gt;.
This can be used to join values that are &quot;close&quot; to each other&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This translates into a double inequality join condition:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which is exactly the type of join expression that IEJoin handles.&lt;/p&gt;
      &lt;h2 id=&quot;performance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#performance&quot;&gt;Performance&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;So how fast is the IEJoin?
It is so fast that it is difficult to compare it to the previous range join algorithms
because the improvements are so large that the other algorithms do not complete in a reasonable amount of time!&lt;/p&gt;
      &lt;h3 id=&quot;simple-measurements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#simple-measurements&quot;&gt;Simple Measurements&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;To give an example, here are the run times for a 100K self join of some employee tax and salary data,
where the goal is to find the 1001 pairs of employees where one has a higher salary but the other has a higher tax rate:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Employees&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Employees&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Algorithm&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NLJ&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;21.440&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;PWMJ&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;38.698&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;IEJoin&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.280&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Another example is a self join to find 3772 overlapping events in a 30K event table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Algorithm&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NLJ&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.985&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;PWMJ&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.780&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;IEJoin&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.226&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In both cases we see performance improvements of 20-100x,
which is very helpful when you run a lot of queries like these!&lt;/p&gt;
      &lt;h3 id=&quot;optimisation-measurements&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#optimisation-measurements&quot;&gt;Optimisation Measurements&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;A third example demonstrates the importance of the join pair filtering and exponential search optimisations.
The data is a state table of
&lt;a href=&quot;https://www.opendata.dk/city-of-aarhus/transaktionsdata-fra-aarhus-kommunes-biblioteker&quot;&gt;library circulation data&lt;/a&gt;
from another &lt;a href=&quot;https://vldb.org/pvldb/vol10/p1346-bouros.pdf&quot;&gt;interval join paper&lt;/a&gt;,
and the query is a point-in-period temporal query used to generate Figure 4d:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;books&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;2013-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2014-01-01&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dates&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checkout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result is a count of the number of books checked out at midnight on each day.
These are the runtimes on an 18 core iMac Pro:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Improvement&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;CPU&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Unoptimized&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&amp;gt; 30m&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;~100%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Filtering&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;119.76s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;269%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Exponential&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.21s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;571%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The query joins a 35M row table with a 365 row table, so most of the data comes from the left hand side.
By avoiding setting bits for the matching rows in the left table, we eliminate almost all &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;L1&lt;/code&gt; checks.
This dramatically reduces the runtime and improved the CPU utilisation.&lt;/p&gt;

&lt;p&gt;The data also has a large number of rows corresponding to books that were checked out at the start of the year,
which all have the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;checkout&lt;/code&gt; date.
Searching left linearly in the first block to find the first match for the scan
resulted in repeated runs of ~120K comparisons.
This caused the runtime to be completely dominated by processing the first block.
By reducing the number of comparisons for these rows from an average of ~60K to 16,
the runtime dropped by a factor of 10 and the CPU utilisation doubled.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion-and-feedback&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/27/iejoin.html#conclusion-and-feedback&quot;&gt;Conclusion and Feedback&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we explained the new DuckDB range join improvements provided by the new IEJoin operator.
This should greatly improve the response time of state table joins and anomaly detection joins.
We hope this makes your DuckDB experience even better – and please let us know if you run into any problems!
Feel free to reach out on our &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;GitHub page&lt;/a&gt;, or our &lt;a href=&quot;https://discord.gg/vukK4xp7Rd&quot;&gt;Discord server&lt;/a&gt;.&lt;/p&gt;

</description><link>https://duckdb.org/2022/05/27/iejoin.html</link><guid isPermaLink="false">https://duckdb.org/2022/05/27/iejoin.html</guid><pubDate>Fri, 27 May 2022 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>Friendlier SQL with DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB offers several extensions to the SQL syntax. For a full list of these features, see the &lt;a href=&quot;https://duckdb.org/docs/guides/sql_features/friendly_sql&quot;&gt;Friendly SQL documentation page&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duck_chewbacca.png&quot; alt=&quot;Chewbacca_the_duck&quot; title=&quot;Chewbacca the duck is pretty friendly&quot; width=&quot;200&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;An elegant user experience is a key design goal of DuckDB. This goal guides much of DuckDB&#39;s architecture: it is simple to install, seamless to integrate with other data structures like Pandas, Arrow, and R Dataframes, and requires no dependencies. Parallelization occurs automatically, and if a computation exceeds available memory, data is gracefully buffered out to disk. And of course, DuckDB&#39;s processing speed makes it easier to get more work accomplished.&lt;/p&gt;

&lt;p&gt;However, SQL is not famous for being user-friendly. DuckDB aims to change that! DuckDB includes both a Relational API for dataframe-style computation, and a highly Postgres-compatible version of SQL. If you prefer dataframe-style computation, we would love your feedback on &lt;a href=&quot;https://github.com/duckdb/duckdb/issues/2000&quot;&gt;our roadmap&lt;/a&gt;. If you are a SQL fan, read on to see how DuckDB is bringing together both innovation and pragmatism to make it easier to write SQL in DuckDB than anywhere else. Please reach out on &lt;a href=&quot;https://github.com/duckdb/duckdb/discussions&quot;&gt;GitHub&lt;/a&gt; or &lt;a href=&quot;https://discord.gg/vukK4xp7Rd&quot;&gt;Discord&lt;/a&gt; and let us know what other features would simplify your SQL workflows. Join us as we teach an old dog new tricks!&lt;/p&gt;
      &lt;h2 id=&quot;select--exclude&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#select--exclude&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * EXCLUDE&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A traditional SQL &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; query requires that requested columns be explicitly specified, with one notable exception: the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt; wildcard. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT *&lt;/code&gt; allows SQL to return all relevant columns. This adds tremendous flexibility, especially when building queries on top of one another. However, we are often interested in &lt;em&gt;almost&lt;/em&gt; all columns. In DuckDB, simply specify which columns to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jar_jar_binks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;midichlorians&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_wars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we can save time repeatedly typing all columns, improve code readability, and retain flexibility as additional columns are added to underlying tables.&lt;/p&gt;

&lt;p&gt;DuckDB&#39;s implementation of this concept can even handle exclusions from multiple tables within a single statement:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;sw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jar_jar_binks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;midichlorians&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cancellation&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_wars&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;firefly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;select--replace&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#select--replace&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * REPLACE&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Similarly, we often wish to use all of the columns in a table, aside from a few small adjustments. This would also prevent the use of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt; and require a list of all columns, including those that remain unedited. In DuckDB, easily apply changes to a small number of columns with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REPLACE&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;REPLACE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movie_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_wars_owned_by_disney&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This allows views, CTE&#39;s, or sub-queries to be built on one another in a highly concise way, while remaining adaptable to new underlying columns.&lt;/p&gt;
      &lt;h2 id=&quot;group-by-all&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#group-by-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY ALL&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A common cause of repetitive and verbose SQL code is the need to specify columns in both the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clause. In theory this adds flexibility to SQL, but in practice it rarely adds value. DuckDB now offers the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; we all expected when we first learned SQL – just &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY ALL&lt;/code&gt; columns in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause that aren&#39;t wrapped in an aggregate function!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;systems&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;planets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cantinas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;villainy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_scum_and_villainy&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_wars_locations&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- GROUP BY systems, planets, cities, cantinas&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now changes to a query can be made in only one place instead of two! Plus this prevents many mistakes where columns are removed from a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; list, but not from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt;, causing duplication.&lt;/p&gt;

&lt;p&gt;Not only does this dramatically simplify many queries, it also makes the above &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EXCLUDE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REPLACE&lt;/code&gt; clauses useful in far more situations. Imagine if we wanted to adjust the above query by no longer considering the level of scum and villainy in each specific cantina:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXCLUDE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cantinas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;booths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;villainy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;villainy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_scum_and_villainy&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_wars_locations&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- GROUP BY systems, planets, cities&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now that is some concise and flexible SQL! How many of your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clauses could be re-written this way?&lt;/p&gt;
      &lt;h2 id=&quot;order-by-all&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#order-by-all&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY ALL&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another common cause for repetition in SQL is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause. DuckDB and other RDBMSs have previously tackled this issue by allowing queries to specify the numbers of columns to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; (For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY 1, 2, 3&lt;/code&gt;). However, frequently the goal is to order by all columns in the query from left to right, and maintaining that numeric list when adding or subtracting columns can be error prone. In DuckDB, simply &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY ALL&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;civility&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_civility&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_wars_universe&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- ORDER BY age, total_civility&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is particularly useful when building summaries, as many other client tools automatically sort results in this manner. DuckDB also supports &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY ALL DESC&lt;/code&gt; to sort each column in reverse order, and options to specify &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS FIRST&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS LAST&lt;/code&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;column-aliases-in-where--group-by--having&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#column-aliases-in-where--group-by--having&quot;&gt;Column Aliases in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HAVING&lt;/code&gt;&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In many SQL dialects, it is not possible to use an alias defined in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause anywhere but in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause of that statement. This commonly leads to verbose CTE&#39;s or subqueries in order to utilize those aliases. In DuckDB, a non-aggregate alias in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause can be immediately used in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clauses, and aggregate aliases can be used in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HAVING&lt;/code&gt; clause, even at the same query depth. No subquery needed!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;only_imperial_storm_troopers_are_so_precise&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;turns_out_a_parsec_is_a_distance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;very_speedy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mistakes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_oops&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oops&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;very_speedy&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;HAVING&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total_oops&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;case-insensitivity-while-maintaining-case&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#case-insensitivity-while-maintaining-case&quot;&gt;Case Insensitivity While Maintaining Case&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB allows queries to be case insensitive, while maintaining the specified case as data flows into and out of the system. This simplifies queries within DuckDB while ensuring compatibility with external libraries.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mandalorian&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;THIS_IS_THE_WAY&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this_is_the_way&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mandalorian&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;THIS_IS_THE_WAY&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;friendly-error-messages&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#friendly-error-messages&quot;&gt;Friendly Error Messages&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Regardless of expertise, and despite DuckDB&#39;s best efforts to understand our intentions, we all make mistakes in our SQL queries. Many RDBMSs leave you trying to use the force to detect an error. In DuckDB, if you make a typo on a column or table name, you will receive a helpful suggestion about the most similar name. Not only that, you will receive an arrow that points directly to the offending location within your query.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_trek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Error: Catalog Error: Table with name star_trek does not exist!
Did you mean &quot;star_wars&quot;?
LINE 1: SELECT * FROM star_trek;
                      ^
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(Don&#39;t worry, ducks and duck-themed databases still love some Trek as well).&lt;/p&gt;

&lt;p&gt;DuckDB&#39;s suggestions are even context specific. Here, we receive a suggestion to use the most similar column from the table we are querying.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_ago&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_wars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Error: Binder Error: Referenced column &quot;long_ago&quot; not found in FROM clause!
Candidate bindings: &quot;star_wars.long_long_ago&quot;
LINE 1: SELECT long_ago FROM star_wars;
               ^
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;string-slicing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#string-slicing&quot;&gt;String Slicing&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Even as SQL fans, we know that SQL can learn a thing or two from newer languages. Instead of using bulky &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUBSTRING&lt;/code&gt; functions, you can slice strings in DuckDB using bracket syntax. As a note, SQL is required to be 1-indexed, so that is a slight difference from other languages (although it keeps DuckDB internally consistent and similar to other DBs).&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;I love you! I know&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nearly_soloed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;nearly_soloed&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;I love you! I k&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;simple-list-and-struct-creation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#simple-list-and-struct-creation&quot;&gt;Simple List and Struct Creation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB provides nested types to allow more flexible data structures than the purely relational model would allow, while retaining high performance. To make them as easy as possible to use, creating a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt; (array) or a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; (object) uses simpler syntax than other SQL systems. Data types are automatically inferred.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;A-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;B-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;X-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Y-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starfighter_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Star Destroyer&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;common_misconceptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Can&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;t in fact destroy a star&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star_destroyer_facts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;list-slicing&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#list-slicing&quot;&gt;List Slicing&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Bracket syntax may also be used to slice a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt;. Again, note that this is 1-indexed for SQL compatibility.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;starfighter_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dont_forget_the_b_wing&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;A-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;B-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;X-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Y-Wing&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;starfighter_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;dont_forget_the_b_wing&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;[B-Wing]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;struct-dot-notation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#struct-dot-notation&quot;&gt;Struct Dot Notation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Use convenient dot notation to access the value of a specific key in a DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; column. If keys contain spaces, double quotes can be used.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;planet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;planet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Amount of sand&quot;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Tatooine&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Amount of sand&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;High&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;planet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;trailing-commas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#trailing-commas&quot;&gt;Trailing Commas&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Have you ever removed your final column from a SQL &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; and been met with an error, only to find you needed to remove the trailing comma as well!? Never? Ok, Jedi… On a more serious note, this feature is an example of DuckDB&#39;s responsiveness to the community. In under 2 days from seeing this issue in a tweet (not even about DuckDB!), this feature was already built, tested, and merged into the primary branch. You can include trailing commas in many places in your query, and we hope this saves you from the most boring but frustrating of errors!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_wing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;proton_torpedoes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;--targeting_computer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;luke_whats_wrong&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_wing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;proton_torpedoes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;function-aliases-from-other-databases&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#function-aliases-from-other-databases&quot;&gt;Function Aliases from Other Databases&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;For many functions, DuckDB supports multiple names in order to align with other database systems. After all, ducks are pretty versatile – they can fly, swim, and walk! Most commonly, DuckDB supports PostgreSQL function names, but many SQLite names are supported, as well as some from other systems. If you are migrating your workloads to DuckDB and a different function name would be helpful, please reach out – they are very easy to add as long as the behavior is the same! See our &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/overview.html&quot;&gt;functions documentation&lt;/a&gt; for details.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;Use the Force, Luke&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sliced_quote_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;I am your father&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sliced_quote_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;substring&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Obi-Wan Kenobi, you&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;re my only hope&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sliced_quote_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;auto-increment-duplicate-column-names&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#auto-increment-duplicate-column-names&quot;&gt;Auto-Increment Duplicate Column Names&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;As you are building a query that joins similar tables, you&#39;ll often encounter duplicate column names. If the query is the final result, DuckDB will simply return the duplicated column names without modifications. However, if the query is used to create a table, or nested in a subquery or Common Table Expression (where duplicate columns are forbidden by other databases!), DuckDB will automatically assign new names to the repeated columns to make query prototyping easier.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie_fighter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie_fighter&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;squadron_one&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;squadron_two&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theyre_coming_in_too_fast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;tie_fighter&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;tie_fighter:1&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;green_one&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;green_two&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;implicit-type-casts&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#implicit-type-casts&quot;&gt;Implicit Type Casts&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB believes in using specific data types for performance, but attempts to automatically cast between types whenever necessary. For example, when joining between an integer and a varchar, DuckDB will automatically cast them to be the same type and complete the join successfully. A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;List&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IN&lt;/code&gt; expression may also be created with a mixture of types, and they will be automatically cast as well. Also, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTEGER&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt; are interchangeable, and thanks to DuckDB&#39;s new storage compression, a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIGINT&lt;/code&gt; usually doesn&#39;t even take up any extra space! Now you can store your data as the optimal data type, but use it easily for the best of both!&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sith_count_int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;INTEGER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sith_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sith_count_varchar&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;VARCHAR&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sith_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sith_count_int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_int&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sith_count_varchar&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_char&lt;/span&gt; 
  &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sith_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sith_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sith_count&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sith_count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;other-friendly-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#other-friendly-features&quot;&gt;Other Friendly Features&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are many other features of DuckDB that make it easier to analyze data with SQL!&lt;/p&gt;

&lt;p&gt;DuckDB &lt;a href=&quot;https://duckdb.org/2022/01/06/time-zones.html&quot;&gt;makes working with time easier in many ways&lt;/a&gt;, including by accepting multiple different syntaxes (from other databases) for the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/interval.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERVAL&lt;/code&gt; data type&lt;/a&gt; used to specify a length of time.&lt;/p&gt;

&lt;p&gt;DuckDB also implements multiple SQL clauses outside of the traditional core clauses including the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/sample.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SAMPLE&lt;/code&gt; clause&lt;/a&gt; for quickly selecting a random subset of your data and the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/query_syntax/qualify.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QUALIFY&lt;/code&gt; clause&lt;/a&gt; that allows filtering of the results of window functions (much like a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HAVING&lt;/code&gt; clause does for aggregates).&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://duckdb.org/docs/stable/sql/statements/select.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DISTINCT ON&lt;/code&gt; clause&lt;/a&gt; allows DuckDB to select unique combinations of a subset of the columns in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause, while returning the first row of data for columns not checked for uniqueness.&lt;/p&gt;
      &lt;h2 id=&quot;ideas-for-the-future&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/05/04/friendlier-sql.html#ideas-for-the-future&quot;&gt;Ideas for the Future&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In addition to what has already been implemented, several other improvements have been suggested. Let us know if one would be particularly useful – we are flexible with our roadmap! If you would like to contribute, we are very open to PRs and you are welcome to reach out on &lt;a href=&quot;https://github.com/duckdb/duckdb&quot;&gt;GitHub&lt;/a&gt; or &lt;a href=&quot;https://discord.gg/vukK4xp7Rd&quot;&gt;Discord&lt;/a&gt; ahead of time to talk through a new feature&#39;s design.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Choose columns via regex
    &lt;ul&gt;
      &lt;li&gt;Decide which columns to select with a pattern rather than specifying columns explicitly&lt;/li&gt;
      &lt;li&gt;ClickHouse supports this with the &lt;a href=&quot;https://clickhouse.com/docs/en/sql-reference/statements/select/#columns-expression&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;COLUMNS&lt;/code&gt; expression&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Incremental column aliases
    &lt;ul&gt;
      &lt;li&gt;Refer to previously defined aliases in subsequent calculated columns rather than re-specifying the calculations&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dot operators for JSON types
    &lt;ul&gt;
      &lt;li&gt;The JSON extension is brand new (&lt;a href=&quot;https://duckdb.org/docs/stable/data/json/overview.html&quot;&gt;see our documentation!&lt;/a&gt;) and already implements friendly &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-&amp;gt;&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-&amp;gt;&amp;gt;&lt;/code&gt; syntax&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks for checking out DuckDB! May the Force be with you…&lt;/p&gt;

</description><link>https://duckdb.org/2022/05/04/friendlier-sql.html</link><guid isPermaLink="false">https://duckdb.org/2022/05/04/friendlier-sql.html</guid><pubDate>Wed, 04 May 2022 00:00:00 GMT</pubDate><author>Alex Monahan</author></item><item><title>Parallel Grouped Aggregation in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB has a fully parallelized aggregate hash table that can efficiently aggregate over millions of groups.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Grouped aggregations are a core data analysis command. It is particularly important for large-scale data analysis (“OLAP”) because it is useful for  computing statistical summaries of huge tables. DuckDB contains a highly optimized parallel aggregation capability for fast and scalable summarization.&lt;/p&gt;

&lt;p&gt;Jump &lt;a href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html#experiments&quot;&gt;straight to the benchmarks&lt;/a&gt;?&lt;/p&gt;
      &lt;h2 id=&quot;introduction&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html#introduction&quot;&gt;Introduction&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; changes the result set cardinality – instead of returning the same number of rows of the input (like a normal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;), &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; returns as many rows as there are groups in the data. Consider this (weirdly familiar) example query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; is followed by two column names, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_returnflag&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_linestatus&lt;/code&gt;. Those are the columns to compute the groups on, and the resulting table will contain all combinations of the same column that occur in the data. We refer to the columns in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clause as the “grouping columns” and all occurring combinations of values therein as “groups”. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause contains four (not five) expressions: References to the grouping columns, and two aggregates: the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt; over &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_extendedprice&lt;/code&gt; and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avg&lt;/code&gt; over &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_quantity&lt;/code&gt;. We refer to those as the “aggregates”.  If executed, the result of this query looks something like this:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;l_returnflag&lt;/th&gt;
      &lt;th&gt;l_linestatus&lt;/th&gt;
      &lt;th&gt;sum(l_extendedprice)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;avg(l_quantity)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;O&lt;/td&gt;
      &lt;td&gt;114935210409.19&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;56568041380.9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25.51&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;56586554400.73&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25.52&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;N&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;1487504710.38&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;25.52&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In general, SQL allows only columns that are mentioned in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clause to be part of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; expressions directly, all other columns need to be subject to one of the aggregate functions like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avg&lt;/code&gt; etc. There are &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/aggregates.html&quot;&gt;many more aggregate functions&lt;/a&gt; depending on which SQL system you use.&lt;/p&gt;

&lt;p&gt;How should a query processing engine compute such an aggregation? There are many design decisions involved, and we will discuss those below and in particular the decisions made by DuckDB. The main issue when computing grouping results is that the groups can occur in the input table in any order. Were the input already sorted on the grouping columns, computing the aggregation would be trivial, as we could just compare the current values for the grouping columns with the previous ones. If a change occurs, the next group begins and a new aggregation result needs to be computed. Since the sorted case is easy, one straightforward way of computing grouped aggregates is to sort the input table on the grouping columns first, and then use the trivial approach. But sorting the input is unfortunately still a computationally expensive operation &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html&quot;&gt;despite our best efforts&lt;/a&gt;. In general, sorting has a computational complexity of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(nlogn)&lt;/code&gt; with n being the number of rows sorted.&lt;/p&gt;
      &lt;h2 id=&quot;hash-tables-for-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html#hash-tables-for-aggregation&quot;&gt;Hash Tables for Aggregation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A better way is to use a hash table. Hash tables are a &lt;a href=&quot;https://en.wikipedia.org/wiki/Hash_table&quot;&gt;foundational data structure in computing&lt;/a&gt; that allow us to find entries with a computational complexity of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(1)&lt;/code&gt;. A full discussion on how hash tables work is far beyond the scope of this post. Below we try to focus on a very basic description and considerations related to aggregate computation.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-bench-nlogn.svg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;O(n) plotted against O(nlogn) to illustrate scaling behavior&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;To add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; rows to a hash table we are looking at a complexity of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(n)&lt;/code&gt;, much, much better than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(nlogn)&lt;/code&gt; for sorting, especially when n goes into the billions. The figure above illustrates how the complexity develops as the table size increases. Another big advantage is that we do not have to make a sorted copy of the input first, which is going to be just as large  as the input. Instead, the hash table will have at most as many entries as there are groups, which can be (and usually are) dramatically fewer than input rows. The overall process is thus this: Scan the input table, and for each row, update the hash table accordingly. Once the input is exhausted, we scan the hash table to provide rows to upstream operators or the query result directly.&lt;/p&gt;
      &lt;h3 id=&quot;collision-handling&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html#collision-handling&quot;&gt;Collision Handling&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;So, hash table it is then! We build a hash table on the input with the groups as keys and the aggregates as the entries. Then, for every input row, we compute a hash of the group values, find the entry in the hash table, and either create or update the aggregate states with the values from the row? Its unfortunately not that simple: Two rows with &lt;em&gt;different&lt;/em&gt; values for the grouping columns may result in a hash that points to the &lt;em&gt;same&lt;/em&gt; hash table entry, which would lead to incorrect results.&lt;/p&gt;

&lt;p&gt;There are two main approaches to &lt;a href=&quot;https://en.wikipedia.org/wiki/Hash_table#Collision_resolution&quot;&gt;work around this problem&lt;/a&gt;: “Chaining” or “linear probing”. With chaining, we do not keep the aggregate values in the hash table directly, but rather keep a list of group values and aggregates. If grouping values points to a hash table entry with an empty list, the new group and the aggregates are simply added. If grouping values point to an existing list, we check for every list entry whether the grouping values match. If so, we update the aggregates for that group. If not, we create a new list entry. In linear probing there are no such lists, but on finding an existing entry, we will compare the grouping values, and if they match we will update the entry. If they do not match, we move one entry down in the hash table and try again. This process finishes when either a matching group entry has been found or an empty hash table entry is found. While theoretically equivalent, computer hardware architecture will favor linear probing because of cache locality. Because linear probing walks the hash table entries &lt;em&gt;linearly&lt;/em&gt;, the next entry will very likely be in the CPU cache and hence access is faster. Chaining will generally lead to random access and much worse performance on modern hardware architectures. We have therefore adopted linear probing for our aggregate hash table.&lt;/p&gt;

&lt;p&gt;Both chaining and linear probing will degrade in theoretical lookup performance from O(1) to O(n) wrt hash table size if there are too many collisions, i.e., too many groups hashing to the same hash table entry. A common solution to this problem is to resize the hash table once the “fill ratio” exceeds some threshold, e.g., 75% is the default for Java’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HashMap&lt;/code&gt;. This is particularly important as we do not know the amount of groups in the result before starting the aggregation. Neither do we assume to know the amount of rows in the input table. We thus start with a fairly small hash table and resize it once the fill ratio exceeds a threshold. The basic hash table structure is shown in the figure below, the table has four slots 0-4. There are already three groups in the table, with group keys 12, 5 and 2. Each group has aggregate values (e.g., from a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUM&lt;/code&gt;) of 43 etc.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-ht-naive.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Basic Aggregate Hash Table Structure&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;A big challenge with the resize of a partially filled hash table after the resize, all the groups are in the wrong place and we would have to move everything, which will be very expensive.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-ht-twopart.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Two-Part Aggregate Hash Table&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;To support resize efficiently, we have implemented a two-part aggregate hash table consisting of a separately-allocated pointer array which points into payload blocks that contain grouping values and aggregate states for each group. The pointers are not actual pointers but symbolic, they refer to a block ID and a row offset within said block. This is shown in the figure above, the hash table entries are split over two payload blocks. On resize, we throw away the pointer array and allocate a bigger one. Then, we read all payload blocks again, hash the group values, and re-insert pointers to them into the new pointer array. The group data thus remains unchanged, which greatly reduces the cost of resizing the hash table. This can be seen in the figure below, where we double the pointer array size but the payload blocks remain unchanged.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-ht-resize.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Resizing Two-Part Aggregate Hash Table&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;The naive two-part hash table design would require a re-hashing of &lt;em&gt;all&lt;/em&gt; group values on resize, which can be quite expensive especially for string values. To speed this up, we also write the raw hash of the group values to the payload blocks for every group. Then, during resize, we don’t have to re-hash the groups but can just read them from the payload blocks, compute the new offset into the pointer array, and insert there.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-ht-hashcache.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Optimization: Adding Hashes to Payload&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;The two-part hash table has a big drawback when looking up entries: There is no ordering between the pointer array and the group entries in the payload blocks. Hence, following the pointer creates random access in the memory hierarchy. This will lead to unnecessary stalls in the computation. To mitigate this issue, we extend the memory layout of the pointer array to include some (1 or 2) bytes from the group hash in addition to the pointer to the payload value. This way, linear probing can first compare the hash bits in the pointer array with the current group hash and decide whether it’s worth following the payload pointer or not. This can potentially continue for every group in the pointer chain. Only when the hash bits match we have to actually follow the pointer and compare the actual groups. This optimization greatly reduces the amount of times the pointer to the payload blocks has to be followed and thereby reduces the amount of random accesses into memory which are directly related to overall performance. It has the nice side-effect of also greatly reducing full group comparisons which can also be expensive, e.g., when aggregating on groups that contain strings.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-ht-salting.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Optimization: Adding Hash Bits to Pointer Array&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;Another (smaller) optimization here concerns the width of the pointer array entries. For small hash tables with few entries, we do not need many bits to encode the payload block offset pointers. DuckDB supports both 4 byte and 8 byte pointer array entries.&lt;/p&gt;

&lt;p&gt;For most aggregate queries, the vast majority of query processing time is spent looking up hash table entries, which is why it&#39;s worth spending time on optimizing them. If you’re curious, the code for all this is in the DuckDB repo, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aggregate_hashtable.cpp&lt;/code&gt;. There is another optimization for when we know that there are only a few distinct groups from column statistics, the perfect hash aggregate, but that’s for another post. But we’re not done here just yet.&lt;/p&gt;
      &lt;h2 id=&quot;parallel-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html#parallel-aggregation&quot;&gt;Parallel Aggregation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;While we now have an aggregate hash table design that should do fairly well for grouped aggregations, we still have not considered the fact that DuckDB automatically parallelizes all queries to use multiple hardware threads (“CPUs”). How does parallelism work together with hash tables? In general, the answer is unfortunately: “Badly”. Hash tables are delicate structures that don’t handle parallel modifications well. For example, imagine one thread would want to resize the hash table while another wants to add some new group data to it. Or how should we handle multiple threads inserting new groups at the same time for the same entry? One could use locks to make sure that only one thread at a time is using the table, but this would mostly defeat parallelizing the query. There has been plenty of research into concurrency-friendly hash tables but the short summary is that it&#39;s still an open issue.&lt;/p&gt;

&lt;p&gt;It is possible to let each thread read data from downstream operators and build individual, local hash tables and merge those together later from a single thread. This works quite nicely if there are few groups like in the example at the top of this post. If there are few groups, a single thread can merge many thread-local hash tables without creating a bottleneck. However, it’s entirely possible there are as many groups as there are input rows, for this tends to happen a lot when someone groups on a column that would be a candidate for a primary key, e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;observation_number&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timestamp&lt;/code&gt; etc. What is thus needed is a parallel merge of the parallel hash tables. We adopt a method from &lt;a href=&quot;https://15721.courses.cs.cmu.edu/spring2016/papers/p743-leis.pdf&quot;&gt;Leis et al.&lt;/a&gt;: Each thread builds not one, but multiple &lt;em&gt;partitioned&lt;/em&gt; hash tables based on a radix-partitioning on the group hash.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-ht-parallel.png&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Partitioning Hash Tables for Parallelized Merging&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;The key observation here is that if two groups have a different hash value, they cannot possibly be the same. Because of this property, it is possible to use the hash values to create fully independent partitions of the groups without requiring any communication between threads as long as all the threads use the same partitioning scheme (see Phase 1 in the above diagram).&lt;/p&gt;

&lt;p&gt;After all the local hash tables have been constructed, we assign individual partitions to each worker thread and merge the hash tables within that partition together (Phase 2). Because the partitions were created using the radix partitioning scheme on the hash, all worker threads can independently merge the hash tables within their respective partitions. The result is correct because each group goes into a single partition and that partition only.&lt;/p&gt;

&lt;p&gt;One interesting detail is that we never need to build a final (possibly giant) hash table that holds all the groups because the radix group partitioning ensures that each group is localized to a partition.&lt;/p&gt;

&lt;p&gt;There are two additional optimizations for the parallel partitioned hash table strategy: 
1) We only start partitioning once a single thread’s aggregate hash table exceeds a fixed limit of entries, currently set to 10 000 rows. This is because using a partitioned hash table is not free. For every row added, we have to figure out which partition it should go into, and we have to merge everything back together at the end. For this reason, we will not start partitioning until the parallelization benefit outweighs the cost. Since the partitioning decision is individual to each thread, it may well be possible only some threads start partitioning. If that is the case, we will need to partition the hash tables of the threads that have not done so before starting merging them. This is a fully thread-local operation however and does not interfere with parallelism. 
2) We will stop adding values to a hash table once its pointer array exceeds a certain threshold. Every thread then builds multiple sets of potentially partitioned hash tables. This is because we do not want the pointer array to become arbitrarily large. While this potentially creates duplicate entries for the same group in multiple hash tables, this is not problematic because we merge them all later anyway. This optimization works particularly well on data sets that have many distinct groups, but have group values that are clustered in the input in some manner. For example, when grouping by day in a data set that is ordered on date.&lt;/p&gt;

&lt;p&gt;There are some kinds of aggregates which cannot use the parallel and partitioned hash table approach. While it is trivial to parallelize a sum, because the sum of the overall result is just the sum of the individual results, this is fairly impossible for computations like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;median&lt;/code&gt;, which DuckDB also supports. Also for this reason, DuckDB also supports &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;approx_quantile&lt;/code&gt;, which &lt;em&gt;is&lt;/em&gt; parallelizable.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;experiments&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;experiments&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html#experiments&quot;&gt;Experiments&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Putting all this together, it’s now time for some performance experiments. We will compare DuckDB’s aggregation operator as described above with the same operator in various Python data wrangling libraries. The other contenders are Pandas, Polars and Arrow. Those are chosen since they can all execute an aggregation operator on Pandas DataFrames without converting into some other storage format first, just like DuckDB.&lt;/p&gt;

&lt;p&gt;For our benchmarks, we generate a synthetic dataset with a pre-defined number of groups over two integer columns and some random integer data to aggregate. The entire dataset is shuffled before the experiments to prevent taking advantage of the clustered nature of the synthetically generated data. For each group, we compute two aggregates, sum of the data column and a simple count. The SQL version of this aggregation would be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT g1, g2, sum(d), count(*) FROM dft GROUP BY g1, g2 LIMIT 1;&lt;/code&gt;. In the experiments below, we vary the dataset size and the amount of groups in them. This should nicely show the scaling behavior of the aggregation.&lt;/p&gt;

&lt;p&gt;Because we are not interested in measuring the result set materialization time which would be significant for millions of groups, we follow the aggregation with an operator that only retrieves the first row. This does not change the complexity of the aggregation at all, since it needs to collect all data before producing even the first result row, since there might be data in the very last input data row that changes results for the first result. Of course this would be fairly unrealistic in practice, but it should nicely isolate the behavior of the aggregation operator only, since a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;head(1)&lt;/code&gt; operation on three columns should be fairly cheap and constant in execution time.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-bench-rows-fewgroups.svg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Varying row count for 1000 groups&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;We measure the elapsed wall clock time required to complete each aggregation. To account for minor variation, we repeat each measurement three times and report the median time required. All experiments were run on a 2021 MacBook Pro with a ten-core M1 Max processor and 64 GB of RAM. Our data generation benchmark script &lt;a href=&quot;https://gist.github.com/hannes/e2599ae338d275c241c567934a13d422&quot;&gt;is available online&lt;/a&gt; and we invite interested readers to re-run the experiment on their machines.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-bench-rows-manygroups.svg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Varying both row count and group count&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;Now let&#39;s discuss some results. We start with varying the amount of rows in the table between one million and 100 millions. We repeat the experiment for both a fixed (small) group count of 1000 and when the amount of groups is equal to the amount of rows. Results are plotted as a &lt;em&gt;log-log plot&lt;/em&gt;, we can see how DuckDB consistently outperforms the other systems, with the single-threaded Pandas being slowest, Polars and Arrow being generally similar.&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://duckdb.org/images/blog/aggregates/aggr-bench-groups.svg&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;figcaption align=&quot;center&quot;&gt;&lt;b&gt;Varying group count for 100M rows&lt;/b&gt;&lt;/figcaption&gt;
&lt;/div&gt;

&lt;p&gt;For the next experiment, we fix the amount of rows at 100M (the largest size we experimented with) and show the full behavior when increasing the group size. We can see again how DuckDB consistently exhibits good scaling behavior when increasing group size, because it can effectively parallelize all phases of aggregation as outlined above. If you are interested in how we generated those plots, the plotting &lt;a href=&quot;https://gist.github.com/hannes/9b0e47625290b8af78de88e1d26441c0&quot;&gt;script is available, too&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/03/07/aggregate-hashtable.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Data analysis pipelines using mostly aggregation spend the vast majority of their execution time in the aggregate hash table, which is why it is worth spending an ungodly amount of human time optimizing them. We have some ideas for future work on this, for example we would like to extend &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html&quot;&gt;our work when comparing sorting keys&lt;/a&gt; to comparing groups in the aggregate hash table. We also would like to add capabilities of dynamically choosing the amount of partitions a thread uses based on dynamic observation of the created hash table, e.g., if partitions are imbalanced we could use more bits to do so. Another large area of future work is to make our aggregate hash table work with out-of-core operations, where an individual hash table no longer fits in memory, this is particularly problematic when merging. And of course there are always opportunities to fine-tune an aggregation operator, and we are continuously improving DuckDBs aggregation operator.&lt;/p&gt;

&lt;p&gt;If you want to work on cutting edge data engineering like this that will be used by thousands of people, consider contributing to DuckDB or join us at DuckDB Labs in Amsterdam!&lt;/p&gt;

</description><link>https://duckdb.org/2022/03/07/aggregate-hashtable.html</link><guid isPermaLink="false">https://duckdb.org/2022/03/07/aggregate-hashtable.html</guid><pubDate>Mon, 07 Mar 2022 00:00:00 GMT</pubDate><author>Hannes Mühleisen and Mark Raasveldt</author></item><item><title>DuckDB Time Zones: Supporting Calendar Extensions</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The DuckDB ICU extension now provides time zone support.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Time zone support is a common request for temporal analytics, but the rules are complex and somewhat arbitrary. 
The most well supported library for locale-specific operations is the &lt;a href=&quot;https://icu.unicode.org/&quot;&gt;International Components for Unicode (ICU)&lt;/a&gt;.
DuckDB already provided collated string comparisons using ICU via an extension (to avoid dependencies),
and we have now connected the existing ICU calendar and time zone functions to the main code 
via the new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP WITH TIME ZONE&lt;/code&gt; (or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMPTZ&lt;/code&gt; for short) data type. The ICU extension is pre-bundled in DuckDB&#39;s Python client and can be optionally installed in the remaining clients.&lt;/p&gt;

&lt;p&gt;In this post, we will describe how time works in DuckDB and what time zone functionality has been added.&lt;/p&gt;
      &lt;h2 id=&quot;what-is-time&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#what-is-time&quot;&gt;What is Time?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;blockquote&gt;
  &lt;p&gt;People assume that time is a strict progression of cause to effect,
but actually from a non-linear, non-subjective viewpoint
it’s more like a big ball of wibbly wobbly timey wimey stuff.&lt;br&gt;
– Doctor Who: Blink&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Time in databases can be very confusing because the way we talk about time is itself confusing.
Local time, GMT, UTC, time zones, leap years, proleptic Gregorian calendars – it all looks like a big mess.
But if you step back, modeling time is actually fairly simple, and can be reduced to two pieces: instants and binning.&lt;/p&gt;
      &lt;h3 id=&quot;instants&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#instants&quot;&gt;Instants&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;You will often hear people (and documentation) say that database time is stored in UTC.
This is sort of right, but it is more accurate to say that databases store &lt;em&gt;instants&lt;/em&gt;.
An instant is a point in universal time, and they are usually given as a count of some time increment from a fixed point in time (called the &lt;em&gt;epoch&lt;/em&gt;).
In DuckDB, the fixed point is the Unix epoch &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1970-01-01 00:00:00 +00:00&lt;/code&gt;, and the increment is microseconds (µs).
(Note that to avoid confusion we will be using ISO-8601 y-m-d notation in this post to denote instants.)
In other words, a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt; column contains instants.&lt;/p&gt;

&lt;p&gt;There are three other temporal types in SQL:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt; – an integral count of days from a fixed date. In DuckDB, the fixed date is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1970-01-01&lt;/code&gt;, again in UTC.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt; – a (positive) count of microseconds up to a single day&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERVAL&lt;/code&gt; – a set of fields for counting time differences. In DuckDB, intervals count months, days and microseconds. (Months are not completely well-defined, but when present, they represent 30 days.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;None of these other temporal types except &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIME&lt;/code&gt; can have a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH TIME ZONE&lt;/code&gt; modifier (and shorter &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TZ&lt;/code&gt; suffix),
but to understand what that modifier means, we first need to talk about &lt;em&gt;temporal binning&lt;/em&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;temporal-binning&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#temporal-binning&quot;&gt;Temporal Binning&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Instants are pretty straightforward – they are just a number – but binning is the part that trips people up.
Binning is probably a familiar idea if you have worked with continuous data:
You break up a set of values into ranges and map each value to the range (or &lt;em&gt;bin&lt;/em&gt;) that it falls into.
Temporal binning is just doing this to instants:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/timezones/tz-instants.svg&quot; alt=&quot;Time Zone Instants at the Epoch&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Temporal binning systems are often called &lt;em&gt;calendars&lt;/em&gt;,
but we are going to avoid that term for now because calendars are usually associated with dates,
and temporal binning also includes rules for time.
These time rules are called &lt;em&gt;time zones&lt;/em&gt;, and they also impact where the day boundaries used by the calendar fall.
For example, here is what the binning for a second time zone looks like at the epoch:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/timezones/tz-timezone.svg&quot; alt=&quot;Two Time Zones at the Epoch&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The most confusing thing about temporal binning is that there is more than one way to bin time,
and it is not always obvious what binning should be used.
For example, what I mean by &quot;today&quot; is a bin of instants often determined by where I live.
Every instant that is part of my &quot;today&quot; goes in that bin.
But notice that I qualified &quot;today&quot; with &quot;where I live&quot;, 
and that qualification determines what binning system is being used.
But &quot;today&quot; could also be determined by &quot;where the events happened&quot;,
which would require a different binning to be applied.&lt;/p&gt;

&lt;p&gt;The biggest temporal binning problem most people run into occurs when daylight savings time changes.
This example contains a daylight savings time change where the &quot;hour&quot; bin is two hours long!
To distinguish the two hours, we needed to include another bin containing the offset from UTC:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/timezones/tz-daylight.svg&quot; alt=&quot;Two Time Zones at a Daylight Savings Time transition&quot; width=&quot;600&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;As this example shows, in order to bin the instants correctly, we need to know the binning rules that apply.
It also shows that we can&#39;t just use the built in binning operations, 
because they don&#39;t understand daylight savings time.&lt;/p&gt;
      &lt;h3 id=&quot;naïve-timestamps&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#na%C3%AFve-timestamps&quot;&gt;Naïve Timestamps&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Instants are sometimes created from a string format using a local binning system instead of an instant.
This results in the instants being offset from UTC, which can cause problems with daylight savings time.
These are called &lt;em&gt;naïve&lt;/em&gt; timestamps, and they may constitute a data cleaning problem.&lt;/p&gt;

&lt;p&gt;Cleaning naïve timestamps requires determining the offset for each timestamp and then updating the value to be an instant.
For most values, this can be done with an inequality join against a table containing the correct offsets,
but the ambiguous values may need to be fixed by hand.
It may also be possible to correct the ambiguous values by assuming that they were inserted in order
and looking for &quot;backwards jumps&quot; using window functions.&lt;/p&gt;

&lt;p&gt;A simple way to avoid this situation going forward is to add the UTC offset to non-UTC strings: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2021-07-31 07:20:15 -07:00&lt;/code&gt;.
The DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; cast operation parses these offsets correctly and will generate the corresponding instant.&lt;/p&gt;
      &lt;h2 id=&quot;time-zone-data-types&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#time-zone-data-types&quot;&gt;Time Zone Data Types&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The SQL standard defines temporal data types qualified by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH TIME ZONE&lt;/code&gt;.
This terminology is confusing because it seems to imply that the time zone will be stored with the value,
but what it really means is &quot;bin this value using the session&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TimeZone&lt;/code&gt; setting&quot;.
Thus a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMPTZ&lt;/code&gt; column also stores instants, 
but expresses a &quot;hint&quot; that it should use a specific binning system.&lt;/p&gt;

&lt;p&gt;There are a number of operations that can be performed on instants without a binning system:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Comparing;&lt;/li&gt;
  &lt;li&gt;Sorting;&lt;/li&gt;
  &lt;li&gt;Increment (µs) difference;&lt;/li&gt;
  &lt;li&gt;Casting to and from regular &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMP&lt;/code&gt;s.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These common operations have been implemented in the main DuckDB code base,
while the binning operations have been delegated to extensions such as ICU.&lt;/p&gt;

&lt;p&gt;One small difference between the display of the new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITH TIME ZONE&lt;/code&gt; types and the older types
is that the new types will be displayed with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+00&lt;/code&gt; UTC offset.
This is simply to make the type differences visible in command line interfaces and for testing.
Properly formatting a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMPTZ&lt;/code&gt; for display in a locale requires using a binning system.&lt;/p&gt;
      &lt;h2 id=&quot;icu-temporal-binning&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#icu-temporal-binning&quot;&gt;ICU Temporal Binning&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB already uses an ICU extension for collating strings for a particular locale,
so it was natural to extend it to expose the ICU calendar and time zone functionality.&lt;/p&gt;
      &lt;h3 id=&quot;icu-time-zones&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#icu-time-zones&quot;&gt;ICU Time Zones&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The first step for supporting time zones is to add the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TimeZone&lt;/code&gt; setting that should be applied.
DuckDB extensions can define and validate their own settings, and the ICU extension now does this:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Load the extension&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- This is not needed in Python or R, as the extension is already installed&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; icu&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Show the current time zone. The default is set to ICU&#39;s current time zone.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duckdb_settings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;TimeZone&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;TimeZone    Europe/Amsterdam    The current time zone   VARCHAR
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Choose a time zone.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;TimeZone&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;America/Los_Angeles&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Emulate Postgres&#39; time zone table&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;abbrev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;utc_offset&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pg_timezone_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ACT ACT 09:30:00
AET AET 10:00:00
AGT AGT -03:00:00
ART ART 02:00:00
AST AST -09:00:00
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;icu-temporal-binning-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#icu-temporal-binning-functions&quot;&gt;ICU Temporal Binning Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Databases like DuckDB and Postgres usually provide some temporal binning functions such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE_PART&lt;/code&gt;.
These functions are part of a single binning system for the conventional (proleptic Gregorian) calendar and the UTC time zone.
Note that casting to a string is a binning operation because the text produced contains bin values.&lt;/p&gt;

&lt;p&gt;Because timestamps that require custom binning have a different data type,
the ICU extension can define additional functions with bindings to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMPTZ&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+&lt;/code&gt; – Add an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERVAL&lt;/code&gt; to a timestamp&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-&lt;/code&gt; – Subtract an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERVAL&lt;/code&gt; from a timestamp&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AGE&lt;/code&gt; – Compute an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INTERVAL&lt;/code&gt; describing the months/days/microseconds between two timestamps (or one timestamp and the current instant).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE_DIFF&lt;/code&gt; – Count part boundary crossings between two timestamp&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE_PART&lt;/code&gt; – Extract a named timestamp part. This includes the part alias functions such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE_SUB&lt;/code&gt; – Count the number of complete parts between two timestamp&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE_TRUNC&lt;/code&gt; – Truncate a timestamp to the given precision&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LAST_DAY&lt;/code&gt; – Returns the last day of the month&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MAKE_TIMESTAMPTZ&lt;/code&gt; – Constructs a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMESTAMPTZ&lt;/code&gt; from parts, including an optional final time zone specifier.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We have not implemented these functions for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TIMETZ&lt;/code&gt; because this type has limited utility, 
but it would not be difficult to add in the future.
We have also not implemented string formatting/casting to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; 
because the type casting system is not yet extensible, 
and the current &lt;a href=&quot;https://github.com/Mytherin/minimal-icu-collation&quot;&gt;ICU build&lt;/a&gt; we are using does not embed this data.&lt;/p&gt;
      &lt;h3 id=&quot;icu-calendar-support&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#icu-calendar-support&quot;&gt;ICU Calendar Support&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;ICU can also perform binning operations for some non-Gregorian calendars. 
We have added support for these calendars via a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Calendar&lt;/code&gt; setting and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;icu_calendar_names&lt;/code&gt; table function:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;LOAD&lt;/span&gt; icu&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Show the current calendar. The default is set to ICU&#39;s current locale.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duckdb_settings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Calendar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Calendar    gregorian   The current calendar    VARCHAR
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- List the available calendars&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DISTINCT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;icu_calendar_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;roc
persian
japanese
iso8601
islamic-umalqura
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- Choose a calendar&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;Calendar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;japanese&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- Extract the current Japanese era number using Tokyo time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;TimeZone&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Asia/Tokyo&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
     &lt;span class=&quot;nf&quot;&gt;era&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;2019-05-01 00:00:00+10&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMPTZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
     &lt;span class=&quot;nf&quot;&gt;era&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;2019-05-01 00:00:00+09&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;TIMESTAMPTZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;235  236
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;caveats&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#caveats&quot;&gt;Caveats&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;ICU has some differences in behavior and representation from the DuckDB implementation. These are hopefully minor issues that should only be of concern to serious time nerds.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ICU represents instants as millisecond counts using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOUBLE&lt;/code&gt;. This makes it lose accuracy far from the epoch (e.g., around the first millennium)&lt;/li&gt;
  &lt;li&gt;ICU uses the Julian calendar for dates before the Gregorian change on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1582-10-15&lt;/code&gt; instead of the proleptic Gregorian calendar. This means that dates prior to the changeover will differ, although ICU will give the date as actually written at the time.&lt;/li&gt;
  &lt;li&gt;ICU computes ages by using part increments instead of using the length of the earlier month like DuckDB and Postgres.&lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;future-work&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#future-work&quot;&gt;Future Work&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Temporal analysis is a large area, and while the ICU time zone support is a big step forward, there is still much that could be done.
Some of these items are core DuckDB improvements that could benefit all temporal binning systems and some expose more ICU functionality.
There is also the prospect for writing other custom binning systems via extensions.&lt;/p&gt;
      &lt;h3 id=&quot;duckdb-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#duckdb-features&quot;&gt;DuckDB Features&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Here are some general projects that all binning systems could benefit from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE_ROLL&lt;/code&gt; function that emulates the ICU calendar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;roll&lt;/code&gt; operation for &quot;rotating&quot; around a containing bin;&lt;/li&gt;
  &lt;li&gt;Making casting operations extensible so extensions can add their own support;&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;icu-functionality&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#icu-functionality&quot;&gt;ICU Functionality&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;ICU is a very rich library with a long pedigree, and there is much that could be done with the existing library:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create a more general &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MAKE_TIMESTAPTZ&lt;/code&gt; variant that takes a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRUCT&lt;/code&gt; with the parts. This could be useful for some non-Gregorian calendars.&lt;/li&gt;
  &lt;li&gt;Extend the embedded data to contain locale temporal information (such as month names) and support formatting (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_char&lt;/code&gt;) and parsing (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_timestamp&lt;/code&gt;) of local dates. One issue here is that the ICU date formatting language is more sophisticated than the Postgres language, so multiple functions might be required (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;icu_to_char&lt;/code&gt;);&lt;/li&gt;
  &lt;li&gt;Extend the binning functions to take per-row calendar and time zone specifications to support row-level temporal analytics such as &quot;what time of day did this happen&quot;?&lt;/li&gt;
&lt;/ul&gt;
      &lt;h3 id=&quot;separation-of-concerns&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#separation-of-concerns&quot;&gt;Separation of Concerns&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Because the time zone data type is defined in the main code base, but the calendar operations are provided by an extension,
it is now possible to write application-specific extensions with custom calendar and time zone support such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Financial 4-4-5 calendars;&lt;/li&gt;
  &lt;li&gt;ISO week-based years;&lt;/li&gt;
  &lt;li&gt;Table-driven calendars;&lt;/li&gt;
  &lt;li&gt;Astronomical calendars with leap seconds;&lt;/li&gt;
  &lt;li&gt;Fun calendars, such as Shire Reckoning and French Republican!&lt;/li&gt;
&lt;/ul&gt;
      &lt;h2 id=&quot;conclusion-and-feedback&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2022/01/06/time-zones.html#conclusion-and-feedback&quot;&gt;Conclusion and Feedback&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we described the new DuckDB time zone functionality as implemented via the ICU extension.
We hope that the functionality provided can enable temporal analytic applications involving time zones.
We also look forward to seeing any custom calendar extensions that our users dream up!&lt;/p&gt;

&lt;p&gt;Last but not least, if you encounter any problems when using our integration, please open an issue in DuckDB&#39;s issue tracker!&lt;/p&gt;

</description><link>https://duckdb.org/2022/01/06/time-zones.html</link><guid isPermaLink="false">https://duckdb.org/2022/01/06/time-zones.html</guid><pubDate>Thu, 06 Jan 2022 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>DuckDB Quacks Arrow: A Zero-Copy Data Integration between Apache Arrow and DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: The zero-copy integration between DuckDB and Apache Arrow allows for rapid analysis of larger than memory datasets in Python and R using either SQL or relational APIs.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;This post is a collaboration with and cross-posted on the &lt;a href=&quot;https://arrow.apache.org/blog/2021/12/03/arrow-duckdb/&quot;&gt;Arrow blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Part of &lt;a href=&quot;https://arrow.apache.org/&quot;&gt;Apache Arrow&lt;/a&gt; is an in-memory data format optimized for analytical libraries. Like Pandas and R Dataframes, it uses a columnar data model. But the Arrow project contains more than just the format: The Arrow C++ library, which is accessible in Python, R, and Ruby via bindings, has additional features that allow you to compute efficiently on datasets. These additional features are on top of the implementation of the in-memory format described above. The datasets may span multiple files in Parquet, CSV, or other formats, and files may even be on remote or cloud storage like HDFS or Amazon S3. The Arrow C++ query engine supports the streaming of query results, has an efficient implementation of complex data types (e.g., Lists, Structs, Maps), and can perform important scan optimizations like Projection and Filter Pushdown.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.duckdb.org/&quot;&gt;DuckDB&lt;/a&gt; is a new analytical data management system that is designed to run complex SQL queries within other processes. DuckDB has bindings for R and Python, among others. DuckDB can query Arrow datasets directly and stream query results back to Arrow. This integration allows users to query Arrow data using DuckDB&#39;s SQL Interface and API, while taking advantage of DuckDB&#39;s parallel vectorized execution engine, without requiring any extra data copying. Additionally, this integration takes full advantage of Arrow&#39;s predicate and filter pushdown while scanning datasets.&lt;/p&gt;

&lt;p&gt;This integration is unique because it uses zero-copy streaming of data between DuckDB and Arrow and vice versa so that you can compose a query using both together. This results in three main benefits:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Larger Than Memory Analysis:&lt;/strong&gt; Since both libraries support streaming query results, we are capable of executing on data without fully loading it from disk. Instead, we can execute one batch at a time. This allows us to execute queries on data that is bigger than memory.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complex Data Types:&lt;/strong&gt; DuckDB can efficiently process complex data types that can be stored in Arrow vectors, including arbitrarily nested structs, lists, and maps.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Advanced Optimizer:&lt;/strong&gt; DuckDB&#39;s state-of-the-art optimizer can push down filters and projections directly into Arrow scans. As a result, only relevant columns and partitions will be read, allowing the system to e.g., take advantage of partition elimination in Parquet files. This significantly accelerates query execution.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For those that are just interested in benchmarks, you can jump ahead &lt;a href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#Benchmark%20Comparison&quot;&gt;benchmark section below&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;quick-tour&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#quick-tour&quot;&gt;Quick Tour&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Before diving into the details of the integration, in this section we provide a quick motivating example of how powerful and simple to use is the DuckDB-Arrow integration. With a few lines of code, you can already start querying Arrow datasets. Say you want to analyze the infamous &lt;a href=&quot;https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page&quot;&gt;NYC Taxi Dataset&lt;/a&gt; and figure out if groups tip more or less than single riders.&lt;/p&gt;
      &lt;h3 id=&quot;r&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#r&quot;&gt;R&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Both Arrow and DuckDB support dplyr pipelines for people more comfortable with using dplyr for their data analysis. The Arrow package includes two helper functions that allow us to pass data back and forth between Arrow and DuckDB (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_duckdb()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_arrow()&lt;/code&gt;).
This is especially useful in cases where something is supported in one of Arrow or DuckDB but not the other. For example, if you find a complex dplyr pipeline where the SQL translation doesn&#39;t work with DuckDB, use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_arrow()&lt;/code&gt; before the pipeline to use the Arrow engine. Or, if you have a function (e.g., windowed aggregates) that aren&#39;t yet implemented in Arrow, use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_duckdb()&lt;/code&gt; to use the DuckDB engine. All while not paying any cost to (re)serialize the data when you pass it back and forth!&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Open dataset using year,month folder partition&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nyc-taxi&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitioning&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Look only at 2015 on, where the number of passenger is positive, the trip distance is&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# greater than a quarter mile, and where the fare amount is positive&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2014&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;passenger_count&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trip_distance&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fare_amount&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Pass off to DuckDB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;passenger_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tip_pct&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tip_amount&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fare_amount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fare_amount&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fare_amount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tip_amount&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tip_amount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tip_pct&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tip_pct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;passenger_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;python&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#python&quot;&gt;Python&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The workflow in Python is as simple as it is in R. In this example we use DuckDB&#39;s Relational API.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow.dataset&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Open dataset using year, month folder partition
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;nyc-taxi/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitioning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# We transform the nyc dataset into a DuckDB relation
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Run same query again
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year &amp;gt; 2014 &amp;amp; passenger_count &amp;gt; 0 &amp;amp; trip_distance &amp;gt; 0.25 &amp;amp; fare_amount &amp;gt; 0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aggregate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT avg(fare_amount), avg(tip_amount), avg(tip_amount / fare_amount) AS tip_pct&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;passenger_count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;duckdb-and-arrow-the-basics&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#duckdb-and-arrow-the-basics&quot;&gt;DuckDB and Arrow: The Basics&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this section, we will look at some basic examples of the code needed to read and output Arrow tables in both Python and R.&lt;/p&gt;
      &lt;h3 id=&quot;setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#setup&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;First we need to install DuckDB and Arrow. The installation process for both libraries in Python and R is shown below.&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Python Install&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;pip &lt;/span&gt;install &lt;span class=&quot;nb&quot;&gt;duckdb
pip &lt;/span&gt;install pyarrow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# R Install&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;duckdb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;arrow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To execute the sample-examples in this section, we need to download the following custom Parquet files:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://duckdb.org/data/integers.parquet&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;integers.parquet&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blobs.duckdb.org/data/lineitemsf1.snappy.parquet&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitemsf1.snappy.parquet&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
      &lt;h4 id=&quot;python-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#python-1&quot;&gt;Python&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;There are two ways in Python of querying data from Arrow:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Through the Relational API&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Reads Parquet File to an Arrow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;integers.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Transforms Arrow Table -&amp;gt; DuckDB Relation
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rel_from_arrow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# we can run a SQL query on this and print the result
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rel_from_arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;arrow_table&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;SELECT sum(data) FROM arrow_table WHERE data &amp;gt; 50&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Transforms DuckDB Relation -&amp;gt; Arrow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table_from_duckdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rel_from_arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;By using replacement scans and querying the object directly with SQL:&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Reads Parquet File to an Arrow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;integers.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Gets Database Connection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# we can run a SQL query on this and print the result
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SELECT sum(data) FROM arrow_table WHERE data &amp;gt; 50&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Transforms Query Result from DuckDB to Arrow Table
# We can directly read the arrow object through DuckDB&#39;s replacement scans.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM arrow_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetch_arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is possible to transform both DuckDB Relations and Query Results back to Arrow.&lt;/p&gt;
      &lt;h4 id=&quot;r-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#r-1&quot;&gt;R&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;In R, you can interact with Arrow data in DuckDB by registering the table as a view (an alternative is to use dplyr as shown above).&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Reads Parquet File to an Arrow Table&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;integers.parquet&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_data_frame&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Gets Database Connection&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbConnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Registers arrow table as a DuckDB view&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;arrow_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# we can run a SQL query on this and print the result&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbGetQuery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;SELECT sum(data) FROM arrow_table WHERE data &amp;gt; 50&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Transforms Query Result from DuckDB to Arrow Table&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbSendQuery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;SELECT * FROM arrow_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;streaming-data-fromto-arrow&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#streaming-data-fromto-arrow&quot;&gt;Streaming Data from/to Arrow&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In the previous section, we depicted how to interact with Arrow tables. However, Arrow also allows users to interact with the data in a streaming fashion. Either consuming it (e.g., from an Arrow Dataset) or producing it (e.g., returning a RecordBatchReader). And of course, DuckDB is able to consume Datasets and produce RecordBatchReaders. This example uses the NYC Taxi Dataset, stored in Parquet files partitioned by year and month, which we can download through the Arrow R package:&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;s3://ursa-labs-taxi-data&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nyc-taxi&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;python-2&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#python-2&quot;&gt;Python&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Reads dataset partitioning it in year/month folder
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;nyc-taxi/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitioning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Gets Database Connection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM nyc_dataset&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# DuckDB&#39;s queries can now produce a Record Batch Reader
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_batch_reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetch_record_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Which means we can stream the whole query per batch.
# This retrieves the first batch
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunk&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record_batch_reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_next_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h4 id=&quot;r-2&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#r-2&quot;&gt;R&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Reads dataset partitioning it in year/month folder&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_dataset&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nyc-taxi/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitioning&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Gets Database Connection&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbConnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# We can use the same function as before to register our arrow dataset&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb_register_arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nyc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbSendQuery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;SELECT * FROM nyc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# DuckDB&#39;s queries can now produce a Record Batch Reader&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_batch_reader&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb_fetch_record_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Which means we can stream the whole query per batch.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# This retrieves the first batch&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur_batch&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_batch_reader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_next_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The preceding R code shows in low-level detail how the data is streaming. We provide the helper &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_arrow()&lt;/code&gt; in the Arrow package which is a wrapper around this that makes it easy to incorporate this streaming into a dplyr pipeline.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In Arrow 6.0.0, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_arrow()&lt;/code&gt; currently returns the full table, but will allow full streaming in our upcoming 7.0.0 release.&lt;/p&gt;
&lt;/blockquote&gt;
      &lt;h2 id=&quot;benchmark-comparison&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#benchmark-comparison&quot;&gt;Benchmark Comparison&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Here we demonstrate in a simple benchmark the performance difference between querying Arrow datasets with DuckDB and querying Arrow datasets with Pandas.
For both the Projection and Filter pushdown comparison, we will use Arrow tables. That is due to Pandas not being capable of consuming Arrow stream objects.&lt;/p&gt;

&lt;p&gt;For the NYC Taxi benchmarks, we used a server in the SciLens cluster and for the TPC-H benchmarks, we used a MacBook Pro with an M1 CPU. In both cases, parallelism in DuckDB was used (which is now on by default).&lt;/p&gt;

&lt;p&gt;For the comparison with Pandas, note that DuckDB runs in parallel, while pandas only support single-threaded execution. Besides that, one should note that we are comparing automatic optimizations. DuckDB&#39;s query optimizer can automatically push down filters and projections. This automatic optimization is not supported in pandas, but it is possible for users to manually perform some of these predicate and filter pushdowns by manually specifying them in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet()&lt;/code&gt; call.&lt;/p&gt;
      &lt;h3 id=&quot;projection-pushdown&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#projection-pushdown&quot;&gt;Projection Pushdown&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In this example we run a simple aggregation on two columns of our lineitem table.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# DuckDB
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;lineitemsf1.snappy.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Transforms Query Result from DuckDB to Arrow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;SELECT sum(l_extendedprice * l_discount) AS revenue
                FROM
                lineitem;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetch_arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Pandas
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;lineitemsf1.snappy.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Converts an Arrow table to a Dataframe
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Runs aggregation
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Creates an Arrow Table from a Dataframe
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.13&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The lineitem table is composed of 16 columns, however, to execute this query only two columns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_extendedprice&lt;/code&gt; and  *  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l_discount&lt;/code&gt; are necessary. Since DuckDB can push down the projection of these columns, it is capable of executing this query about one order of magnitude faster than Pandas.&lt;/p&gt;
      &lt;h3 id=&quot;filter-pushdown&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#filter-pushdown&quot;&gt;Filter Pushdown&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For our filter pushdown we repeat the same aggregation used in the previous section, but add filters on 4 more columns.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# DuckDB
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;lineitemsf1.snappy.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Get database connection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Transforms Query Result from DuckDB to Arrow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;SELECT sum(l_extendedprice * l_discount) AS revenue
        FROM
            lineitem
        WHERE
            l_shipdate &amp;gt;= CAST(&#39;1994-01-01&#39; AS date)
            AND l_shipdate &amp;lt; CAST(&#39;1995-01-01&#39; AS date)
            AND l_discount BETWEEN 0.05
            AND 0.07
            AND l_quantity &amp;lt; 24; &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetch_arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Pandas
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;lineitemsf1.snappy.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1994-01-01&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1995-01-01&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.07&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_quantity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_discount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;new_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.04&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.29&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The difference now between DuckDB and Pandas is more drastic, being two orders of magnitude faster than Pandas. Again, since both the filter and projection are pushed down to Arrow, DuckDB reads less data than Pandas, which can&#39;t automatically perform this optimization.&lt;/p&gt;
      &lt;h3 id=&quot;streaming&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#streaming&quot;&gt;Streaming&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;As demonstrated before, DuckDB is capable of consuming and producing Arrow data in a streaming fashion. In this section we run a simple benchmark, to showcase the benefits in speed and memory usage when comparing it to full materialization and Pandas. This example uses the full NYC taxi dataset which you can download&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# DuckDB
# Open dataset using year,month folder partition
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;nyc-taxi/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitioning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Get database connection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Run query that selects part of the data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT total_amount, passenger_count,year FROM nyc where total_amount &amp;gt; 100 and year &amp;gt; 2014&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create Record Batch Reader from Query Result.
# &quot;fetch_record_batch()&quot; also accepts an extra parameter related to the desired produced chunk size.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record_batch_reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetch_record_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Retrieve all batch chunks
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunk&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record_batch_reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_next_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;chunk&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record_batch_reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_next_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Pandas
# We must exclude one of the columns of the NYC dataset due to an unimplemented cast in Arrow.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;working_columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;vendor_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pickup_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dropoff_at&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;passenger_count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;trip_distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pickup_longitude&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;pickup_latitude&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;store_and_fwd_flag&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dropoff_longitude&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dropoff_latitude&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;payment_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;fare_amount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;extra&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mta_tax&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tip_amount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tolls_amount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_amount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Open dataset using year,month folder partition
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitioning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;month&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Generate a scanner to skip problematic column
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset_scanner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyc_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scanner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;working_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Materialize dataset to an Arrow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset_scanner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate Dataframe from Arow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyc_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Apply Filter
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nyc_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_amount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nyc_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2014&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Apply Projection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_amount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;passenger_count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;year&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Transform Result back to an Arrow Table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Peak memory usage (GBs)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;146.91&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;248&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The difference in times between DuckDB and Pandas is a combination of all the integration benefits we explored in this article. In DuckDB the filter pushdown is applied to perform partition elimination (i.e., we skip reading the Parquet files where the year is &amp;lt;= 2014). The filter pushdown is also used to eliminate unrelated row_groups (i.e., row groups where the total amount is always &amp;lt;= 100). Due to our projection pushdown, Arrow only has to read the columns of interest from the Parquet files, which allows it to read only 4 out of 20 columns. On the other hand, Pandas is not capable of automatically pushing down any of these optimizations, which means that the full dataset must be read. &lt;strong&gt;This results in the 4 orders of magnitude difference in query execution time.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the table above, we also depict the comparison of peak memory usage between DuckDB (Streaming) and Pandas (Fully-Materializing).  In DuckDB, we only need to load the row group of interest into memory. Hence our memory usage is low. We also have constant memory usage since we only have to keep one of these row groups in-memory at a time. Pandas, on the other hand, has to fully materialize all Parquet files when executing the query. Because of this, we see a constant steep increase in its memory consumption. &lt;strong&gt;The total difference in memory consumption of the two solutions is around 3 orders of magnitude.&lt;/strong&gt;&lt;/p&gt;
      &lt;h2 id=&quot;conclusion-and-feedback&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/12/03/duck-arrow.html#conclusion-and-feedback&quot;&gt;Conclusion and Feedback&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In this blog post, we mainly showcased how to execute queries on Arrow datasets with DuckDB. There are additional libraries that can also consume the Arrow format but they have different purposes and capabilities. As always, we are happy to hear if you want to see benchmarks with different tools for a post in the future! Feel free to drop us an &lt;a href=&quot;https://duckdb.org/cdn-cgi/l/email-protection#58283d3c2a37183c2d3b333c3a34393a2b763b373563323736182e37342c2a37363c392c39763b3735&quot;&gt;email&lt;/a&gt; or share your thoughts directly in the Hacker News post.&lt;/p&gt;

&lt;p&gt;Last but not least, if you encounter any problems when using our integration, please open an issue in either &lt;a href=&quot;https://github.com/duckdb/duckdb/issues&quot;&gt;DuckDB&#39;s issue tracker&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/projects/ARROW/&quot;&gt;Arrow&#39;s issue tracker&lt;/a&gt;, depending on which library has a problem.&lt;/p&gt;

</description><link>https://duckdb.org/2021/12/03/duck-arrow.html</link><guid isPermaLink="false">https://duckdb.org/2021/12/03/duck-arrow.html</guid><pubDate>Fri, 03 Dec 2021 00:00:00 GMT</pubDate><author>Pedro Holanda and Jonathan Keane</author></item><item><title>DuckDB – Lord of the Enums: The Fellowship of the Categorical and Factors</title><description>&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duck-lotr.png&quot; alt=&quot;dict-enc&quot; width=&quot;300&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;String types are one of the most commonly used types. However, often string columns have a limited number of distinct values. For example, a country column will never have more than a few hundred unique entries. Storing a data type as a plain string causes a waste of storage and compromises query performance. A better solution is to dictionary encode these columns. In dictionary encoding, the data is split into two parts: the category and the values. The category stores the actual strings, and the values stores a reference to the strings. This encoding is depicted below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/dictionary-encoding.png&quot; alt=&quot;dict-enc&quot; width=&quot;500&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;In the old times, users would manually perform dictionary encoding by creating lookup tables and translating their ids back with join operations. Environments like Pandas and R support these types more elegantly. &lt;a href=&quot;https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html&quot;&gt;Pandas Categorical&lt;/a&gt; and &lt;a href=&quot;https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Factors&quot;&gt;R Factors&lt;/a&gt; are types that allow for columns of strings with many duplicate entries to be efficiently stored through dictionary encoding.&lt;/p&gt;

&lt;p&gt;Dictionary encoding not only allows immense storage savings but also allows systems to operate on numbers instead of on strings, drastically boosting query performance. By lowering RAM usage, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s also allow DuckDB to scale to significantly larger datasets.&lt;/p&gt;

&lt;p&gt;To allow DuckDB to fully integrate with these encoded structures, we implemented Enum Types. This blog post will show code snippets of how to use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; types from both SQL API and Python/R clients, and will demonstrate the performance benefits of the enum types over using regular strings. To the best of our knowledge, DuckDB is the first RDBMS that natively integrates with Pandas categorical columns and R factors.&lt;/p&gt;
      &lt;h2 id=&quot;sql&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#sql&quot;&gt;SQL&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Our Enum SQL syntax is heavily inspired by &lt;a href=&quot;https://www.postgresql.org/docs/9.1/datatype-enum.html&quot;&gt;Postgres&lt;/a&gt;. Below, we depict how to create and use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; type.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TYPE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lotr_race&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ENUM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Orc&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;character&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;race&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lotr_race&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;character&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Frodo Quackins&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Quackalf &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- We can perform a normal string comparison&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- Note that &#39;Hobbit&#39; will be cast to a lotr_race&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- hence this comparison is actually a fast integer comparison&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;character&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;race&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;----&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Frodo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Quackins&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; columns behave exactly the same as normal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VARCHAR&lt;/code&gt; columns. They can be used in string functions (such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;substring&lt;/code&gt;), they can be compared, ordered, etc. The only exception is that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; columns can only hold the values that are specified in the enum definition. Inserting a value that is not part of the enum definition will result in an error.&lt;/p&gt;

&lt;p&gt;DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s are currently static (i.e., values can not be added or removed after the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; definition). However, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; updates are on the roadmap for the next version.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://duckdb.org/docs/stable/sql/data_types/enum.html&quot;&gt;the documentation&lt;/a&gt; for more information.&lt;/p&gt;
      &lt;h2 id=&quot;python&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#python&quot;&gt;Python&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#setup&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;First we need to install DuckDB and Pandas. The installation process of both libraries in Python is straightforward:&lt;/p&gt;

&lt;div class=&quot;language-batch highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Python Install&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;pip &lt;/span&gt;install &lt;span class=&quot;nb&quot;&gt;duckdb
pip &lt;/span&gt;install pandas 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;usage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#usage&quot;&gt;Usage&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Pandas columns from the categorical type are directly converted to DuckDB&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; types:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Our unencoded data.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Elf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Elf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Man&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# &#39;pd.Categorical&#39; automatically encodes the data as a categorical column
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;races&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# We can query this dataframe as we would any other
# The conversion from categorical columns to enums happens automatically
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM df_in&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;r&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#r&quot;&gt;R&lt;/a&gt;
        
      &lt;/h2&gt;
    
      &lt;h3 id=&quot;setup-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#setup-1&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We only need to install DuckDB in our R client, and we are ready to go.&lt;/p&gt;

&lt;div class=&quot;language-R highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# R Install&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;duckdb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;usage-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#usage-1&quot;&gt;Usage&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Similar to our previous example with Pandas, R Factor columns are also automatically converted to DuckDB&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; types.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;duckdb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbConnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;on.exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbDisconnect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Our unencoded data.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Elf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Elf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Man&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Our R dataframe holding an encoded version of our data column&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# &#39;as.factor&#39; automatically encodes it.&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_in&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;races&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as.factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;


&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb_register&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;characters&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_out&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbReadTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;characters&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;benchmark-comparison&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#benchmark-comparison&quot;&gt;Benchmark Comparison&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To demonstrate the performance of DuckDB when running operations on categorical columns of Pandas DataFrames, we present a number of benchmarks. The source code for the benchmarks is available &lt;a href=&quot;https://raw.githubusercontent.com/duckdb/duckdb-web/main/_posts/benchmark_scripts/enum.py&quot;&gt;here&lt;/a&gt;. In our benchmarks we always consume and produce Pandas DataFrames.&lt;/p&gt;
      &lt;h3 id=&quot;dataset&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#dataset&quot;&gt;Dataset&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Our dataset is composed of one dataframe with 4 columns and 10 million rows. The first two columns are named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subrace&lt;/code&gt; representing races. They are both categorical, with the same categories but different values. The other two columns &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race_string&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subrace_string&lt;/code&gt; are the string representations of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subrace&lt;/code&gt;``.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;race_categories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Elf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Man&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;race&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race_categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;subrace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race_categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;s&quot;&gt;&#39;subrace&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                       &lt;span class=&quot;s&quot;&gt;&#39;race_string&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;race&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;s&quot;&gt;&#39;subrace_string&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,})&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#10,000,000 rows
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;grouped-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#grouped-aggregation&quot;&gt;Grouped Aggregation&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In our grouped aggregation benchmark, we do a count of how many characters for each race we have in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race_string&lt;/code&gt; column of our table.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duck_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT race, count(*) FROM df GROUP BY race&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duck_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT race_string, count(*) FROM df GROUP BY race_string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pandas_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race_string&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race_string&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The table below depicts the timings of this operation. We can see the benefits of performing grouping on encoded values over strings, with DuckDB being 4× faster when grouping small unsigned values.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (Categorical)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (String)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.04&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (Categorical)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.06&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (String)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.40&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;filter&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#filter&quot;&gt;Filter&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In our filter benchmark, we do a count of how many Hobbit characters we have in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race_string&lt;/code&gt; column of our table.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duck_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT count(*) FROM df WHERE race = &#39;Hobbit&#39;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duck_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT count(*) FROM df WHERE race_string = &#39;Hobbit&#39;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Hobbit&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pandas_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Hobbit&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race_string&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For the DuckDB enum type, DuckDB converts the string &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Hobbit&lt;/code&gt; to a value in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;, which returns an unsigned integer. We can then do fast numeric comparisons, instead of expensive string comparisons, which results in greatly improved performance.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (Categorical)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.003&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (String)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.023&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (Categorical)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.158&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (String)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.440&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;enum--enum-comparison&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#enum--enum-comparison&quot;&gt;Enum – Enum Comparison&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In this benchmark, we perform an equality comparison of our two breed columns. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subrace&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race_string&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subrace_string&lt;/code&gt;``&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duck_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT count(*) FROM df WHERE race = subrace&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;duck_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT count(*) FROM df WHERE race_string = subrace_string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pandas_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race_string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subrace_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race_string&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s can be compared directly on their encoded values. This results in a time difference similar to the previous case, again because we are able to compare numeric values instead of strings.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (Categorical)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.005&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (String)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.040&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (Categorical)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.130&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (String)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.550&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h3 id=&quot;storage&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#storage&quot;&gt;Storage&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In this benchmark, we compare the storage savings of storing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; Types vs Strings.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;race_categories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Hobbit&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Elf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;Man&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Mayar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;race&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race_categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;categorical_race&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;race&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;string_race&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;race&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;race&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;duck_cat.db&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CREATE TABLE character AS SELECT * FROM categorical_race&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;duck_str.db&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CREATE TABLE character AS SELECT * FROM string_race&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The table below depicts the DuckDB file size differences when storing the same column as either an Enum or a plain string. Since the dictionary-encoding does not repeat the string values, we can see a reduction of one order of magnitude in size.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Size (MB)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (Categorical)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (String)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;102&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;what-about-the-sequels&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#what-about-the-sequels&quot;&gt;What about the Sequels?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There are three main directions we will pursue in the following versions of DuckDB related to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Automatic Storage Encoding: As described in the introduction, users frequently define database columns as Strings when in reality they are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s. Our idea is to automatically detect and dictionary-encode these columns, without any input of the user and in a way that is completely invisible to them.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; Updates: As said in the introduction, our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s are currently static. We will allow the insertion and removal of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; categories.&lt;/li&gt;
  &lt;li&gt;Integration with other Data Formats: We want to expand our integration with data formats that implement &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;-like structures.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;feedback&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/26/duck-enum.html#feedback&quot;&gt;Feedback&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;As usual, let us know what you think about our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt; integration, which data formats you would like us to integrate with and any ideas you would like us to pursue on this topic! Feel free to send me an &lt;a href=&quot;https://duckdb.org/cdn-cgi/l/email-protection#0a7a6f6e78654a6e7f69616e68666b687924696567&quot;&gt;email&lt;/a&gt;. If you encounter any problems when using our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ENUM&lt;/code&gt;s, please open an issue in our &lt;a href=&quot;https://github.com/duckdb/duckdb/issues&quot;&gt;issue tracker&lt;/a&gt;!&lt;/p&gt;

</description><link>https://duckdb.org/2021/11/26/duck-enum.html</link><guid isPermaLink="false">https://duckdb.org/2021/11/26/duck-enum.html</guid><pubDate>Fri, 26 Nov 2021 00:00:00 GMT</pubDate><author>Pedro Holanda</author></item><item><title>Fast Moving Holistic Aggregates</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB, a free and open-source analytical data management system, has a windowing API that can compute complex moving aggregates like interquartile ranges and median absolute deviation much faster than the conventional approaches.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;In a &lt;a href=&quot;https://duckdb.org/2021/10/13/windowing.html&quot;&gt;previous post&lt;/a&gt;,
we described the DuckDB windowing architecture and mentioned the support for
some advanced moving aggregates.
In this post, we will compare the performance various possible moving implementations of these functions
and explain how DuckDB&#39;s performant implementations work.&lt;/p&gt;
      &lt;h2 id=&quot;what-is-an-aggregate-function&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#what-is-an-aggregate-function&quot;&gt;What Is an Aggregate Function?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;When people think of aggregate functions, they typically have something simple in mind such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUM&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AVG&lt;/code&gt;.
But more generally, what an aggregate function does is &lt;em&gt;summarise&lt;/em&gt; a set of values into a single value.
Such summaries can be arbitrarily complex, and involve any data type.
For example, DuckDB provides aggregates for concatenating strings (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRING_AGG&lt;/code&gt;)
and constructing lists (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIST&lt;/code&gt;).
In SQL, aggregated sets come from either a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clause or an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; windowing specification.&lt;/p&gt;
      &lt;h3 id=&quot;holistic-aggregates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#holistic-aggregates&quot;&gt;Holistic Aggregates&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;All of the basic SQL aggregate functions like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SUM&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MAX&lt;/code&gt; can be computed
by reading values one at a time and throwing them away.
But there are some functions that potentially need to keep track of all the values before they can produce a result.
These are called &lt;em&gt;holistic&lt;/em&gt; aggregates, and they require more care when implementing.&lt;/p&gt;

&lt;p&gt;For some aggregates (like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STRING_AGG&lt;/code&gt;) the order of the values can change the result.
This is not a problem for windowing because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; clauses can specify an ordering,
but in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clause, the values are unordered.
To handle this, order sensitive aggregates can include a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITHIN GROUP(ORDER BY &amp;lt;expr&amp;gt;)&lt;/code&gt; clause
to specify the order of the values.
Because the values must all be collected and sorted,
aggregates that use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WITHIN GROUP&lt;/code&gt; clause are holistic.&lt;/p&gt;
      &lt;h3 id=&quot;statistical-holistic-aggregates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#statistical-holistic-aggregates&quot;&gt;Statistical Holistic Aggregates&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Because sorting the arguments to a windowed aggregate can be specified with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; clause,
you might wonder if there are any other kinds of holistic aggregates that do not use sorting,
or which use an ordering different from the one in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; clause.
It turns out that there are a number of important statistical functions that
turn into holistic aggregates in SQL.
In particular, here are the statistical holistic aggregates that DuckDB currently supports:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Function&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode(x)&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The most common value in a set&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;median(x)&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The middle value of a set&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile_disc(x, &amp;lt;frac&amp;gt;)&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The exact value corresponding to a fractional position.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile_cont(x, &amp;lt;frac&amp;gt;)&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The interpolated value corresponding to a fractional position.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile_disc(x, [&amp;lt;frac&amp;gt;...])&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;A list of the exact values corresponding to a list of fractional positions.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile_cont(x, [&amp;lt;frac&amp;gt;...])&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;A list of the interpolated value corresponding to a list of fractional positions.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mad(x)&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;The median of the absolute values of the differences of each value from the median.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Where things get really interesting is when we try to compute moving versions of these aggregates.
For example, computing a moving &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AVG&lt;/code&gt; is fairly straightforward:
You can subtract values that have left the frame and add in the new ones,
or use the segment tree approach from the &lt;a href=&quot;https://duckdb.org/2021/10/13/windowing.html&quot;&gt;previous post on windowing&lt;/a&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;python-example&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#python-example&quot;&gt;Python Example&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Computing a moving median is not as easy.
Let&#39;s look at a simple example of how we might implement moving &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;median&lt;/code&gt; in Python
for the following string data, using a frame that includes one element from each side:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/holistic/python.svg&quot; alt=&quot;Python Median Example&quot; title=&quot;Figure 1: Python Median Example&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;For this example we are using strings so we don&#39;t have to worry about interpolating values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;a&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;b&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;c&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;d&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;c&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;b&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# First index of the frame
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# Last index of the frame
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Copy the frame values
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# Sort the frame values
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# Middle index of the frame
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;median&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# The median is the middle value
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;median&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Each frame has a different set of values to aggregate and we can&#39;t change the order in the table,
so we have to copy them each time before we sort.
Sorting is slow, and there is a lot of repetition.&lt;/p&gt;

&lt;p&gt;All of these holistic aggregates have similar problems
if we just reuse the simple implementations for moving versions.
Fortunately, there are much faster approaches for all of them.&lt;/p&gt;
      &lt;h2 id=&quot;moving-holistic-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#moving-holistic-aggregation&quot;&gt;Moving Holistic Aggregation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In the &lt;a href=&quot;https://duckdb.org/2021/10/13/windowing.html&quot;&gt;previous post on windowing&lt;/a&gt;,
we explained the component operations used to implement a generic aggregate function
(initialize, update, finalize, combine and window).
In the rest of this post, we will dig into how they can be implemented for these complex aggregates.&lt;/p&gt;
      &lt;h3 id=&quot;quantile&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#quantile&quot;&gt;Quantile&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt; aggregate variants all extract the value(s) at a given fraction (or fractions) of the way
through the ordered list of values in the set.
The simplest variant is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;median&lt;/code&gt; function, which we met in the introduction, which uses a fraction of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0.5&lt;/code&gt;.
There are other variants depending on whether the values are
quantitative (i.e., they have a distance and the values can be interpolated)
or merely ordinal (i.e., they can be ordered, but ties have to be broken.)
Still other variants depend on whether the fraction is a single value or a list of values,
but they can all be implemented in similar ways.&lt;/p&gt;

&lt;p&gt;A common way to implement &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt; that we saw in the Python example is to collect all the values into the state,
sort them, and then read out the values at the requested positions.
(This is probably why the SQL standard refers to it as an &quot;ordered-set aggregate&quot;.)
States can be combined by concatenation,
which lets us group in parallel and build segment trees for windowing.&lt;/p&gt;

&lt;p&gt;This approach is very time-consuming because sorting is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N log N)&lt;/code&gt;,
but happily for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt; we can use a related algorithm called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QuickSelect&lt;/code&gt;,
which can find a positional value in only &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N)&lt;/code&gt; time by &lt;em&gt;partially sorting&lt;/em&gt; the array.
You may have run into this algorithm if you have ever used the
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;std::nth_element&lt;/code&gt; algorithm in the C++ standard library.
This works well for grouped quantiles, but for moving quantiles
the segment tree approach ends up being about 5% slower than just starting from scratch for each value.&lt;/p&gt;

&lt;p&gt;To really improve the performance of moving quantiles,
we note that the partial order probably does not change much between frames.
If we maintain a list of indirect indicies into the window and call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nth_element&lt;/code&gt; on the indicies,
we can reorder the partially ordered indicies instead of the values themselves.
In the common case where the frame has the same size,
we can even check to see whether the new value disrupts the partial ordering at all,
and skip the reordering!
With this approach, we can obtain a significant performance boost of 1.5-10 times.&lt;/p&gt;

&lt;p&gt;In this example, we have a 3-element frame (green) that moves one space to the right for each value:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/holistic/median.svg&quot; alt=&quot;Median Example&quot; title=&quot;Figure 2: Median Example&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The median values in orange must be computed from scratch.
Notice that in the example, this only happens at the start of the window.
The median values in white are computed using the existing partial ordering.
In the example, this happens when the frame changes size.
Finally, the median values in blue do not require reordering
because the new value is the same as the old value.
With this algorithm, we can create a faster implementation of single-fraction &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt; without sorting.&lt;/p&gt;
      &lt;h3 id=&quot;interquartile-ranges-iqr&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#interquartile-ranges-iqr&quot;&gt;InterQuartile Ranges (IQR)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We can extend this implementation to &lt;em&gt;lists&lt;/em&gt; of fractions by leveraging the fact that each call to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nth_element&lt;/code&gt;
partially orders the values, which further improves performance.
The &quot;reuse&quot; trick can be generalised to distinguish between fractions that are undisturbed
and ones that need to be recomputed.&lt;/p&gt;

&lt;p&gt;A common application of multiple fractions is computing
&lt;a href=&quot;https://en.wikipedia.org/wiki/Interquartile_range&quot;&gt;interquartile ranges&lt;/a&gt;
by using the fraction list &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[0.25, 0.5, 0.75]&lt;/code&gt;.
This is the fraction list we use for the multiple fraction benchmarks.
Combined with moving &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MIN&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MAX&lt;/code&gt;,
this moving aggregate can be used to generate the data for a moving box-and-whisker plot.&lt;/p&gt;
      &lt;h3 id=&quot;median-absolute-deviation-mad&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#median-absolute-deviation-mad&quot;&gt;Median Absolute Deviation (MAD)&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Maintaining the partial ordering can also be used to boost the performance of the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Median_absolute_deviation&quot;&gt;median absolute deviation&lt;/a&gt;
(or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mad&lt;/code&gt;) aggregate.
Unfortunately, the second partial ordering can&#39;t use the single value trick
because the &quot;function&quot; being used to partially order the values will have changed if the data median changes.
Still, the values are still probably not far off,
which again improves the performance of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nth_element&lt;/code&gt;.&lt;/p&gt;
      &lt;h3 id=&quot;mode&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#mode&quot;&gt;Mode&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; aggregate returns the most common value in a set.
One common way to implement it is to accumulate all the values in the state,
sort them and then scan for the longest run.
These states can be combined by merging,
which lets us compute the mode in parallel and build segment trees for windowing.&lt;/p&gt;

&lt;p&gt;Once again, this approach is very time-consuming because sorting is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N log N)&lt;/code&gt;.
It may also use more memory than necessary because it keeps &lt;em&gt;all&lt;/em&gt; the values
instead of keeping only the unique values.
If there are heavy-hitters in the list,
(which is typically what &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; is being used to find)
this can be significant.&lt;/p&gt;

&lt;p&gt;Another way to implement &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; is to use a hash map for the state that maps values to counts.
Hash tables are typically &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N)&lt;/code&gt; for accumulation, which is an improvement on sorting,
and they only need to store unique values.
If the state also tracks the largest value and count seen so far,
we can just return that value when we finalize the aggregate.
States can be combined by merging,
which lets us group in parallel and build segment trees for windowing.&lt;/p&gt;

&lt;p&gt;Unfortunately, as the benchmarks below demonstrate, this segment tree approach for windowing is quite slow!
The overhead of merging the hash tables for the segment trees turns out to be about 5% slower
than just building a new hash table for each row in the window.
But for a moving &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; computation,
we can instead make a single hash table and update it every time the frame moves,
removing the old values, adding the new values, and updating the value/count pair.
At times the current mode value may have its count decremented,
but when that happens we can rescan the table to find the new mode.&lt;/p&gt;

&lt;p&gt;In this example, the 4-element frame (green) moves one space to the right for each value:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/holistic/mode.svg&quot; alt=&quot;Mode Example&quot; title=&quot;Figure 3: Mode Example&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;When the mode is unchanged (blue) it can be used directly.
When the mode becomes ambiguous (orange), we must recan the table.
This approach is much faster,
and in the benchmarks it comes in between 15 and 55 times faster than the other two.&lt;/p&gt;
      &lt;h2 id=&quot;microbenchmarks&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#microbenchmarks&quot;&gt;Microbenchmarks&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To benchmark the various implementations, we run moving window queries against a 10M table of integers:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The results are then re-aggregated down to one row to remove the impact of streaming the results.
The frames are 100 elements wide, and the test is repeated with a fixed trailing frame:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;quantile_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ROW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iqr&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and a variable frame that moves pseudo-randomly around the current value:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;quantile_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;47&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;521&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;47&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;521&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iqr&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The two examples here are the interquartile range queries;
the other queries use the single argument aggregates &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;median&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mad&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As a final step, we ran the same query with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;count(*)&lt;/code&gt;,
which has the same overhead as the other benchmarks, but is trivial to compute
(it just returns the frame size).
That overhead was subtracted from the run times to give the algorithm timings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/holistic/benchmarks.svg&quot; alt=&quot;Holistic Aggregate Benchmarks&quot; title=&quot;Figure 3: Holistic Aggregate Benchmarks&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;As can be seen, there is a substantial benefit from implementing the window operation
for all of these aggregates, often on the order of a factor of ten.&lt;/p&gt;

&lt;p&gt;An unexpected finding was that the segment tree approach for these complex states
is always slower (by about 5%) than simply creating the state for each output row.
This suggests that when writing combinable complex aggregates,
it is well worth benchmarking the aggregate
and then considering providing a window operation instead of deferring to the segment tree machinery.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/11/12/moving-holistic.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s aggregate API enables aggregate functions to define a windowing operation
that can significantly improve the performance of moving window computations for complex aggregates.
This functionality has been used to significantly speed up windowing for several statistical aggregates,
such as mode, interquartile ranges and median absolute deviation.&lt;/p&gt;

&lt;p&gt;DuckDB is a free and open-source database management system (MIT licensed).
It aims to be the SQLite for Analytics,
and provides a fast and efficient database system with zero external dependencies.
It is available not just for Python, but also for C/C++, R, Java, and more.&lt;/p&gt;

</description><link>https://duckdb.org/2021/11/12/moving-holistic.html</link><guid isPermaLink="false">https://duckdb.org/2021/11/12/moving-holistic.html</guid><pubDate>Fri, 12 Nov 2021 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>DuckDB-Wasm: Efficient Analytical SQL in the Browser</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: &lt;a href=&quot;https://github.com/duckdb/duckdb-wasm&quot;&gt;DuckDB-Wasm&lt;/a&gt; is an in-process analytical SQL database for the browser. It is powered by WebAssembly, speaks Arrow fluently, reads Parquet, CSV and JSON files backed by Filesystem APIs or HTTP requests and has been tested with Chrome, Firefox, Safari and Node.js. You can try it in your browser at &lt;a href=&quot;https://shell.duckdb.org/&quot;&gt;shell.duckdb.org&lt;/a&gt; or on &lt;a href=&quot;https://observablehq.com/@cmudig/duckdb&quot;&gt;Observable&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/duckdb_wasm.svg&quot; alt=&quot;DuckDB-Wasm logo&quot; width=&quot;240&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;DuckDB-Wasm is fast! If you&#39;re here for performance numbers, head over to our benchmarks at &lt;a href=&quot;https://shell.duckdb.org/versus&quot;&gt;shell.duckdb.org/versus&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
      &lt;h2 id=&quot;efficient-analytics-in-the-browser&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#efficient-analytics-in-the-browser&quot;&gt;Efficient Analytics in the Browser&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The web browser has evolved to a universal computation platform that even runs in your car. Its rise has been accompanied by increasing requirements for the browser programming language JavaScript.
JavaScript was, first and foremost, designed to be very flexible which comes at the cost of a reduced processing efficiency compared to native languages like C++.
This becomes particularly apparent when considering the execution times of more complex data analysis tasks that often fall behind the native execution by orders of magnitude.
In the past, such analysis tasks have therefore been pushed to servers that tie any client-side processing to additional round-trips over the internet and introduce their own set of scalability problems.&lt;/p&gt;

&lt;p&gt;The processing capabilities of browsers were boosted tremendously 4 years ago with the introduction of WebAssembly:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;WebAssembly (abbreviated Wasm) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable compilation target for programming languages, enabling deployment on the web for client and server applications.&lt;/p&gt;

  &lt;p&gt;The Wasm stack machine is designed to be encoded in a size- and load-time efficient binary format. WebAssembly aims to execute at native speed by taking advantage of common hardware capabilities available on a wide range of platforms.&lt;/p&gt;

  &lt;p&gt;(ref: &lt;a href=&quot;https://webassembly.org/&quot;&gt;https://webassembly.org/&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Four years later, the WebAssembly revolution is in full progress with first implementations being shipped in four major browsers. It has already brought us game engines, &lt;a href=&quot;https://blog.stackblitz.com/posts/introducing-webcontainers/&quot;&gt;entire IDEs&lt;/a&gt; and even a browser version of &lt;a href=&quot;https://web.dev/ps-on-the-web/&quot;&gt;Photoshop&lt;/a&gt;. Today, we join the ranks with a first release of the npm library &lt;a href=&quot;https://www.npmjs.com/package/@duckdb/duckdb-wasm&quot;&gt;@duckdb/duckdb-wasm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As an in-process analytical database, DuckDB has the rare opportunity to siginificantly speed up OLAP workloads in the browser. We believe that there is a need for a comprehensive and self-contained data analysis library. DuckDB-wasm automatically offloads your queries to dedicated worker threads and reads Parquet, CSV and JSON files from either your local filesystem or HTTP servers driven by plain SQL input.
In this blog post, we want to introduce the library and present challenges on our journey towards a browser-native OLAP database.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;DuckDB-Wasm is not yet stable. You will find rough edges and bugs in this release. Please share your thoughts with us &lt;a href=&quot;https://github.com/duckdb/duckdb-wasm/discussions&quot;&gt;on GitHub&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
      &lt;h2 id=&quot;how-to-get-data-in&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#how-to-get-data-in&quot;&gt;How to Get Data In?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let&#39;s dive into examples.
DuckDB-Wasm provides a variety of ways to load your data. First, raw SQL value clauses like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT INTO sometable VALUES (1, &#39;foo&#39;), (2, &#39;bar&#39;)&lt;/code&gt; are easy to formulate and only depend on plain SQL text. Alternatively, SQL statements like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CREATE TABLE foo AS SELECT * FROM &#39;somefile.parquet&#39;&lt;/code&gt; consult our integrated web filesystem to resolve &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;somefile.parquet&lt;/code&gt; locally, remotely or from a buffer. The methods &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;insertCSVFromPath&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;insertJSONFromPath&lt;/code&gt; further provide convenient ways to import CSV and JSON files using additional typed settings like column types. And finally, the method &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;insertArrowFromIPCStream&lt;/code&gt; (optionally through &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;insertArrowTable&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;insertArrowBatches&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;insertArrowVectors&lt;/code&gt;) copies raw IPC stream bytes directly into a WebAssembly stream decoder.&lt;/p&gt;

&lt;p&gt;The following example presents different options how data can be imported into DuckDB-Wasm:&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Data can be inserted from an existing arrow.Table&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;insertArrowTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;existingTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;arrow_table&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ..., from Arrow vectors&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;insertArrowVectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Int32Vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Utf8Vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;arrow_vectors&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ..., from a raw Arrow IPC stream&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;streamResponse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fetch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`someapi`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;streamReader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;streamResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;streamInserts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;streamReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;streamInserts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;insertArrowFromIPCStream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;streamed&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}));&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;streamInserts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ..., from CSV files&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// (interchangeable: registerFile{Text,Buffer,URL,Handle})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;registerFileText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`data.csv`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;1|foo&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;2|bar&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ... with typed insert options&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;importCSVFromPath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;data.csv&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;detect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;delimiter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;col1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;col2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Utf8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ..., from JSON documents in row-major format&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;registerFileText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;rows.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`[
    { &quot;col1&quot;: 1, &quot;col2&quot;: &quot;foo&quot; },
    { &quot;col1&quot;: 2, &quot;col2&quot;: &quot;bar&quot; },
]`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ... or column-major format&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;registerFileText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;columns.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;`{
    &quot;col1&quot;: [1, 2],
    &quot;col2&quot;: [&quot;foo&quot;, &quot;bar&quot;]
}`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ... with typed insert options&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;importJSONFromPath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;rows.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;importJSONFromPath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;columns.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ..., from Parquet files&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;pickedFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;letUserPickFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;registerFileHandle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;local.parquet&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;pickedFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;registerFileURL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;remote.parquet&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;https://origin/remote.parquet&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// ..., by specifying URLs in the SQL text&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`
    CREATE TABLE direct AS
        SELECT * FROM &#39;https://origin/remote.parquet&#39;
`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ..., or by executing raw insert statements&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`INSERT INTO existing_table
    VALUES (1, &quot;foo&quot;), (2, &quot;bar&quot;)`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;how-to-get-data-out&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#how-to-get-data-out&quot;&gt;How to Get Data Out?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we have the data loaded, DuckDB-Wasm can run queries on two different ways that differ in the result materialization. First, the method &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt; runs a query to completion and returns the results as single &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow.Table&lt;/code&gt;. Second, the method &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;send&lt;/code&gt; fetches query results lazily through an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arrow.RecordBatchStreamReader&lt;/code&gt;. Both methods are generic and allow for typed results in Typescript:&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Either materialize the query result&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Int32&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`
    SELECT * FROM generate_series(1, 100) t(v)
`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ..., or fetch the result chunks lazily&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Int32&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`
    SELECT * FROM generate_series(1, 100) t(v)
`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// ...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, you can prepare statements for parameterized queries using:&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Prepare query&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;prepare&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Int32&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;`SELECT (v + ?) AS v FROM generate_series(0, 10000) t(v);`&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ... and run the query with materialized results&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;234&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ... or result chunks&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;234&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// ...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;looks-like-arrow-to-me&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#looks-like-arrow-to-me&quot;&gt;Looks like Arrow to Me&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB-Wasm uses &lt;a href=&quot;https://arrow.apache.org/&quot;&gt;Arrow&lt;/a&gt; as data protocol for the data import and all query results. Arrow is a database-friendly columnar format that is organized in chunks of column vectors, called record batches and that support zero-copy reads with only a small overhead. The npm library &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apache-arrow&lt;/code&gt; implements the Arrow format in the browser and is already used by other data processing frameworks, like &lt;a href=&quot;https://github.com/uwdata/arquero&quot;&gt;Arquero&lt;/a&gt;. Arrow therefore not only spares us the implementation of the SQL type logic in JavaScript, it also makes us compatible to existing tools.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why not use plain Javascript objects?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;WebAssembly is isolated and memory-safe. This isolation is part of it&#39;s DNA and drives fundamental design decisions in DuckDB-Wasm. For example, WebAssembly introduces a barrier towards the traditional JavaScript heap. Crossing this barrier is difficult as JavaScript has to deal with native function calls, memory ownership and serialization performance. Languages like C++ make this worse as they rely on smart pointers that are not available through the FFI. They leave us with the choice to either pass memory ownership to static singletons within the WebAssembly instance or maintain the memory through C-style APIs in JavaScript, a language that is too dynamic for sound implementations of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization&quot;&gt;RAII idiom&lt;/a&gt;. The memory-isolation forces us to serialize data before we can pass it to the WebAssembly instance. Browsers can serialize JavaScript objects natively to and from JSON using the functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JSON.stringify&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JSON.parse&lt;/code&gt; but this is slower compared to, for example, copying raw native arrays.&lt;/p&gt;
      &lt;h2 id=&quot;web-filesystem&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#web-filesystem&quot;&gt;Web Filesystem&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB-Wasm integrates a dedicated filesystem for WebAssembly. DuckDB itself is built on top of a virtual filesystem that decouples higher level tasks, such as reading a Parquet file, from low-level filesystem APIs that are specific to the operating system. We leverage this abstraction in DuckDB-Wasm to tailor filesystem implementations to the different WebAssembly environments.&lt;/p&gt;

&lt;p&gt;The following figure shows our current web filesystem in action. The sequence diagram presents a user running a SQL query that scans a single Parquet file. The query is first offloaded to a dedicated web worker through a JavaScript API. There, it is passed to the WebAssembly module that processes the query until the execution hits the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parquet_scan&lt;/code&gt; table function. This table function then reads the file using a buffered filesystem which, in turn, issues paged reads on the web filesystem. This web filesystem then uses an environment-specific runtime to read the file from several possible locations.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/webfs.svg&quot; alt=&quot;Example Web Filesystem shown visually&quot; title=&quot;Web Filesystem&quot; style=&quot;width:100%; max-width:800px&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/p&gt;

&lt;p&gt;Depending on the context, the Parquet file may either reside on the local device, on a remote server or in a buffer that was registered by the user upfront. We deliberately treat all three cases equally to unify the retrieval and processing of external data. This does not only simplify the analysis, it also enables more advanced features like partially consuming structured file formats. Parquet files, for example, consist of multiple row groups that store data in a column-major fashion. As a result, we may not need to download the entire file for a query but only required bytes.&lt;/p&gt;

&lt;p&gt;A query like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT count(*) FROM parquet_scan(...)&lt;/code&gt;, for example, can be evaluated on the file metadata alone and will finish in milliseconds even on remote files that are several terabytes large. Another more general example are paging scans with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OFFSET&lt;/code&gt; qualifiers such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM parquet_scan(...) LIMIT 20 OFFSET 40&lt;/code&gt;, or queries with selective filter predicates where entire row groups can be skipped based on metadata statistics. These partial file reads are no groundbreaking novelty and could be implemented in JavaScript today, but with DuckDB-Wasm, these optimizations are now driven by the semantics of SQL queries instead of fine-tuned application logic.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: The common denominator among the available File APIs is unfortunately not large. This limits the features that we can provide in the browser. For example, local persistency of DuckDB databases would be a feature with significant impact but requires a way to either read and write synchronously into user-provided files or IndexedDB. We might be able to bypass these limitations in the future but this is subject of ongoing research.&lt;/em&gt;&lt;/p&gt;
      &lt;h2 id=&quot;advanced-features&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#advanced-features&quot;&gt;Advanced Features&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;WebAssembly 1.0 has landed in all major browsers. The WebAssembly Community Group fixed the design of this first version back in November 2017, which is now referred to as WebAssembly MVP. Since then, the development has been ongoing with eight additional features that have been added to the standard and at least five proposals that are currently in progress.&lt;/p&gt;

&lt;p&gt;The rapid pace of this development presents challenges and opportunities for library authors. On the one hand, the different features find their way into the browsers at different speeds which leads to a fractured space of post-MVP functionality. On the other hand, features can bring flat performance improvements and are therefore indispensable when aiming for a maximum performance.&lt;/p&gt;

&lt;p&gt;The most promising feature for DuckDB-Wasm is &lt;a href=&quot;https://github.com/WebAssembly/exception-handling/blob/main/proposals/exception-handling/Exceptions.md&quot;&gt;exception handling&lt;/a&gt; which is already enabled by default in Chrome 95. DuckDB and DuckDB-Wasm are written in C++ and use exceptions for faulty situations. DuckDB does not use exceptions for general control flow but to automatically propagate errors upwards to the top-level plan driver. In native environments, these exceptions are implemented as &quot;zero-cost exceptions&quot; as they induce no overhead until they are thrown. With the WebAssembly MVP, however, that is no longer possible as the compiler toolchain Emscripten has to emulate exceptions through JavaScript. Without WebAssembly exceptions, DuckDB-Wasm calls throwing functions through a JavaScript hook that can catch exceptions emulated through JavaScript &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aborts&lt;/code&gt;. An example for these hook calls is shown in the following figure. Both stack traces originate from a single paged read of a Parquet file in DuckDB-Wasm. The left side shows a stack trace with the WebAssembly MVP and requires multiple calls through the functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wasm-to-js-i*&lt;/code&gt; . The right stack trace uses WebAssembly exceptions without any hook calls.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://duckdb.org/images/blog/wasm-eh.png&quot; alt=&quot;Exception handling shown visually&quot; title=&quot;WebAssembly Exceptions&quot; style=&quot;width:100%; max-width:600px;border-radius:4px;border:1px solid rgb(200,200,200);&quot; referrerpolicy=&quot;no-referrer&quot;&gt;
&lt;/p&gt;

&lt;p&gt;This fractured feature space is a temporary challenge that will be resolved once high-impact features like exception handling, SIMD and bulk-memory operations are available everywhere. In the meantime, we will ship multiple WebAssembly modules that are compiled for different feature sets and adaptively pick the best bundle for you using dynamic browser checks.&lt;/p&gt;

&lt;p&gt;The following example shows how the asynchronous version of DuckDB-Wasm can be instantiated using either manual or JsDelivr bundles:&lt;/p&gt;

&lt;div class=&quot;language-ts highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Import the ESM bundle (supports tree-shaking)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb-esm.js&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Either bundle them manually, for example as Webpack assets&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb_wasm&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb.wasm&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb_wasm_next&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb-next.wasm&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb_wasm_next_coi&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb-next-coi.wasm&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;WEBPACK_BUNDLES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DuckDBBundles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;asyncDefault&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mainModule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb_wasm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mainWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb-browser-async.worker.js&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;meta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;asyncNext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mainModule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb_wasm_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mainWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb-browser-async-next.worker.js&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;meta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;asyncNextCOI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mainModule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb_wasm_next_coi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;mainWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb-browser-async-next-coi.worker.js&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;meta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;pthreadWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;@duckdb/duckdb-wasm/dist/duckdb-browser-async-next-coi.pthread.worker.js&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;meta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// ..., or load the bundles from jsdelivr&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSDELIVR_BUNDLES&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;getJsDelivrBundles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Select a bundle based on browser checks&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bundle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;selectBundle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;JSDELIVR_BUNDLES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Instantiate the asynchronus version of DuckDB-Wasm&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;mainWorker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ConsoleLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;AsyncDuckDB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;worker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;instantiate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;mainModule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;bundle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;pthreadWorker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;You can also test the features and selected bundle in your browser using the web shell command &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.features&lt;/code&gt; .&lt;/em&gt;&lt;/p&gt;
      &lt;h2 id=&quot;multithreading&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#multithreading&quot;&gt;Multithreading&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In 2018, the Spectre and Meltdown vulnerabilities sent crippling shockwaves through the internet. Today, we are facing the repercussions of these events, in particular in software that runs arbitrary user code – such as web browsers. Shortly after the publications, all major browser vendors restricted the use of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SharedArrayBuffers&lt;/code&gt; to prevent dangerous timing attacks. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SharedArrayBuffers&lt;/code&gt; are raw buffers that can be shared among web workers for global state and an alternative to the browser-specific message passing. These restrictions had detrimental effects on WebAssembly modules since  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SharedArrayBuffers&lt;/code&gt; are neccessary for the implementation of POSIX threads in WebAssembly.&lt;/p&gt;

&lt;p&gt;Without &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SharedArrayBuffers&lt;/code&gt;, WebAssembly modules can run in a dedicated web worker to unblock the main event loop but won&#39;t be able to spawn additional workers for parallel computations within the same instance. By default, we therefore cannot unleash the parallel query execution of DuckDB in the web. However, browser vendors have recently started to reenable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SharedArrayBuffers&lt;/code&gt; for websites that are &lt;a href=&quot;https://web.dev/coop-coep/&quot;&gt;cross-origin-isolated&lt;/a&gt;. A website is cross-origin-isolated if it ships the main document with the following HTTP headers:&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Cross-Origin-Embedder-Policy: require-corp
Cross-Origin-Opener-Policy: same-origin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These headers will instruct browsers to A) isolate the top-level document from other top-level documents outside its own origin and B) prevent the document from making arbitrary cross-origin requests unless the requested resource explicitly opts in. Both restrictions have far reaching implications for a website since many third-party data sources won&#39;t yet provide the headers today and the top-level isolation currently hinders the communication with, for example, OAuth pop up&#39;s (&lt;a href=&quot;https://github.com/whatwg/html/issues/6364&quot;&gt;there are plans to lift that&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;We therefore assume that DuckDB-Wasm will find the majority of users on non-isolated websites. We are, however, experimenting with dedicated bundles for isolated sites using the suffix &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-next-coi&lt;/code&gt;) and will closely monitor the future need of our users.&lt;/em&gt;&lt;/p&gt;
      &lt;h2 id=&quot;web-shell&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#web-shell&quot;&gt;Web Shell&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We further host a web shell powered by DuckDB-Wasm alongside the library release at &lt;a href=&quot;https://shell.duckdb.org/&quot;&gt;shell.duckdb.org&lt;/a&gt;.
Use the following shell commands to query remote TPC-H files at scale factor 0.01.
When querying your own, make sure to properly set CORS headers since your browser will otherwise block these requests.
You can alternatively use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.files&lt;/code&gt; command to register files from the local filesystem.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/lineitem.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/customer.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_acctbal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/customer.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/orders.parquet&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_acctbal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/customer.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/nation.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_nationkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_nationkey&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/region.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&#39;https://shell.duckdb.org/data/tpch/0_01/parquet/nation.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_regionkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_regionkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;evaluation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#evaluation&quot;&gt;Evaluation&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The following table teases the execution times of some TPC-H queries at scale factor 0.5 using the libraries &lt;a href=&quot;https://www.npmjs.com/package/@duckdb/duckdb-wasm&quot;&gt;DuckDB-Wasm&lt;/a&gt;, &lt;a href=&quot;https://github.com/sql-js/sql.js/&quot;&gt;sql.js&lt;/a&gt;, &lt;a href=&quot;https://github.com/uwdata/arquero&quot;&gt;Arquero&lt;/a&gt; and &lt;a href=&quot;https://github.com/google/lovefield&quot;&gt;Lovefield&lt;/a&gt;. You can find a more in-depth discussion with all TPC-H queries, additional scale factors and Microbenchmarks &lt;a href=&quot;https://shell.duckdb.org/versus&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Query&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;DuckDB-wasm&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;sql.js&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Arquero&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Lovefield&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.855 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8.441 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;24.031 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12.666 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.179 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.758 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16.848 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.587 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.151 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.384 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.519 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.779 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.197 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.965 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18.286 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;13.117 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.086 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.294 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.379 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.253 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.319 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.677 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.013 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;74.926 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.236 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4.126 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.589 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18.983 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.351 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.238 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;23.096 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;18.229 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.276 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.080 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;11.932 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10.372 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.194 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.887 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;16.387 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9.795 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.086 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.194 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.332 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.449 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;16&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.137 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.453 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.294 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.590 s&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;19&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;&lt;strong&gt;0.377 s&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.272 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;65.403 s&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9.977 s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;future-research&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/29/duckdb-wasm.html#future-research&quot;&gt;Future Research&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We believe that WebAssembly unveils hitherto dormant potential for shared query processing between clients and servers. Pushing computation closer to the client can eliminate costly round-trips to the server and thus increase interactivity and scalability of in-browser analytics. We further believe that the release of DuckDB-Wasm could be the first step towards a more universal data plane spanning across multiple layers including traditional database servers, clients, CDN workers and computational storage. As an in-process analytical database, DuckDB might be the ideal driver for distributed query plans that increase the scalability and interactivity of SQL databases at low costs.&lt;/p&gt;

</description><link>https://duckdb.org/2021/10/29/duckdb-wasm.html</link><guid isPermaLink="false">https://duckdb.org/2021/10/29/duckdb-wasm.html</guid><pubDate>Fri, 29 Oct 2021 00:00:00 GMT</pubDate><author>André Kohn and Dominik Moritz</author></item><item><title>Windowing in DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB, a free and open-source analytical data management system, has a state-of-the-art windowing engine that can compute complex moving aggregates like inter-quartile ranges as well as simpler moving averages.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Window functions (those using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; clause) are important tools for analysing data series,
but they can be slow if not implemented carefully.
In this post, we will take a look at how DuckDB implements windowing.
We will also see how DuckDB can leverage its aggregate function architecture
to compute useful moving aggregates such as moving inter-quartile ranges (IQRs).&lt;/p&gt;
      &lt;h2 id=&quot;beyond-sets&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#beyond-sets&quot;&gt;Beyond Sets&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The original relational model as developed by Codd in the 1970s treated relations as &lt;em&gt;unordered sets&lt;/em&gt; of tuples.
While this was nice for theoretical computer science work,
it ignored the way humans think using physical analogies (the &quot;embodied brain&quot; model from neuroscience).
In particular, humans naturally order data to help them understand it and engage with it.
To help with this, SQL uses the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; clause for horizontal layout and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause for vertical layout.&lt;/p&gt;

&lt;p&gt;Still, the orderings that humans put on data are often more than neurological crutches.
For example, time places a natural ordering on measurements,
and wide swings in those measurements can themselves be important data,
or they may indicate that the data needs to be cleaned by smoothing.
Trends may be present or relative changes may be more important for analysis than raw values.
To help answer such questions, SQL introduced &lt;em&gt;analytic&lt;/em&gt; (or &lt;em&gt;window&lt;/em&gt;) functions in 2003.&lt;/p&gt;
      &lt;h3 id=&quot;window-functions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#window-functions&quot;&gt;Window Functions&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Windowing works by breaking a relation up into independent &lt;em&gt;partitions&lt;/em&gt;, &lt;em&gt;ordering&lt;/em&gt; those partitions,
and then defining &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html&quot;&gt;various functions&lt;/a&gt; that can be computed for each row
using the nearby values.
These functions include all the aggregate functions (such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avg&lt;/code&gt;)
as well as some window-specific functions (such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rank()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nth_value(&amp;lt;expression&amp;gt;, &amp;lt;N&amp;gt;)&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Some window functions depend only on the partition boundary and the ordering,
but a few (including all the aggregates) also use a &lt;em&gt;frame&lt;/em&gt;.
Frames are specified as a number of rows on either side (&lt;em&gt;preceding&lt;/em&gt; or &lt;em&gt;following&lt;/em&gt;) of the &lt;em&gt;current row&lt;/em&gt;.
The distance can either be specified as a number of &lt;em&gt;rows&lt;/em&gt; or a &lt;em&gt;range&lt;/em&gt; of values
using the partition&#39;s ordering value and a distance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/windowing/framing.svg&quot; alt=&quot;The Window Computation Environment&quot; title=&quot;Figure 1: The Window Computation Environment&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Framing is the most confusing part of the windowing environment,
so let&#39;s look at a very simple example and ignore the partitioning and ordering for a moment.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt;
                 &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;we&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query computes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt; of each point and the points on either side of it:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/windowing/moving-sum.jpg&quot; alt=&quot;Moving sum of three values&quot; title=&quot;Figure 2: A moving sum of three values&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Notice that at the edge of the partition, there are only two values added together.&lt;/p&gt;
      &lt;h3 id=&quot;power-generation-example&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#power-generation-example&quot;&gt;Power Generation Example&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Now let&#39;s look at a concrete example of a window function query.
Suppose we have some power plant generation data:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Plant&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Date&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;MWh&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;564337&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;507405&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;528523&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;469538&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-06&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;474163&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-07&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;507213&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-08&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;613040&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-09&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;582588&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;499506&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;482014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;486134&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;531518&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;118860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;101977&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;106054&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;92182&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-06&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;94492&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-07&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;99932&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-08&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;118854&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-09&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;113506&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;96644&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;93806&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;98963&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;107170&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The data is noisy, so we want to compute a 7 day moving average for each plant.
To do this, we can use this window query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;MWh&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt;
                  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;MWh 7-day Moving Average&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Generation History&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This query computes the seven day moving average of the power generated by each power plant on each day.
The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; clause is the way that SQL specifies that a function is to be computed in a window.
It partitions the data by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Plant&lt;/code&gt; (to keep the different power plants&#39; data separate),
orders each plant&#39;s partition by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Date&lt;/code&gt; (to put the energy measurements next to each other),
and uses a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RANGE&lt;/code&gt; frame of three days on either side of each day for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;avg&lt;/code&gt;
(to handle any missing days).
Here is the result:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Plant&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Date&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;MWh 7-day&lt;br&gt;Moving Average&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;517450.75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;508793.20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;508529.83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;523459.85&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-06&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;526067.14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-07&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;524938.71&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-08&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;518294.57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-09&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;520665.42&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;528859.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;532466.66&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;516352.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Boston&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;499793.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-02&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;104768.25&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-03&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;102713.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-04&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;102249.50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-05&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;104621.57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-06&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;103856.71&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-07&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;103094.85&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-08&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;101345.14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-09&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;102313.85&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;104125.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-11&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;104823.83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-12&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;102017.80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Worcester&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2019-01-13&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;99145.75&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You can request multiple different &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OVER&lt;/code&gt; clauses in the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;, and each will be computed separately.
Often, however, you want to use the same window for multiple functions,
and you can do this by using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WINDOW&lt;/code&gt; clause to define a &lt;em&gt;named&lt;/em&gt; window:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;MWh&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seven&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;MWh 7-day Moving Average&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Generation History&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WINDOW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seven&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This would be useful, for example,
if one also wanted the 7-day moving  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt;  to show the bounds of the data.&lt;/p&gt;
      &lt;h2 id=&quot;under-the-feathers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#under-the-feathers&quot;&gt;Under the Feathers&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;That is a long list of complicated functionality!
Making it all work relatively quickly has many pieces,
so lets have a look at how they all get implemented in DuckDB.&lt;/p&gt;
      &lt;h3 id=&quot;pipeline-breaking&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#pipeline-breaking&quot;&gt;Pipeline Breaking&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;The first thing to notice is that windowing is a &quot;pipeline breaker&quot;.
That is, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Window&lt;/code&gt; operator has to read all of its inputs before it can start computing a function.
This means that if there is some other way to compute something,
it may well be faster to use a different technique.&lt;/p&gt;

&lt;p&gt;One common analytic task is to find the last value in some group.
For example, suppose we want the last recorded power output for each plant.
It is tempting to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rank()&lt;/code&gt; window function with a reverse sort for this task:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;MWh&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;MWh&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;rank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but this requires materialising the entire table, partitioning it, sorting the partitions,
and then pulling out a single row from those partitions.
A much faster way to do this is to use a self join to filter the table
to contain only the last (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max&lt;/code&gt;) value of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATE&lt;/code&gt; field:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;MWh&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lasts&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lasts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lasts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This join query requires two scans of the table, but the only materialised data is the filtering table
(which is probably much smaller than the original table), and there is no sorting at all.&lt;/p&gt;

&lt;p&gt;This type of query showed up &lt;a href=&quot;https://bwlewis.github.io/duckdb_and_r/last/last.html&quot;&gt;in a user&#39;s blog&lt;/a&gt;
and we found that the join query was over 20 times faster on their data set:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/windowing/last-in-group.jpg&quot; alt=&quot;Window takes 13 seconds, Join takes half a second&quot; title=&quot;Figure 3: Last in Group Join vs Window Comparison&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Of course most analytic tasks that use windowing &lt;em&gt;do&lt;/em&gt; require using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Window&lt;/code&gt; operator,
and DuckDB uses a collection of techniques to make the performance as fast as possible.&lt;/p&gt;
      &lt;h3 id=&quot;partitioning-and-sorting&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#partitioning-and-sorting&quot;&gt;Partitioning and Sorting&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;At one time, windowing was implemented by sorting on both the partition and the ordering fields
and then finding the partition boundaries.
This is resource intensive, both because the entire relation must be sorted,
and because sorting is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N log N)&lt;/code&gt; in the size of the relation.
Fortunately, there are faster ways to implement this step.&lt;/p&gt;

&lt;p&gt;To reduce resource consumption, DuckDB uses the partitioning scheme from Leis et al.&#39;s
&lt;a href=&quot;http://www.vldb.org/pvldb/vol8/p1058-leis.pdf&quot;&gt;&lt;em&gt;Efficient Processing of Window Functions in Analytical SQL Queries&lt;/em&gt;&lt;/a&gt;
and breaks the partitions up into 1024 chunks using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N)&lt;/code&gt; hashing.
The chunks still need to be sorted on all the fields because there may be hash collisions,
but each partition can now be 1024 times smaller, which reduces the runtime significantly.
Moreover, the partitions can easily be extracted and processed in parallel.&lt;/p&gt;

&lt;p&gt;Sorting in DuckDB recently got a &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html&quot;&gt;big performance boost&lt;/a&gt;,
along with the ability to work on partitions that were larger than memory.
This functionality has been also added to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Window&lt;/code&gt; operator,
resulting in a 33% improvement in the last-in-group example:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/windowing/last-in-group-sort.jpg&quot; alt=&quot;Window takes X seconds, Join takes half a second&quot; title=&quot;Figure 4: Last in Group Sorting Performance Improvement&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;As a final optimisation, even though you can request multiple window functions,
DuckDB will collect functions that use the same partitioning and ordering,
and share the data layout between those functions.&lt;/p&gt;
      &lt;h3 id=&quot;aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#aggregation&quot;&gt;Aggregation&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Most of the &lt;a href=&quot;https://duckdb.org/docs/stable/sql/functions/window_functions.html&quot;&gt;general-purpose window functions&lt;/a&gt; are straightforward to compute,
but windowed aggregate functions can be expensive because they need to look at multiple values for each row.
They often need to look at the same value multiple times, or repeatedly look at a large number of values,
so over the years several approaches have been taken to improve performance.&lt;/p&gt;
      &lt;h4 id=&quot;naïve-windowed-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#na%C3%AFve-windowed-aggregation&quot;&gt;Naïve Windowed Aggregation&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Before explaining how DuckDB implements windowed aggregation,
we need to take a short detour through how ordinary aggregates are implemented.
Aggregate &quot;functions&quot; are implemented using three required operations and one optional operation:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Initialize&lt;/em&gt; – Creates a state that will be updated.
For &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt;, this is the running total, starting at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; (because a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt; of zero items is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt;, not zero.)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Update&lt;/em&gt; – Updates the state with a new value. For &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt;, this adds the value to the state.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Finalize&lt;/em&gt; – Produces the final aggregate value from the state.
For &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt;, this just copies the running total.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Combine&lt;/em&gt; – Combines two states into a single state.
Combine is optional, but when present it allows the aggregate to be computed in parallel.
For &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt;, this produces a new state with the sum of the two input values.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The simplest way to compute an individual windowed aggregate value is to &lt;em&gt;initialize&lt;/em&gt; a state,
&lt;em&gt;update&lt;/em&gt; the state with all the values in the window frame,
and then use &lt;em&gt;finalize&lt;/em&gt; to produce the value of the windowed aggregate.
This naïve algorithm will always work, but it is quite inefficient.
For example, a running total will re-add all the values from the start of the partition
for each running total, and this has a run time of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N^2)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To improve on this, some databases add additional
&lt;a href=&quot;https://www.postgresql.org/docs/14/sql-createaggregate.html&quot;&gt;&quot;moving state&quot; operations&lt;/a&gt;
that can add or remove individual values incrementally.
This reduces computation in some common cases,
but it can only be used for certain aggregates.
For example, it doesn&#39;t work for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min&lt;/code&gt;) because you don&#39;t know if there are multiple duplicate minima.
Moreover, if the frame boundaries move around a lot, it can still degenerate to an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N^2)&lt;/code&gt; run time.&lt;/p&gt;
      &lt;h4 id=&quot;segment-tree-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#segment-tree-aggregation&quot;&gt;Segment Tree Aggregation&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Instead of adding more functions, DuckDB uses the &lt;em&gt;segment tree&lt;/em&gt; approach from Leis et al. above.
This works by building a tree on top of the entire partition with the aggregated values at the bottom.
Values are combined into states at nodes above them in the tree until there is a single root:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/windowing/segment-tree.png&quot; alt=&quot;Segment Tree for sum aggregation&quot; title=&quot;Figure 5: Segment Tree for sum aggregation. Only the red nodes (7, 13, 20) have to be aggregated to compute the sum of 7, 3, 10, 6, 2, 8, 4&quot; style=&quot;max-width:90%;width:90%;height:auto&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;To compute a value, the algorithm generates states for the ragged ends of the frame,
&lt;em&gt;combines&lt;/em&gt; states in the tree above the values in the frame,
and &lt;em&gt;finalizes&lt;/em&gt; the result from the last remaining state.
So in the example above (Figure 5 from Leis et al.) only three values need to be added instead of 7.
This technique can be used for all &lt;em&gt;combinable&lt;/em&gt; aggregates.&lt;/p&gt;
      &lt;h4 id=&quot;general-windowed-aggregation&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#general-windowed-aggregation&quot;&gt;General Windowed Aggregation&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;The biggest drawback of segment trees is the need to manage a potentially large number of intermediate states.
For the simple states used for standard distributive aggregates like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt;,
this is not a problem because the states are small,
the tree keeps the number of states logarithmically low,
and the state used to compute each value is also cheap.&lt;/p&gt;

&lt;p&gt;For some aggregates, however, the state is not small.
Typically these are so-called &lt;em&gt;holistic&lt;/em&gt; aggregates,
where the value depends on all the values of the frame.
Examples of such aggregates are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt;,
where each state may have to contain a copy of &lt;em&gt;all&lt;/em&gt; the values seen so far.
While segment trees &lt;em&gt;can&lt;/em&gt; be used to implement moving versions of any combinable aggregate,
this can be quite expensive for large, complex states -
and this was not the original goal of the algorithm.&lt;/p&gt;

&lt;p&gt;To solve this problem, we use the approach from Wesley and Xu&#39;s
&lt;a href=&quot;http://www.vldb.org/pvldb/vol9/p1221-wesley.pdf&quot;&gt;&lt;em&gt;Incremental Computation of Common Windowed Holistic Aggregates&lt;/em&gt;&lt;/a&gt;,
which generalises segment trees to aggregate-specific data structures.
The aggregate can define a fifth optional &lt;em&gt;window&lt;/em&gt; operation,
which will be passed the bottom of the tree and the bounds of the current and previous frame.
The aggregate can then create an appropriate data structure for its implementation.&lt;/p&gt;

&lt;p&gt;For example, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; function maintains a hash table of counts that it can update efficiently,
and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt; function maintains a partially sorted list of frame indexes.
Moreover, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile&lt;/code&gt; functions can take an array of quantile values,
which further increases performance by sharing the partially ordered results
among the different quantile values.&lt;/p&gt;

&lt;p&gt;Because these aggregates can be used in a windowing context,
the moving average example above can be easily modified to produce a moving inter-quartile range:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;quantile_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;MWh&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seven&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;MWh 7-day Moving IQR&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Generation History&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WINDOW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seven&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Plant&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;Date&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;RANGE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRECEDING&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DAYS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FOLLOWING&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Moving quantiles like this are
&lt;a href=&quot;https://blogs.sas.com/content/iml/2021/05/26/running-median-smoother.html&quot;&gt;more robust to anomalies&lt;/a&gt;,
which makes them a valuable tool for data series analysis,
but they are not generally implemented in most database systems.
There are some approaches that can be used in some query engines,
but the lack of a general moving aggregation architecture means that these solutions can be
&lt;a href=&quot;https://docs.oracle.com/cd/E57185_01/HIRUG/ch12s07s08.html&quot;&gt;unnatural&lt;/a&gt;
or &lt;a href=&quot;https://ndesmo.github.io/blog/oracle-moving-metrics/&quot;&gt;complex&lt;/a&gt;.
DuckDB&#39;s implementation uses the standard window notation,
which means you don&#39;t have to learn new syntax or pull the data out into another tool.&lt;/p&gt;
      &lt;h4 id=&quot;ordered-set-aggregates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#ordered-set-aggregates&quot;&gt;Ordered Set Aggregates&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;Window functions are often closely associated with some special
&quot;&lt;a href=&quot;https://www.postgresql.org/docs/current/functions-aggregate.html#FUNCTIONS-ORDEREDSET-TABLE&quot;&gt;ordered set aggregates&lt;/a&gt;&quot;
defined by the SQL standard.
Some databases implement these functions using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Window&lt;/code&gt; operator,
but this is rather inefficient because sorting the data (an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N log N)&lt;/code&gt; operation) is not required -
it suffices to use
Hoare&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N)&lt;/code&gt;
&lt;a href=&quot;https://courses.cs.vt.edu/~cs3114/Summer15/Notes/Supplemental/p321-hoare.pdf&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FIND&lt;/code&gt;&lt;/a&gt;
algorithm as used in the STL&#39;s
&lt;a href=&quot;https://en.cppreference.com/w/cpp/algorithm/nth_element&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;std::nth_element&lt;/code&gt;&lt;/a&gt;.
DuckDB translates these ordered set aggregates to use the faster &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile_cont&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quantile_disc&lt;/code&gt;,
and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode&lt;/code&gt; regular aggregate functions, thereby avoiding using windowing entirely.&lt;/p&gt;
      &lt;h4 id=&quot;extensions&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#extensions&quot;&gt;Extensions&lt;/a&gt;
        
      &lt;/h4&gt;
    

&lt;p&gt;This architecture also means that any new aggregates we add
can benefit from the existing windowing infrastructure.
DuckDB is an open source project, and we welcome submissions of useful aggregate functions -
or you can create your own domain-specific ones in your own fork.
At some point we hope to have a UDF architecture that will allow plug-in aggregates,
and the simplicity and power of the interface will let these plugins leverage the notational
simplicity and run time performance that the internal functions enjoy.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/10/13/windowing.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s windowing implementation uses a variety of techniques
to speed up what can be the slowest part of an analytic query.
It is well integrated with the sorting subsystem and the aggregate function architecture,
which makes expressing advanced moving aggregates both natural and efficient.&lt;/p&gt;

&lt;p&gt;DuckDB is a free and open-source database management system (MIT licensed).
It aims to be the SQLite for Analytics,
and provides a fast and efficient database system with zero external dependencies.
It is available not just for Python, but also for C/C++, R, Java, and more.&lt;/p&gt;

</description><link>https://duckdb.org/2021/10/13/windowing.html</link><guid isPermaLink="false">https://duckdb.org/2021/10/13/windowing.html</guid><pubDate>Wed, 13 Oct 2021 00:00:00 GMT</pubDate><author>Richard Wesley</author></item><item><title>Fastest Table Sort in the West – Redesigning DuckDB’s Sort</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB, a free and open-source analytical data management system, has a new highly efficient parallel sorting implementation that can sort much more data than fits in main memory.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Database systems use sorting for many purposes, the most obvious purpose being when a user adds an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause to their query.
Sorting is also used within operators, such as window functions.
DuckDB recently improved its sorting implementation, which is now able to sort data in parallel and sort more data than fits in memory.
In this post, we will take a look at how DuckDB sorts, and how this compares to other data management systems.&lt;/p&gt;

&lt;p&gt;Not interested in the implementation? &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#comparison&quot;&gt;Jump straight to the experiments!&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;sorting-relational-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#sorting-relational-data&quot;&gt;Sorting Relational Data&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Sorting is one of the most well-studied problems in computer science, and it is an important aspect of data management. There are &lt;a href=&quot;https://sortbenchmark.org/&quot;&gt;entire communities&lt;/a&gt; dedicated to who sorts fastest.
Research into sorting algorithms tends to focus on sorting large arrays or key/value pairs.
While important, this does not cover how to implement sorting in a database system.
There is a lot more to sorting tables than just sorting a large array of integers!&lt;/p&gt;

&lt;p&gt;Consider the following example query on a snippet of a TPC-DS table:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_customer_sk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_birth_country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_birth_year&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customer&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_birth_country&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;c_birth_year&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;ASC&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULLS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which yields:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;c_customer_sk&lt;/th&gt;
      &lt;th&gt;c_birth_country&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;c_birth_year&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64760&lt;/td&gt;
      &lt;td&gt;NETHERLANDS&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1991&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;75011&lt;/td&gt;
      &lt;td&gt;NETHERLANDS&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1992&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;89949&lt;/td&gt;
      &lt;td&gt;NETHERLANDS&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1992&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;90766&lt;/td&gt;
      &lt;td&gt;NETHERLANDS&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;NULL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;42927&lt;/td&gt;
      &lt;td&gt;GERMANY&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1924&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In other words: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_country&lt;/code&gt; is ordered descendingly, and where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_country&lt;/code&gt; is equal, we sort on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_year&lt;/code&gt; ascendingly.
By specifying &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULLS LAST&lt;/code&gt;, null values are treated as the lowest value in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_year&lt;/code&gt; column.
Whole rows are thus reordered, not just the columns in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause. The columns that are not in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause we call &quot;payload columns&quot;.
Therefore, payload column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_customer_sk&lt;/code&gt; has to be reordered too.&lt;/p&gt;

&lt;p&gt;It is easy to implement something that can evaluate the example query using any sorting implementation, for instance, &lt;strong&gt;C++&lt;/strong&gt;&#39;s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;std::sort&lt;/code&gt;.
While &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;std::sort&lt;/code&gt; is excellent algorithmically, it is still a single-threaded approach that is unable to efficiently sort by multiple columns because function call overhead would quickly dominate sorting time.
Below we will discuss why that is.&lt;/p&gt;

&lt;p&gt;To achieve good performance when sorting tables, a custom sorting implementation is needed. We are – of course – not the first to implement relational sorting, so we dove into the literature to look for guidance.&lt;/p&gt;

&lt;p&gt;In 2006 the famous Goetz Graefe wrote a survey on &lt;a href=&quot;http://wwwlgis.informatik.uni-kl.de/archiv/wwwdvs.informatik.uni-kl.de/courses/DBSREAL/SS2005/Vorlesungsunterlagen/Implementing_Sorting.pdf&quot;&gt;implementing sorting in database systems&lt;/a&gt;.
In this survey, he collected many sorting techniques that are known to the community. This is a great guideline if you are about to start implementing sorting for tables.&lt;/p&gt;

&lt;p&gt;The cost of sorting is dominated by comparing values and moving data around.
Anything that makes these two operations cheaper will have a big impact on the total runtime.&lt;/p&gt;

&lt;p&gt;There are two obvious ways to go about implementing a comparator when we have multiple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clauses:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Loop through the clauses: Compare columns until we find one that is not equal, or until we have compared all columns.
This is fairly complex already, as this requires a loop with an if/else inside of it for every single row of data.
If we have columnar storage, this comparator has to jump between columns, &lt;a href=&quot;https://ir.cwi.nl/pub/13805&quot;&gt;causing random access in memory&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Entirely sort the data by the first clause, then sort by the second clause, but only where the first clause was equal, and so on.
This approach is especially inefficient when there are many duplicate values, as it requires multiple passes over the data.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;binary-string-comparison&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#binary-string-comparison&quot;&gt;Binary String Comparison&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The binary string comparison technique improves sorting performance by simplifying the comparator. It encodes &lt;em&gt;all&lt;/em&gt; columns in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; clause into a single binary sequence that, when compared using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;memcmp&lt;/code&gt; will yield the correct overall sorting order. Encoding the data is not free, but since we are using the comparator so much during sorting, it will pay off.
Let us take another look at 3 rows of the example:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;c_birth_country&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;c_birth_year&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;NETHERLANDS&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1991&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NETHERLANDS&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1992&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GERMANY&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1924&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;On &lt;a href=&quot;https://en.wikipedia.org/wiki/Endianness&quot;&gt;little-endian&lt;/a&gt; hardware, the bytes that represent these values look like this in memory, assuming 32-bit integer representation for the year:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;c_birth_country&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- NETHERLANDS&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;01001110&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01000101&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01010100&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01001000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01000101&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01010010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01001100&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01000001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01001110&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01000100&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01010011&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- GERMANY&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;01000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01000101&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01010010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01001101&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01000001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01001110&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;01011001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;c_birth_year&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 1991&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;11000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 1992&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;11001000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 1924&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;10000100&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The trick is to convert these to a binary string that encodes the sorting order:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- NETHERLANDS | 1991&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;10110001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10101011&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10101101&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110011&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111110&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111011&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10101100&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11111111&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;10000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11000111&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- NETHERLANDS | 1992&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;10110001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10101011&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10101101&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110011&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111110&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111011&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10101100&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11111111&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;10000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11001000&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- GERMANY     | 1924&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;10111000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10101101&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110010&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10111110&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10110001&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10100110&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11111111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11111111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11111111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11111111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11111111&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;10000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000000&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;00000111&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000100&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The binary string is fixed-size because this makes it much easier to move it around during sorting.&lt;/p&gt;

&lt;p&gt;The string &quot;GERMANY&quot; is shorter than &quot;NETHERLANDS&quot;, therefore it is padded with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;00000000&lt;/code&gt;&#39;s.
All bits in column &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_country&lt;/code&gt; are subsequently inverted because this column is sorted descendingly.
If a string is too long we encode its prefix and only look at the whole string if the prefixes are equal.&lt;/p&gt;

&lt;p&gt;The bytes in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_year&lt;/code&gt; are swapped because we need the big-endian representation to encode the sorting order.
The first bit is also flipped, to preserve order between positive and negative integers for &lt;a href=&quot;https://en.wikipedia.org/wiki/Signed_number_representations&quot;&gt;signed integers&lt;/a&gt;.
If there are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values, these must be encoded using an additional byte (not shown in the example).&lt;/p&gt;

&lt;p&gt;With this binary string, we can now compare both columns at the same time by comparing only the binary string representation. 
This can be done with a single &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;memcmp&lt;/code&gt; in &lt;strong&gt;C++&lt;/strong&gt;! The compiler will emit efficient assembly for single function call, even auto-generating &lt;a href=&quot;https://en.wikipedia.org/wiki/SIMD&quot;&gt;SIMD instructions&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This technique solves one of the problems mentioned above, namely the function call overhead when using complex comparators.&lt;/p&gt;
      &lt;h2 id=&quot;radix-sort&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#radix-sort&quot;&gt;Radix Sort&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we have a cheap comparator, we have to choose our sorting algorithm.
Every computer science student learns about &lt;a href=&quot;https://en.wikipedia.org/wiki/Sorting_algorithm#Comparison_sorts&quot;&gt;comparison-based&lt;/a&gt; sorting algorithms like &lt;a href=&quot;https://en.wikipedia.org/wiki/Quicksort&quot;&gt;Quicksort&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Merge_sort&quot;&gt;Merge sort&lt;/a&gt;, which have &lt;em&gt;O (n&lt;/em&gt; log &lt;em&gt;n)&lt;/em&gt; time complexity, where &lt;em&gt;n&lt;/em&gt; is the number of records being sorted.&lt;/p&gt;

&lt;p&gt;However, there are also &lt;a href=&quot;https://en.wikipedia.org/wiki/Sorting_algorithm#Non-comparison_sorts&quot;&gt;distribution-based&lt;/a&gt; sorting algorithms, which typically have a time complexity of &lt;em&gt;O (n k)&lt;/em&gt;, where &lt;em&gt;k&lt;/em&gt; is the width of the sorting key.
This class of sorting algorithms scales much better with a larger &lt;em&gt;n&lt;/em&gt; because &lt;em&gt;k&lt;/em&gt; is constant, whereas log &lt;em&gt;n&lt;/em&gt; is not.&lt;/p&gt;

&lt;p&gt;One such algorithm is &lt;a href=&quot;https://en.wikipedia.org/wiki/Radix_sort&quot;&gt;Radix sort&lt;/a&gt;.
This algorithm sorts the data by computing the data distribution with &lt;a href=&quot;https://en.wikipedia.org/wiki/Counting_sort&quot;&gt;Counting sort&lt;/a&gt;, multiple times until all digits have been counted.&lt;/p&gt;

&lt;p&gt;It may sound counter-intuitive to encode the sorting key columns such that we have a cheap comparator, and then choose a sorting algorithm that does not compare records.
However, the encoding is necessary for Radix sort: Binary strings that produce a correct order with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;memcmp&lt;/code&gt; will produce a correct order if we do a byte-by-byte Radix sort.&lt;/p&gt;
      &lt;h2 id=&quot;two-phase-parallel-sorting&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#two-phase-parallel-sorting&quot;&gt;Two-Phase Parallel Sorting&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB uses &lt;a href=&quot;https://15721.courses.cs.cmu.edu/spring2016/papers/p743-leis.pdf&quot;&gt;Morsel-Driven Parallelism&lt;/a&gt;, a framework for parallel query execution.
For the sorting operator, this means that multiple threads collect roughly an equal amount of data, in parallel, from the table.&lt;/p&gt;

&lt;p&gt;We use this parallelism for sorting by first having each thread sort the data it collects using our Radix sort.
After this first sorting phase, each thread has one or more sorted blocks of data, which must be combined into the final sorted result.
&lt;a href=&quot;https://en.wikipedia.org/wiki/Merge_sort&quot;&gt;Merge sort&lt;/a&gt; is the algorithm of choice for this task.
There are two main ways of implementing merge sort: &lt;a href=&quot;https://en.wikipedia.org/wiki/K-way_merge_algorithm&quot;&gt;K-way merge&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Cascade_merge_sort&quot;&gt;Cascade merge&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;K-way merge merges K lists into one sorted list in one pass, and is traditionally &lt;a href=&quot;https://en.wikipedia.org/wiki/External_sorting#External_merge_sort&quot;&gt;used for external sorting (sorting more data than fits in memory)&lt;/a&gt; because it minimizes I/O.
Cascade merge merges two lists of sorted data at a time until only one sorted list remains, and is used for in-memory sorting because it is more efficient than K-way merge.
We aim to have an implementation that has high in-memory performance, which gracefully degrades as we go over the limit of available memory.
Therefore, we choose cascade merge.&lt;/p&gt;

&lt;p&gt;In a cascade merge sort, we merge two blocks of sorted data at a time until only one sorted block remains.
Naturally, we want to use all available threads to compute the merge.
If we have many more sorted blocks than threads, we can assign each thread to merge two blocks.
However, as the blocks get merged, we will not have enough blocks to keep all threads busy.
This is especially slow when the final two blocks are merged: One thread has to process all the data.&lt;/p&gt;

&lt;p&gt;To fully parallelize this phase, we have implemented &lt;a href=&quot;https://arxiv.org/pdf/1406.2628.pdf&quot;&gt;Merge Path&lt;/a&gt; by Oded Green et al.
Merge Path pre-computes &lt;em&gt;where&lt;/em&gt; the sorted lists will intersect while merging, shown in the image below (taken from the paper).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/merge_path.png&quot; alt=&quot;Merge Path – A Visually Intuitive Approach to Parallel Merging&quot; title=&quot;Merge Path by Oded Green, Saher Odeh, Yitzhak Birk&quot; style=&quot;max-width:70%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The intersections along the merge path can be efficiently computed using &lt;a href=&quot;https://en.wikipedia.org/wiki/Binary_search_algorithm&quot;&gt;Binary Search&lt;/a&gt;.
If we know where the intersections are, we can merge partitions of the sorted data independently in parallel.
This allows us to use all available threads effectively for the entire merge phase.
For another trick to improve merge sort, see &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#predication&quot;&gt;the appendix&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;columns-or-rows&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#columns-or-rows&quot;&gt;Columns or Rows?&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Besides comparisons, the other big cost of sorting is moving data around.
DuckDB has a vectorized execution engine.
Data is stored in a columnar layout, which is processed in batches (called chunks) at a time.
This layout is great for analytical query processing because the chunks fit in the CPU cache, and it gives a lot of opportunities for the compiler to generate SIMD instructions.
However, when the table is sorted, entire rows are shuffled around, rather than columns.&lt;/p&gt;

&lt;p&gt;We could stick to the columnar layout while sorting: Sort the key columns, then re-order the payload columns one by one.
However, re-ordering will cause a random access pattern in memory for each column.
If there are many payload columns, this will be slow.
Converting the columns to rows will make re-ordering rows much easier.
This conversion is of course not free: Columns need to be copied to rows, and back from rows to columns again after sorting.&lt;/p&gt;

&lt;p&gt;Because we want to support external sorting, we have to store data in &lt;a href=&quot;https://research.cs.wisc.edu/coral/minibase/bufMgr/bufMgr.html&quot;&gt;buffer-managed&lt;/a&gt; blocks that can be offloaded to disk.
Because we have to copy the input data to these blocks anyway, converting the rows to columns is effectively free.&lt;/p&gt;

&lt;p&gt;There are a few operators that are inherently row-based, such as joins and aggregations.
DuckDB has a unified internal row layout for these operators, and we decided to use it for the sorting operator as well.
This layout has only been used in memory so far.
In the next section, we will explain how we got it to work on disk as well. We should note that we will only write sorting data to disk if main memory is not able to hold it.&lt;/p&gt;
      &lt;h2 id=&quot;external-sorting&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#external-sorting&quot;&gt;External Sorting&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The buffer manager can unload blocks from memory to disk.
This is not something we actively do in our sorting implementation, but rather something that the buffer manager decides to do if memory would fill up otherwise.
It uses a least-recently-used queue to decide which blocks to write.
More on how to properly use this queue in &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#zigzag&quot;&gt;the appendix&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When we need a block, we &quot;pin&quot; it, which reads it from disk if it is not loaded already.
Accessing disk is much slower than accessing memory, therefore it is crucial that we minimize the number of reads and writes.&lt;/p&gt;

&lt;p&gt;Unloading data to disk is easy for fixed-size columns like integers, but more difficult for variable-sized columns like strings.
Our row layout uses fixed-size rows, which cannot fit strings with arbitrary sizes.
Therefore, strings are represented by a pointer, which points into a separate block of memory where the actual string data lives, a so-called &quot;string heap&quot;.&lt;/p&gt;

&lt;p&gt;We have changed our heap to also store strings row-by-row in buffer-managed blocks:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/heap.svg&quot; alt=&quot;Each fixed-size row has its own variable-sized row in the heap&quot; title=&quot;DuckDB&#39;s row layout heap&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Each row has an additional 8-byte field &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pointer&lt;/code&gt; which points to the start of this row in the heap.
This is useless in the in-memory representation, but we will see why it is useful for the on-disk representation in just a second.&lt;/p&gt;

&lt;p&gt;If the data fits in memory, the heap blocks stay pinned, and only the fixed-size rows are re-ordered while sorting.
If the data does not fit in memory, the blocks need to be offloaded to disk, and the heap will also be re-ordered while sorting.
When a heap block is offloaded to disk, the pointers pointing into it are invalidated.
When we load the block back into memory, the pointers will have changed.&lt;/p&gt;

&lt;p&gt;This is where our row-wise layout comes into play.
The 8-byte &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pointer&lt;/code&gt; field is overwritten with an 8-byte &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;offset&lt;/code&gt; field, denoting where in the heap block strings of this row can be found.
This technique is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Pointer_swizzling&quot;&gt;&quot;pointer swizzling&quot;&lt;/a&gt;.
When we swizzle the pointers, the row layout and heap block look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/heap_swizzled.svg&quot; alt=&quot;Pointers are &#39;swizzled&#39;: replaced by offsets&quot; title=&quot;DuckDB&#39;s &#39;swizzled&#39; row layout heap&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The pointers to the subsequent string values are also overwritten with an 8-byte relative offset, denoting how far this string is offset from the start of the row in the heap (hence every &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stringA&lt;/code&gt; has an offset of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;: It is the first string in the row).
Using relative offsets within rows rather than absolute offsets is very useful during sorting, as these relative offsets stay constant, and do not need to be updated when a row is copied.&lt;/p&gt;

&lt;p&gt;When the blocks need to be scanned to read the sorted result, we &quot;unswizzle&quot; the pointers, making them point to the string again.&lt;/p&gt;

&lt;p&gt;With this dual-purpose row-wise representation, we can easily copy around both the fixed-size rows and the variable-sized rows in the heap.
Besides having the buffer manager load/unload blocks, the only difference between in-memory and external sorting is that we swizzle/unswizzle pointers to the heap blocks, and copy data from the heap blocks during merge sort.&lt;/p&gt;

&lt;p&gt;All this reduces overhead when blocks need to be moved in and out of memory, which will lead to graceful performance degradation as we approach the limit of available memory.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;comparison&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;comparison-with-other-systems&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#comparison-with-other-systems&quot;&gt;Comparison with Other Systems&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we have covered most of the techniques that are used in our sorting implementation, we want to know how we compare to other systems.
DuckDB is often used for interactive data analysis, and is therefore often compared to tools like &lt;a href=&quot;https://dplyr.tidyverse.org/&quot;&gt;dplyr&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this setting, people are usually running on laptops or PCs, therefore we will run these experiments on a 2020 MacBook Pro.
This laptop has an &lt;a href=&quot;https://en.wikipedia.org/wiki/Apple_M1&quot;&gt;Apple M1 CPU&lt;/a&gt;, which is &lt;a href=&quot;https://en.wikipedia.org/wiki/ARM_architecture&quot;&gt;ARM&lt;/a&gt;-based.
The M1 processor has 8 cores: 4 high-performance (Firestorm) cores, and 4 energy-efficient (Icestorm) cores.
The Firestorm cores have very, very fast single-thread performance, so this should level the playing field between single- and multi-threaded sorting implementations somewhat.
The MacBook has 16 GB of memory, and &lt;a href=&quot;https://eclecticlight.co/2020/12/12/how-fast-is-the-ssd-inside-an-m1-mac/&quot;&gt;one of the fastest SSDs found in a laptop&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will be comparing against the following systems:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://clickhouse.tech/&quot;&gt;ClickHouse&lt;/a&gt;, version 21.7.5&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://dbdb.io/db/hyper&quot;&gt;HyPer&lt;/a&gt;, version 2021.2.1.12564&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pandas.pydata.org/&quot;&gt;Pandas&lt;/a&gt;, version 1.3.2&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sqlite.org/index.html&quot;&gt;SQLite&lt;/a&gt;, version 3.36.0&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ClickHouse and HyPer are included in our comparison because they are analytical SQL engines with an emphasis on performance.
Pandas and SQLite are included in our comparison because they can be used to perform relational operations within Python, like DuckDB.
Pandas operates fully in memory, whereas SQLite is a more traditional disk-based system.
This list of systems should give us a good mix of single-/multi-threaded, and in-memory/external sorting.&lt;/p&gt;

&lt;p&gt;ClickHouse was built for M1 using &lt;a href=&quot;https://clickhouse.tech/docs/en/development/build-osx/&quot;&gt;this guide&lt;/a&gt;.
We have set the memory limit to 12 GB, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_bytes_before_external_sort&lt;/code&gt; to 10 GB, following &lt;a href=&quot;https://clickhouse.tech/docs/en/sql-reference/statements/select/order-by/#implementation-details&quot;&gt;this suggestion&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;HyPer is &lt;a href=&quot;https://www.tableau.com/products/new-features/hyper&quot;&gt;Tableau&#39;s data engine&lt;/a&gt;, created by the &lt;a href=&quot;http://db.in.tum.de/&quot;&gt;database group at the University of Munich&lt;/a&gt;.
It does not run natively (yet) on ARM-based processors like the M1.
We will use &lt;a href=&quot;https://en.wikipedia.org/wiki/Rosetta_(software)#Rosetta_2&quot;&gt;Rosetta 2&lt;/a&gt;, macOS&#39;s x86 emulator to run it.
Emulation causes some overhead, so we have included an experiment on an x86 machine in &lt;a href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#x86&quot;&gt;the appendix&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Benchmarking sorting in database systems is not straightforward.
Ideally, we would like to measure only the time it takes to sort the data, not the time it takes to read the input data and show the output.
Not every system has a profiler to measure the time of the sorting operator exactly, so this is not an option.&lt;/p&gt;

&lt;p&gt;To approach a fair comparison, we will measure the end-to-end time of queries that sort the data and write the result to a temporary table, i.e.:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TEMPORARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is no perfect solution to this problem, but this should give us a good comparison because the end-to-end time of this query should be dominated by sorting.
For Pandas we will use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort_values&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inplace=False&lt;/code&gt; to mimic this query.&lt;/p&gt;

&lt;p&gt;In ClickHouse, temporary tables can only exist in memory, which is problematic for our out-of-core experiments.
Therefore we will use a regular &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TABLE&lt;/code&gt;, but then we also need to choose a table engine.
Most of the table engines apply compression or create an index, which we do not want to measure.
Therefore we have chosen the simplest on-disk engine, which is &lt;a href=&quot;https://clickhouse.tech/docs/en/engines/table-engines/special/file/#file&quot;&gt;File&lt;/a&gt;, with format &lt;a href=&quot;https://clickhouse.tech/docs/en/interfaces/formats/#native&quot;&gt;Native&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The table engine we chose for the input tables for ClickHouse is &lt;a href=&quot;https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree&quot;&gt;MergeTree&lt;/a&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORDER BY tuple()&lt;/code&gt;.
We chose this because we encountered strange behavior with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;File(Native)&lt;/code&gt; input tables, where there was no difference in runtime between the queries &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT * FROM ... ORDER BY&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT col1 FROM ... ORDER BY&lt;/code&gt;.
Presumably, because all columns in the table were sorted regardless of how many there were selected.&lt;/p&gt;

&lt;p&gt;To measure stable end-to-end query time, we run each query 5 times and report the median run time.
There are some differences in reading/writing tables between the systems.
For instance, Pandas cannot read/write from/to disk, so both the input and output data frame will be in memory.
DuckDB will not write the output table to disk unless there is not enough room to keep it in memory, and therefore also may have an advantage.
However, sorting dominates the total runtime, so these differences are not that impactful.&lt;/p&gt;
      &lt;h2 id=&quot;random-integers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#random-integers&quot;&gt;Random Integers&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We will start with a simple example.
We have generated the first 100 million integers and shuffled them, and we want to know how well the systems can sort them.
This experiment is more of a micro-benchmark than anything else and is of little real-world significance.&lt;/p&gt;

&lt;p&gt;For our first experiment, we will look at how the systems scale with the number of rows.
From the initial table with integers, we have made 9 more tables, with 10M, 20M, …, 90M integers each.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/randints_scaling.svg&quot; alt=&quot;Sorting 10-100M random integers&quot; title=&quot;Random Integers Experiment&quot; style=&quot;max-width:100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Being a traditional disk-based database system, SQLite always opts for an external sorting strategy.
It writes intermediate sorted blocks to disk even if they fit in main-memory, therefore it is much slower.
The performance of the other systems is in the same ballpark, with DuckDB and ClickHouse going toe-to-toe with ~3 and ~4 seconds for 100M integers.
Because SQLite is so much slower, we will not include it in our next set of experiments (TPC-DS).&lt;/p&gt;

&lt;p&gt;DuckDB and ClickHouse both make very good use out of all available threads, with a single-threaded sort in parallel, followed by a parallel merge sort.
We are not sure what strategy HyPer uses.
For our next experiment, we will zoom in on multi-threading, and see how well ClickHouse and DuckDB scale with the number of threads (we were not able to set the number of threads for HyPer).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/randints_threads.svg&quot; alt=&quot;Sorting 100M random integers&quot; title=&quot;Threads Experiment&quot; style=&quot;max-width:70%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;This plot demonstrates that Radix sort is very fast.
DuckDB sorts 100M integers in just under 5 seconds using a single thread, which is much faster than ClickHouse.
Adding threads does not improve performance as much for DuckDB, because Radix Sort is so much faster than Merge Sort.
Both systems end up at about the same performance at 4 threads.&lt;/p&gt;

&lt;p&gt;Beyond 4 threads we do not see performance improve much more, due to the CPU architecture.
For all of the of other the experiments, we have set both DuckDB and ClickHouse to use 4 threads.&lt;/p&gt;

&lt;p&gt;For our last experiment with random integers, we will see how the sortedness of the input may impact performance.
This is especially important to do in systems that use Quicksort because Quicksort performs much worse on inversely sorted data than on random data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/randints_sortedness.svg&quot; alt=&quot;Sorting 100M integers with different sortedness&quot; title=&quot;Sortedness Experiment&quot; style=&quot;max-width:100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Not surprisingly, all systems perform better on sorted data, sometimes by a large margin.
ClickHouse, Pandas, and SQLite likely have some optimization here: e.g., keeping track of sortedness in the catalog, or checking sortedness while scanning the input.
DuckDB and HyPer have only a very small difference in performance when the input data is sorted, and do not have such an optimization.
For DuckDB the slightly improved performance can be explained due to a better memory access pattern during sorting: When the data is already sorted the access pattern is mostly sequential.&lt;/p&gt;

&lt;p&gt;Another interesting result is that DuckDB sorts data faster than some of the other systems can read already sorted data.&lt;/p&gt;
      &lt;h2 id=&quot;tpc-ds&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#tpc-ds&quot;&gt;TPC-DS&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;For the next comparison, we have improvised a relational sorting benchmark on two tables from the standard &lt;a href=&quot;http://www.tpc.org/tpcds/&quot;&gt;TPC Decision Support benchmark (TPC-DS)&lt;/a&gt;.
TPC-DS is challenging for sorting implementations because it has wide tables (with many columns, unlike the tables in &lt;a href=&quot;http://www.tpc.org/tpch/&quot;&gt;TPC-H&lt;/a&gt;), and a mix of fixed- and variable-sized types.
The number of rows increases with the scale factor.
The tables used here are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catalog_sales&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catalog_sales&lt;/code&gt; has 34 columns, all fixed-size types (integer and double), and grows to have many rows as the scale factor increases.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt; has 18 columns (10 integers, and 8 strings), and a decent amount of rows as the scale factor increases.
The row counts of both tables at each scale factor are shown in the table below.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;SF&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;customer&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;catalog_sales&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100,000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1,441,548&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;500,000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;14,401,261&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2,000,000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;143,997,065&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;300&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5,000,000&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;260,014,080&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We will use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt; at SF100 and SF300, which fits in memory at every scale factor.
We will use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catalog_sales&lt;/code&gt; table at SF10 and SF100, which does not fit in memory anymore at SF100.&lt;/p&gt;

&lt;p&gt;The data was generated using DuckDB&#39;s TPC-DS extension, then exported to CSV in a random order to undo any ordering patterns that could have been in the generated data.&lt;/p&gt;
      &lt;h2 id=&quot;catalog-sales-numeric-types&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#catalog-sales-numeric-types&quot;&gt;Catalog Sales (Numeric Types)&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Our first experiment on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catalog_sales&lt;/code&gt; table is selecting 1 column, then 2 columns, …, up to all 34, always ordering by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cs_quantity&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cs_item_sk&lt;/code&gt;.
This experiment will tell us how well the different systems can re-order payload columns.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/tpcds_catalog_sales_payload.svg&quot; alt=&quot;Increasing the number of payload columns for the catalog_sales table&quot; title=&quot;Catalog Sales Payload Experiment&quot; style=&quot;max-width:100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;We see similar trends at SF10 and SF100, but for SF100, at around 12 payload columns or so, the data does not fit in memory anymore, and ClickHouse and HyPer show a big drop in performance.
ClickHouse switches to an external sorting strategy, which is much slower than its in-memory strategy.
Therefore, adding a few payload columns results in a runtime that is orders of magnitude higher.
At 20 payload columns ClickHouse runs into the following error:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;DB::Exception: Memory limit (for query) exceeded: would use 11.18 GiB (attempt to allocate chunk of 4204712 bytes), maximum: 11.18 GiB: (while reading column cs_list_price): (while reading from part ./store/523/5230c288-7ed5-45fa-9230-c2887ed595fa/all_73_108_2/ from mark 4778 with max_rows_to_read = 8192): While executing MergeTreeThread.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;HyPer also drops in performance before erroring out with the following message:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ERROR:  Cannot allocate 333982248 bytes of memory: The `global memory limit` limit of 12884901888 bytes was exceeded.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As far as we are aware, HyPer uses &lt;a href=&quot;https://man7.org/linux/man-pages/man2/mmap.2.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mmap&lt;/code&gt;&lt;/a&gt;, which creates a mapping between memory and a file.
This allows the operating system to move data between memory and disk.
While useful, it is no substitute for a proper external sort, as it creates random access to disk, which is very slow.&lt;/p&gt;

&lt;p&gt;Pandas performs surprisingly well on SF100, despite the data not fitting in memory.
Pandas can only do this because macOS dynamically increases swap size.
Most operating systems do not do this and would fail to load the data at all.
Using swap usually slows down processing significantly, but the SSD is so fast that there is no visible performance drop!&lt;/p&gt;

&lt;p&gt;While Pandas loads the data, swap size grows to an impressive ~40 GB: Both the file and the data frame are fully in memory/swap at the same time, rather than streamed into memory.
This goes down to ~20 GB of memory/swap when the file is done being read.
Pandas is able to get quite far into the experiment until it crashes with the following error:&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB performs well both in-memory and external, and there is no clear visible point at which data no longer fits in memory: Runtime is fast and reliable.&lt;/p&gt;
      &lt;h2 id=&quot;customer-strings--integers&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#customer-strings--integers&quot;&gt;Customer (Strings &amp;amp; Integers)&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we have seen how the systems handle large amounts of fixed-size types, it is time to see some variable-size types!
For our first experiment on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt; table, we will select all columns, and order them by either 3 integer columns (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_year&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_month&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_day&lt;/code&gt;), or by 2 string columns (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_first_name&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_last_name&lt;/code&gt;).
Comparing strings is much, much more difficult than comparing integers, because strings can have variable sizes, and need to be compare byte-by-byte, whereas integers always have the same comparison.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/tpcds_customer_type_sort_barplot.svg&quot; alt=&quot;Comparing sorting speed with different sorting key types&quot; title=&quot;Customer Sort Type Experiment&quot; style=&quot;max-width:100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;As expected, ordering by strings is more expensive than ordering by integers, except for HyPer, which is impressive.
Pandas has only a slightly bigger difference between ordering by integers and ordering by strings than ClickHouse and DuckDB.
This difference is explained by an expensive comparator between strings.
Pandas uses &lt;a href=&quot;https://numpy.org/&quot;&gt;NumPy&lt;/a&gt;&#39;s sort, which is efficiently implemented in &lt;strong&gt;C&lt;/strong&gt;.
However, when this sorts strings, it has to use virtual function calls to compare a Python string object, which is slower than a simple &quot;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;&lt;/code&gt;&quot; between integers in &lt;strong&gt;C&lt;/strong&gt;.
Nevertheless, Pandas performs well on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt; table.&lt;/p&gt;

&lt;p&gt;In our next experiment, we will see how the payload type affects performance.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;customer&lt;/code&gt; has 10 integer columns and 8 string columns.
We will either select all integer columns or all string columns and order by (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_year&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_month&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_birth_day&lt;/code&gt;) every time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/tpcds_customer_type_payload_barplot.svg&quot; alt=&quot;Comparing sorting speed with different payload types&quot; title=&quot;Customer Payload Type Experiment&quot; style=&quot;max-width:100%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;As expected, re-ordering strings takes much more time than re-ordering integers.
Pandas has an advantage here because it already has the strings in memory, and most likely only needs to re-order pointers to these strings.
The database systems need to copy strings twice: Once when reading the input table, and again when creating the output table.
Profiling in DuckDB reveals that the actual sorting takes less than a second at SF300, and most time is spent on (de)serializing strings.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s new parallel sorting implementation can efficiently sort more data than fits in memory, making use of the speed of modern SSDs.
Where other systems crash because they run out of memory, or switch to an external sorting strategy that is much slower, DuckDB&#39;s performance gracefully degrades as it goes over the memory limit.&lt;/p&gt;

&lt;p&gt;The code that was used to run the experiments can be found &lt;a href=&quot;https://github.com/lnkuiper/experiments/tree/master/sorting&quot;&gt;here&lt;/a&gt;.
If we made any mistakes, please let us know!&lt;/p&gt;

&lt;p&gt;DuckDB is a free and open-source database management system (MIT licensed). It aims to be the SQLite for Analytics, and provides a fast and efficient database system with zero external dependencies. It is available not just for Python, but also for C/C++, R, Java, and more.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=28328657&quot;&gt;Discuss this post on Hacker News&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hannes.muehleisen.org/publications/ICDE2023-sorting.pdf&quot;&gt;Read our paper on sorting at ICDE &#39;23&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Listen to Laurens&#39; appearance on the Disseminate podcast:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://open.spotify.com/show/6IQIF9oRSf0FPjBUj0AkYA&quot;&gt;Spotify&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5hY2FzdC5jb20vcHVibGljL3Nob3dzL2Rpc3NlbWluYXRl&quot;&gt;Google&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://podcasts.apple.com/us/podcast/disseminate-the-computer-science-research-podcast/id1631350873&quot;&gt;Apple&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;predication&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;appendix-a-predication&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#appendix-a-predication&quot;&gt;Appendix A: Predication&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Another technique we have used to speed up merge sort is &lt;em&gt;predication&lt;/em&gt;.
With this technique, we turn code with &lt;em&gt;if/else&lt;/em&gt; branches into code without branches.
Modern CPUs try to predict whether the &lt;em&gt;if&lt;/em&gt;, or the &lt;em&gt;else&lt;/em&gt; branch will be predicted.
If this is hard to predict, it can slow down the code.
Take a look at the example of pseudo-code with branches below.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// continue until merged&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// check which side is smaller&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memcmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// copy from left side and advance&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;memcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// copy from right side and advance&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;memcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// advance result&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;result_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We are merging the data from the left and right blocks into a result block, one entry at a time, by advancing pointers.
This code can be made &lt;em&gt;branchless&lt;/em&gt; by using the comparison boolean as a 0 or 1, shown in the pseudo-code below.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// continue until merged&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// store comparison result in a bool&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left_less&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memcmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right_less&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left_less&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// copy from either side&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;memcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left_less&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;memcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right_less&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// advance either one&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left_less&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;l_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right_less&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// advance result&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;result_ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;left_less&lt;/code&gt; is true, it is equal to 1.
This means &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;right_less&lt;/code&gt; is false, and therefore equal to 0.
We use this to copy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;entry&lt;/code&gt; bytes from the left side, and 0 bytes from the right side, and incrementing the left and right pointers accordingly.&lt;/p&gt;

&lt;p&gt;With predicated code, the CPU does not have to predict which instructions to execute, which means there will be fewer instruction cache misses!&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;zigzag&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;appendix-b-zig-zagging&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#appendix-b-zig-zagging&quot;&gt;Appendix B: Zig-Zagging&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;A simple trick to reduce I/O is zig-zagging through the pairs of blocks to merge in the cascaded merge sort.
This is illustrated in the image below (dashes arrows indicate in which order the blocks are merged).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/zigzag.svg&quot; alt=&quot;Zig-zagging through the merge sort iterations to reduce read and write operations&quot; title=&quot;Zig-zagging to reduce I/O&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;By zig-zagging through the blocks, we start an iteration by merging the last blocks that were merged in the previous iteration.
Those blocks are likely still in memory, saving us some precious read/write operations.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;x86&quot;&gt;&lt;/a&gt;&lt;/p&gt;
      &lt;h2 id=&quot;appendix-c-x86-experiment&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/08/27/external-sorting.html#appendix-c-x86-experiment&quot;&gt;Appendix C: x86 Experiment&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We also ran the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;catalog_sales&lt;/code&gt; SF100 experiment on a machine with x86 CPU architecture, to get a more fair comparison with HyPer (without Rosetta 2 emulation).
The machine has an Intel(R) Xeon(R) W-2145 CPU @ 3.70 GHz, which has 8 cores (up to 16 virtual threads), and 128 GB of RAM, so this time the data fits fully in memory.
We have set the number of threads that DuckDB and ClickHouse use to 8 because we saw no visibly improved performance past 8.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/sorting/jewels_payload.svg&quot; alt=&quot;Increasing the number of payload columns for the catalog_sales table (jewels)&quot; title=&quot;Catalog Sales Payload Experiment (on bigger machine)&quot; style=&quot;max-width:90%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;Pandas performs comparatively worse than on the MacBook, because it has a single-threaded implementation, and this CPU has a lower single-thread performance.
Again, Pandas crashes with an error (this machine does not dynamically increase swap):&lt;/p&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;numpy.core._exceptions.MemoryError: Unable to allocate 6.32 GiB for an array with shape (6, 141430723) and data type float64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DuckDB, HyPer, and ClickHouse all make good use out of more available threads, being significantly faster than on the MacBook.&lt;/p&gt;

&lt;p&gt;An interesting pattern in this plot is that DuckDB and HyPer scale very similarly with additional payload columns.
Although DuckDB is faster at sorting, re-ordering the payload seems to cost about the same for both systems.
Therefore it is likely that HyPer also uses a row layout.&lt;/p&gt;

&lt;p&gt;ClickHouse scales worse with additional payload columns.
ClickHouse does not use a row layout, and therefore has to pay the cost of random access as each column is re-ordered after sorting.&lt;/p&gt;

</description><link>https://duckdb.org/2021/08/27/external-sorting.html</link><guid isPermaLink="false">https://duckdb.org/2021/08/27/external-sorting.html</guid><pubDate>Fri, 27 Aug 2021 00:00:00 GMT</pubDate><author>Laurens Kuiper</author></item><item><title>Querying Parquet with Precision Using DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB, a free and open source analytical data management system, can run SQL queries directly on Parquet files and automatically take advantage of the advanced features of the Parquet format.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Apache Parquet is the most common &quot;Big Data&quot; storage format for analytics. In Parquet files, data is stored in a columnar-compressed binary format. Each Parquet file stores a single table. The table is partitioned into row groups, which each contain a subset of the rows of the table. Within a row group, the table data is stored in a columnar fashion.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/parquet.svg&quot; alt=&quot;Example parquet file shown visually. The parquet file (taxi.parquet) is divided into row groups that each have two columns (pickup_at and dropoff_at)&quot; title=&quot;Taxi Parquet File&quot; style=&quot;max-width:30%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;The Parquet format has a number of properties that make it suitable for analytical use cases:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The columnar representation means that individual columns can be (efficiently) read. No need to always read the entire file!&lt;/li&gt;
  &lt;li&gt;The file contains per-column statistics in every row group (min/max value, and the number of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NULL&lt;/code&gt; values). These statistics allow the reader to skip row groups if they are not required.&lt;/li&gt;
  &lt;li&gt;The columnar compression significantly reduces the file size of the format, which in turn reduces the storage requirement of data sets. This can often turn Big Data into Medium Data.&lt;/li&gt;
&lt;/ol&gt;
      &lt;h2 id=&quot;duckdb-and-parquet&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#duckdb-and-parquet&quot;&gt;DuckDB and Parquet&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB&#39;s zero-dependency Parquet reader is able to directly execute SQL queries on Parquet files without any import or analysis step. Because of the natural columnar format of Parquet, this is very fast!&lt;/p&gt;

&lt;p&gt;DuckDB will read the Parquet files in a streaming fashion, which means you can perform queries on large Parquet files that do not fit in your main memory.&lt;/p&gt;

&lt;p&gt;DuckDB is able to automatically detect which columns and rows are required for any given query. This allows users to analyze much larger and more complex Parquet files without needing to perform manual optimizations or investing in more hardware.&lt;/p&gt;

&lt;p&gt;And as an added bonus, DuckDB is able to do all of this using parallel processing and over multiple Parquet files at the same time using the glob syntax.&lt;/p&gt;

&lt;p&gt;As a short teaser, here is a code snippet that allows you to directly run a SQL query on top of a Parquet file.&lt;/p&gt;

&lt;p&gt;To install the DuckDB package:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;pip &lt;/span&gt;install &lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To download the Parquet file:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;wget &lt;/span&gt;https://blobs.duckdb.org/data/taxi_2019_04.parquet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, run the following Python script:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&#39;&#39;
   SELECT count(*)
   FROM &#39;taxi_2019_04.parquet&#39;
   WHERE pickup_at BETWEEN &#39;2019-04-15&#39; AND &#39;2019-04-20&#39;
   &#39;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;automatic-filter--projection-pushdown&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#automatic-filter--projection-pushdown&quot;&gt;Automatic Filter &amp;amp; Projection Pushdown&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Let us dive into the previous query to better understand the power of the Parquet format when combined with DuckDB&#39;s query optimizer.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;taxi_2019_04.parquet&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickup_at&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2019-04-15&#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;2019-04-20&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this query, we read a single column from our Parquet file (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pickup_at&lt;/code&gt;). Any other columns stored in the Parquet file can be entirely skipped, as we do not need them to answer our query.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://duckdb.org/images/blog/parquet-filter-svg.svg&quot; alt=&quot;Projection &amp;amp; filter pushdown into parquet file example.&quot; title=&quot;Filter Pushdown&quot; style=&quot;max-width:30%&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;

&lt;p&gt;In addition, only rows that have a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pickup_at&lt;/code&gt; between the 15th and the 20th of April 2019 influence the result of the query. Any rows that do not satisfy this predicate can be skipped.&lt;/p&gt;

&lt;p&gt;We can use the statistics inside the Parquet file to great advantage here. Any row groups that have a max value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pickup_at&lt;/code&gt; lower than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2019-04-15&lt;/code&gt;, or a min value higher than &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2019-04-20&lt;/code&gt;, can be skipped. In some cases, that allows us to skip reading entire files.&lt;/p&gt;
      &lt;h2 id=&quot;duckdb-versus-pandas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#duckdb-versus-pandas&quot;&gt;DuckDB versus Pandas&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To illustrate how effective these automatic optimizations are, we will run a number of queries on top of Parquet files using both Pandas and DuckDB.&lt;/p&gt;

&lt;p&gt;In these queries, we use a part of the infamous New York Taxi dataset stored as Parquet files, specifically data from April, May and June 2019. These files are ca. 360 MB in size together and contain around 21 million rows of 18 columns each. The three files are placed into the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;taxi/&lt;/code&gt; folder.&lt;/p&gt;

&lt;p&gt;The examples are available &lt;a href=&quot;https://colab.research.google.com/drive/1e1beWqYOcFidKl2IxHtxT5s9i_6KYuNY&quot;&gt;here as an interactive notebook over at Google Colab&lt;/a&gt;. The timings reported here are from this environment for reproducibility.&lt;/p&gt;
      &lt;h2 id=&quot;reading-multiple-parquet-files&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#reading-multiple-parquet-files&quot;&gt;Reading Multiple Parquet Files&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;First we look at some rows in the dataset. There are three Parquet files in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;taxi/&lt;/code&gt; folder. &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html&quot;&gt;DuckDB supports the globbing syntax&lt;/a&gt;, which allows it to query all three files simultaneously.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
   SELECT *
   FROM &#39;taxi/*.parquet&#39;
   LIMIT 5&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;pickup_at&lt;/th&gt;
      &lt;th&gt;dropoff_at&lt;/th&gt;
      &lt;th&gt;passenger_count&lt;/th&gt;
      &lt;th&gt;trip_distance&lt;/th&gt;
      &lt;th&gt;rate_code_id&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;2019-04-01 00:04:09&lt;/td&gt;
      &lt;td&gt;2019-04-01 00:06:35&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.5&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2019-04-01 00:22:45&lt;/td&gt;
      &lt;td&gt;2019-04-01 00:25:43&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2019-04-01 00:39:48&lt;/td&gt;
      &lt;td&gt;2019-04-01 01:19:39&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10.9&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2019-04-01 00:35:32&lt;/td&gt;
      &lt;td&gt;2019-04-01 00:37:11&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2019-04-01 00:44:05&lt;/td&gt;
      &lt;td&gt;2019-04-01 00:57:58&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4.8&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Despite the query selecting all columns from three (rather large) Parquet files, the query completes instantly. This is because DuckDB processes the Parquet file in a streaming fashion, and will stop reading the Parquet file after the first few rows are read as that is all required to satisfy the query.&lt;/p&gt;

&lt;p&gt;If we try to do the same in Pandas, we realize it is not so straightforward, as Pandas cannot read multiple Parquet files in one call. We will first have to use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas.concat&lt;/code&gt; to concatenate the three Parquet files together:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;glob&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;
     &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;taxi/*.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Below are the timings for both of these queries.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;System&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.015&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12.300&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Pandas takes significantly longer to complete this query. That is because Pandas not only needs to read each of the three Parquet files in their entirety, it has to concatenate these three separate Pandas DataFrames together.&lt;/p&gt;
      &lt;h2 id=&quot;concatenate-into-a-single-file&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#concatenate-into-a-single-file&quot;&gt;Concatenate into a Single File&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We can address the concatenation issue by creating a single big Parquet file from the three smaller parts. We can use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; library for this, which has support for reading multiple Parquet files and streaming them into a single large file. Note that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; parquet reader is the very same parquet reader that is used by Pandas internally.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyarrow.parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# concatenate all three parquet files
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ParquetDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;taxi/&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_group_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that &lt;a href=&quot;https://duckdb.org/docs/stable/data/parquet/overview.html#writing-to-parquet-files&quot;&gt;DuckDB also has support for writing Parquet files&lt;/a&gt; using the COPY statement.&lt;/p&gt;
      &lt;h2 id=&quot;querying-the-large-file&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#querying-the-large-file&quot;&gt;Querying the Large File&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now let us repeat the previous experiment, but using the single file instead.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# DuckDB
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
   SELECT *
   FROM &#39;alltaxi.parquet&#39;
   LIMIT 5&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Pandas
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;System&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.02&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.50&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that Pandas performs better than before, as the concatenation is avoided. However, the entire file still needs to be read into memory, which takes both a significant amount of time and memory.&lt;/p&gt;

&lt;p&gt;For DuckDB it does not really matter how many Parquet files need to be read in a query.&lt;/p&gt;
      &lt;h2 id=&quot;counting-rows&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#counting-rows&quot;&gt;Counting Rows&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now suppose we want to figure out how many rows are in our data set. We can do that using the following code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# DuckDB
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
   SELECT count(*)
   FROM &#39;alltaxi.parquet&#39;
&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Pandas
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;System&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.015&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.500&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;DuckDB completes the query very quickly, as it automatically recognizes  what needs to be read from the Parquet file and minimizes the required reads. Pandas has to read the entire file again, which causes it to take  the same amount of time as the previous query.&lt;/p&gt;

&lt;p&gt;For this query, we can improve Pandas&#39; time through manual optimization. In order to get a count, we only need a single column from the file. By manually specifying a single column to be read in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt; command, we can get the same result but much faster.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;vendor_id&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;System&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.015&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (optimized)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.200&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;While this is much faster, this still takes more than a second as the entire &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vendor_id&lt;/code&gt; column has to be read into memory as a Pandas column only to count the number of rows.&lt;/p&gt;
      &lt;h2 id=&quot;filtering-rows&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#filtering-rows&quot;&gt;Filtering Rows&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;It is common to use some sort of filtering predicate to only look at the interesting parts of a data set. For example, imagine we want to know how many taxi rides occur after the 30th of June 2019. We can do that using the following query in DuckDB:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
   SELECT count(*)
   FROM &#39;alltaxi.parquet&#39;
   WHERE pickup_at &amp;gt; &#39;2019-06-30&#39;
&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The query completes in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;45ms&lt;/code&gt; and yields the following result:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;167022&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In Pandas, we can perform the same operation using a naive approach.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# pandas naive
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pickup_at &amp;gt; &#39;2019-06-30&#39;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This again reads the entire file into memory, however, causing this query to take &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;7.5s&lt;/code&gt;. With the manual projection pushdown we can bring this down to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0.9s&lt;/code&gt;. Still significantly higher than DuckDB.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# pandas projection pushdown
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;pickup_at&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pickup_at &amp;gt; &#39;2019-06-30&#39;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; parquet reader also allows us to perform filter pushdown into the scan, however. Once we add this we end up with a much more competitive &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;70ms&lt;/code&gt; to complete the query.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;pickup_at&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;pickup_at&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;&amp;gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;2019-06-30&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;System&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (projection pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (projection &amp;amp; filter pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.07&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This shows that the results here are not due to DuckDB&#39;s parquet reader being faster than the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; Parquet reader. The reason that DuckDB performs better on these queries is because its optimizers automatically extract all required columns and filters from the SQL query, which then get automatically utilized in the Parquet reader with no manual effort required.&lt;/p&gt;

&lt;p&gt;Interestingly, both the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; Parquet reader and DuckDB are significantly faster than performing this operation natively in Pandas on a materialized DataFrame.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# read the entire parquet file into Pandas
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# run the query natively in Pandas
# note: we only time this part
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;pickup_at&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pickup_at &amp;gt; &#39;2019-06-30&#39;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;System&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (projection pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.90&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (projection &amp;amp; filter pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (native)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.26&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;aggregates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#aggregates&quot;&gt;Aggregates&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Finally lets look at a more complex aggregation. Say we want to compute the number of rides per passenger. With DuckDB and SQL, it looks like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    SELECT passenger_count, count(*)
    FROM &#39;alltaxi.parquet&#39;
    GROUP BY passenger_count&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The query completes in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;220ms&lt;/code&gt; and yields the following result:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;passenger_count&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;count&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;408742&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15356631&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3332927&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;944833&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;439066&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;910516&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;546467&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;106&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;72&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;64&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For the SQL-averse and as a teaser for a future blog post, DuckDB also has a &quot;Relational API&quot; that allows for a more Python-esque declaration of queries. Here&#39;s the equivalent to the above SQL query, that provides the exact same result and performance:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aggregate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count, count(*)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now as a comparison, let&#39;s run the same query in Pandas in the same way we did previously.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# naive
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# projection pushdown
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;alltaxi.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# native (parquet file pre-loaded into memory)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;passenger_count&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;count&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;System&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.22&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (projection pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.58&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (native)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.51&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that DuckDB is faster than Pandas in all three scenarios, without needing to perform any manual optimizations and without needing to load the Parquet file into memory in its entirety.&lt;/p&gt;
      &lt;h2 id=&quot;conclusion&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/06/25/querying-parquet.html#conclusion&quot;&gt;Conclusion&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;DuckDB can efficiently run queries directly on top of Parquet files without requiring an initial loading phase. The system will automatically take advantage of all of Parquet&#39;s advanced features to speed up query execution.&lt;/p&gt;

&lt;p&gt;DuckDB is a free and open source database management system (MIT licensed). It aims to be the SQLite for Analytics, and provides a fast and efficient database system with zero external dependencies. It is available not just for Python, but also for C/C++, R, Java, and more.&lt;/p&gt;

</description><link>https://duckdb.org/2021/06/25/querying-parquet.html</link><guid isPermaLink="false">https://duckdb.org/2021/06/25/querying-parquet.html</guid><pubDate>Fri, 25 Jun 2021 00:00:00 GMT</pubDate><author>Hannes Mühleisen and Mark Raasveldt</author></item><item><title>Efficient SQL on Pandas with DuckDB</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB, a free and open source analytical data management system, can efficiently run SQL queries directly on Pandas DataFrames.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Recently, an article was published &lt;a href=&quot;https://hakibenita.com/sql-for-data-analysis&quot;&gt;advocating for using SQL for Data Analysis&lt;/a&gt;. Here at team DuckDB, we are huge fans of &lt;a href=&quot;https://en.wikipedia.org/wiki/SQL&quot;&gt;SQL&lt;/a&gt;. It is a versatile and flexible language that allows the user to efficiently perform a wide variety of data transformations, without having to care about how the data is physically represented or how to do these data transformations in the most optimal way.&lt;/p&gt;

&lt;p&gt;While you can very effectively perform aggregations and data transformations in an external database system such as Postgres if your data is stored there, at some point you will need to convert that data back into &lt;a href=&quot;https://pandas.pydata.org/&quot;&gt;Pandas&lt;/a&gt; and &lt;a href=&quot;https://numpy.org/&quot;&gt;NumPy&lt;/a&gt;. These libraries serve as the standard for data exchange between the vast ecosystem of Data Science libraries in Python&lt;sup&gt;1&lt;/sup&gt; such as &lt;a href=&quot;https://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt; or &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;TensorFlow&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;a href=&quot;https://arrow.apache.org/&quot;&gt;Apache Arrow&lt;/a&gt; is gaining significant traction in this domain as well, and DuckDB also quacks Arrow.&lt;/p&gt;

&lt;p&gt;If you are reading from a file (e.g., a CSV or Parquet file) often your data will never be loaded into an external database system at all, and will instead be directly loaded into a Pandas DataFrame.&lt;/p&gt;
      &lt;h2 id=&quot;sql-on-pandas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#sql-on-pandas&quot;&gt;SQL on Pandas&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;After your data has been converted into a Pandas DataFrame often additional data wrangling and analysis still need to be performed. SQL is a very powerful tool for performing these types of data transformations. Using DuckDB, it is possible to run SQL efficiently right on top of Pandas DataFrames.&lt;/p&gt;

&lt;p&gt;As a short teaser, here is a code snippet that allows you to do exactly that: run arbitrary SQL queries directly on Pandas DataFrames using DuckDB.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# to install: pip install duckdb
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mydf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;a&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT sum(a) FROM mydf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the rest of the article, we will go more in-depth into how this works and how fast it is.&lt;/p&gt;
      &lt;h2 id=&quot;data-integration--sql-on-pandas&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#data-integration--sql-on-pandas&quot;&gt;Data Integration &amp;amp; SQL on Pandas&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;One of the core goals of DuckDB is that accessing data in common formats should be easy. DuckDB is fully capable of running queries in parallel &lt;em&gt;directly&lt;/em&gt; on top of a Pandas DataFrame (or on a Parquet/CSV file, or on an Arrow table, …). A separate (time-consuming) import step is not necessary.&lt;/p&gt;

&lt;p&gt;DuckDB can also write query results directly to any of these formats. You can use DuckDB to process a Pandas DataFrame in parallel using SQL, and convert the result back to a Pandas DataFrame again, so you can then use the result in other Data Science libraries.&lt;/p&gt;

&lt;p&gt;When you run a query in SQL, DuckDB will look for Python variables whose name matches the table names in your query and automatically start reading your Pandas DataFrames. Looking back at the previous example we can see this in action:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mydf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;a&#39;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]})&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT sum(a) FROM mydf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The SQL table name &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mydf&lt;/code&gt; is interpreted as the local Python variable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mydf&lt;/code&gt; that happens to be a Pandas DataFrame, which DuckDB can read and query directly. The column names and types are also extracted automatically from the DataFrame.&lt;/p&gt;

&lt;p&gt;Not only is this process painless, it is highly efficient. For many queries, you can use DuckDB to process data faster than Pandas, and with a much lower total memory usage, &lt;em&gt;without ever leaving the Pandas DataFrame binary format&lt;/em&gt; (&quot;Pandas-in, Pandas-out&quot;). Unlike when using an external database system such as Postgres, the data transfer time of the input or the output is negligible (see Appendix A for details).&lt;/p&gt;
      &lt;h2 id=&quot;sql-on-pandas-performance&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#sql-on-pandas-performance&quot;&gt;SQL on Pandas Performance&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;To demonstrate the performance of DuckDB when executing SQL on Pandas DataFrames, we now present a number of benchmarks. The source code for the benchmarks is available for interactive use &lt;a href=&quot;https://colab.research.google.com/drive/1eg_TJpPQr2tyYKWjISJlX8IEAi8Qln3U?usp=sharing&quot;&gt;in Google Colab&lt;/a&gt;. In these benchmarks, we operate &lt;em&gt;purely&lt;/em&gt; on Pandas DataFrames. Both the DuckDB code and the Pandas code operates fully on a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pandas-in, Pandas-out&lt;/code&gt; basis.&lt;/p&gt;
      &lt;h3 id=&quot;benchmark-setup-and-data-set&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#benchmark-setup-and-data-set&quot;&gt;Benchmark Setup and Data Set&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;We run the benchmark entirely from within the Google Colab environment. For our benchmark dataset, we use the &lt;a href=&quot;http://www.tpc.org/tpch/&quot;&gt;infamous TPC-H data set&lt;/a&gt;. Specifically, we focus on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;orders&lt;/code&gt; tables as these are the largest tables in the benchmark. The total dataset size is around 1 GB in uncompressed CSV format (&quot;scale factor&quot; 1).&lt;/p&gt;

&lt;p&gt;As DuckDB is capable of using multiple processors (multi-threading), we include both a single-threaded variant and a variant with two threads. Note that while DuckDB can scale far beyond two threads, Google Colab only supports two.&lt;/p&gt;
      &lt;h3 id=&quot;setup&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#setup&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;First we need to install DuckDB. This is a simple one-liner.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;pip &lt;/span&gt;install &lt;span class=&quot;nb&quot;&gt;duckdb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To set up the dataset for processing we download two parquet files using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wget&lt;/code&gt;. After that, we load the data into a Pandas DataFrame using the built-in Parquet reader of DuckDB. The system automatically infers that we are reading a parquet file by looking at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.parquet&lt;/code&gt; extension of the file.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM &#39;lineitemsf1.snappy.parquet&#39;&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;SELECT * FROM &#39;orders.parquet&#39;&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;ungrouped-aggregates&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#ungrouped-aggregates&quot;&gt;Ungrouped Aggregates&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For our first query, we will run a set of ungrouped aggregates over the Pandas DataFrame. Here is the SQL query:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The Pandas code looks similar:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (1 Thread)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.079&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (2 Threads)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.048&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.070&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This benchmark involves a very simple query, and Pandas performs very well here. These simple queries are where Pandas excels (ha), as it can directly call into the numpy routines that implement these aggregates, which are highly efficient. Nevertheless, we can see that DuckDB performs similar to Pandas in the single-threaded scenario, and benefits from its multi-threading support when enabled.&lt;/p&gt;
      &lt;h3 id=&quot;grouped-aggregate&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#grouped-aggregate&quot;&gt;Grouped Aggregate&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For our second query, we will run the same set of aggregates, but this time include a grouping condition. In SQL, we can do this by adding a GROUP BY clause to the query.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In Pandas, we use the groupby function before we perform the aggregation.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_returnflag&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;l_linestatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (1 Thread)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.43&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (2 Threads)&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.84&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This query is already getting more complex, and while Pandas does a decent job, it is a factor two slower than the single-threaded version of DuckDB. DuckDB has a highly optimized aggregate hash-table implementation that will perform both the grouping and the computation of all the aggregates in a single pass over the data.&lt;/p&gt;
      &lt;h3 id=&quot;grouped-aggregate-with-a-filter&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#grouped-aggregate-with-a-filter&quot;&gt;Grouped Aggregate with a Filter&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Now suppose that we don&#39;t want to perform an aggregate over all of the data, but instead only want to select a subset of the data to aggregate. We can do this by adding a filter clause that removes any tuples we are not interested in. In SQL, we can accomplish this through the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; clause.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1998-09-02&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In Pandas, we can create a filtered variant of the DataFrame by using the selection brackets.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# filter out the rows
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_shipdate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1998-09-02&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# perform the aggregate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_returnflag&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;l_linestatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In DuckDB, the query optimizer will combine the filter and aggregation into a single pass over the data, only reading relevant columns. In Pandas, however, we have no such luck. The filter as it is executed will actually subset the entire lineitem table, &lt;em&gt;including any columns we are not using!&lt;/em&gt; As a result of this, the filter operation is much more time-consuming than it needs to be.&lt;/p&gt;

&lt;p&gt;We can manually perform this optimization (&quot;projection pushdown&quot; in database literature). To do this, we first need to select only the columns that are relevant to our query and then subset the lineitem dataframe. We will end up with the following code snippet:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# projection pushdown
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pushed_down_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_shipdate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;l_returnflag&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;l_linestatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# perform the filter
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pushed_down_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pushed_down_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_shipdate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1998-09-02&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# perform the aggregate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_returnflag&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;l_linestatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (1 Thread)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.60&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (2 Threads)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.42&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (manual pushdown)&amp;nbsp;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2.23&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;While the manual projection pushdown significantly speeds up the query in Pandas, there is still a significant time penalty for the filtered aggregate. To process a filter, Pandas will write a copy of the entire DataFrame (minus the filtered out rows) back into memory. This operation can be time consuming when the filter is not very selective.&lt;/p&gt;

&lt;p&gt;Due to its holistic query optimizer and efficient query processor, DuckDB performs significantly better on this query.&lt;/p&gt;
      &lt;h3 id=&quot;joins&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#joins&quot;&gt;Joins&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;For the final query, we will join (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;merge&lt;/code&gt; in Pandas) the lineitem table with the orders table, and apply a filter that only selects orders which have the status we are interested in. This leads us to the following query in SQL:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_orderkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1998-09-02&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_orderstatus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;O&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For Pandas, we have to add a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;merge&lt;/code&gt; step. In a basic approach, we merge lineitem and orders together, then apply the filters, and finally apply the grouping and aggregation. This will give us the following code snippet:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# perform the join
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merged&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;left_on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_orderkey&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;right_on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;o_orderkey&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# filter out the rows
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filtered_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merged&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;merged&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_shipdate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1998-09-02&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;filtered_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filtered_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;o_orderstatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# perform the aggregate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtered_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_returnflag&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;l_linestatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we have missed two performance opportunities:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First, we are merging far too many columns, because we are merging columns that are not required for the remainder of the query (projection pushdown).&lt;/li&gt;
  &lt;li&gt;Second, we are merging far too many rows. We can apply the filters prior to the merge to reduce the amount of data that we need to merge (filter pushdown).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Applying these two optimizations manually results in the following code snippet:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# projection &amp;amp; filter on lineitem table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lineitem_projected&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_shipdate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;l_orderkey&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;l_linestatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;l_returnflag&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lineitem_filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_projected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;lineitem_projected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_shipdate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;1998-09-02&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# projection and filter on order table
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orders_projected&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;o_orderkey&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;s&quot;&gt;&#39;o_orderstatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;orders_filtered&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders_projected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;orders_projected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;o_orderstatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;O&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# perform the join
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merged&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_filtered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;orders_filtered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;left_on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_orderkey&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;right_on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;o_orderkey&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# perform the aggregate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merged&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_returnflag&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;l_linestatus&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Both of these optimizations are automatically applied by DuckDB&#39;s query optimizer.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (1 Thread)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (2 Threads)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.53&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;15.2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (manual pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.78&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We see that the basic approach is extremely time consuming compared to the optimized version. This demonstrates the usefulness of the automatic query optimizer. Even after optimizing, the Pandas code is still significantly slower than DuckDB because it stores intermediate results in memory after the individual filters and joins.&lt;/p&gt;
      &lt;h3 id=&quot;takeaway&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#takeaway&quot;&gt;Takeaway&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;Using DuckDB, you can take advantage of the powerful and expressive SQL language without having to worry about moving your data in – and out – of Pandas. DuckDB is extremely simple to install, and offers many advantages such as a query optimizer, automatic multi-threading and larger-than-memory computation. DuckDB uses the Postgres SQL parser, and offers many of the same SQL features as Postgres, including advanced features such as window functions, correlated subqueries, (recursive) common table expressions, nested types and sampling. If you are missing a feature, please &lt;a href=&quot;https://github.com/duckdb/duckdb/issues&quot;&gt;open an issue&lt;/a&gt;.&lt;/p&gt;
      &lt;h2 id=&quot;appendix-a-there-and-back-again-transferring-data-from-pandas-to-a-sql-engine-and-back&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#appendix-a-there-and-back-again-transferring-data-from-pandas-to-a-sql-engine-and-back&quot;&gt;Appendix A: There and Back Again: Transferring Data from Pandas to a SQL Engine and Back&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Traditional SQL engines use the Client-Server paradigm, which means that a client program connects through a socket to a server. Queries are run on the server, and results are sent back down to the client afterwards. This is the same when using for example Postgres from Python. Unfortunately, this transfer &lt;a href=&quot;http://www.vldb.org/pvldb/vol10/p1022-muehleisen.pdf&quot;&gt;is a serious bottleneck&lt;/a&gt;. In-process engines such as SQLite or DuckDB do not run into this problem.&lt;/p&gt;

&lt;p&gt;To showcase how costly this data transfer over a socket is, we have run a benchmark involving Postgres, SQLite and DuckDB. The source code for the benchmark can be found &lt;a href=&quot;https://gist.github.com/hannes/a95a39a1eda63aeb0ca13fd82d1ba49c&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this benchmark we copy a (fairly small) Pandas data frame consisting of 10M 4-byte integers (40 MB) from Python to the PostgreSQL, SQLite and DuckDB databases. Since the default Pandas &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_sql&lt;/code&gt; was rather slow, we added a separate optimization in which we tell Pandas to write the data frame to a temporary CSV file, and then tell PostgreSQL to directly copy data from that file into a newly created table. This of course will only work if the database server is running on the same machine as Python.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas to Postgres using to_sql&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;111.25&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas to Postgres using temporary CSV file&amp;nbsp;&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas to SQLite using to_sql&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;6.80&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas to DuckDB&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.03&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;While SQLite performs significantly better than Postgres here, it is still rather slow. That is because the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_sql&lt;/code&gt; function in Pandas runs a large number of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSERT INTO&lt;/code&gt; statements, which involves transforming all the individual values of the Pandas DataFrame into a row-wise representation of  Python objects which are then passed onto the system. DuckDB on the other hand directly reads the underlying array from Pandas, which makes this operation almost instant.&lt;/p&gt;

&lt;p&gt;Transferring query results or tables back from the SQL system into Pandas is another potential bottleneck. Using the built-in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_sql_query&lt;/code&gt; is extremely slow, but even the more optimized CSV route still takes at least a second for this tiny data set. DuckDB, on the other hand, also performs this transformation almost instantaneously.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;PostgreSQL to Pandas using read_sql_query&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.08&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;PostgreSQL to Pandas using temporary CSV file&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.29&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;SQLite to Pandas using read_sql_query&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5.20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB to Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.04&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
      &lt;h2 id=&quot;appendix-b-comparison-to-pandasql&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#appendix-b-comparison-to-pandasql&quot;&gt;Appendix B: Comparison to PandaSQL&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;There is a package called &lt;a href=&quot;https://pypi.org/project/pandasql/&quot;&gt;PandaSQL&lt;/a&gt; that also provides the facilities of running SQL directly on top of Pandas. However, it is built using the to_sql and from_sql infrastructure that we have seen is extremely slow in Appendix A.&lt;/p&gt;

&lt;p&gt;Nevertheless, for good measure we have run the first Ungrouped Aggregate query in PandaSQL to time it. When we first tried to run the query on the original dataset, however, we ran into an out-of-memory error that crashed our colab session. For that reason, we have decided to run the benchmark again for PandaSQL using a sample of 10% of the original data set size (600K rows). Here are the results:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (1 Thread)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.023&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (2 Threads)&amp;nbsp;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.014&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.017&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;PandaSQL&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;24.43&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that PandaSQL (powered by SQLite) is around 1000X~ slower than either Pandas or DuckDB on this straightforward benchmark. The performance difference was so large we have opted not to run the other benchmarks for PandaSQL.&lt;/p&gt;
      &lt;h2 id=&quot;appendix-c-query-on-parquet-directly&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#appendix-c-query-on-parquet-directly&quot;&gt;Appendix C: Query on Parquet Directly&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;In the benchmarks above, we fully read the parquet files into Pandas. However, DuckDB also has the capability of directly running queries on top of Parquet files (in parallel!). In this appendix, we show the performance of this compared to loading the file into Python first.&lt;/p&gt;

&lt;p&gt;For the benchmark, we will run two queries: the simplest query (the ungrouped aggregate) and the most complex query (the final join) and compare the cost of running this query directly on the Parquet file, compared to loading it into Pandas using the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt; function.&lt;/p&gt;
      &lt;h3 id=&quot;setup-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#setup-1&quot;&gt;Setup&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;In DuckDB, we can create a view over the Parquet file using the following query. This allows us to run queries over the Parquet file as if it was a regular table. Note that we do not need to worry about projection pushdown at all: we can just do a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT *&lt;/code&gt; and DuckDB&#39;s optimizer will take care of only projecting the required columns at query time.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VIEW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;lineitemsf1.snappy.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VIEW&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders_parquet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;orders.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h3 id=&quot;ungrouped-aggregate&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#ungrouped-aggregate&quot;&gt;Ungrouped Aggregate&lt;/a&gt;
        
      &lt;/h3&gt;
    

&lt;p&gt;After we have set up this view, we can run the same queries we ran before, but this time against the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lineitem_parquet&lt;/code&gt; table.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For Pandas, we will first need to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt; to load the data into Pandas. To do this, we use the Parquet reader powered by Apache Arrow. After that, we can run the query as we did before.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lineitem_pandas_parquet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;lineitemsf1.snappy.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_pandas_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, we now again run into the problem where Pandas will read the Parquet file in its entirety. In order to circumvent this, we will need to perform projection pushdown manually again by providing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_parquet&lt;/code&gt; method with the set of columns that we want to read.&lt;/p&gt;

&lt;p&gt;The optimizer in DuckDB will figure this out by itself by looking at the query you are executing.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lineitem_pandas_parquet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;lineitemsf1.snappy.parquet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem_pandas_parquet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sum&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;min&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;max&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;l_extendedprice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;mean&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (1 Thread)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (2 Threads)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;7.87&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (manual pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.17&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that the performance difference between doing the pushdown and not doing the pushdown is dramatic. When we perform the pushdown, Pandas has performance in the same ballpark as DuckDB. Without the pushdown, however, it is loading the entire file from disk, including the other 15 columns that are not required to answer the query.&lt;/p&gt;
      &lt;h2 id=&quot;joins-1&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/05/14/sql-on-pandas.html#joins-1&quot;&gt;Joins&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now for the final query that we saw in the join section previously. To recap:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_extendedprice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lineitem&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orders&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_orderkey&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_orderkey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_shipdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DATE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;1998-09-02&#39;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_orderstatus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;O&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_returnflag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l_linestatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For Pandas we again create two versions. A naive version, and a manually optimized version. The exact code used can be found &lt;a href=&quot;https://colab.research.google.com/drive/1eg_TJpPQr2tyYKWjISJlX8IEAi8Qln3U?usp=sharing&quot;&gt;in Google Colab&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Name&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Time (s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (1 Thread)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;1.04&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DuckDB (2 Threads)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;0.89&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;20.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Pandas (manual pushdown)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;3.95&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We see that for this more complex query the slight difference in performance between running over a Pandas DataFrame and a Parquet file vanishes, and the DuckDB timings become extremely similar to the timings we saw before. The added Parquet read again increases the necessity of manually performing optimizations on the Pandas code, which is not required at all when running SQL in DuckDB.&lt;/p&gt;

</description><link>https://duckdb.org/2021/05/14/sql-on-pandas.html</link><guid isPermaLink="false">https://duckdb.org/2021/05/14/sql-on-pandas.html</guid><pubDate>Fri, 14 May 2021 00:00:00 GMT</pubDate><author>Mark Raasveldt and Hannes Mühleisen</author></item><item><title>Testing Out DuckDB&#39;s Full Text Search Extension</title><description>&lt;div class=&quot;excerpt&quot;&gt;
&lt;p&gt;&lt;em&gt;TL;DR: DuckDB now has full-text search functionality, similar to the FTS5 extension in SQLite. The main difference is that our FTS extension is fully formulated in SQL. We tested it out on TREC disks 4 and 5.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Searching through textual data stored in a database can be cumbersome, as SQL does not provide a good way of formulating questions such as &quot;Give me all the documents about &lt;strong&gt;Mallard Ducks&lt;/strong&gt;&quot;: string patterns with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; will only get you so far. Despite SQL&#39;s shortcomings here, storing textual data in a database is commonplace. Consider the table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;products (id INTEGER, name VARCHAR, description VARCHAR&lt;/code&gt;) – it would be useful to search through the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;name&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;description&lt;/code&gt; columns for a website that sells these products.&lt;/p&gt;

&lt;p&gt;We expect a search engine to return us results within milliseconds. For a long time databases were unsuitable for this task, because they could not search large inverted indexes at this speed: transactional database systems are not made for this use case. However, analytical database systems, can keep up with state-of-the art information retrieval systems. The company &lt;a href=&quot;https://www.spinque.com/&quot;&gt;Spinque&lt;/a&gt; is a good example of this. At Spinque, MonetDB is used as a computation engine for customized search engines.&lt;/p&gt;

&lt;p&gt;DuckDB&#39;s FTS implementation follows the paper &quot;&lt;a href=&quot;https://www.duckdb.org/pdf/SIGIR2014-column-stores-ir-prototyping.pdf&quot;&gt;Old Dogs Are Great at New Tricks&lt;/a&gt;&quot;. A keen observation there is that advances made to the database system, such as parallelization, will speed up your search engine &quot;for free&quot;!&lt;/p&gt;

&lt;p&gt;Alright, enough about the &quot;why&quot;, let&#39;s get to the &quot;how&quot;.&lt;/p&gt;
      &lt;h2 id=&quot;preparing-the-data&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/01/25/full-text-search.html#preparing-the-data&quot;&gt;Preparing the Data&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The TREC 2004 Robust Retrieval Track has 250 &quot;topics&quot; (search queries) over TREC disks 4 and 5. The data consist of many text files stored in SGML format, along with a corresponding DTD (document type definition) file. This format is rarely used anymore, but it is similar to XML. We will use OpenSP&#39;s command line tool &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;osx&lt;/code&gt; to convert it to XML. Because there are many files, I wrote a Bash script:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; latimes/xml
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;i &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt; 1 9&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;dtds/la.dtd latimes-&lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt; | osx &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; latimes/xml/latimes-&lt;span class=&quot;nv&quot;&gt;$i&lt;/span&gt;.xml
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This sorts the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;latimes&lt;/code&gt; files. Repeat for the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fbis&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cr&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fr94&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ft&lt;/code&gt; files.&lt;/p&gt;

&lt;p&gt;To parse the XML I used BeautifulSoup. Each document has a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docno&lt;/code&gt; identifier, and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text&lt;/code&gt; field. Because the documents do not come from the same source, they differ in what other fields they have. I chose to take all of the fields.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;duckdb&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiprocessing&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# fill variable &#39;files&#39; with the path to each .xml file that we created here
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dict_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fpath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;bs_content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;html.parser&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# find all &#39;doc&#39; nodes
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs_content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findChildren&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;doc&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recursive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;row_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findChildren&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recursive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;row_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recursive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dict_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dict_list&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# process documents (in parallel to speed things up)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;list_of_dict_lists&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imap_unordered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;list_of_dict_lists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create pandas dataframe from the parsed data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;documents_df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sublist&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list_of_dict_lists&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sublist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now that we have a dataframe, we can register it in DuckDB.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# create database connection and register the dataframe
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;db/trec04_05.db&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_only&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;register&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;documents_df&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;documents_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create a table from the dataframe so that it persists
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CREATE TABLE documents AS (SELECT * FROM documents_df)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is the end of my preparation script, so I closed the database connection.&lt;/p&gt;
      &lt;h2 id=&quot;building-the-search-engine&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/01/25/full-text-search.html#building-the-search-engine&quot;&gt;Building the Search Engine&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;We can now build the inverted index and the retrieval model using a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PRAGMA&lt;/code&gt; statement.
The extension is &lt;a href=&quot;https://duckdb.org/docs/stable/extensions/full_text_search.html&quot;&gt;documented here&lt;/a&gt;.
We create an index table on table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;documents&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main.documents&lt;/code&gt; that we created with our script.
The column that identifies our documents is called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docno&lt;/code&gt;, and we wish to create an inverted index on the fields supplied.
I supplied all fields by using the &#39;*&#39; shortcut.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duckdb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;db/trec04_05.db&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_only&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PRAGMA create_fts_index(&#39;documents&#39;, &#39;docno&#39;, &#39;*&#39;, stopwords=&#39;english&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Under the hood, a parameterized SQL script is called. The schema &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fts_main_documents&lt;/code&gt; is created, along with tables &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docs&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;terms&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dict&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stats&lt;/code&gt;, that make up the inverted index. If you&#39;re curious what this look like, take a look at our source code under the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;extension&lt;/code&gt; folder in DuckDB&#39;s source code!&lt;/p&gt;
      &lt;h2 id=&quot;running-the-benchmark&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/01/25/full-text-search.html#running-the-benchmark&quot;&gt;Running the Benchmark&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;The data is now fully prepared. Now we want to run the queries in the benchmark, one by one. We load the topics file as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# the &#39;topics&#39; file is not structured nicely, therefore we need parse some of it using regex
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;after_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&amp;lt;&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&amp;gt;([\s\S]*?)&amp;lt;.*&amp;gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;topic_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;../../trec/topics&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bs_content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;lxml&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs_content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findChildren&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;top&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;top_content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# we need the number and title of each topic
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;after_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;num&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39; &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;after_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;title&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;topic_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This gives us a dictionary that has query number as keys, and query strings as values, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;301 -&amp;gt; &#39;International Organized Crime&#39;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We want to store the results in a specific format, so that they can be evaluated by &lt;a href=&quot;https://github.com/usnistgov/trec_eval.git&quot;&gt;trec eval&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# create a prepared statement to make querying our document collection easier
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    PREPARE fts_query AS (
        WITH scored_docs AS (
            SELECT *, fts_main_documents.match_bm25(docno, ?) AS score FROM documents)
        SELECT docno, score
        FROM scored_docs
        WHERE score IS NOT NULL
        ORDER BY score DESC
        LIMIT 1000)
    &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# enable parallelism
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;PRAGMA threads=32&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topic_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;q_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topic_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&#39;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39; &#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;EXECUTE fts_query(&#39;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&#39;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; Q0 &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; STANDARD&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;con&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;results&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;w+&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
      &lt;h2 id=&quot;results&quot;&gt;
        
        &lt;a style=&quot;text-decoration: none;&quot; href=&quot;https://duckdb.org/2021/01/25/full-text-search.html#results&quot;&gt;Results&lt;/a&gt;
        
      &lt;/h2&gt;
    

&lt;p&gt;Now that we have created our &#39;results&#39; file, we can compare them to the relevance assessments &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qrels&lt;/code&gt; using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;trec_eval&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./trec_eval &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; P.30 &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; map qrels results
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;map                     all 0.2324
P_30                    all 0.2948
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Not bad! While these results are not as high as the reproducible by &lt;a href=&quot;https://github.com/castorini/anserini&quot;&gt;Anserini&lt;/a&gt;, they are definitely acceptable. The difference in performance can be explained by differences in&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Which stemmer was used (we used &#39;porter&#39;)&lt;/li&gt;
  &lt;li&gt;Which stopwords were used (we used the list of 571 English stopwords used in the SMART system)&lt;/li&gt;
  &lt;li&gt;Pre-processing (removal of accents, punctuation, numbers)&lt;/li&gt;
  &lt;li&gt;BM25 parameters (we used the default k=1.2 and b=0.75, non-conjunctive)&lt;/li&gt;
  &lt;li&gt;Which fields were indexed (we used all columns by supplying &#39;*&#39;)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Retrieval time for each query was between 0.5 and 1.3 seconds on our machine, which will be improved with further improvements to DuckDB. I hope you enjoyed reading this blog, and become inspired to test out the extension as well!&lt;/p&gt;

</description><link>https://duckdb.org/2021/01/25/full-text-search.html</link><guid isPermaLink="false">https://duckdb.org/2021/01/25/full-text-search.html</guid><pubDate>Mon, 25 Jan 2021 00:00:00 GMT</pubDate><author>Laurens Kuiper</author></item></channel></rss>