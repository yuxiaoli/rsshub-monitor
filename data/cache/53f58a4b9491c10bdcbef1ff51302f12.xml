<?xml version="1.0" encoding="UTF-8"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>detection</title><link>https://papers.cool/arxiv/search?highlight=1&amp;query=Detection&amp;sort=0</link><atom:link href="http://127.0.0.1:1200/papers/query/Detection" rel="self" type="application/rss+xml"></atom:link><description>detection - Powered by RSSHub</description><generator>RSSHub</generator><webMaster>contact@rsshub.app (RSSHub)</webMaster><language>en</language><lastBuildDate>Wed, 19 Mar 2025 23:27:46 GMT</lastBuildDate><ttl>60</ttl><item><title>HGO-YOLO: Advancing Anomaly Behavior Detection with Hierarchical Features and Lightweight Optimized Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2503.07371&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2503.07371&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Qizhi Zheng&lt;/p&gt;   &lt;p&gt;Accurate and real-time object detection is crucial for anomaly behavior detection, especially in scenarios constrained by hardware limitations, where balancing accuracy and speed is essential for enhancing detection performance. This study proposes a model called HGO-YOLO, which integrates the HGNetv2 architecture into YOLOv8. This combination expands the receptive field and captures a wider range of features while simplifying model complexity through GhostConv. We introduced a lightweight detection head, OptiConvDetect, which utilizes parameter sharing to construct the detection head effectively. Evaluation results show that the proposed algorithm achieves a mAP@0.5 of 87.4% and a recall rate of 81.1%, with a model size of only 4.6 MB and a frame rate of 56 FPS on the CPU. HGO-YOLO not only improves accuracy by 3.0% but also reduces computational load by 51.69% (from 8.9 GFLOPs to 4.3 GFLOPs), while increasing the frame rate by a factor of 1.7. Additionally, real-time tests were conducted on Raspberry Pi4 and NVIDIA platforms. These results indicate that the HGO-YOLO model demonstrates superior performance in anomaly behavior detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2503.07371</link><guid isPermaLink="false">https://papers.cool/arxiv/2503.07371</guid><pubDate>Mon, 10 Mar 2025 14:29:12 GMT</pubDate><author>Qizhi Zheng</author></item><item><title>Optimum Noncoherent Detection of Constant-Envelope Signals using Received Signal Magnitudes -- Energy Detection and Amplitude Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2502.17897&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2502.17897&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mu Jia&lt;/p&gt;   &lt;p&gt;Constant-envelope signals are widely employed in wireless communication systems due to their hardware-friendly design, energy efficiency, and enhanced reliability. However, detecting these signals reliably using simple, power-efficient receivers remains a critical challenge. While coherent detection methods generally offer superior performance, they require complex frequency synchronization, which increases receiver complexity and power consumption. In contrast, noncoherent detection is inherently simpler since it avoids frequency synchronization. However, traditional noncoherent detection approaches still rely on In-phase and Quadrature-phase (IQ) demodulators to extract the noisy received signal magnitudes, and assume the energy detector as the test statistic according to the IQ structure, without rigorous theoretical justification. Motivated by the practical need for robust and low-complexity detection, this paper proposes a comprehensive framework for optimal signal detection using a simple bandpass-filter envelope-detector (BFED) in conjunction with a Bayesian approach and the generalized likelihood ratio test (GLRT) under unknown amplitude conditions. By leveraging approximations of the modified Bessel functions, we derive two distinct regimes of the optimal detector. In the low SNR regime, we rigorously prove that the energy detector emerges as the Bayesian-optimal solution, thereby establishing its theoretical validity for the first time. In the high SNR regime, we derive a novel amplitude-based detector that directly compares the estimated amplitude against the noise standard deviation, leading to a simple yet optimal detection strategy. Numerical simulations validate the theoretical findings, confirming that both the energy and amplitude detectors achieve the minimum error probability in their respective SNR domains.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2502.17897</link><guid isPermaLink="false">https://papers.cool/arxiv/2502.17897</guid><pubDate>Tue, 25 Feb 2025 06:42:13 GMT</pubDate><author>Mu Jia</author></item><item><title>Object Detection and Tracking</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2502.10310&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2502.10310&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Md Pranto&lt;/p&gt;   &lt;p&gt;Efficient and accurate object detection is an important topic in the development of computer vision systems. With the advent of deep learning techniques, the accuracy of object detection has increased significantly. The project aims to integrate a modern technique for object detection with the aim of achieving high accuracy with real-time performance. The reliance on other computer vision algorithms in many object identification systems, which results in poor and ineffective performance, is a significant obstacle. In this research, we solve the end-to-end object detection problem entirely using deep learning techniques. The network is trained using the most difficult publicly available dataset, which is used for an annual item detection challenge. Applications that need object detection can benefit the system&#39;s quick and precise finding.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2502.10310</link><guid isPermaLink="false">https://papers.cool/arxiv/2502.10310</guid><pubDate>Fri, 14 Feb 2025 17:13:52 GMT</pubDate><author>Md Pranto</author></item><item><title>SAFE: Self-Supervised Anomaly Detection Framework for Intrusion Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2502.07119&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2502.07119&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Elvin Li&lt;/p&gt;   &lt;p&gt;The proliferation of IoT devices has significantly increased network vulnerabilities, creating an urgent need for effective Intrusion Detection Systems (IDS). Machine Learning-based IDS (ML-IDS) offer advanced detection capabilities but rely on labeled attack data, which limits their ability to identify unknown threats. Self-Supervised Learning (SSL) presents a promising solution by using only normal data to detect patterns and anomalies. This paper introduces SAFE, a novel framework that transforms tabular network intrusion data into an image-like format, enabling Masked Autoencoders (MAEs) to learn robust representations of network behavior. The features extracted by the MAEs are then incorporated into a lightweight novelty detector, enhancing the effectiveness of anomaly detection. Experimental results demonstrate that SAFE outperforms the state-of-the-art anomaly detection method, Scale Learning-based Deep Anomaly Detection method (SLAD), by up to 26.2% and surpasses the state-of-the-art SSL-based network intrusion detection approach, Anomal-E, by up to 23.5% in F1-score.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2502.07119</link><guid isPermaLink="false">https://papers.cool/arxiv/2502.07119</guid><pubDate>Mon, 10 Feb 2025 23:20:59 GMT</pubDate><author>Elvin Li</author></item><item><title>SoccerSynth-Detection: A Synthetic Dataset for Soccer Player Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2501.09281&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2501.09281&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Haobin Qin&lt;/p&gt;   &lt;p&gt;In soccer video analysis, player detection is essential for identifying key events and reconstructing tactical positions. The presence of numerous players and frequent occlusions, combined with copyright restrictions, severely restricts the availability of datasets, leaving limited options such as SoccerNet-Tracking and SportsMOT. These datasets suffer from a lack of diversity, which hinders algorithms from adapting effectively to varied soccer video contexts. To address these challenges, we developed SoccerSynth-Detection, the first synthetic dataset designed for the detection of synthetic soccer players. It includes a broad range of random lighting and textures, as well as simulated camera motion blur. We validated its efficacy using the object detection model (Yolov8n) against real-world datasets (SoccerNet-Tracking and SportsMoT). In transfer tests, it matched the performance of real datasets and significantly outperformed them in images with motion blur; in pre-training tests, it demonstrated its efficacy as a pre-training dataset, significantly enhancing the algorithm&#39;s overall performance. Our work demonstrates the potential of synthetic datasets to replace real datasets for algorithm training in the field of soccer video analysis.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2501.09281</link><guid isPermaLink="false">https://papers.cool/arxiv/2501.09281</guid><pubDate>Thu, 16 Jan 2025 04:06:59 GMT</pubDate><author>Haobin Qin</author></item><item><title>Seamless Detection: Unifying Salient Object Detection and Camouflaged Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2412.16840&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2412.16840&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yi Liu&lt;/p&gt;   &lt;p&gt;Achieving joint learning of Salient Object Detection (SOD) and Camouflaged Object Detection (COD) is extremely challenging due to their distinct object characteristics, i.e., saliency and camouflage. The only preliminary research treats them as two contradictory tasks, training models on large-scale labeled data alternately for each task and assessing them independently. However, such task-specific mechanisms fail to meet real-world demands for addressing unknown tasks effectively. To address this issue, in this paper, we pioneer a task-agnostic framework to unify SOD and COD. To this end, inspired by the agreeable nature of binary segmentation for SOD and COD, we propose a Contrastive Distillation Paradigm (CDP) to distil the foreground from the background, facilitating the identification of salient and camouflaged objects amidst their surroundings. To probe into the contribution of our CDP, we design a simple yet effective contextual decoder involving the interval-layer and global context, which achieves an inference speed of 67 fps. Besides the supervised setting, our CDP can be seamlessly integrated into unsupervised settings, eliminating the reliance on extensive human annotations. Experiments on public SOD and COD datasets demonstrate the superiority of our proposed framework in both supervised and unsupervised settings, compared with existing state-of-the-art approaches. Code is available on https://github.com/liuyi1989/Seamless-Detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2412.16840</link><guid isPermaLink="false">https://papers.cool/arxiv/2412.16840</guid><pubDate>Sun, 22 Dec 2024 03:25:43 GMT</pubDate><author>Yi Liu</author></item><item><title>Deepfake detection, image manipulation detection, fairness, generalization</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2412.16428&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2412.16428&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Uzoamaka Ezeakunne&lt;/p&gt;   &lt;p&gt;Despite the progress made in deepfake detection research, recent studies have shown that biases in the training data for these detectors can result in varying levels of performance across different demographic groups, such as race and gender. These disparities can lead to certain groups being unfairly targeted or excluded. Traditional methods often rely on fair loss functions to address these issues, but they under-perform when applied to unseen datasets, hence, fairness generalization remains a challenge. In this work, we propose a data-driven framework for tackling the fairness generalization problem in deepfake detection by leveraging synthetic datasets and model optimization. Our approach focuses on generating and utilizing synthetic data to enhance fairness across diverse demographic groups. By creating a diverse set of synthetic samples that represent various demographic groups, we ensure that our model is trained on a balanced and representative dataset. This approach allows us to generalize fairness more effectively across different domains. We employ a comprehensive strategy that leverages synthetic data, a loss sharpness-aware optimization pipeline, and a multi-task learning framework to create a more equitable training environment, which helps maintain fairness across both intra-dataset and cross-dataset evaluations. Extensive experiments on benchmark deepfake detection datasets demonstrate the efficacy of our approach, surpassing state-of-the-art approaches in preserving fairness during cross-dataset evaluation. Our results highlight the potential of synthetic datasets in achieving fairness generalization, providing a robust solution for the challenges faced in deepfake detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2412.16428</link><guid isPermaLink="false">https://papers.cool/arxiv/2412.16428</guid><pubDate>Sat, 21 Dec 2024 01:28:35 GMT</pubDate><author>Uzoamaka Ezeakunne</author></item><item><title>Facade: High-Precision Insider Threat Detection Using Deep Contextual Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2412.06700&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2412.06700&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alex Kantchelian&lt;/p&gt;   &lt;p&gt;We present Facade (Fast and Accurate Contextual Anomaly DEtection): a high-precision deep-learning-based anomaly detection system deployed at Google (a large technology company) as the last line of defense against insider threats since 2018. Facade is an innovative unsupervised action-context system that detects suspicious actions by considering the context surrounding each action, including relevant facts about the user and other entities involved. It is built around a new multi-modal model that is trained on corporate document access, SQL query, and HTTP/RPC request logs. To overcome the scarcity of incident data, Facade harnesses a novel contrastive learning strategy that relies solely on benign data. Its use of history and implicit social network featurization efficiently handles the frequent out-of-distribution events that occur in a rapidly changing corporate environment, and sustains Facade&#39;s high precision performance for a full year after training. Beyond the core model, Facade contributes an innovative clustering approach based on user and action embeddings to improve detection robustness and achieve high precision, multi-scale detection. Functionally what sets Facade apart from existing anomaly detection systems is its high precision. It detects insider attackers with an extremely low false positive rate, lower than 0.01%. For single rogue actions, such as the illegitimate access to a sensitive document, the false positive rate is as low as 0.0003%. To the best of our knowledge, Facade is the only published insider risk anomaly detection system that helps secure such a large corporate environment.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2412.06700</link><guid isPermaLink="false">https://papers.cool/arxiv/2412.06700</guid><pubDate>Mon, 09 Dec 2024 17:46:28 GMT</pubDate><author>Alex Kantchelian</author></item><item><title>Practitioners&#39; Expectations on Log Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2412.01066&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2412.01066&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xiaoxue Ma&lt;/p&gt;   &lt;p&gt;Log anomaly detection has become a common practice for software engineers to analyze software system behavior. Despite significant research efforts in log anomaly detection over the past decade, it remains unclear what are practitioners&#39; expectations on log anomaly detection and whether current research meets their needs. To fill this gap, we conduct an empirical study, surveying 312 practitioners from 36 countries about their expectations on log anomaly detection. In particular, we investigate various factors influencing practitioners&#39; willingness to adopt log anomaly detection tools. We then perform a literature review on log anomaly detection, focusing on publications in premier venues from 2014 to 2024, to compare practitioners&#39; needs with the current state of research. Based on this comparison, we highlight the directions for researchers to focus on to develop log anomaly detection techniques that better meet practitioners&#39; expectations.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2412.01066</link><guid isPermaLink="false">https://papers.cool/arxiv/2412.01066</guid><pubDate>Mon, 02 Dec 2024 03:01:35 GMT</pubDate><author>Xiaoxue Ma</author></item><item><title>From Audio Deepfake Detection to AI-Generated Music Detection -- A Pathway and Overview</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2412.00571&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2412.00571&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yupei Li&lt;/p&gt;   &lt;p&gt;As Artificial Intelligence (AI) technologies continue to evolve, their use in generating realistic, contextually appropriate content has expanded into various domains. Music, an art form and medium for entertainment, deeply rooted into human culture, is seeing an increased involvement of AI into its production. However, the unregulated use of AI music generation (AIGM) tools raises concerns about potential negative impacts on the music industry, copyright and artistic integrity, underscoring the importance of effective AIGM detection. This paper provides an overview of existing AIGM detection methods. To lay a foundation to the general workings and challenges of AIGM detection, we first review general principles of AIGM, including recent advancements in deepfake audios, as well as multimodal detection techniques. We further propose a potential pathway for leveraging foundation models from audio deepfake detection to AIGM detection. Additionally, we discuss implications of these tools and propose directions for future research to address ongoing challenges in the field.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2412.00571</link><guid isPermaLink="false">https://papers.cool/arxiv/2412.00571</guid><pubDate>Sat, 30 Nov 2024 19:53:23 GMT</pubDate><author>Yupei Li</author></item><item><title>Cutting-Edge Detection of Fatigue in Drivers: A Comparative Study of Object Detection Models</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2410.15030&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2410.15030&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Amelia Jones&lt;/p&gt;   &lt;p&gt;This research delves into the development of a fatigue detection system based on modern object detection algorithms, particularly YOLO (You Only Look Once) models, including YOLOv5, YOLOv6, YOLOv7, and YOLOv8. By comparing the performance of these models, we evaluate their effectiveness in real-time detection of fatigue-related behavior in drivers. The study addresses challenges like environmental variability and detection accuracy and suggests a roadmap for enhancing real-time detection. Experimental results demonstrate that YOLOv8 offers superior performance, balancing accuracy with speed. Data augmentation techniques and model optimization have been key in enhancing system adaptability to various driving conditions.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2410.15030</link><guid isPermaLink="false">https://papers.cool/arxiv/2410.15030</guid><pubDate>Sat, 19 Oct 2024 08:06:43 GMT</pubDate><author>Amelia Jones</author></item><item><title>Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2410.13616&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2410.13616&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kristina Telegraph&lt;/p&gt;   &lt;p&gt;This work presents advancements in multi-class vehicle detection using UAV cameras through the development of spatiotemporal object detection models. The study introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing 6, 600 annotated sequential frame images captured by UAVs, enabling comprehensive training and evaluation of algorithms for holistic spatiotemporal perception. A YOLO-based object detection algorithm is enhanced to incorporate temporal dynamics, resulting in improved performance over single frame models. The integration of attention mechanisms into spatiotemporal models is shown to further enhance performance. Experimental validation demonstrates significant progress, with the best spatiotemporal model exhibiting a 16.22% improvement over single frame models, while it is demonstrated that attention mechanisms hold the potential for additional performance gains.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2410.13616</link><guid isPermaLink="false">https://papers.cool/arxiv/2410.13616</guid><pubDate>Thu, 17 Oct 2024 14:49:37 GMT</pubDate><author>Kristina Telegraph</author></item><item><title>Real-time Fuel Leakage Detection via Online Change Point Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2410.09741&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2410.09741&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ruimin Chu&lt;/p&gt;   &lt;p&gt;Early detection of fuel leakage at service stations with underground petroleum storage systems is a crucial task to prevent catastrophic hazards. Current data-driven fuel leakage detection methods employ offline statistical inventory reconciliation, leading to significant detection delays. Consequently, this can result in substantial financial loss and environmental impact on the surrounding community. In this paper, we propose a novel framework called Memory-based Online Change Point Detection (MOCPD) which operates in near real-time, enabling early detection of fuel leakage. MOCPD maintains a collection of representative historical data within a size-constrained memory, along with an adaptively computed threshold. Leaks are detected when the dissimilarity between the latest data and historical memory exceeds the current threshold. An update phase is incorporated in MOCPD to ensure diversity among historical samples in the memory. With this design, MOCPD is more robust and achieves a better recall rate while maintaining a reasonable precision score. We have conducted a variety of experiments comparing MOCPD to commonly used online change point detection (CPD) baselines on real-world fuel variance data with induced leakages, actual fuel leakage data and benchmark CPD datasets. Overall, MOCPD consistently outperforms the baseline methods in terms of detection accuracy, demonstrating its applicability to fuel leakage detection and CPD problems.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2410.09741</link><guid isPermaLink="false">https://papers.cool/arxiv/2410.09741</guid><pubDate>Sun, 13 Oct 2024 06:22:13 GMT</pubDate><author>Ruimin Chu</author></item><item><title>1M-Deepfakes Detection Challenge</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2409.06991&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2409.06991&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhixi Cai&lt;/p&gt;   &lt;p&gt;The detection and localization of deepfake content, particularly when small fake segments are seamlessly mixed with real videos, remains a significant challenge in the field of digital media security. Based on the recently released AV-Deepfake1M dataset, which contains more than 1 million manipulated videos across more than 2,000 subjects, we introduce the 1M-Deepfakes Detection Challenge. This challenge is designed to engage the research community in developing advanced methods for detecting and localizing deepfake manipulations within the large-scale high-realistic audio-visual dataset. The participants can access the AV-Deepfake1M dataset and are required to submit their inference results for evaluation across the metrics for detection or localization tasks. The methodologies developed through the challenge will contribute to the development of next-generation deepfake detection and localization systems. Evaluation scripts, baseline models, and accompanying code will be available on https://github.com/ControlNet/AV-Deepfake1M.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2409.06991</link><guid isPermaLink="false">https://papers.cool/arxiv/2409.06991</guid><pubDate>Wed, 11 Sep 2024 03:43:53 GMT</pubDate><author>Zhixi Cai</author></item><item><title>Active-IRS-Enabled Target Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2409.04155&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2409.04155&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Song Xianxin&lt;/p&gt;   &lt;p&gt;This letter studies an active intelligent reflecting surface (IRS)-enabled non-line-of-sight (NLoS) target detection system, in which an active IRS equipped with active reflecting elements and sensors is strategically deployed to facilitate target detection in the NLoS region of the base station (BS) by processing echo signals through the BS-IRS-target-IRS link. First, we design an optimal detector based on the Neyman-Pearson (NP) theorem and derive the corresponding detection probability. Intriguingly, it is demonstrated that the optimal detector can exploit both the BS&#39;s transmit signal and the active IRS&#39;s reflection noise for more effective detection. Subsequently, we jointly optimize the transmit beamforming at the BS and the reflective beamforming at the active IRS to maximize the detection probability, subject to the maximum transmit power constraint at the BS, as well as the maximum amplification power and gain constraints at the active IRS. Finally, simulation results unveil that the proposed joint beamforming design significantly enhances the detection probability, with the active IRS outperforming its fully- and semi-passive counterparts in detection performance.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2409.04155</link><guid isPermaLink="false">https://papers.cool/arxiv/2409.04155</guid><pubDate>Fri, 06 Sep 2024 09:34:55 GMT</pubDate><author>Song Xianxin</author></item><item><title>BFA-YOLO: Balanced multiscale object detection network for multi-view building facade attachments detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2409.04025&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2409.04025&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yangguang Chen&lt;/p&gt;   &lt;p&gt;Detection of building facade attachments such as doors, windows, balconies, air conditioner units, billboards, and glass curtain walls plays a pivotal role in numerous applications. Building facade attachments detection aids in vbuilding information modeling (BIM) construction and meeting Level of Detail 3 (LOD3) standards. Yet, it faces challenges like uneven object distribution, small object detection difficulty, and background interference. To counter these, we propose BFA-YOLO, a model for detecting facade attachments in multi-view images. BFA-YOLO incorporates three novel innovations: the Feature Balanced Spindle Module (FBSM) for addressing uneven distribution, the Target Dynamic Alignment Task Detection Head (TDATH) aimed at improving small object detection, and the Position Memory Enhanced Self-Attention Mechanism (PMESA) to combat background interference, with each component specifically designed to solve its corresponding challenge. Detection efficacy of deep network models deeply depends on the dataset&#39;s characteristics. Existing open source datasets related to building facades are limited by their single perspective, small image pool, and incomplete category coverage. We propose a novel method for building facade attachments detection dataset construction and construct the BFA-3D dataset for facade attachments detection. The BFA-3D dataset features multi-view, accurate labels, diverse categories, and detailed classification. BFA-YOLO surpasses YOLOv8 by 1.8% and 2.9% in mAP@0.5 on the multi-view BFA-3D and street-view Facade-WHU datasets, respectively. These results underscore BFA-YOLO&#39;s superior performance in detecting facade attachments.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2409.04025</link><guid isPermaLink="false">https://papers.cool/arxiv/2409.04025</guid><pubDate>Fri, 06 Sep 2024 04:44:52 GMT</pubDate><author>Yangguang Chen</author></item><item><title>Missile detection and destruction robot using detection algorithm</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2407.07452&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2407.07452&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Md Kamrul Siam&lt;/p&gt;   &lt;p&gt;This research is based on the present missile detection technologies in the world and the analysis of these technologies to find a cost effective solution to implement the system in Bangladesh. The paper will give an idea of the missile detection technologies using the electro-optical sensor and the pulse doppler radar. The system is made to detect the target missile. Automatic detection and destruction with the help of ultrasonic sonar, a metal detector sensor, and a smoke detector sensor. The system is mainly based on an ultrasonic sonar sensor. It has a transducer, a transmitter, and a receiver. Transducer is connected with the connected with controller. When it detects an object by following the algorithm, it finds its distance and angle. It can also assure whether the system can destroy the object or not by using another algorithm&#39;s simulation.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2407.07452</link><guid isPermaLink="false">https://papers.cool/arxiv/2407.07452</guid><pubDate>Wed, 10 Jul 2024 08:12:21 GMT</pubDate><author>Md Kamrul Siam</author></item><item><title>Small Aerial Target Detection for Airborne Infrared Detection Systems using LightGBM and Trajectory Constraints</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2407.01278&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2407.01278&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xiaoliang Sun&lt;/p&gt;   &lt;p&gt;Factors, such as rapid relative motion, clutter background, etc., make robust small aerial target detection for airborne infrared detection systems a challenge. Existing methods are facing difficulties when dealing with such cases. We consider that a continuous and smooth trajectory is critical in boosting small infrared aerial target detection performance. A simple and effective small aerial target detection method for airborne infrared detection system using light gradient boosting model (LightGBM) and trajectory constraints is proposed in this article. First, we simply formulate target candidate detection as a binary classification problem. Target candidates in every individual frame are detected via interesting pixel detection and a trained LightGBM model. Then, the local smoothness and global continuous characteristic of the target trajectory are modeled as short-strict and long-loose constraints. The trajectory constraints are used efficiently for detecting the true small infrared aerial targets from numerous target candidates. Experiments on public datasets demonstrate that the proposed method performs better than other existing methods. Furthermore, a public dataset for small aerial target detection in airborne infrared detection systems is constructed. To the best of our knowledge, this dataset has the largest data scale and richest scene types within this field.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2407.01278</link><guid isPermaLink="false">https://papers.cool/arxiv/2407.01278</guid><pubDate>Mon, 01 Jul 2024 13:33:40 GMT</pubDate><author>Xiaoliang Sun</author></item><item><title>Language-driven Grasp Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2406.09489&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2406.09489&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; An Dinh Vuong&lt;/p&gt;   &lt;p&gt;Grasp detection is a persistent and intricate challenge with various industrial applications. Recently, many methods and datasets have been proposed to tackle the grasp detection problem. However, most of them do not consider using natural language as a condition to detect the grasp poses. In this paper, we introduce Grasp-Anything++, a new language-driven grasp detection dataset featuring 1M samples, over 3M objects, and upwards of 10M grasping instructions. We utilize foundation models to create a large-scale scene corpus with corresponding images and grasp prompts. We approach the language-driven grasp detection task as a conditional generation problem. Drawing on the success of diffusion models in generative tasks and given that language plays a vital role in this task, we propose a new language-driven grasp detection method based on diffusion models. Our key contribution is the contrastive training objective, which explicitly contributes to the denoising process to detect the grasp pose given the language instructions. We illustrate that our approach is theoretically supportive. The intensive experiments show that our method outperforms state-of-the-art approaches and allows real-world robotic grasping. Finally, we demonstrate our large-scale dataset enables zero-short grasp detection and is a challenging benchmark for future work. Project website: https://airvlab.github.io/grasp-anything/&lt;/p&gt; </description><link>https://papers.cool/arxiv/2406.09489</link><guid isPermaLink="false">https://papers.cool/arxiv/2406.09489</guid><pubDate>Thu, 13 Jun 2024 16:06:59 GMT</pubDate><author>An Dinh Vuong</author></item><item><title>Detection-Rate-Emphasized Multi-objective Evolutionary Feature Selection for Network Intrusion Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2406.09180&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2406.09180&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zi-Hang Cheng&lt;/p&gt;   &lt;p&gt;Network intrusion detection is one of the most important issues in the field of cyber security, and various machine learning techniques have been applied to build intrusion detection systems. However, since the number of features to describe the network connections is often large, where some features are redundant or noisy, feature selection is necessary in such scenarios, which can both improve the efficiency and accuracy. Recently, some researchers focus on using multi-objective evolutionary algorithms (MOEAs) to select features. But usually, they only consider the number of features and classification accuracy as the objectives, resulting in unsatisfactory performance on a critical metric, detection rate. This will lead to the missing of many real attacks and bring huge losses to the network system. In this paper, we propose DR-MOFS to model the feature selection problem in network intrusion detection as a three-objective optimization problem, where the number of features, accuracy and detection rate are optimized simultaneously, and use MOEAs to solve it. Experiments on two popular network intrusion detection datasets NSL-KDD and UNSW-NB15 show that in most cases the proposed method can outperform previous methods, i.e., lead to fewer features, higher accuracy and detection rate.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2406.09180</link><guid isPermaLink="false">https://papers.cool/arxiv/2406.09180</guid><pubDate>Thu, 13 Jun 2024 14:42:17 GMT</pubDate><author>Zi-Hang Cheng</author></item><item><title>Tracking Small Birds by Detection Candidate Region Filtering and Detection History-aware Association</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2405.17323&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2405.17323&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tingwei Liu&lt;/p&gt;   &lt;p&gt;This paper focuses on tracking birds that appear small in a panoramic video. When the size of the tracked object is small in the image (small object tracking) and move quickly, object detection and association suffers. To address these problems, we propose Adaptive Slicing Aided Hyper Inference (Adaptive SAHI), which reduces the candidate regions to apply detection, and Detection History-aware Similarity Criterion (DHSC), which accurately associates objects in consecutive frames based on the detection history. Experiments on the NUBird2022 dataset verifies the effectiveness of the proposed method by showing improvements in both accuracy and speed.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2405.17323</link><guid isPermaLink="false">https://papers.cool/arxiv/2405.17323</guid><pubDate>Mon, 27 May 2024 16:22:38 GMT</pubDate><author>Tingwei Liu</author></item><item><title>Quantum Edge Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2405.11373&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2405.11373&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Santiago Llorens&lt;/p&gt;   &lt;p&gt;This paper introduces quantum edge detection, aimed at locating boundaries of quantum domains where all particles share the same pure state. Focusing on the 1D scenario of a string of particles, we develop an optimal protocol for quantum edge detection, efficiently computing its success probability through Schur-Weyl duality and semidefinite programming techniques. We analyze the behavior of the success probability as a function of the string length and local dimension, with emphasis in the limit of long strings. We present a protocol based on square root measurement, which proves asymptotically optimal. Additionally, we explore a mixed quantum change point detection scenario where the state of particles transitions from known to unknown, which may find practical applications in detecting malfunctions in quantum devices&lt;/p&gt; </description><link>https://papers.cool/arxiv/2405.11373</link><guid isPermaLink="false">https://papers.cool/arxiv/2405.11373</guid><pubDate>Sat, 18 May 2024 19:22:15 GMT</pubDate><author>Santiago Llorens</author></item><item><title>Roadside Monocular 3D Detection via 2D Detection Prompting</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2404.01064&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2404.01064&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yechi Ma&lt;/p&gt;   &lt;p&gt;The problem of roadside monocular 3D detection requires detecting objects of interested classes in a 2D RGB frame and predicting their 3D information such as locations in bird&#39;s-eye-view (BEV). It has broad applications in traffic control, vehicle-vehicle communication, and vehicle-infrastructure cooperative perception. To approach this problem, we present a novel and simple method by prompting the 3D detector using 2D detections. Our method builds on a key insight that, compared with 3D detectors, a 2D detector is much easier to train and performs significantly better w.r.t detections on the 2D image plane. That said, one can exploit 2D detections of a well-trained 2D detector as prompts to a 3D detector, being trained in a way of inflating such 2D detections to 3D towards 3D detection. To construct better prompts using the 2D detector, we explore three techniques: (a) concatenating both 2D and 3D detectors&#39; features, (b) attentively fusing 2D and 3D detectors&#39; features, and (c) encoding predicted 2D boxes x, y, width, height, label and attentively fusing such with the 3D detector&#39;s features. Surprisingly, the third performs the best. Moreover, we present a yaw tuning tactic and a class-grouping strategy that merges classes based on their functionality; these techniques improve 3D detection performance further. Comprehensive ablation studies and extensive experiments demonstrate that our method resoundingly outperforms prior works, achieving the state-of-the-art on two large-scale roadside 3D detection benchmarks.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2404.01064</link><guid isPermaLink="false">https://papers.cool/arxiv/2404.01064</guid><pubDate>Mon, 01 Apr 2024 11:57:34 GMT</pubDate><author>Yechi Ma</author></item><item><title>BAM: Box Abstraction Monitors for Real-time OoD Detection in Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2403.18373&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2403.18373&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Changshun Wu&lt;/p&gt;   &lt;p&gt;Out-of-distribution (OoD) detection techniques for deep neural networks (DNNs) become crucial thanks to their filtering of abnormal inputs, especially when DNNs are used in safety-critical applications and interact with an open and dynamic environment. Nevertheless, integrating OoD detection into state-of-the-art (SOTA) object detection DNNs poses significant challenges, partly due to the complexity introduced by the SOTA OoD construction methods, which require the modification of DNN architecture and the introduction of complex loss functions. This paper proposes a simple, yet surprisingly effective, method that requires neither retraining nor architectural change in object detection DNN, called Box Abstraction-based Monitors (BAM). The novelty of BAM stems from using a finite union of convex box abstractions to capture the learned features of objects for in-distribution (ID) data, and an important observation that features from OoD data are more likely to fall outside of these boxes. The union of convex regions within the feature space allows the formation of non-convex and interpretable decision boundaries, overcoming the limitations of VOS-like detectors without sacrificing real-time performance. Experiments integrating BAM into Faster R-CNN-based object detection DNNs demonstrate a considerably improved performance against SOTA OoD detection techniques.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2403.18373</link><guid isPermaLink="false">https://papers.cool/arxiv/2403.18373</guid><pubDate>Wed, 27 Mar 2024 09:10:01 GMT</pubDate><author>Changshun Wu</author></item><item><title>GPT-generated Text Detection: Benchmark Dataset and Tensor-based Detection Method</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2403.07321&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2403.07321&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zubair Qazi&lt;/p&gt;   &lt;p&gt;As natural language models like ChatGPT become increasingly prevalent in applications and services, the need for robust and accurate methods to detect their output is of paramount importance. In this paper, we present GPT Reddit Dataset (GRiD), a novel Generative Pretrained Transformer (GPT)-generated text detection dataset designed to assess the performance of detection models in identifying generated responses from ChatGPT. The dataset consists of a diverse collection of context-prompt pairs based on Reddit, with human-generated and ChatGPT-generated responses. We provide an analysis of the dataset&#39;s characteristics, including linguistic diversity, context complexity, and response quality. To showcase the dataset&#39;s utility, we benchmark several detection methods on it, demonstrating their efficacy in distinguishing between human and ChatGPT-generated responses. This dataset serves as a resource for evaluating and advancing detection techniques in the context of ChatGPT and contributes to the ongoing efforts to ensure responsible and trustworthy AI-driven communication on the internet. Finally, we propose GpTen, a novel tensor-based GPT text detection method that is semi-supervised in nature since it only has access to human-generated text and performs on par with fully-supervised baselines.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2403.07321</link><guid isPermaLink="false">https://papers.cool/arxiv/2403.07321</guid><pubDate>Tue, 12 Mar 2024 05:15:21 GMT</pubDate><author>Zubair Qazi</author></item><item><title>FriendNet: Detection-Friendly Dehazing Network</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2403.04443&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2403.04443&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yihua Fan&lt;/p&gt;   &lt;p&gt;Adverse weather conditions often impair the quality of captured images, inevitably inducing cutting-edge object detection models for advanced driver assistance systems (ADAS) and autonomous driving. In this paper, we raise an intriguing question: can the combination of image restoration and object detection enhance detection performance in adverse weather conditions? To answer it, we propose an effective architecture that bridges image dehazing and object detection together via guidance information and task-driven learning to achieve detection-friendly dehazing, termed FriendNet. FriendNet aims to deliver both high-quality perception and high detection capacity. Different from existing efforts that intuitively treat image dehazing as pre-processing, FriendNet establishes a positive correlation between these two tasks. Clean features generated by the dehazing network potentially contribute to improvements in object detection performance. Conversely, object detection crucially guides the learning process of the image dehazing network under the task-driven learning scheme. We shed light on how downstream tasks can guide upstream dehazing processes, considering both network architecture and learning objectives. We design Guidance Fusion Block (GFB) and Guidance Attention Block (GAB) to facilitate the integration of detection information into the network. Furthermore, the incorporation of the detection task loss aids in refining the optimization process. Additionally, we introduce a new Physics-aware Feature Enhancement Block (PFEB), which integrates physics-based priors to enhance the feature extraction and representation capabilities. Extensive experiments on synthetic and real-world datasets demonstrate the superiority of our method over state-of-the-art methods on both image quality and detection precision. Our source code is available at https://github.com/fanyihua0309/FriendNet.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2403.04443</link><guid isPermaLink="false">https://papers.cool/arxiv/2403.04443</guid><pubDate>Thu, 07 Mar 2024 12:19:04 GMT</pubDate><author>Yihua Fan</author></item><item><title>Order-detection, representation-detection, and applications to cable knots</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2402.15465&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2402.15465&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Adam Clay&lt;/p&gt;   &lt;p&gt;Given a $3$-manifold $M$ with multiple incompressible torus boundary components, we develop a general definition of order-detection of tuples of slopes on the boundary components of $M$. In parallel, we arrive at a general definition of representation-detection of tuples of slopes, and show that these two kinds of slope detection are equivalent -- in the sense that a tuple of slopes on the boundary of $M$ is order-detected if and only if it is representation-detected. We use these results, together with new &quot;relative gluing theorems,&quot; to show how the work of Eisenbud-Hirsch-Neumann, Jankins-Neumann and Naimi can be used to determine tuples of representation-detected slopes and, in turn, the behaviour of order-detected slopes on the boundary of a knot manifold with respect to cabling. Our cabling results improve upon work of the first author and Watson, and in particular, this new approach shows how one can use the equivalence between representation-detection and order-detection to derive orderability results that parallel known behaviour of L-spaces with respect to Dehn filling.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2402.15465</link><guid isPermaLink="false">https://papers.cool/arxiv/2402.15465</guid><pubDate>Fri, 23 Feb 2024 17:55:28 GMT</pubDate><author>Adam Clay</author></item><item><title>Optimal non-Gaussian operations in difference-intensity detection and parity detection-based Mach-Zehnder interferometer</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2312.10774&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2312.10774&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Manali Verma&lt;/p&gt;   &lt;p&gt;We investigate the benefits of probabilistic non-Gaussian operations in phase estimation using difference-intensity and parity detection-based Mach-Zehnder interferometers (MZI). We consider an experimentally implementable model to perform three different non-Gaussian operations, namely photon subtraction (PS), photon addition (PA), and photon catalysis (PC) on a single-mode squeezed vacuum (SSV) state. In difference-intensity detection-based MZI, two PC operation is found to be the most optimal, while for parity detection-based MZI, two PA operation emerges as the most optimal process. We have also provided the corresponding squeezing and transmissivity parameters at best performance, making our study relevant for experimentalists. Further, we have derived the general expression of moment-generating function, which shall be useful in exploring other detection schemes such as homodyne detection and quadratic homodyne detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2312.10774</link><guid isPermaLink="false">https://papers.cool/arxiv/2312.10774</guid><pubDate>Sun, 17 Dec 2023 17:52:14 GMT</pubDate><author>Manali Verma</author></item><item><title>Effects of detection-beam focal offset on displacement detection in optical tweezers</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2311.06088&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2311.06088&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Anni Chen&lt;/p&gt;   &lt;p&gt;A high-resolution displacement detection can be achieved by analyzing the scattered light of the trapping beams from the particle in optical tweezers. In some applications where trapping and displacement detection need to be separated, a detection beam can be introduced for independent displacement detection. However, the detection beam focus possibly deviates from the centre of the particle, which will affect the performance of the displacement detection. In this paper, we detect the radial displacement of the particle by utilizing the forward scattered light of the detection beam from the particle. The effects of the lateral and axial offsets between the detection beam focus and the particle centre on the displacement detection are analyzed by the simulation and experiment. The results show that the lateral offsets will decrease the detection sensitivity and linear range and aggravate the crosstalk between the x-direction signal and y-direction signal of QPD. The axial offsets also affect the detection sensitivity, an optimal axial offset can improve the sensitivity of the displacement detection substantially. In addition, the influence of system parameters, such as particle radius a, numerical aperture of the condenser NAc and numerical aperture of the objective NAo on the optimal axial offset are discussed. A combination of conventional optical tweezers instrument and a detection beam provides a more flexible working point, allowing for the active modulation of the sensitivity and linear range of the displacement detection. This work would be of great interest for improving the accuracy of the displacement and force detection performed by the optical tweezers.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2311.06088</link><guid isPermaLink="false">https://papers.cool/arxiv/2311.06088</guid><pubDate>Fri, 10 Nov 2023 14:41:04 GMT</pubDate><author>Anni Chen</author></item><item><title>Post-experiment coincidence detection techniques for direct detection of two-body correlations</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2308.16746&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2308.16746&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dezhong Cao&lt;/p&gt;   &lt;p&gt;It is one challenge to develop experimental techniques for direct detection of the many-body correlations of strongly correlated electrons, which exhibit a variety of unsolved mysteries. In this article, we present a post-experiment coincidence counting method and propose two post-experiment coincidence detection techniques, post-experiment coincidence angle-resolved photoemission spectroscopy (cARPES) and post-experiment coincidence inelastic neutron scattering (cINS). By coincidence detection of two photoelectric processes or two neutron-scattering processes, the post-experiment coincidence detection techniques can detect directly the two-body correlations of strongly correlated electrons in particle-particle channel or two-spin channel. The post-experiment coincidence detection techniques can be implemented upon the pulse-resolved angle-resolved photoemission spectroscopy (ARPES) or inelastic neutron scattering (INS) experimental apparatus with pulse photon or neutron source. When implemented experimentally, they will be powerful techniques to study the highly esoteric high-temperature superconductivity and the highly coveted quantum spin liquids.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2308.16746</link><guid isPermaLink="false">https://papers.cool/arxiv/2308.16746</guid><pubDate>Thu, 31 Aug 2023 14:06:23 GMT</pubDate><author>Dezhong Cao</author></item><item><title>Joint Microseismic Event Detection and Location with a Detection Transformer</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2307.09207&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2307.09207&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuanyuan Yang&lt;/p&gt;   &lt;p&gt;Microseismic event detection and location are two primary components in microseismic monitoring, which offers us invaluable insights into the subsurface during reservoir stimulation and evolution. Conventional approaches for event detection and location often suffer from manual intervention and/or heavy computation, while current machine learning-assisted approaches typically address detection and location separately; such limitations hinder the potential for real-time microseismic monitoring. We propose an approach to unify event detection and source location into a single framework by adapting a Convolutional Neural Network backbone and an encoder-decoder Transformer with a set-based Hungarian loss, which is applied directly to recorded waveforms. The proposed network is trained on synthetic data simulating multiple microseismic events corresponding to random source locations in the area of suspected microseismic activities. A synthetic test on a 2D profile of the SEAM Time Lapse model illustrates the capability of the proposed method in detecting the events properly and locating them in the subsurface accurately; while, a field test using the Arkoma Basin data further proves its practicability, efficiency, and its potential in paving the way for real-time monitoring of microseismic events.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2307.09207</link><guid isPermaLink="false">https://papers.cool/arxiv/2307.09207</guid><pubDate>Sun, 16 Jul 2023 10:56:46 GMT</pubDate><author>Yuanyuan Yang</author></item><item><title>Detection-Recovery and Detection-Refutation Gaps via Reductions from Planted Clique</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2306.17719&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2306.17719&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Guy Bresler&lt;/p&gt;   &lt;p&gt;Planted Dense Subgraph (PDS) problem is a prototypical problem with a computational-statistical gap. It also exhibits an intriguing additional phenomenon: different tasks, such as detection or recovery, appear to have different computational limits. A detection-recovery gap for PDS was substantiated in the form of a precise conjecture given by Chen and Xu (2014) (based on the parameter values for which a convexified MLE succeeds) and then shown to hold for low-degree polynomial algorithms by Schramm and Wein (2022) and for MCMC algorithms for Ben Arous et al. (2020). In this paper, we demonstrate that a slight variation of the Planted Clique Hypothesis with secret leakage (introduced in Brennan and Bresler (2020)), implies a detection-recovery gap for PDS. In the same vein, we also obtain a sharp lower bound for refutation, yielding a detection-refutation gap. Our methods build on the framework of Brennan and Bresler (2020) to construct average-case reductions mapping secret leakage Planted Clique to appropriate target problems.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2306.17719</link><guid isPermaLink="false">https://papers.cool/arxiv/2306.17719</guid><pubDate>Fri, 30 Jun 2023 15:02:47 GMT</pubDate><author>Guy Bresler</author></item><item><title>Taming Detection Transformers for Medical Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2306.15472&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2306.15472&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Marc K. Ickler&lt;/p&gt;   &lt;p&gt;The accurate detection of suspicious regions in medical images is an error-prone and time-consuming process required by many routinely performed diagnostic procedures. To support clinicians during this difficult task, several automated solutions were proposed relying on complex methods with many hyperparameters. In this study, we investigate the feasibility of DEtection TRansformer (DETR) models for volumetric medical object detection. In contrast to previous works, these models directly predict a set of objects without relying on the design of anchors or manual heuristics such as non-maximum-suppression to detect objects. We show by conducting extensive experiments with three models, namely DETR, Conditional DETR, and DINO DETR on four data sets (CADA, RibFrac, KiTS19, and LIDC) that these set prediction models can perform on par with or even better than currently existing methods. DINO DETR, the best-performing model in our experiments demonstrates this by outperforming a strong anchor-based one-stage detector, Retina U-Net, on three out of four data sets.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2306.15472</link><guid isPermaLink="false">https://papers.cool/arxiv/2306.15472</guid><pubDate>Tue, 27 Jun 2023 13:46:15 GMT</pubDate><author>Marc K. Ickler</author></item><item><title>WePaMaDM-Outlier Detection: Weighted Outlier Detection using Pattern Approaches for Mass Data Mining</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2306.06139&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2306.06139&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ravindrakumar Purohit&lt;/p&gt;   &lt;p&gt;Weighted Outlier Detection is a method for identifying unusual or anomalous data points in a dataset, which can be caused by various factors like human error, fraud, or equipment malfunctions. Detecting outliers can reveal vital information about system faults, fraudulent activities, and patterns in the data, assisting experts in addressing the root causes of these anomalies. However,creating a model of normal data patterns to identify outliers can be challenging due to the nature of input data, labeled data availability, and specific requirements of the problem. This article proposed the WePaMaDM-Outlier Detection with distinct mass data mining domain, demonstrating that such techniques are domain-dependent and usually developed for specific problem formulations. Nevertheless, similar domains can adapt solutions with modifications. This work also investigates the significance of data modeling in outlier detection techniques in surveillance, fault detection, and trend analysis, also referred to as novelty detection, a semisupervised task where the algorithm learns to recognize abnormality while being taught the normal class.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2306.06139</link><guid isPermaLink="false">https://papers.cool/arxiv/2306.06139</guid><pubDate>Fri, 09 Jun 2023 07:00:00 GMT</pubDate><author>Ravindrakumar Purohit</author></item><item><title>A Dual-level Detection Method for Video Copy Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2305.12361&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2305.12361&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tianyi Wang&lt;/p&gt;   &lt;p&gt;With the development of multimedia technology, Video Copy Detection has been a crucial problem for social media platforms. Meta AI hold Video Similarity Challenge on CVPR 2023 to push the technology forward. In this paper, we share our winner solutions on both tracks to help progress in this area. For Descriptor Track, we propose a dual-level detection method with Video Editing Detection (VED) and Frame Scenes Detection (FSD) to tackle the core challenges on Video Copy Detection. Experimental results demonstrate the effectiveness and efficiency of our proposed method. Code is available at https://github.com/FeipengMa6/VSC22-Submission.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2305.12361</link><guid isPermaLink="false">https://papers.cool/arxiv/2305.12361</guid><pubDate>Sun, 21 May 2023 06:19:08 GMT</pubDate><author>Tianyi Wang</author></item><item><title>A Comparative Study of Face Detection Algorithms for Masked Face Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2305.11077&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2305.11077&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sahel Mohammad Iqbal&lt;/p&gt;   &lt;p&gt;Contemporary face detection algorithms have to deal with many challenges such as variations in pose, illumination, and scale. A subclass of the face detection problem that has recently gained increasing attention is occluded face detection, or more specifically, the detection of masked faces. Three years on since the advent of the COVID-19 pandemic, there is still a complete lack of evidence regarding how well existing face detection algorithms perform on masked faces. This article first offers a brief review of state-of-the-art face detectors and detectors made for the masked face problem, along with a review of the existing masked face datasets. We evaluate and compare the performances of a well-representative set of face detectors at masked face detection and conclude with a discussion on the possible contributing factors to their performance.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2305.11077</link><guid isPermaLink="false">https://papers.cool/arxiv/2305.11077</guid><pubDate>Thu, 18 May 2023 16:03:37 GMT</pubDate><author>Sahel Mohammad Iqbal</author></item><item><title>Context-Aware Chart Element Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2305.04151&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2305.04151&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Pengyu Yan&lt;/p&gt;   &lt;p&gt;As a prerequisite of chart data extraction, the accurate detection of chart basic elements is essential and mandatory. In contrast to object detection in the general image domain, chart element detection relies heavily on context information as charts are highly structured data visualization formats. To address this, we propose a novel method CACHED, which stands for Context-Aware Chart Element Detection, by integrating a local-global context fusion module consisting of visual context enhancement and positional context encoding with the Cascade R-CNN framework. To improve the generalization of our method for broader applicability, we refine the existing chart element categorization and standardized 18 classes for chart basic elements, excluding plot elements. Our CACHED method, with the updated category of chart elements, achieves state-of-the-art performance in our experiments, underscoring the importance of context in chart element detection. Extending our method to the bar plot detection task, we obtain the best result on the PMC test dataset.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2305.04151</link><guid isPermaLink="false">https://papers.cool/arxiv/2305.04151</guid><pubDate>Sun, 07 May 2023 00:08:39 GMT</pubDate><author>Pengyu Yan</author></item><item><title>AGAD: Adversarial Generative Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2304.04211&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2304.04211&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jian Shi&lt;/p&gt;   &lt;p&gt;Anomaly detection suffered from the lack of anomalies due to the diversity of abnormalities and the difficulties of obtaining large-scale anomaly data. Semi-supervised anomaly detection methods are often used to solely leverage normal data to detect abnormalities that deviated from the learnt normality distributions. Meanwhile, given the fact that limited anomaly data can be obtained with a minor cost in practice, some researches also investigated anomaly detection methods under supervised scenarios with limited anomaly data. In order to address the lack of abnormal data for robust anomaly detection, we propose Adversarial Generative Anomaly Detection (AGAD), a self-contrast-based anomaly detection paradigm that learns to detect anomalies by generating \textit{contextual adversarial information} from the massive normal examples. Essentially, our method generates pseudo-anomaly data for both supervised and semi-supervised anomaly detection scenarios. Extensive experiments are carried out on multiple benchmark datasets and real-world datasets, the results show significant improvement in both supervised and semi-supervised scenarios. Importantly, our approach is data-efficient that can boost up the detection accuracy with no more than 5% anomalous training data.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2304.04211</link><guid isPermaLink="false">https://papers.cool/arxiv/2304.04211</guid><pubDate>Sun, 09 Apr 2023 10:40:02 GMT</pubDate><author>Jian Shi</author></item><item><title>Entanglement detection with trace polynomials</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2303.07761&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2303.07761&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Albert Rico&lt;/p&gt;   &lt;p&gt;We provide a systematic method for nonlinear entanglement detection based on trace polynomial inequalities. In particular, this allows to employ multi-partite witnesses for the detection of bipartite states, and vice versa. We identify witnesses for which linear detection of an entangled state fails, but for which nonlinear detection succeeds. With the trace polynomial formulation a great variety of witnesses arise from immamant inequalities, which can be implemented in the laboratory through randomized measurements.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2303.07761</link><guid isPermaLink="false">https://papers.cool/arxiv/2303.07761</guid><pubDate>Tue, 14 Mar 2023 10:06:34 GMT</pubDate><author>Albert Rico</author></item><item><title>Achieving Counterfactual Fairness for Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2303.02318&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2303.02318&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xiao Han&lt;/p&gt;   &lt;p&gt;Ensuring fairness in anomaly detection models has received much attention recently as many anomaly detection applications involve human beings. However, existing fair anomaly detection approaches mainly focus on association-based fairness notions. In this work, we target counterfactual fairness, which is a prevalent causation-based fairness notion. The goal of counterfactually fair anomaly detection is to ensure that the detection outcome of an individual in the factual world is the same as that in the counterfactual world where the individual had belonged to a different group. To this end, we propose a counterfactually fair anomaly detection (CFAD) framework which consists of two phases, counterfactual data generation and fair anomaly detection. Experimental results on a synthetic dataset and two real datasets show that CFAD can effectively detect anomalies as well as ensure counterfactual fairness.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2303.02318</link><guid isPermaLink="false">https://papers.cool/arxiv/2303.02318</guid><pubDate>Sat, 04 Mar 2023 04:45:12 GMT</pubDate><author>Xiao Han</author></item><item><title>Robust Detection Outcome: A Metric for Pathology Detection in Medical Images</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2303.01920&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2303.01920&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Felix Meissen&lt;/p&gt;   &lt;p&gt;Detection of pathologies is a fundamental task in medical imaging and the evaluation of algorithms that can perform this task automatically is crucial. However, current object detection metrics for natural images do not reflect the specific clinical requirements in pathology detection sufficiently. To tackle this problem, we propose Robust Detection Outcome (RoDeO); a novel metric for evaluating algorithms for pathology detection in medical images, especially in chest X-rays. RoDeO evaluates different errors directly and individually, and reflects clinical needs better than current metrics. Extensive evaluation on the ChestX-ray8 dataset shows the superiority of our metrics compared to existing ones. We released the code at https://github.com/FeliMe/RoDeO and published RoDeO as pip package (rodeometric).&lt;/p&gt; </description><link>https://papers.cool/arxiv/2303.01920</link><guid isPermaLink="false">https://papers.cool/arxiv/2303.01920</guid><pubDate>Fri, 03 Mar 2023 13:45:13 GMT</pubDate><author>Felix Meissen</author></item><item><title>Benchmarking Deepart Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2302.14475&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2302.14475&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yabin Wang&lt;/p&gt;   &lt;p&gt;Deepfake technologies have been blurring the boundaries between the real and unreal, likely resulting in malicious events. By leveraging newly emerged deepfake technologies, deepfake researchers have been making a great upending to create deepfake artworks (deeparts), which are further closing the gap between reality and fantasy. To address potentially appeared ethics questions, this paper establishes a deepart detection database (DDDB) that consists of a set of high-quality conventional art images (conarts) and five sets of deepart images generated by five state-of-the-art deepfake models. This database enables us to explore once-for-all deepart detection and continual deepart detection. For the two new problems, we suggest four benchmark evaluations and four families of solutions on the constructed DDDB. The comprehensive study demonstrates the effectiveness of the proposed solutions on the established benchmark dataset, which is capable of paving a way to more interesting directions of deepart detection. The constructed benchmark dataset and the source code will be made publicly available.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2302.14475</link><guid isPermaLink="false">https://papers.cool/arxiv/2302.14475</guid><pubDate>Tue, 28 Feb 2023 10:34:44 GMT</pubDate><author>Yabin Wang</author></item><item><title>Towards Accurate Acne Detection via Decoupled Sequential Detection Head</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2301.12219&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2301.12219&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xin Wei&lt;/p&gt;   &lt;p&gt;Accurate acne detection plays a crucial role in acquiring precise diagnosis and conducting proper therapy. However, the ambiguous boundaries and arbitrary dimensions of acne lesions severely limit the performance of existing methods. In this paper, we address these challenges via a novel Decoupled Sequential Detection Head (DSDH), which can be easily adopted by mainstream two-stage detectors. DSDH brings two simple but effective improvements to acne detection. Firstly, the offset and scaling tasks are explicitly introduced, and their incompatibility is settled by our task-decouple mechanism, which improves the capability of predicting the location and size of acne lesions. Second, we propose the task-sequence mechanism, and execute offset and scaling sequentially to gain a more comprehensive insight into the dimensions of acne lesions. In addition, we build a high-quality acne detection dataset named ACNE-DET to verify the effectiveness of DSDH. Experiments on ACNE-DET and the public benchmark ACNE04 show that our method outperforms the state-of-the-art methods by significant margins. Our code and dataset are publicly available at (temporarily anonymous).&lt;/p&gt; </description><link>https://papers.cool/arxiv/2301.12219</link><guid isPermaLink="false">https://papers.cool/arxiv/2301.12219</guid><pubDate>Sat, 28 Jan 2023 14:58:51 GMT</pubDate><author>Xin Wei</author></item><item><title>Multi Lane Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2212.11533&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2212.11533&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Fei Wu&lt;/p&gt;   &lt;p&gt;Lane detection is a long-standing task and a basic module in autonomous driving. The task is to detect the lane of the current driving road, and provide relevant information such as the ID, direction, curvature, width, length, with visualization. Our work is based on CNN backbone DLA-34, along with Affinity Fields, aims to achieve robust detection of various lanes without assuming the number of lanes. Besides, we investigate novel decoding methods to achieve more efficient lane detection algorithm.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2212.11533</link><guid isPermaLink="false">https://papers.cool/arxiv/2212.11533</guid><pubDate>Thu, 22 Dec 2022 08:20:08 GMT</pubDate><author>Fei Wu</author></item><item><title>YolOOD: Utilizing Object Detection Concepts for Multi-Label Out-of-Distribution Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2212.02081&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2212.02081&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alon Zolfi&lt;/p&gt;   &lt;p&gt;Out-of-distribution (OOD) detection has attracted a large amount of attention from the machine learning research community in recent years due to its importance in deployed systems. Most of the previous studies focused on the detection of OOD samples in the multi-class classification task. However, OOD detection in the multi-label classification task, a more common real-world use case, remains an underexplored domain. In this research, we propose YolOOD - a method that utilizes concepts from the object detection domain to perform OOD detection in the multi-label classification task. Object detection models have an inherent ability to distinguish between objects of interest (in-distribution) and irrelevant objects (e.g., OOD objects) in images that contain multiple objects belonging to different class categories. These abilities allow us to convert a regular object detection model into an image classifier with inherent OOD detection capabilities with just minor changes. We compare our approach to state-of-the-art OOD detection methods and demonstrate YolOOD&#39;s ability to outperform these methods on a comprehensive suite of in-distribution and OOD benchmark datasets.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2212.02081</link><guid isPermaLink="false">https://papers.cool/arxiv/2212.02081</guid><pubDate>Mon, 05 Dec 2022 07:52:08 GMT</pubDate><author>Alon Zolfi</author></item><item><title>A Hybrid Deep Learning Anomaly Detection Framework for Intrusion Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2212.00966&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2212.00966&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rahul Kale&lt;/p&gt;   &lt;p&gt;Cyber intrusion attacks that compromise the users&#39; critical and sensitive data are escalating in volume and intensity, especially with the growing connections between our daily life and the Internet. The large volume and high complexity of such intrusion attacks have impeded the effectiveness of most traditional defence techniques. While at the same time, the remarkable performance of the machine learning methods, especially deep learning, in computer vision, had garnered research interests from the cyber security community to further enhance and automate intrusion detections. However, the expensive data labeling and limitation of anomalous data make it challenging to train an intrusion detector in a fully supervised manner. Therefore, intrusion detection based on unsupervised anomaly detection is an important feature too. In this paper, we propose a three-stage deep learning anomaly detection based network intrusion attack detection framework. The framework comprises an integration of unsupervised (K-means clustering), semi-supervised (GANomaly) and supervised learning (CNN) algorithms. We then evaluated and showed the performance of our implemented framework on three benchmark datasets: NSL-KDD, CIC-IDS2018, and TON_IoT.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2212.00966</link><guid isPermaLink="false">https://papers.cool/arxiv/2212.00966</guid><pubDate>Fri, 02 Dec 2022 04:40:54 GMT</pubDate><author>Rahul Kale</author></item><item><title>Is Out-of-Distribution Detection Learnable?</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2210.14707&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2210.14707&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhen Fang&lt;/p&gt;   &lt;p&gt;Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms. To study the generalization of OOD detection, in this paper, we investigate the probably approximately correct (PAC) learning theory of OOD detection, which is proposed by researchers as an open problem. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we also offer theoretical supports for several representative OOD detection works based on our OOD theory.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2210.14707</link><guid isPermaLink="false">https://papers.cool/arxiv/2210.14707</guid><pubDate>Wed, 26 Oct 2022 13:35:19 GMT</pubDate><author>Zhen Fang</author></item><item><title>Stance Detection and Open Research Avenues</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2210.12383&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2210.12383&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dilek Küçük&lt;/p&gt;   &lt;p&gt;This tutorial aims to cover the state-of-the-art on stance detection and address open research avenues for interested researchers and practitioners. Stance detection is a recent research topic where the stance towards a given target or target set is determined based on the given content and there are significant application opportunities of stance detection in various domains. The tutorial comprises two parts where the first part outlines the fundamental concepts, problems, approaches, and resources of stance detection, while the second part covers open research avenues and application areas of stance detection. The tutorial will be a useful guide for researchers and practitioners of stance detection, social media analysis, information retrieval, and natural language processing.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2210.12383</link><guid isPermaLink="false">https://papers.cool/arxiv/2210.12383</guid><pubDate>Sat, 22 Oct 2022 08:18:09 GMT</pubDate><author>Dilek Küçük</author></item><item><title>Anomaly Detection Requires Better Representations</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2210.10773&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2210.10773&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tal Reiss&lt;/p&gt;   &lt;p&gt;Anomaly detection seeks to identify unusual phenomena, a central task in science and industry. The task is inherently unsupervised as anomalies are unexpected and unknown during training. Recent advances in self-supervised representation learning have directly driven improvements in anomaly detection. In this position paper, we first explain how self-supervised representations can be easily used to achieve state-of-the-art performance in commonly reported anomaly detection benchmarks. We then argue that tackling the next generation of anomaly detection tasks requires new technical and conceptual improvements in representation learning.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2210.10773</link><guid isPermaLink="false">https://papers.cool/arxiv/2210.10773</guid><pubDate>Wed, 19 Oct 2022 17:59:32 GMT</pubDate><author>Tal Reiss</author></item><item><title>A Survey on Explainable Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2210.06959&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2210.06959&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhong Li&lt;/p&gt;   &lt;p&gt;In the past two decades, most research on anomaly detection has focused on improving the accuracy of the detection, while largely ignoring the explainability of the corresponding methods and thus leaving the explanation of outcomes to practitioners. As anomaly detection algorithms are increasingly used in safety-critical domains, providing explanations for the high-stakes decisions made in those domains has become an ethical and regulatory requirement. Therefore, this work provides a comprehensive and structured survey on state-of-the-art explainable anomaly detection techniques. We propose a taxonomy based on the main aspects that characterize each explainable anomaly detection technique, aiming to help practitioners and researchers find the explainable anomaly detection method that best suits their needs.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2210.06959</link><guid isPermaLink="false">https://papers.cool/arxiv/2210.06959</guid><pubDate>Thu, 13 Oct 2022 12:37:22 GMT</pubDate><author>Zhong Li</author></item><item><title>Rethinking the Detection Head Configuration for Traffic Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2210.03883&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2210.03883&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yi Shi&lt;/p&gt;   &lt;p&gt;Multi-scale detection plays an important role in object detection models. However, researchers usually feel blank on how to reasonably configure detection heads combining multi-scale features at different input resolutions. We find that there are different matching relationships between the object distribution and the detection head at different input resolutions. Based on the instructive findings, we propose a lightweight traffic object detection network based on matching between detection head and object distribution, termed as MHD-Net. It consists of three main parts. The first is the detection head and object distribution matching strategy, which guides the rational configuration of detection head, so as to leverage multi-scale features to effectively detect objects at vastly different scales. The second is the cross-scale detection head configuration guideline, which instructs to replace multiple detection heads with only two detection heads possessing of rich feature representations to achieve an excellent balance between detection accuracy, model parameters, FLOPs and detection speed. The third is the receptive field enlargement method, which combines the dilated convolution module with shallow features of backbone to further improve the detection accuracy at the cost of increasing model parameters very slightly. The proposed model achieves more competitive performance than other models on BDD100K dataset and our proposed ETFOD-v2 dataset. The code will be available.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2210.03883</link><guid isPermaLink="false">https://papers.cool/arxiv/2210.03883</guid><pubDate>Sat, 08 Oct 2022 02:23:57 GMT</pubDate><author>Yi Shi</author></item><item><title>Out-of-Distribution Detection for LiDAR-based 3D Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2209.14435&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2209.14435&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chengjie Huang&lt;/p&gt;   &lt;p&gt;3D object detection is an essential part of automated driving, and deep neural networks (DNNs) have achieved state-of-the-art performance for this task. However, deep models are notorious for assigning high confidence scores to out-of-distribution (OOD) inputs, that is, inputs that are not drawn from the training distribution. Detecting OOD inputs is challenging and essential for the safe deployment of models. OOD detection has been studied extensively for the classification task, but it has not received enough attention for the object detection task, specifically LiDAR-based 3D object detection. In this paper, we focus on the detection of OOD inputs for LiDAR-based 3D object detection. We formulate what OOD inputs mean for object detection and propose to adapt several OOD detection methods for object detection. We accomplish this by our proposed feature extraction method. To evaluate OOD detection methods, we develop a simple but effective technique of generating OOD objects for a given object detection model. Our evaluation based on the KITTI dataset shows that different OOD detection methods have biases toward detecting specific OOD objects. It emphasizes the importance of combined OOD detection methods and more research in this direction.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2209.14435</link><guid isPermaLink="false">https://papers.cool/arxiv/2209.14435</guid><pubDate>Wed, 28 Sep 2022 21:39:25 GMT</pubDate><author>Chengjie Huang</author></item><item><title>Collaborative Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2209.09923&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2209.09923&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ke Bai&lt;/p&gt;   &lt;p&gt;In recommendation systems, items are likely to be exposed to various users and we would like to learn about the familiarity of a new user with an existing item. This can be formulated as an anomaly detection (AD) problem distinguishing between &quot;common users&quot; (nominal) and &quot;fresh users&quot; (anomalous). Considering the sheer volume of items and the sparsity of user-item paired data, independently applying conventional single-task detection methods on each item quickly becomes difficult, while correlations between items are ignored. To address this multi-task anomaly detection problem, we propose collaborative anomaly detection (CAD) to jointly learn all tasks with an embedding encoding correlations among tasks. We explore CAD with conditional density estimation and conditional likelihood ratio estimation. We found that: $i$) estimating a likelihood ratio enjoys more efficient learning and yields better results than density estimation. $ii$) It is beneficial to select a small number of tasks in advance to learn a task embedding model, and then use it to warm-start all task embeddings. Consequently, these embeddings can capture correlations between tasks and generalize to new correlated tasks.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2209.09923</link><guid isPermaLink="false">https://papers.cool/arxiv/2209.09923</guid><pubDate>Tue, 20 Sep 2022 18:01:07 GMT</pubDate><author>Ke Bai</author></item><item><title>From Disfluency Detection to Intent Detection and Slot Filling</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2209.08359&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2209.08359&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mai Hoang Dao&lt;/p&gt;   &lt;p&gt;We present the first empirical study investigating the influence of disfluency detection on downstream tasks of intent detection and slot filling. We perform this study for Vietnamese -- a low-resource language that has no previous study as well as no public dataset available for disfluency detection. First, we extend the fluent Vietnamese intent detection and slot filling dataset PhoATIS by manually adding contextual disfluencies and annotating them. Then, we conduct experiments using strong baselines for disfluency detection and joint intent detection and slot filling, which are based on pre-trained language models. We find that: (i) disfluencies produce negative effects on the performances of the downstream intent detection and slot filling tasks, and (ii) in the disfluency context, the pre-trained multilingual language model XLM-R helps produce better intent detection and slot filling performances than the pre-trained monolingual language model PhoBERT, and this is opposite to what generally found in the fluency context.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2209.08359</link><guid isPermaLink="false">https://papers.cool/arxiv/2209.08359</guid><pubDate>Sat, 17 Sep 2022 16:03:57 GMT</pubDate><author>Mai Hoang Dao</author></item><item><title>Adversarial Detection: Attacking Object Detection in Real Time</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2209.01962&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2209.01962&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Han Wu&lt;/p&gt;   &lt;p&gt;Intelligent robots rely on object detection models to perceive the environment. Following advances in deep learning security it has been revealed that object detection models are vulnerable to adversarial attacks. However, prior research primarily focuses on attacking static images or offline videos. Therefore, it is still unclear if such attacks could jeopardize real-world robotic applications in dynamic environments. This paper bridges this gap by presenting the first real-time online attack against object detection models. We devise three attacks that fabricate bounding boxes for nonexistent objects at desired locations. The attacks achieve a success rate of about 90% within about 20 iterations. The demo video is available at https://youtu.be/zJZ1aNlXsMU.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2209.01962</link><guid isPermaLink="false">https://papers.cool/arxiv/2209.01962</guid><pubDate>Mon, 05 Sep 2022 13:32:41 GMT</pubDate><author>Han Wu</author></item><item><title>Radio Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2209.00590&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2209.00590&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; A. Connolly&lt;/p&gt;   &lt;p&gt;Detection techniques at radio wavelengths play an important role in the future of astrophysics experiments. The radio detection of cosmic rays, neutrinos, and photons has emerged as the technology of choice at the highest energies. Cosmological surveys require the detection of radiation at mm wavelengths at thresholds down to the fundamental noise limit. High energy astroparticle and neutrino detectors use large volumes of a naturally occurring suitable dielectric: the Earth&#39;s atmosphere and large volumes of cold ice as available in polar regions. The detection technology for radio detection of cosmic particles has matured in the past decade and is ready to move beyond prototyping or midscale applications. Instrumentation for radio detection has reached a maturity for science scale detectors. Radio detection provides competitive results in terms of the measurement of energy and direction and in particle identification when to compared to currently applied technologies for high-energy neutrinos when deployed in ice and for ultra-high-energy cosmic rays, neutrinos, and photons when deployed in the atmosphere. It has significant advantages in terms of cost per detection station and ease of deployment.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2209.00590</link><guid isPermaLink="false">https://papers.cool/arxiv/2209.00590</guid><pubDate>Thu, 01 Sep 2022 17:04:05 GMT</pubDate><author>A. Connolly</author></item><item><title>Verifiable Obstacle Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2208.14403&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2208.14403&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ayoosh Bansal&lt;/p&gt;   &lt;p&gt;Perception of obstacles remains a critical safety concern for autonomous vehicles. Real-world collisions have shown that the autonomy faults leading to fatal collisions originate from obstacle existence detection. Open source autonomous driving implementations show a perception pipeline with complex interdependent Deep Neural Networks. These networks are not fully verifiable, making them unsuitable for safety-critical tasks. In this work, we present a safety verification of an existing LiDAR based classical obstacle detection algorithm. We establish strict bounds on the capabilities of this obstacle detection algorithm. Given safety standards, such bounds allow for determining LiDAR sensor properties that would reliably satisfy the standards. Such analysis has as yet been unattainable for neural network based perception systems. We provide a rigorous analysis of the obstacle detection system with empirical results based on real-world sensor data.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2208.14403</link><guid isPermaLink="false">https://papers.cool/arxiv/2208.14403</guid><pubDate>Tue, 30 Aug 2022 17:15:35 GMT</pubDate><author>Ayoosh Bansal</author></item><item><title>Scaling Novel Object Detection with Weakly Supervised Detection Transformers</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2207.05205&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2207.05205&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tyler LaBonte&lt;/p&gt;   &lt;p&gt;A critical object detection task is finetuning an existing model to detect novel objects, but the standard workflow requires bounding box annotations which are time-consuming and expensive to collect. Weakly supervised object detection (WSOD) offers an appealing alternative, where object detectors can be trained using image-level labels. However, the practical application of current WSOD models is limited, as they only operate at small data scales and require multiple rounds of training and refinement. To address this, we propose the Weakly Supervised Detection Transformer, which enables efficient knowledge transfer from a large-scale pretraining dataset to WSOD finetuning on hundreds of novel objects. Additionally, we leverage pretrained knowledge to improve the multiple instance learning (MIL) framework often used in WSOD methods. Our experiments show that our approach outperforms previous state-of-the-art models on large-scale novel object detection datasets, and our scaling study reveals that class quantity is more important than image quantity for WSOD pretraining. The code is available at https://github.com/tmlabonte/weakly-supervised-DETR.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2207.05205</link><guid isPermaLink="false">https://papers.cool/arxiv/2207.05205</guid><pubDate>Mon, 11 Jul 2022 21:45:54 GMT</pubDate><author>Tyler LaBonte</author></item><item><title>Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2206.03484&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2206.03484&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Lingchen Meng&lt;/p&gt;   &lt;p&gt;Combining multiple datasets enables performance boost on many computer vision tasks. But similar trend has not been witnessed in object detection when combining multiple datasets due to two inconsistencies among detection datasets: taxonomy difference and domain gap. In this paper, we address these challenges by a new design (named Detection Hub) that is dataset-aware and category-aligned. It not only mitigates the dataset inconsistency but also provides coherent guidance for the detector to learn across multiple datasets. In particular, the dataset-aware design is achieved by learning a dataset embedding that is used to adapt object queries as well as convolutional kernels in detection heads. The categories across datasets are semantically aligned into a unified space by replacing one-hot category representations with word embedding and leveraging the semantic coherence of language embedding. Detection Hub fulfills the benefits of large data on object detection. Experiments demonstrate that joint training on multiple datasets achieves significant performance gains over training on each dataset alone. Detection Hub further achieves SoTA performance on UODB benchmark with wide variety of datasets.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2206.03484</link><guid isPermaLink="false">https://papers.cool/arxiv/2206.03484</guid><pubDate>Tue, 07 Jun 2022 17:59:44 GMT</pubDate><author>Lingchen Meng</author></item><item><title>Detection of Fights in Videos: A Comparison Study of Anomaly Detection and Action Recognition</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2205.11394&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2205.11394&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Weijun Tan&lt;/p&gt;   &lt;p&gt;Detection of fights is an important surveillance application in videos. Most existing methods use supervised binary action recognition. Since frame-level annotations are very hard to get for anomaly detection, weakly supervised learning using multiple instance learning is widely used. This paper explores the detection of fights in videos as one special type of anomaly detection and as binary action recognition. We use the UBI-Fight and NTU-CCTV-Fight datasets for most of the study since they have frame-level annotations. We find that the anomaly detection has similar or even better performance than the action recognition. Furthermore, we study to use anomaly detection as a toolbox to generate training datasets for action recognition in an iterative way conditioned on the performance of the anomaly detection. Experiment results should show that we achieve state-of-the-art performance on three fight detection datasets.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2205.11394</link><guid isPermaLink="false">https://papers.cool/arxiv/2205.11394</guid><pubDate>Mon, 23 May 2022 15:41:02 GMT</pubDate><author>Weijun Tan</author></item><item><title>Improved Orientation Estimation and Detection with Hybrid Object Detection Networks for Automotive Radar</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2205.02111&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2205.02111&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Michael Ulrich&lt;/p&gt;   &lt;p&gt;This paper presents novel hybrid architectures that combine grid- and point-based processing to improve the detection performance and orientation estimation of radar-based object detection networks. Purely grid-based detection models operate on a bird&#39;s-eye-view (BEV) projection of the input point cloud. These approaches suffer from a loss of detailed information through the discrete grid resolution. This applies in particular to radar object detection, where relatively coarse grid resolutions are commonly used to account for the sparsity of radar point clouds. In contrast, point-based models are not affected by this problem as they process point clouds without discretization. However, they generally exhibit worse detection performances than grid-based methods. We show that a point-based model can extract neighborhood features, leveraging the exact relative positions of points, before grid rendering. This has significant benefits for a subsequent grid-based convolutional detection backbone. In experiments on the public nuScenes dataset our hybrid architecture achieves improvements in terms of detection performance (19.7% higher mAP for car class than next-best radar-only submission) and orientation estimates (11.5% relative orientation improvement) over networks from previous literature.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2205.02111</link><guid isPermaLink="false">https://papers.cool/arxiv/2205.02111</guid><pubDate>Tue, 03 May 2022 06:29:03 GMT</pubDate><author>Michael Ulrich</author></item><item><title>Anomalous Sound Detection Based on Machine Activity Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2204.07353&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2204.07353&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tomoya Nishida&lt;/p&gt;   &lt;p&gt;We have developed an unsupervised anomalous sound detection method for machine condition monitoring that utilizes an auxiliary task -- detecting when the target machine is active. First, we train a model that detects machine activity by using normal data with machine activity labels and then use the activity-detection error as the anomaly score for a given sound clip if we have access to the ground-truth activity labels in the inference phase. If these labels are not available, the anomaly score is calculated through outlier detection on the embedding vectors obtained by the activity-detection model. Solving this auxiliary task enables the model to learn the difference between the target machine sounds and similar background noise, which makes it possible to identify small deviations in the target sounds. Experimental results showed that the proposed method improves the anomaly-detection performance of the conventional method complementarily by means of an ensemble.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2204.07353</link><guid isPermaLink="false">https://papers.cool/arxiv/2204.07353</guid><pubDate>Fri, 15 Apr 2022 07:23:32 GMT</pubDate><author>Tomoya Nishida</author></item><item><title>Proactive Image Manipulation Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2203.15880&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2203.15880&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Vishal Asnani&lt;/p&gt;   &lt;p&gt;Image manipulation detection algorithms are often trained to discriminate between images manipulated with particular Generative Models (GMs) and genuine/real images, yet generalize poorly to images manipulated with GMs unseen in the training. Conventional detection algorithms receive an input image passively. By contrast, we propose a proactive scheme to image manipulation detection. Our key enabling technique is to estimate a set of templates which when added onto the real image would lead to more accurate manipulation detection. That is, a template protected real image, and its manipulated version, is better discriminated compared to the original real image vs. its manipulated one. These templates are estimated using certain constraints based on the desired properties of templates. For image manipulation detection, our proposed approach outperforms the prior work by an average precision of 16% for CycleGAN and 32% for GauGAN. Our approach is generalizable to a variety of GMs showing an improvement over prior work by an average precision of 10% averaged across 12 GMs. Our code is available at https://www.github.com/vishal3477/proactive_IMD.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2203.15880</link><guid isPermaLink="false">https://papers.cool/arxiv/2203.15880</guid><pubDate>Tue, 29 Mar 2022 20:02:04 GMT</pubDate><author>Vishal Asnani</author></item><item><title>F2DNet: Fast Focal Detection Network for Pedestrian Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2203.02331&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2203.02331&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Abdul Hannan Khan&lt;/p&gt;   &lt;p&gt;Two-stage detectors are state-of-the-art in object detection as well as pedestrian detection. However, the current two-stage detectors are inefficient as they do bounding box regression in multiple steps i.e. in region proposal networks and bounding box heads. Also, the anchor-based region proposal networks are computationally expensive to train. We propose F2DNet, a novel two-stage detection architecture which eliminates redundancy of current two-stage detectors by replacing the region proposal network with our focal detection network and bounding box head with our fast suppression head. We benchmark F2DNet on top pedestrian detection datasets, thoroughly compare it against the existing state-of-the-art detectors and conduct cross dataset evaluation to test the generalizability of our model to unseen data. Our F2DNet achieves 8.7\%, 2.2\%, and 6.1\% MR-2 on City Persons, Caltech Pedestrian, and Euro City Person datasets respectively when trained on a single dataset and reaches 20.4\% and 26.2\% MR-2 in heavy occlusion setting of Caltech Pedestrian and City Persons datasets when using progressive fine-tunning. Furthermore, F2DNet have significantly lesser inference time compared to the current state-of-the-art. Code and trained models will be available at https://github.com/AbdulHannanKhan/F2DNet.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2203.02331</link><guid isPermaLink="false">https://papers.cool/arxiv/2203.02331</guid><pubDate>Fri, 04 Mar 2022 14:13:38 GMT</pubDate><author>Abdul Hannan Khan</author></item><item><title>Trustworthy Anomaly Detection: A Survey</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2202.07787&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2202.07787&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shuhan Yuan&lt;/p&gt;   &lt;p&gt;Anomaly detection has a wide range of real-world applications, such as bank fraud detection and cyber intrusion detection. In the past decade, a variety of anomaly detection models have been developed, which lead to big progress towards accurately detecting various anomalies. Despite the successes, anomaly detection models still face many limitations. The most significant one is whether we can trust the detection results from the models. In recent years, the research community has spent a great effort to design trustworthy machine learning models, such as developing trustworthy classification models. However, the attention to anomaly detection tasks is far from sufficient. Considering that many anomaly detection tasks are life-changing tasks involving human beings, labeling someone as anomalies or fraudsters should be extremely cautious. Hence, ensuring the anomaly detection models conducted in a trustworthy fashion is an essential requirement to deploy the models to conduct automatic decisions in the real world. In this brief survey, we summarize the existing efforts and discuss open problems towards trustworthy anomaly detection from the perspectives of interpretability, fairness, robustness, and privacy-preservation.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2202.07787</link><guid isPermaLink="false">https://papers.cool/arxiv/2202.07787</guid><pubDate>Tue, 15 Feb 2022 23:25:37 GMT</pubDate><author>Shuhan Yuan</author></item><item><title>Adversarial Detection without Model Information</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2202.04271&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2202.04271&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Abhishek Moitra&lt;/p&gt;   &lt;p&gt;Prior state-of-the-art adversarial detection works are classifier model dependent, i.e., they require classifier model outputs and parameters for training the detector or during adversarial detection. This makes their detection approach classifier model specific. Furthermore, classifier model outputs and parameters might not always be accessible. To this end, we propose a classifier model independent adversarial detection method using a simple energy function to distinguish between adversarial and natural inputs. We train a standalone detector independent of the classifier model, with a layer-wise energy separation (LES) training to increase the separation between natural and adversarial energies. With this, we perform energy distribution-based adversarial detection. Our method achieves comparable performance with state-of-the-art detection works (ROC-AUC &amp;gt; 0.9) across a wide range of gradient, score and gaussian noise attacks on CIFAR10, CIFAR100 and TinyImagenet datasets. Furthermore, compared to prior works, our detection approach is light-weight, requires less amount of training data (40% of the actual dataset) and is transferable across different datasets. For reproducibility, we provide layer-wise energy separation training code at https://github.com/Intelligent-Computing-Lab-Yale/Energy-Separation-Training&lt;/p&gt; </description><link>https://papers.cool/arxiv/2202.04271</link><guid isPermaLink="false">https://papers.cool/arxiv/2202.04271</guid><pubDate>Wed, 09 Feb 2022 04:38:16 GMT</pubDate><author>Abhishek Moitra</author></item><item><title>Fully Convolutional Change Detection Framework with Generative Adversarial Network for Unsupervised, Weakly Supervised and Regional Supervised Change ...</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2201.06030&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2201.06030&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chen Wu&lt;/p&gt;   &lt;p&gt;Deep learning for change detection is one of the current hot topics in the field of remote sensing. However, most end-to-end networks are proposed for supervised change detection, and unsupervised change detection models depend on traditional pre-detection methods. Therefore, we proposed a fully convolutional change detection framework with generative adversarial network, to conclude unsupervised, weakly supervised, regional supervised, and fully supervised change detection tasks into one framework. A basic Unet segmentor is used to obtain change detection map, an image-to-image generator is implemented to model the spectral and spatial variation between multi-temporal images, and a discriminator for changed and unchanged is proposed for modeling the semantic changes in weakly and regional supervised change detection task. The iterative optimization of segmentor and generator can build an end-to-end network for unsupervised change detection, the adversarial process between segmentor and discriminator can provide the solutions for weakly and regional supervised change detection, the segmentor itself can be trained for fully supervised task. The experiments indicate the effectiveness of the propsed framework in unsupervised, weakly supervised and regional supervised change detection. This paper provides theorical definitions for unsupervised, weakly supervised and regional supervised change detection tasks, and shows great potentials in exploring end-to-end network for remote sensing change detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2201.06030</link><guid isPermaLink="false">https://papers.cool/arxiv/2201.06030</guid><pubDate>Sun, 16 Jan 2022 12:10:16 GMT</pubDate><author>Chen Wu</author></item><item><title>Radio-Assisted Human Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2112.08743&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2112.08743&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chengrun Qiu&lt;/p&gt;   &lt;p&gt;In this paper, we propose a radio-assisted human detection framework by incorporating radio information into the state-of-the-art detection methods, including anchor-based onestage detectors and two-stage detectors. We extract the radio localization and identifer information from the radio signals to assist the human detection, due to which the problem of false positives and false negatives can be greatly alleviated. For both detectors, we use the confidence score revision based on the radio localization to improve the detection performance. For two-stage detection methods, we propose to utilize the region proposals generated from radio localization rather than relying on region proposal network (RPN). Moreover, with the radio identifier information, a non-max suppression method with the radio localization constraint has also been proposed to further suppress the false detections and reduce miss detections. Experiments on the simulative Microsoft COCO dataset and Caltech pedestrian datasets show that the mean average precision (mAP) and the miss rate of the state-of-the-art detection methods can be improved with the aid of radio information. Finally, we conduct experiments in real-world scenarios to demonstrate the feasibility of our proposed method in practice.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2112.08743</link><guid isPermaLink="false">https://papers.cool/arxiv/2112.08743</guid><pubDate>Thu, 16 Dec 2021 09:53:41 GMT</pubDate><author>Chengrun Qiu</author></item><item><title>Fracture Detection in Wrist X-ray Images Using Deep Learning-Based Object Detection Models</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2111.07355&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2111.07355&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Fırat Hardalaç&lt;/p&gt;   &lt;p&gt;Hospitals, especially their emergency services, receive a high number of wrist fracture cases. For correct diagnosis and proper treatment of these, images obtained from various medical equipment must be viewed by physicians, along with the patients medical records and physical examination. The aim of this study is to perform fracture detection by use of deep learning on wrist Xray images to support physicians in the diagnosis of these fractures, particularly in the emergency services. Using SABL, RegNet, RetinaNet, PAA, Libra R_CNN, FSAF, Faster R_CNN, Dynamic R_CNN and DCN deep learning based object detection models with various backbones, 20 different fracture detection procedures were performed on Gazi University Hospitals dataset of wrist Xray images. To further improve these procedures, five different ensemble models were developed and then used to reform an ensemble model to develop a unique detection model, wrist fracture detection_combo (WFD_C). From 26 different models for fracture detection, the highest detection result obtained was 0.8639 average precision (AP50) in the WFD-C model. Huawei Turkey R&amp;amp;D Center supports this study within the scope of the ongoing cooperation project coded 071813 between Gazi University, Huawei and Medskor. Code is available at https://github.com/fatihuysal88/wrist-d&lt;/p&gt; </description><link>https://papers.cool/arxiv/2111.07355</link><guid isPermaLink="false">https://papers.cool/arxiv/2111.07355</guid><pubDate>Sun, 14 Nov 2021 14:21:24 GMT</pubDate><author>Fırat Hardalaç</author></item><item><title>Detection Limits of NaI Scintillator Detector Based Aerial Source Detection Systems</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2111.07756&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2111.07756&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Sebastian Ritter&lt;/p&gt;   &lt;p&gt;Aerial source detection systems have the capability to rapidly provide radiological data over a large area of land. Sodium Iodine (NaI) scintillator based aerial radiation detection systems of compact physical sizes have the potential aid nuclear security applications in a cost-effective manner when deployed on aerial vehicle systems. The Minimum Detectable Activity (MDA) of NaI scintillator airborne detectors is qualitatively evaluated as a function of detector-source distance and as a function of detector-source relative speed. It is found that the MDA increases exponentially with vehicle height and that MDA increases directly proportionally with the relative speed plus the square root of the relative speed. Furthermore, detection limits of an aerial detection system are evaluated in a case study. MDA is evaluated for the nuclear materials U-238 and Pu-239 as defined by the IAEA Safeguards Glossary Table II and MDA is evaluated for arbitrarily selected isotopes found in Table I.2 of the IAEA document TECDOC-1344.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2111.07756</link><guid isPermaLink="false">https://papers.cool/arxiv/2111.07756</guid><pubDate>Tue, 19 Oct 2021 03:16:56 GMT</pubDate><author>Sebastian Ritter</author></item><item><title>Out-of-Distribution Detection Using Outlier Detection Methods</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2108.08218&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2108.08218&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jan Diers&lt;/p&gt;   &lt;p&gt;Out-of-distribution detection (OOD) deals with anomalous input to neural networks. In the past, specialized methods have been proposed to reject predictions on anomalous input. Similarly, it was shown that feature extraction models in combination with outlier detection algorithms are well suited to detect anomalous input. We use outlier detection algorithms to detect anomalous input as reliable as specialized methods from the field of OOD. No neural network adaptation is required; detection is based on the model&#39;s softmax score. Our approach works unsupervised using an Isolation Forest and can be further improved by using a supervised learning method such as Gradient Boosting.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2108.08218</link><guid isPermaLink="false">https://papers.cool/arxiv/2108.08218</guid><pubDate>Wed, 18 Aug 2021 16:05:53 GMT</pubDate><author>Jan Diers</author></item><item><title>Locally Interpretable One-Class Anomaly Detection for Credit Card Fraud Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2108.02501&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2108.02501&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tungyu Wu&lt;/p&gt;   &lt;p&gt;For the highly imbalanced credit card fraud detection problem, most existing methods either use data augmentation methods or conventional machine learning models, while neural network-based anomaly detection approaches are lacking. Furthermore, few studies have employed AI interpretability tools to investigate the feature importance of transaction data, which is crucial for the black-box fraud detection module. Considering these two points together, we propose a novel anomaly detection framework for credit card fraud detection as well as a model-explaining module responsible for prediction explanations. The fraud detection model is composed of two deep neural networks, which are trained in an unsupervised and adversarial manner. Precisely, the generator is an AutoEncoder aiming to reconstruct genuine transaction data, while the discriminator is a fully-connected network for fraud detection. The explanation module has three white-box explainers in charge of interpretations of the AutoEncoder, discriminator, and the whole detection model, respectively. Experimental results show the state-of-the-art performances of our fraud detection model on the benchmark dataset compared with baselines. In addition, prediction analyses by three explainers are presented, offering a clear perspective on how each feature of an instance of interest contributes to the final model output.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2108.02501</link><guid isPermaLink="false">https://papers.cool/arxiv/2108.02501</guid><pubDate>Thu, 05 Aug 2021 10:19:12 GMT</pubDate><author>Tungyu Wu</author></item><item><title>Continual Novelty Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2106.12964&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2106.12964&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rahaf Aljundi&lt;/p&gt;   &lt;p&gt;Novelty Detection methods identify samples that are not representative of a model&#39;s training set thereby flagging misleading predictions and bringing a greater flexibility and transparency at deployment time. However, research in this area has only considered Novelty Detection in the offline setting. Recently, there has been a growing realization in the computer vision community that applications demand a more flexible framework - Continual Learning - where new batches of data representing new domains, new classes or new tasks become available at different points in time. In this setting, Novelty Detection becomes more important, interesting and challenging. This work identifies the crucial link between the two problems and investigates the Novelty Detection problem under the Continual Learning setting. We formulate the Continual Novelty Detection problem and present a benchmark, where we compare several Novelty Detection methods under different Continual Learning settings. We show that Continual Learning affects the behaviour of novelty detection algorithms, while novelty detection can pinpoint insights in the behaviour of a continual learner. We further propose baselines and discuss possible research directions. We believe that the coupling of the two problems is a promising direction to bring vision models into practice.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2106.12964</link><guid isPermaLink="false">https://papers.cool/arxiv/2106.12964</guid><pubDate>Thu, 24 Jun 2021 12:30:41 GMT</pubDate><author>Rahaf Aljundi</author></item><item><title>Multi-Perspective Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2105.09903&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2105.09903&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Peter Jakob&lt;/p&gt;   &lt;p&gt;Anomaly detection is a critical problem in the manufacturing industry. In many applications, images of objects to be analyzed are captured from multiple perspectives which can be exploited to improve the robustness of anomaly detection. In this work, we build upon the deep support vector data description algorithm and address multi-perspective anomaly detection using three different fusion techniques, i.e., early fusion, late fusion, and late fusion with multiple decoders. We employ different augmentation techniques with a denoising process to deal with scarce one-class data, which further improves the performance (ROC AUC $= 80\%$). Furthermore, we introduce the dices dataset, which consists of over 2000 grayscale images of falling dices from multiple perspectives, with 5\% of the images containing rare anomalies (e.g., drill holes, sawing, or scratches). We evaluate our approach on the new dices dataset using images from two different perspectives and also benchmark on the standard MNIST dataset. Extensive experiments demonstrate that our proposed {multi-perspective} approach exceeds the state-of-the-art {single-perspective anomaly detection on both the MNIST and dices datasets}. To the best of our knowledge, this is the first work that focuses on addressing multi-perspective anomaly detection in images by jointly using different perspectives together with one single objective function for anomaly detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2105.09903</link><guid isPermaLink="false">https://papers.cool/arxiv/2105.09903</guid><pubDate>Thu, 20 May 2021 17:07:36 GMT</pubDate><author>Peter Jakob</author></item><item><title>Understanding Deep MIMO Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2105.05044&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2105.05044&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Qiang Hu&lt;/p&gt;   &lt;p&gt;Incorporating deep learning (DL) into multiple-input multiple-output (MIMO) detection has been deemed as a promising technique for future wireless communications. However, most DL-based detection algorithms are lack of theoretical interpretation on internal mechanisms and could not provide general guidance on network design. In this paper, we analyze the performance of DL-based MIMO detection to better understand its strengths and weaknesses. We investigate two different architectures: a data-driven DL detector with a neural network activated by rectifier linear unit (ReLU) function and a model-driven DL detector from unfolding a traditional iterative detection algorithm. We demonstrate that data-driven DL detector asymptotically approaches to the maximum a posterior (MAP) detector in various scenarios but requires enough training samples to converge in time-varying channels. On the other hand, the model-driven DL detector utilizes model expert knowledge to alleviate the impact of channels and establish a relatively reliable detection method with a small set of training data. Due to its model specific property, the performance of model-driven DL detector is largely determined by the underlying iterative detection algorithm, which is usually suboptimal compared to the MAP detector. Simulation results confirm our analytical results and demonstrate the effectiveness of DL-based MIMO detection for both linear and nonlinear signal systems.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2105.05044</link><guid isPermaLink="false">https://papers.cool/arxiv/2105.05044</guid><pubDate>Tue, 11 May 2021 13:52:34 GMT</pubDate><author>Qiang Hu</author></item><item><title>Variational Pedestrian Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2104.12389&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2104.12389&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuang Zhang&lt;/p&gt;   &lt;p&gt;Pedestrian detection in a crowd is a challenging task due to a high number of mutually-occluding human instances, which brings ambiguity and optimization difficulties to the current IoU-based ground truth assignment procedure in classical object detection methods. In this paper, we develop a unique perspective of pedestrian detection as a variational inference problem. We formulate a novel and efficient algorithm for pedestrian detection by modeling the dense proposals as a latent variable while proposing a customized Auto Encoding Variational Bayes (AEVB) algorithm. Through the optimization of our proposed algorithm, a classical detector can be fashioned into a variational pedestrian detector. Experiments conducted on CrowdHuman and CityPersons datasets show that the proposed algorithm serves as an efficient solution to handle the dense pedestrian detection problem for the case of single-stage detectors. Our method can also be flexibly applied to two-stage detectors, achieving notable performance enhancement.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2104.12389</link><guid isPermaLink="false">https://papers.cool/arxiv/2104.12389</guid><pubDate>Mon, 26 Apr 2021 08:06:41 GMT</pubDate><author>Yuang Zhang</author></item><item><title>Advances In Malware Detection- An Overview</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2104.01835&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2104.01835&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Heena&lt;/p&gt;   &lt;p&gt;Malware has become a widely used means in cyber attacks in recent decades because of various new obfuscation techniques used by malwares. In order to protect the systems, data and information, detection of malware is needed as early as possible. There are various studies on malware detection techniques that have been done but there is no method which can detect the malware completely and make malware detection problematic. Static Malware analysis is very effective for known malwares but it does not work for zero day malware which leads to the need of dynamic malware detection and the behaviour based malware detection is comparatively good among all detection techniques like signature based, deep learning based, mobile/IOT and cloud based detection but still it is not able to detect all zero day malware which shows the malware detection is very challenging task and need more techniques for malware detection. This paper describes a literature review of various methods of malware detection. A short description of each method is provided and discusses various studies already done in the advanced malware detection field and their comparison based on the detection method used, accuracy and other parameters. Apart from this we will discuss various malware detection tools, dataset and their sources which can be used in further study. This paper gives you the detailed knowledge of advanced malwares, its detection methods, how you can protect your devices and data from malware attacks and it gives the comparison of different studies on malware detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2104.01835</link><guid isPermaLink="false">https://papers.cool/arxiv/2104.01835</guid><pubDate>Mon, 05 Apr 2021 10:12:11 GMT</pubDate><author>Heena</author></item><item><title>Triple-cooperative Video Shadow Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2103.06533&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2103.06533&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhihao Chen&lt;/p&gt;   &lt;p&gt;Shadow detection in a single image has received significant research interest in recent years. However, much fewer works have been explored in shadow detection over dynamic scenes. The bottleneck is the lack of a well-established dataset with high-quality annotations for video shadow detection. In this work, we collect a new video shadow detection dataset, which contains 120 videos with 11, 685 frames, covering 60 object categories, varying lengths, and different motion/lighting conditions. All the frames are annotated with a high-quality pixel-level shadow mask. To the best of our knowledge, this is the first learning-oriented dataset for video shadow detection. Furthermore, we develop a new baseline model, named triple-cooperative video shadow detection network (TVSD-Net). It utilizes triple parallel networks in a cooperative manner to learn discriminative representations at intra-video and inter-video levels. Within the network, a dual gated co-attention module is proposed to constrain features from neighboring frames in the same video, while an auxiliary similarity loss is introduced to mine semantic information between different videos. Finally, we conduct a comprehensive study on ViSha, evaluating 12 state-of-the-art models (including single image shadow detectors, video object segmentation, and saliency detection methods). Experiments demonstrate that our model outperforms SOTA competitors.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2103.06533</link><guid isPermaLink="false">https://papers.cool/arxiv/2103.06533</guid><pubDate>Thu, 11 Mar 2021 08:54:19 GMT</pubDate><author>Zhihao Chen</author></item><item><title>Towards Fair Deep Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2012.14961&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2012.14961&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hongjing Zhang&lt;/p&gt;   &lt;p&gt;Anomaly detection aims to find instances that are considered unusual and is a fundamental problem of data science. Recently, deep anomaly detection methods were shown to achieve superior results particularly in complex data such as images. Our work focuses on deep one-class classification for anomaly detection which learns a mapping only from the normal samples. However, the non-linear transformation performed by deep learning can potentially find patterns associated with social bias. The challenge with adding fairness to deep anomaly detection is to ensure both making fair and correct anomaly predictions simultaneously. In this paper, we propose a new architecture for the fair anomaly detection approach (Deep Fair SVDD) and train it using an adversarial network to de-correlate the relationships between the sensitive attributes and the learned representations. This differs from how fairness is typically added namely as a regularizer or a constraint. Further, we propose two effective fairness measures and empirically demonstrate that existing deep anomaly detection methods are unfair. We show that our proposed approach can remove the unfairness largely with minimal loss on the anomaly detection performance. Lastly, we conduct an in-depth analysis to show the strength and limitations of our proposed model, including parameter analysis, feature visualization, and run-time analysis.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2012.14961</link><guid isPermaLink="false">https://papers.cool/arxiv/2012.14961</guid><pubDate>Tue, 29 Dec 2020 22:34:45 GMT</pubDate><author>Hongjing Zhang</author></item><item><title>SWA Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2012.12645&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2012.12645&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Haoyang Zhang&lt;/p&gt;   &lt;p&gt;Do you want to improve 1.0 AP for your object detector without any inference cost and any change to your detector? Let us tell you such a recipe. It is surprisingly simple: train your detector for an extra 12 epochs using cyclical learning rates and then average these 12 checkpoints as your final detection model}. This potent recipe is inspired by Stochastic Weights Averaging (SWA), which is proposed in arXiv:1803.05407 for improving generalization in deep neural networks. We found it also very effective in object detection. In this technique report, we systematically investigate the effects of applying SWA to object detection as well as instance segmentation. Through extensive experiments, we discover the aforementioned workable policy of performing SWA in object detection, and we consistently achieve $\sim$1.0 AP improvement over various popular detectors on the challenging COCO benchmark, including Mask RCNN, Faster RCNN, RetinaNet, FCOS, YOLOv3 and VFNet. We hope this work will make more researchers in object detection know this technique and help them train better object detectors. Code is available at: https://github.com/hyz-xmaster/swa_object_detection .&lt;/p&gt; </description><link>https://papers.cool/arxiv/2012.12645</link><guid isPermaLink="false">https://papers.cool/arxiv/2012.12645</guid><pubDate>Wed, 23 Dec 2020 13:26:10 GMT</pubDate><author>Haoyang Zhang</author></item><item><title>Identity-Driven DeepFake Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2012.03930&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2012.03930&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xiaoyi Dong&lt;/p&gt;   &lt;p&gt;DeepFake detection has so far been dominated by ``artifact-driven&#39;&#39; methods and the detection performance significantly degrades when either the type of image artifacts is unknown or the artifacts are simply too hard to find. In this work, we present an alternative approach: Identity-Driven DeepFake Detection. Our approach takes as input the suspect image/video as well as the target identity information (a reference image or video). We output a decision on whether the identity in the suspect image/video is the same as the target identity. Our motivation is to prevent the most common and harmful DeepFakes that spread false information of a targeted person. The identity-based approach is fundamentally different in that it does not attempt to detect image artifacts. Instead, it focuses on whether the identity in the suspect image/video is true. To facilitate research on identity-based detection, we present a new large scale dataset ``Vox-DeepFake&quot;, in which each suspect content is associated with multiple reference images collected from videos of a target identity. We also present a simple identity-based detection algorithm called the OuterFace, which may serve as a baseline for further research. Even trained without fake videos, the OuterFace algorithm achieves superior detection accuracy and generalizes well to different DeepFake methods, and is robust with respect to video degradation techniques -- a performance not achievable with existing detection algorithms.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2012.03930</link><guid isPermaLink="false">https://papers.cool/arxiv/2012.03930</guid><pubDate>Mon, 07 Dec 2020 18:59:08 GMT</pubDate><author>Xiaoyi Dong</author></item><item><title>Class-agnostic Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2011.14204&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2011.14204&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ayush Jaiswal&lt;/p&gt;   &lt;p&gt;Object detection models perform well at localizing and classifying objects that they are shown during training. However, due to the difficulty and cost associated with creating and annotating detection datasets, trained models detect a limited number of object types with unknown objects treated as background content. This hinders the adoption of conventional detectors in real-world applications like large-scale object matching, visual grounding, visual relation prediction, obstacle detection (where it is more important to determine the presence and location of objects than to find specific types), etc. We propose class-agnostic object detection as a new problem that focuses on detecting objects irrespective of their object-classes. Specifically, the goal is to predict bounding boxes for all objects in an image but not their object-classes. The predicted boxes can then be consumed by another system to perform application-specific classification, retrieval, etc. We propose training and evaluation protocols for benchmarking class-agnostic detectors to advance future research in this domain. Finally, we propose (1) baseline methods and (2) a new adversarial learning framework for class-agnostic detection that forces the model to exclude class-specific information from features used for predictions. Experimental results show that adversarial learning improves class-agnostic detection efficacy.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2011.14204</link><guid isPermaLink="false">https://papers.cool/arxiv/2011.14204</guid><pubDate>Sat, 28 Nov 2020 19:22:38 GMT</pubDate><author>Ayush Jaiswal</author></item><item><title>Defocus Blur Detection via Salient Region Detection Prior</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2011.09677&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2011.09677&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ming Qian&lt;/p&gt;   &lt;p&gt;Defocus blur always occurred in photos when people take photos by Digital Single Lens Reflex Camera(DSLR), giving salient region and aesthetic pleasure. Defocus blur Detection aims to separate the out-of-focus and depth-of-field areas in photos, which is an important work in computer vision. Current works for defocus blur detection mainly focus on the designing of networks, the optimizing of the loss function, and the application of multi-stream strategy, meanwhile, these works do not pay attention to the shortage of training data. In this work, to address the above data-shortage problem, we turn to rethink the relationship between two tasks: defocus blur detection and salient region detection. In an image with bokeh effect, it is obvious that the salient region and the depth-of-field area overlap in most cases. So we first train our network on the salient region detection tasks, then transfer the pre-trained model to the defocus blur detection tasks. Besides, we propose a novel network for defocus blur detection. Experiments show that our transfer strategy works well on many current models, and demonstrate the superiority of our network.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2011.09677</link><guid isPermaLink="false">https://papers.cool/arxiv/2011.09677</guid><pubDate>Thu, 19 Nov 2020 05:56:11 GMT</pubDate><author>Ming Qian</author></item><item><title>Slender Object Detection: Diagnoses and Improvements</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2011.08529&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2011.08529&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhaoyi Wan&lt;/p&gt;   &lt;p&gt;In this paper, we are concerned with the detection of a particular type of objects with extreme aspect ratios, namely \textbf{slender objects}. In real-world scenarios, slender objects are actually very common and crucial to the objective of a detection system. However, this type of objects has been largely overlooked by previous object detection algorithms. Upon our investigation, for a classical object detection method, a drastic drop of $18.9\%$ mAP on COCO is observed, if solely evaluated on slender objects. Therefore, we systematically study the problem of slender object detection in this work. Accordingly, an analytical framework with carefully designed benchmark and evaluation protocols is established, in which different algorithms and modules can be inspected and compared. \New Our study reveals that effective slender object detection can be achieved ~\textbf{with none of} (1) anchor-based localization; (2) specially designed box representations. Instead, \textbf{the critical aspect of improving slender object detection is feature adaptation}. It identifies and extends the insights of existing methods that are previously underexploited. Furthermore, we propose a feature adaption strategy that achieves clear and consistent improvements over current representative object detection methods.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2011.08529</link><guid isPermaLink="false">https://papers.cool/arxiv/2011.08529</guid><pubDate>Tue, 17 Nov 2020 09:39:42 GMT</pubDate><author>Zhaoyi Wan</author></item><item><title>SwiftFace: Real-Time Face Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2009.13743&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2009.13743&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Leonardo Ramos&lt;/p&gt;   &lt;p&gt;Computer vision is a field of artificial intelligence that trains computers to interpret the visual world in a way similar to that of humans. Due to the rapid advancements in technology and the increasing availability of sufficiently large training datasets, the topics within computer vision have experienced a steep growth in the last decade. Among them, one of the most promising fields is face detection. Being used daily in a wide variety of fields; from mobile apps and augmented reality for entertainment purposes, to social studies and security cameras; designing high-performance models for face detection is crucial. On top of that, with the aforementioned growth in face detection technologies, precision and accuracy are no longer the only relevant factors: for real-time face detection, speed of detection is essential. SwiftFace is a novel deep learning model created solely to be a fast face detection model. By focusing only on detecting faces, SwiftFace performs 30% faster than current state-of-the-art face detection models. Code available at https://github.com/leo7r/swiftface&lt;/p&gt; </description><link>https://papers.cool/arxiv/2009.13743</link><guid isPermaLink="false">https://papers.cool/arxiv/2009.13743</guid><pubDate>Tue, 29 Sep 2020 03:09:29 GMT</pubDate><author>Leonardo Ramos</author></item><item><title>False Detection (Positives and Negatives) in Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2008.06986&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2008.06986&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Subrata Goswami&lt;/p&gt;   &lt;p&gt;Object detection is a very important function of visual perception systems. Since the early days of classical object detection based on HOG to modern deep learning based detectors, object detection has improved in accuracy. Two stage detectors usually have higher accuracy than single stage ones. Both types of detectors use some form of quantization of the search space of rectangular regions of image. There are far more of the quantized elements than true objects. The way these bounding boxes are filtered out possibly results in the false positive and false negatives. This empirical experimental study explores ways of reducing false positives and negatives with labelled data.. In the process also discovered insufficient labelling in Openimage 2019 Object Detection dataset.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2008.06986</link><guid isPermaLink="false">https://papers.cool/arxiv/2008.06986</guid><pubDate>Sun, 16 Aug 2020 20:09:05 GMT</pubDate><author>Subrata Goswami</author></item><item><title>Anomaly Detection-Based Unknown Face Presentation Attack Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2007.05856&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2007.05856&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yashasvi Baweja&lt;/p&gt;   &lt;p&gt;Anomaly detection-based spoof attack detection is a recent development in face Presentation Attack Detection (fPAD), where a spoof detector is learned using only non-attacked images of users. These detectors are of practical importance as they are shown to generalize well to new attack types. In this paper, we present a deep-learning solution for anomaly detection-based spoof attack detection where both classifier and feature representations are learned together end-to-end. First, we introduce a pseudo-negative class during training in the absence of attacked images. The pseudo-negative class is modeled using a Gaussian distribution whose mean is calculated by a weighted running mean. Secondly, we use pairwise confusion loss to further regularize the training process. The proposed approach benefits from the representation learning power of the CNNs and learns better features for fPAD task as shown in our ablation study. We perform extensive experiments on four publicly available datasets: Replay-Attack, Rose-Youtu, OULU-NPU and Spoof in Wild to show the effectiveness of the proposed approach over the previous methods. Code is available at: \url{https://github.com/yashasvi97/IJCB2020_anomaly}&lt;/p&gt; </description><link>https://papers.cool/arxiv/2007.05856</link><guid isPermaLink="false">https://papers.cool/arxiv/2007.05856</guid><pubDate>Sat, 11 Jul 2020 21:20:55 GMT</pubDate><author>Yashasvi Baweja</author></item><item><title>Detection as Regression: Certified Object Detection by Median Smoothing</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2007.03730&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2007.03730&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ping-yeh Chiang&lt;/p&gt;   &lt;p&gt;Despite the vulnerability of object detectors to adversarial attacks, very few defenses are known to date. While adversarial training can improve the empirical robustness of image classifiers, a direct extension to object detection is very expensive. This work is motivated by recent progress on certified classification by randomized smoothing. We start by presenting a reduction from object detection to a regression problem. Then, to enable certified regression, where standard mean smoothing fails, we propose median smoothing, which is of independent interest. We obtain the first model-agnostic, training-free, and certified defense for object detection against $\ell_2$-bounded attacks. The code for all experiments in the paper is available at http://github.com/Ping-C/CertifiedObjectDetection .&lt;/p&gt; </description><link>https://papers.cool/arxiv/2007.03730</link><guid isPermaLink="false">https://papers.cool/arxiv/2007.03730</guid><pubDate>Tue, 07 Jul 2020 18:40:19 GMT</pubDate><author>Ping-yeh Chiang</author></item><item><title>Entropic Out-of-Distribution Detection: Seamless Detection of Unknown Examples</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2006.04005&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2006.04005&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; David Macêdo&lt;/p&gt;   &lt;p&gt;In this paper, we argue that the unsatisfactory out-of-distribution (OOD) detection performance of neural networks is mainly due to the SoftMax loss anisotropy and propensity to produce low entropy probability distributions in disagreement with the principle of maximum entropy. Current out-of-distribution (OOD) detection approaches usually do not directly fix the SoftMax loss drawbacks, but rather build techniques to circumvent it. Unfortunately, those methods usually produce undesired side effects (e.g., classification accuracy drop, additional hyperparameters, slower inferences, and collecting extra data). In the opposite direction, we propose replacing SoftMax loss with a novel loss function that does not suffer from the mentioned weaknesses. The proposed IsoMax loss is isotropic (exclusively distance-based) and provides high entropy posterior probability distributions. Replacing the SoftMax loss by IsoMax loss requires no model or training changes. Additionally, the models trained with IsoMax loss produce as fast and energy-efficient inferences as those trained using SoftMax loss. Moreover, no classification accuracy drop is observed. The proposed method does not rely on outlier/background data, hyperparameter tuning, temperature calibration, feature extraction, metric learning, adversarial training, ensemble procedures, or generative models. Our experiments showed that IsoMax loss works as a seamless SoftMax loss drop-in replacement that significantly improves neural networks&#39; OOD detection performance. Hence, it may be used as a baseline OOD detection approach to be combined with current or future OOD detection techniques to achieve even higher results.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2006.04005</link><guid isPermaLink="false">https://papers.cool/arxiv/2006.04005</guid><pubDate>Sun, 07 Jun 2020 00:34:57 GMT</pubDate><author>David Macêdo</author></item><item><title>CircleNet: Anchor-free Detection with Circle Representation</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2006.02474&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2006.02474&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Haichun Yang&lt;/p&gt;   &lt;p&gt;Object detection networks are powerful in computer vision, but not necessarily optimized for biomedical object detection. In this work, we propose CircleNet, a simple anchor-free detection method with circle representation for detection of the ball-shaped glomerulus. Different from the traditional bounding box based detection method, the bounding circle (1) reduces the degrees of freedom of detection representation, (2) is naturally rotation invariant, (3) and optimized for ball-shaped objects. The key innovation to enable this representation is the anchor-free framework with the circle detection head. We evaluate CircleNet in the context of detection of glomerulus. CircleNet increases average precision of the glomerulus detection from 0.598 to 0.647. Another key advantage is that CircleNet achieves better rotation consistency compared with bounding box representations.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2006.02474</link><guid isPermaLink="false">https://papers.cool/arxiv/2006.02474</guid><pubDate>Wed, 03 Jun 2020 18:31:51 GMT</pubDate><author>Haichun Yang</author></item><item><title>Fair Outlier Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2005.09900&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2005.09900&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Deepak P&lt;/p&gt;   &lt;p&gt;An outlier detection method may be considered fair over specified sensitive attributes if the results of outlier detection are not skewed towards particular groups defined on such sensitive attributes. In this task, we consider, for the first time to our best knowledge, the task of fair outlier detection. In this work, we consider the task of fair outlier detection over multiple multi-valued sensitive attributes (e.g., gender, race, religion, nationality, marital status etc.). We propose a fair outlier detection method, FairLOF, that is inspired by the popular LOF formulation for neighborhood-based outlier detection. We outline ways in which unfairness could be induced within LOF and develop three heuristic principles to enhance fairness, which form the basis of the FairLOF method. Being a novel task, we develop an evaluation framework for fair outlier detection, and use that to benchmark FairLOF on quality and fairness of results. Through an extensive empirical evaluation over real-world datasets, we illustrate that FairLOF is able to achieve significant improvements in fairness at sometimes marginal degradations on result quality as measured against the fairness-agnostic LOF method.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2005.09900</link><guid isPermaLink="false">https://papers.cool/arxiv/2005.09900</guid><pubDate>Wed, 20 May 2020 08:02:41 GMT</pubDate><author>Deepak P</author></item><item><title>Any-Shot Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2003.07003&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2003.07003&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shafin Rahman&lt;/p&gt;   &lt;p&gt;Previous work on novel object detection considers zero or few-shot settings where none or few examples of each category are available for training. In real world scenarios, it is less practical to expect that &#39;all&#39; the novel classes are either unseen or {have} few-examples. Here, we propose a more realistic setting termed &#39;Any-shot detection&#39;, where totally unseen and few-shot categories can simultaneously co-occur during inference. Any-shot detection offers unique challenges compared to conventional novel object detection such as, a high imbalance between unseen, few-shot and seen object classes, susceptibility to forget base-training while learning novel classes and distinguishing novel classes from the background. To address these challenges, we propose a unified any-shot detection model, that can concurrently learn to detect both zero-shot and few-shot object classes. Our core idea is to use class semantics as prototypes for object detection, a formulation that naturally minimizes knowledge forgetting and mitigates the class-imbalance in the label space. Besides, we propose a rebalanced loss function that emphasizes difficult few-shot cases but avoids overfitting on the novel classes to allow detection of totally unseen classes. Without bells and whistles, our framework can also be used solely for Zero-shot detection and Few-shot detection tasks. We report extensive experiments on Pascal VOC and MS-COCO datasets where our approach is shown to provide significant improvements.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2003.07003</link><guid isPermaLink="false">https://papers.cool/arxiv/2003.07003</guid><pubDate>Mon, 16 Mar 2020 03:43:15 GMT</pubDate><author>Shafin Rahman</author></item><item><title>Progressive Object Transfer Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/2002.04741&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/2002.04741&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hao Chen&lt;/p&gt;   &lt;p&gt;Recent development of object detection mainly depends on deep learning with large-scale benchmarks. However, collecting such fully-annotated data is often difficult or expensive for real-world applications, which restricts the power of deep neural networks in practice. Alternatively, humans can detect new objects with little annotation burden, since humans often use the prior knowledge to identify new objects with few elaborately-annotated examples, and subsequently generalize this capacity by exploiting objects from wild images. Inspired by this procedure of learning to detect, we propose a novel Progressive Object Transfer Detection (POTD) framework. Specifically, we make three main contributions in this paper. First, POTD can leverage various object supervision of different domains effectively into a progressive detection procedure. Via such human-like learning, one can boost a target detection task with few annotations. Second, POTD consists of two delicate transfer stages, i.e., Low-Shot Transfer Detection (LSTD), and Weakly-Supervised Transfer Detection (WSTD). In LSTD, we distill the implicit object knowledge of source detector to enhance target detector with few annotations. It can effectively warm up WSTD later on. In WSTD, we design a recurrent object labelling mechanism for learning to annotate weakly-labeled images. More importantly, we exploit the reliable object supervision from LSTD, which can further enhance the robustness of target detector in the WSTD stage. Finally, we perform extensive experiments on a number of challenging detection benchmarks with different settings. The results demonstrate that, our POTD outperforms the recent state-of-the-art approaches.&lt;/p&gt; </description><link>https://papers.cool/arxiv/2002.04741</link><guid isPermaLink="false">https://papers.cool/arxiv/2002.04741</guid><pubDate>Wed, 12 Feb 2020 00:16:24 GMT</pubDate><author>Hao Chen</author></item><item><title>PPDM: Parallel Point Detection and Matching for Real-time Human-Object Interaction Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1912.12898&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1912.12898&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yue Liao&lt;/p&gt;   &lt;p&gt;We propose a single-stage Human-Object Interaction (HOI) detection method that has outperformed all existing methods on HICO-DET dataset at 37 fps on a single Titan XP GPU. It is the first real-time HOI detection method. Conventional HOI detection methods are composed of two stages, i.e., human-object proposals generation, and proposals classification. Their effectiveness and efficiency are limited by the sequential and separate architecture. In this paper, we propose a Parallel Point Detection and Matching (PPDM) HOI detection framework. In PPDM, an HOI is defined as a point triplet &amp;lt; human point, interaction point, object point&amp;gt;. Human and object points are the center of the detection boxes, and the interaction point is the midpoint of the human and object points. PPDM contains two parallel branches, namely point detection branch and point matching branch. The point detection branch predicts three points. Simultaneously, the point matching branch predicts two displacements from the interaction point to its corresponding human and object points. The human point and the object point originated from the same interaction point are considered as matched pairs. In our novel parallel architecture, the interaction points implicitly provide context and regularization for human and object detection. The isolated detection boxes are unlikely to form meaning HOI triplets are suppressed, which increases the precision of HOI detection. Moreover, the matching between human and object detection boxes is only applied around limited numbers of filtered candidate interaction points, which saves much computational cost. Additionally, we build a new application-oriented database named HOI-A, which severs as a good supplement to the existing datasets. The source code and the dataset will be made publicly available to facilitate the development of HOI detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1912.12898</link><guid isPermaLink="false">https://papers.cool/arxiv/1912.12898</guid><pubDate>Mon, 30 Dec 2019 12:00:55 GMT</pubDate><author>Yue Liao</author></item><item><title>Fatigue Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1911.10629&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1911.10629&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ashish Verma&lt;/p&gt;   &lt;p&gt;Nowadays, there are many fatigue detection methods and the majority of them are tracking eye in real-time using one or two cameras to detect the physical responses in eyes. It is indicated that the responses in eyes have high relativity with driver fatigue. As part of this project, We will propose a fatigue detection system based on pose estimation. Using pose estimation, We plan to mark the body joints in the upper body for shoulders and neck. Then, we plan to compare the location of the joints of the current posture with the ideal posture.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1911.10629</link><guid isPermaLink="false">https://papers.cool/arxiv/1911.10629</guid><pubDate>Sun, 24 Nov 2019 22:36:15 GMT</pubDate><author>Ashish Verma</author></item><item><title>Robust Anomaly Detection and Backdoor Attack Detection Via Differential Privacy</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1911.07116&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1911.07116&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Min Du&lt;/p&gt;   &lt;p&gt;Outlier detection and novelty detection are two important topics for anomaly detection. Suppose the majority of a dataset are drawn from a certain distribution, outlier detection and novelty detection both aim to detect data samples that do not fit the distribution. Outliers refer to data samples within this dataset, while novelties refer to new samples. In the meantime, backdoor poisoning attacks for machine learning models are achieved through injecting poisoning samples into the training dataset, which could be regarded as &quot;outliers&quot; that are intentionally added by attackers. Differential privacy has been proposed to avoid leaking any individual&#39;s information, when aggregated analysis is performed on a given dataset. It is typically achieved by adding random noise, either directly to the input dataset, or to intermediate results of the aggregation mechanism. In this paper, we demonstrate that applying differential privacy can improve the utility of outlier detection and novelty detection, with an extension to detect poisoning samples in backdoor attacks. We first present a theoretical analysis on how differential privacy helps with the detection, and then conduct extensive experiments to validate the effectiveness of differential privacy in improving outlier detection, novelty detection, and backdoor attack detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1911.07116</link><guid isPermaLink="false">https://papers.cool/arxiv/1911.07116</guid><pubDate>Sat, 16 Nov 2019 23:32:20 GMT</pubDate><author>Min Du</author></item><item><title>Face Detection on Surveillance Images</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1910.11121&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1910.11121&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Mohammad Iqbal Nouyed&lt;/p&gt;   &lt;p&gt;In last few decades, a lot of progress has been made in the field of face detection. Various face detection methods have been proposed by numerous researchers working in this area. The two well-known benchmarking platform: the FDDB and WIDER face detection provide quite challenging scenarios to assess the efficacy of the detection methods. These benchmarking data sets are mostly created using images from the public network ie. the Internet. A recent, face detection and open-set recognition challenge has shown that those same face detection algorithms produce high false alarms for images taken in surveillance scenario. This shows the difficult nature of the surveillance environment. Our proposed body pose based face detection method was one of the top performers in this competition. In this paper, we perform a comparative performance analysis of some of the well known face detection methods including the few used in that competition, and, compare them to our proposed body pose based face detection method. Experiment results show that, our proposed method that leverages body information to detect faces, is the most realistic approach in terms of accuracy, false alarms and average detection time, when surveillance scenario is in consideration.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1910.11121</link><guid isPermaLink="false">https://papers.cool/arxiv/1910.11121</guid><pubDate>Tue, 22 Oct 2019 02:10:58 GMT</pubDate><author>Mohammad Iqbal Nouyed</author></item><item><title>DeepMark: One-Shot Clothing Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1910.01225&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1910.01225&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alexey Sidnev&lt;/p&gt;   &lt;p&gt;The one-shot approach, DeepMark, for fast clothing detection as a modification of a multi-target network, CenterNet, is proposed in the paper. The state-of-the-art accuracy of 0.723 mAP for bounding box detection task and 0.532 mAP for landmark detection task on the DeepFashion2 Challenge dataset were achieved. The proposed architecture can be used effectively on the low-power devices.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1910.01225</link><guid isPermaLink="false">https://papers.cool/arxiv/1910.01225</guid><pubDate>Wed, 02 Oct 2019 21:18:17 GMT</pubDate><author>Alexey Sidnev</author></item><item><title>LSTM-Based Anomaly Detection: Detection Rules from Extreme Value Theory</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1909.06041&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1909.06041&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Neema Davis&lt;/p&gt;   &lt;p&gt;In this paper, we explore various statistical techniques for anomaly detection in conjunction with the popular Long Short-Term Memory (LSTM) deep learning model for transportation networks. We obtain the prediction errors from an LSTM model, and then apply three statistical models based on (i) the Gaussian distribution, (ii) Extreme Value Theory (EVT), and (iii) the Tukey&#39;s method. Using statistical tests and numerical studies, we find strong evidence against the widely employed Gaussian distribution based detection rule on the prediction errors. Next, motivated by fundamental results from Extreme Value Theory, we propose a detection technique that does not assume any parent distribution on the prediction errors. Through numerical experiments conducted on several real-world traffic data sets, we show that the EVT-based detection rule is superior to other detection rules, and is supported by statistical evidence.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1909.06041</link><guid isPermaLink="false">https://papers.cool/arxiv/1909.06041</guid><pubDate>Fri, 13 Sep 2019 05:31:07 GMT</pubDate><author>Neema Davis</author></item><item><title>Anomaly Detection with Inexact Labels</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1909.04807&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1909.04807&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Tomoharu Iwata&lt;/p&gt;   &lt;p&gt;We propose a supervised anomaly detection method for data with inexact anomaly labels, where each label, which is assigned to a set of instances, indicates that at least one instance in the set is anomalous. Although many anomaly detection methods have been proposed, they cannot handle inexact anomaly labels. To measure the performance with inexact anomaly labels, we define the inexact AUC, which is our extension of the area under the ROC curve (AUC) for inexact labels. The proposed method trains an anomaly score function so that the smooth approximation of the inexact AUC increases while anomaly scores for non-anomalous instances become low. We model the anomaly score function by a neural network-based unsupervised anomaly detection method, e.g., autoencoders. The proposed method performs well even when only a small number of inexact labels are available by incorporating an unsupervised anomaly detection mechanism with inexact AUC maximization. Using various datasets, we experimentally demonstrate that our proposed method improves the anomaly detection performance with inexact anomaly labels, and outperforms existing unsupervised and supervised anomaly detection and multiple instance learning methods.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1909.04807</link><guid isPermaLink="false">https://papers.cool/arxiv/1909.04807</guid><pubDate>Wed, 11 Sep 2019 01:30:38 GMT</pubDate><author>Tomoharu Iwata</author></item><item><title>Figurative Usage Detection of Symptom Words to Improve Personal Health Mention Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1906.05466&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1906.05466&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Adith Iyer&lt;/p&gt;   &lt;p&gt;Personal health mention detection deals with predicting whether or not a given sentence is a report of a health condition. Past work mentions errors in this prediction when symptom words, i.e. names of symptoms of interest, are used in a figurative sense. Therefore, we combine a state-of-the-art figurative usage detection with CNN-based personal health mention detection. To do so, we present two methods: a pipeline-based approach and a feature augmentation-based approach. The introduction of figurative usage detection results in an average improvement of 2.21% F-score of personal health mention detection, in the case of the feature augmentation-based approach. This paper demonstrates the promise of using figurative usage detection to improve personal health mention detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1906.05466</link><guid isPermaLink="false">https://papers.cool/arxiv/1906.05466</guid><pubDate>Thu, 13 Jun 2019 03:42:34 GMT</pubDate><author>Adith Iyer</author></item><item><title>Panoptic Edge Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1906.00590&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1906.00590&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuan Hu&lt;/p&gt;   &lt;p&gt;Pursuing more complete and coherent scene understanding towards realistic vision applications drives edge detection from category-agnostic to category-aware semantic level. However, finer delineation of instance-level boundaries still remains unexcavated. In this work, we address a new finer-grained task, termed panoptic edge detection (PED), which aims at predicting semantic-level boundaries for stuff categories and instance-level boundaries for instance categories, in order to provide more comprehensive and unified scene understanding from the perspective of edges.We then propose a versatile framework, Panoptic Edge Network (PEN), which aggregates different tasks of object detection, semantic and instance edge detection into a single holistic network with multiple branches. Based on the same feature representation, the semantic edge branch produces semantic-level boundaries for all categories and the object detection branch generates instance proposals. Conditioned on the prior information from these two branches, the instance edge branch aims at instantiating edge predictions for instance categories. Besides, we also devise a Panoptic Dual F-measure (F2) metric for the new PED task to uniformly measure edge prediction quality for both stuff and instances. By joint end-to-end training, the proposed PEN framework outperforms all competitive baselines on Cityscapes and ADE20K datasets.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1906.00590</link><guid isPermaLink="false">https://papers.cool/arxiv/1906.00590</guid><pubDate>Mon, 03 Jun 2019 06:18:30 GMT</pubDate><author>Yuan Hu</author></item><item><title>Agnostic Lane Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1905.03704&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1905.03704&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuenan Hou&lt;/p&gt;   &lt;p&gt;Lane detection is an important yet challenging task in autonomous driving, which is affected by many factors, e.g., light conditions, occlusions caused by other vehicles, irrelevant markings on the road and the inherent long and thin property of lanes. Conventional methods typically treat lane detection as a semantic segmentation task, which assigns a class label to each pixel of the image. This formulation heavily depends on the assumption that the number of lanes is pre-defined and fixed and no lane changing occurs, which does not always hold. To make the lane detection model applicable to an arbitrary number of lanes and lane changing scenarios, we adopt an instance segmentation approach, which first differentiates lanes and background and then classify each lane pixel into each lane instance. Besides, a multi-task learning paradigm is utilized to better exploit the structural information and the feature pyramid architecture is used to detect extremely thin lanes. Three popular lane detection benchmarks, i.e., TuSimple, CULane and BDD100K, are used to validate the effectiveness of our proposed algorithm.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1905.03704</link><guid isPermaLink="false">https://papers.cool/arxiv/1905.03704</guid><pubDate>Thu, 02 May 2019 05:58:17 GMT</pubDate><author>Yuenan Hou</author></item><item><title>Progressive LiDAR Adaptation for Road Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1904.01206&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1904.01206&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhe Chen&lt;/p&gt;   &lt;p&gt;Despite rapid developments in visual image-based road detection, robustly identifying road areas in visual images remains challenging due to issues like illumination changes and blurry images. To this end, LiDAR sensor data can be incorporated to improve the visual image-based road detection, because LiDAR data is less susceptible to visual noises. However, the main difficulty in introducing LiDAR information into visual image-based road detection is that LiDAR data and its extracted features do not share the same space with the visual data and visual features. Such gaps in spaces may limit the benefits of LiDAR information for road detection. To overcome this issue, we introduce a novel Progressive LiDAR Adaptation-aided Road Detection (PLARD) approach to adapt LiDAR information into visual image-based road detection and improve detection performance. In PLARD, progressive LiDAR adaptation consists of two subsequent modules: 1) data space adaptation, which transforms the LiDAR data to the visual data space to align with the perspective view by applying altitude difference-based transformation; and 2) feature space adaptation, which adapts LiDAR features to visual features through a cascaded fusion structure. Comprehensive empirical studies on the well-known KITTI road detection benchmark demonstrate that PLARD takes advantage of both the visual and LiDAR information, achieving much more robust road detection even in challenging urban scenes. In particular, PLARD outperforms other state-of-the-art road detection models and is currently top of the publicly accessible benchmark leader-board.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1904.01206</link><guid isPermaLink="false">https://papers.cool/arxiv/1904.01206</guid><pubDate>Tue, 02 Apr 2019 04:22:23 GMT</pubDate><author>Zhe Chen</author></item><item><title>The Probabilistic Object Detection Challenge</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1903.07840&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1903.07840&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; John Skinner&lt;/p&gt;   &lt;p&gt;We introduce a new challenge for computer and robotic vision, the first ACRV Robotic Vision Challenge, Probabilistic Object Detection. Probabilistic object detection is a new variation on traditional object detection tasks, requiring estimates of spatial and semantic uncertainty. We extend the traditional bounding box format of object detection to express spatial uncertainty using gaussian distributions for the box corners. The challenge introduces a new test dataset of video sequences, which are designed to more closely resemble the kind of data available to a robotic system. We evaluate probabilistic detections using a new probability-based detection quality (PDQ) measure. The goal in creating this challenge is to draw the computer and robotic vision communities together, toward applying object detection solutions for practical robotics applications.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1903.07840</link><guid isPermaLink="false">https://papers.cool/arxiv/1903.07840</guid><pubDate>Tue, 19 Mar 2019 05:18:52 GMT</pubDate><author>John Skinner</author></item><item><title>Searching for Technosignatures: Implications of Detection and Non-Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1903.06550&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1903.06550&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jacob Haqq-Misra&lt;/p&gt;   &lt;p&gt;The search for technosignatures from the Galaxy or the nearby universe raises two main questions: What are the possible characteristics of technosignatures? and How can future searches be optimized to enhance the probability of detection? Addressing these questions requires an interdisciplinary approach, combining i) the study of Anthropocene as a planetary transition and thus a possible proxy also for other planets, ii) the active search for technosignatures in the radio/optical and infrared range, and iii) the statistical modelling of technosignatures and Bayesian inference methods to learn from both detection and non-detection. This strategy (combining modelling and observations) offers the best scientific opportunity in the next decade to discover the possible existence of technological civilizations beyond Earth.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1903.06550</link><guid isPermaLink="false">https://papers.cool/arxiv/1903.06550</guid><pubDate>Thu, 14 Mar 2019 03:57:23 GMT</pubDate><author>Jacob Haqq-Misra</author></item><item><title>Towards Pedestrian Detection Using RetinaNet in ECCV 2018 Wider Pedestrian Detection Challenge</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1902.01031&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1902.01031&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Md Ashraful Alam Milton&lt;/p&gt;   &lt;p&gt;The main essence of this paper is to investigate the performance of RetinaNet based object detectors on pedestrian detection. Pedestrian detection is an important research topic as it provides a baseline for general object detection and has a great number of practical applications like autonomous car, robotics and Security camera. Though extensive research has made huge progress in pedestrian detection, there are still many issues and open for more research and improvement. Recent deep learning based methods have shown state-of-the-art performance in computer vision tasks such as image classification, object detection, and segmentation. Wider pedestrian detection challenge aims at finding improve solutions for pedestrian detection problem. In this paper, We propose a pedestrian detection system based on RetinaNet. Our solution has scored 0.4061 mAP. The code is available at https://github.com/miltonbd/ECCV_2018_pedestrian_detection_challenege.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1902.01031</link><guid isPermaLink="false">https://papers.cool/arxiv/1902.01031</guid><pubDate>Mon, 04 Feb 2019 04:49:59 GMT</pubDate><author>Md Ashraful Alam Milton</author></item><item><title>Confidence Trigger Detection: Accelerating Real-time Tracking-by-detection Systems</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1902.00615&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1902.00615&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zhicheng Ding&lt;/p&gt;   &lt;p&gt;Real-time object tracking necessitates a delicate balance between speed and accuracy, a challenge exacerbated by the computational demands of deep learning methods. In this paper, we propose Confidence-Triggered Detection (CTD), an innovative approach that strategically bypasses object detection for frames closely resembling intermediate states, leveraging tracker confidence scores. CTD not only enhances tracking speed but also preserves accuracy, surpassing existing tracking algorithms. Through extensive evaluation across various tracker confidence thresholds, we identify an optimal trade-off between tracking speed and accuracy, providing crucial insights for parameter fine-tuning and enhancing CTD&#39;s practicality in real-world scenarios. Our experiments across diverse detection models underscore the robustness and versatility of the CTD framework, demonstrating its potential to enable real-time tracking in resource-constrained environments.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1902.00615</link><guid isPermaLink="false">https://papers.cool/arxiv/1902.00615</guid><pubDate>Sat, 02 Feb 2019 01:52:53 GMT</pubDate><author>Zhicheng Ding</author></item><item><title>A backward procedure for change-point detection with applications to copy number variation detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1812.10107&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1812.10107&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Seung Jun Shin&lt;/p&gt;   &lt;p&gt;Change-point detection regains much attention recently for analyzing array or sequencing data for copy number variation (CNV) detection. In such applications, the true signals are typically very short and buried in the long data sequence, which makes it challenging to identify the variations efficiently and accurately. In this article, we propose a new change-point detection method, a backward procedure, which is not only fast and simple enough to exploit high-dimensional data but also performs very well for detecting short signals. Although motivated by CNV detection, the backward procedure is generally applicable to assorted change-point problems that arise in a variety of scientific applications. It is illustrated by both simulated and real CNV data that the backward detection has clear advantages over other competing methods especially when the true signal is short.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1812.10107</link><guid isPermaLink="false">https://papers.cool/arxiv/1812.10107</guid><pubDate>Tue, 25 Dec 2018 13:49:47 GMT</pubDate><author>Seung Jun Shin</author></item><item><title>Adversarially Learned Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1812.02288&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1812.02288&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Houssam Zenati&lt;/p&gt;   &lt;p&gt;Anomaly detection is a significant and hence well-studied problem. However, developing effective anomaly detection methods for complex and high-dimensional data remains a challenge. As Generative Adversarial Networks (GANs) are able to model the complex high-dimensional distributions of real-world data, they offer a promising approach to address this challenge. In this work, we propose an anomaly detection method, Adversarially Learned Anomaly Detection (ALAD) based on bi-directional GANs, that derives adversarially learned features for the anomaly detection task. ALAD then uses reconstruction errors based on these adversarially learned features to determine if a data sample is anomalous. ALAD builds on recent advances to ensure data-space and latent-space cycle-consistencies and stabilize GAN training, which results in significantly improved anomaly detection performance. ALAD achieves state-of-the-art performance on a range of image and tabular datasets while being several hundred-fold faster at test time than the only published GAN-based method.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1812.02288</link><guid isPermaLink="false">https://papers.cool/arxiv/1812.02288</guid><pubDate>Thu, 06 Dec 2018 01:44:59 GMT</pubDate><author>Houssam Zenati</author></item><item><title>Integrated Object Detection and Tracking with Tracklet-Conditioned Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1811.11167&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1811.11167&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Zheng Zhang&lt;/p&gt;   &lt;p&gt;Accurate detection and tracking of objects is vital for effective video understanding. In previous work, the two tasks have been combined in a way that tracking is based heavily on detection, but the detection benefits marginally from the tracking. To increase synergy, we propose to more tightly integrate the tasks by conditioning the object detection in the current frame on tracklets computed in prior frames. With this approach, the object detection results not only have high detection responses, but also improved coherence with the existing tracklets. This greater coherence leads to estimated object trajectories that are smoother and more stable than the jittered paths obtained without tracklet-conditioned detection. Over extensive experiments, this approach is shown to achieve state-of-the-art performance in terms of both detection and tracking accuracy, as well as noticeable improvements in tracking stability.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1811.11167</link><guid isPermaLink="false">https://papers.cool/arxiv/1811.11167</guid><pubDate>Tue, 27 Nov 2018 18:58:07 GMT</pubDate><author>Zheng Zhang</author></item><item><title>Sequential Subspace Change-Point Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1811.03936&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1811.03936&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Liyan Xie&lt;/p&gt;   &lt;p&gt;We consider the online monitoring of multivariate streaming data for changes that are characterized by an unknown subspace structure manifested in the covariance matrix. In particular, we consider the covariance structure changes from an identity matrix to an unknown spiked covariance model. We assume the post-change distribution is unknown, and propose two detection procedures: the Largest-Eigenvalue Shewhart chart and the Subspace-CUSUM detection procedure. We present theoretical approximations to the average run length (ARL) and the expected detection delay (EDD) for the Largest-Eigenvalue Shewhart chart and also provide analysis for tuning parameters of the Subspace-CUSUM procedure. The performance of the proposed methods is illustrated using simulation and real data for human gesture detection and seismic event detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1811.03936</link><guid isPermaLink="false">https://papers.cool/arxiv/1811.03936</guid><pubDate>Fri, 09 Nov 2018 14:56:27 GMT</pubDate><author>Liyan Xie</author></item><item><title>Focal Loss in 3D Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1809.06065&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1809.06065&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Peng Yun&lt;/p&gt;   &lt;p&gt;3D object detection is still an open problem in autonomous driving scenes. When recognizing and localizing key objects from sparse 3D inputs, autonomous vehicles suffer from a larger continuous searching space and higher fore-background imbalance compared to image-based object detection. In this paper, we aim to solve this fore-background imbalance in 3D object detection. Inspired by the recent use of focal loss in image-based object detection, we extend this hard-mining improvement of binary cross entropy to point-cloud-based object detection and conduct experiments to show its performance based on two different 3D detectors: 3D-FCN and VoxelNet. The evaluation results show up to 11.2AP gains through the focal loss in a wide range of hyperparameters for 3D object detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1809.06065</link><guid isPermaLink="false">https://papers.cool/arxiv/1809.06065</guid><pubDate>Mon, 17 Sep 2018 08:02:00 GMT</pubDate><author>Peng Yun</author></item><item><title>Differentially Private Change-Point Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1808.10056&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1808.10056&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Rachel Cummings&lt;/p&gt;   &lt;p&gt;The change-point detection problem seeks to identify distributional changes at an unknown change-point k* in a stream of data. This problem appears in many important practical settings involving personal data, including biosurveillance, fault detection, finance, signal detection, and security systems. The field of differential privacy offers data analysis tools that provide powerful worst-case privacy guarantees. We study the statistical problem of change-point detection through the lens of differential privacy. We give private algorithms for both online and offline change-point detection, analyze these algorithms theoretically, and provide empirical validation of our results.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1808.10056</link><guid isPermaLink="false">https://papers.cool/arxiv/1808.10056</guid><pubDate>Wed, 29 Aug 2018 22:17:24 GMT</pubDate><author>Rachel Cummings</author></item><item><title>Social network aided plagiarism detection: Social network aided plagiarism detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1807.02830&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1807.02830&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Aljaž Zrnec&lt;/p&gt;   &lt;p&gt;The prevalence of different kinds of electronic devices and the volume of content on the Web have increased the amount of plagiarism, which is considered an unethical act. If we want to be efficient in the detection and prevention of these acts, we have to improve today&#39;s methods of discovering plagiarism. The paper presents a research study where a framework for the improved detection of plagiarism is proposed. The framework focuses on the integration of social network information, information from the Web, and an advanced semantically enriched visualization of information about authors and documents that enables the exploration of obtained data by seeking of advanced patterns of plagiarism. To support the proposed framework, a special software tool was also developed. The statistical evaluation confirmed that the employment of social network analysis and advanced visualization techniques led to improvements in the confirmation and investigation stages of the plagiarism detection process, thereby enhancing the overall efficiency of the plagiarism detection process.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1807.02830</link><guid isPermaLink="false">https://papers.cool/arxiv/1807.02830</guid><pubDate>Sun, 08 Jul 2018 14:29:00 GMT</pubDate><author>Aljaž Zrnec</author></item><item><title>Open Logo Detection Challenge</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1807.01964&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1807.01964&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hang Su&lt;/p&gt;   &lt;p&gt;Existing logo detection benchmarks consider artificial deployment scenarios by assuming that large training data with fine-grained bounding box annotations for each class are available for model training. Such assumptions are often invalid in realistic logo detection scenarios where new logo classes come progressively and require to be detected with little or none budget for exhaustively labelling fine-grained training data for every new class. Existing benchmarks are thus unable to evaluate the true performance of a logo detection method in realistic and open deployments. In this work, we introduce a more realistic and challenging logo detection setting, called Open Logo Detection. Specifically, this new setting assumes fine-grained labelling only on a small proportion of logo classes whilst the remaining classes have no labelled training data to simulate the open deployment. We further create an open logo detection benchmark, called OpenLogo,to promote the investigation of this new challenge. OpenLogo contains 27,083 images from 352 logo classes, built by aggregating/refining 7 existing datasets and establishing an open logo detection evaluation protocol. To address this challenge, we propose a Context Adversarial Learning (CAL) approach to synthesising training data with coherent logo instance appearance against diverse background context for enabling more effective optimisation of contemporary deep learning detection models. Experiments show the performance advantage of CAL over existing state-of-the-art alternative methods on the more realistic and challenging OpenLogo benchmark.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1807.01964</link><guid isPermaLink="false">https://papers.cool/arxiv/1807.01964</guid><pubDate>Thu, 05 Jul 2018 12:40:39 GMT</pubDate><author>Hang Su</author></item><item><title>Client-Specific Anomaly Detection for Face Presentation Attack Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1807.00848&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1807.00848&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Shervin Rahimzadeh Arashloo&lt;/p&gt;   &lt;p&gt;The one-class anomaly detection approach has previously been found to be effective in face presentation attack detection, especially in an \textit{unseen} attack scenario, where the system is exposed to novel types of attacks. This work follows the same anomaly-based formulation of the problem and analyses the merits of deploying \textit{client-specific} information for face spoofing detection. We propose training one-class client-specific classifiers (both generative and discriminative) using representations obtained from pre-trained deep convolutional neural networks. Next, based on subject-specific score distributions, a distinct threshold is set for each client, which is then used for decision making regarding a test query. Through extensive experiments using different one-class systems, it is shown that the use of client-specific information in a one-class anomaly detection formulation (both in model construction as well as decision threshold tuning) improves the performance significantly. In addition, it is demonstrated that the same set of deep convolutional features used for the recognition purposes is effective for face presentation attack detection in the class-specific one-class anomaly detection paradigm.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1807.00848</link><guid isPermaLink="false">https://papers.cool/arxiv/1807.00848</guid><pubDate>Mon, 02 Jul 2018 18:19:03 GMT</pubDate><author>Shervin Rahimzadeh Arashloo</author></item><item><title>Non-overlapping community detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1805.11584&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1805.11584&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Le2i Hocine Cherifi&lt;/p&gt;   &lt;p&gt;The richness of definitions and features of the community-detection problem has led to an impressive body of literature. In fact, many community-detection methods and surveys have been introduced in recent years. The goal here is to present a state-of-the-art of the most mature research in this area. We will therefore concentrate on non-overlapping community detection with the basic graph model. In this chapter we will give an overview of the most influential approaches to community detection that encompass most of the main methods and techniques. A special focus will also be given to community evaluation.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1805.11584</link><guid isPermaLink="false">https://papers.cool/arxiv/1805.11584</guid><pubDate>Tue, 29 May 2018 17:01:43 GMT</pubDate><author>Le2i Hocine Cherifi</author></item><item><title>Quickest Detection of Intermittent Signals With Application to Vision Based Aircraft Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1804.09846&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1804.09846&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Jasmin James&lt;/p&gt;   &lt;p&gt;In this paper we consider the problem of quickly detecting changes in an intermittent signal that can (repeatedly) switch between a normal and an anomalous state. We pose this intermittent signal detection problem as an optimal stopping problem and establish a quickest intermittent signal detection (ISD) rule with a threshold structure. We develop bounds to characterise the performance of our ISD rule and establish a new filter for estimating its detection delays. Finally, we examine the performance of our ISD rule in both a simulation study and an important vision based aircraft detection application where the ISD rule demonstrates improvements in detection range and false alarm rates relative to the current state of the art aircraft detection techniques.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1804.09846</link><guid isPermaLink="false">https://papers.cool/arxiv/1804.09846</guid><pubDate>Thu, 26 Apr 2018 01:14:14 GMT</pubDate><author>Jasmin James</author></item><item><title>Fake Colorized Image Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1801.02768&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1801.02768&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yuanfang Guo&lt;/p&gt;   &lt;p&gt;Image forensics aims to detect the manipulation of digital images. Currently, splicing detection, copy-move detection and image retouching detection are drawing much attentions from researchers. However, image editing techniques develop with time goes by. One emerging image editing technique is colorization, which can colorize grayscale images with realistic colors. Unfortunately, this technique may also be intentionally applied to certain images to confound object recognition algorithms. To the best of our knowledge, no forensic technique has yet been invented to identify whether an image is colorized. We observed that, compared to natural images, colorized images, which are generated by three state-of-the-art methods, possess statistical differences for the hue and saturation channels. Besides, we also observe statistical inconsistencies in the dark and bright channels, because the colorization process will inevitably affect the dark and bright channel values. Based on our observations, i.e., potential traces in the hue, saturation, dark and bright channels, we propose two simple yet effective detection methods for fake colorized images: Histogram based Fake Colorized Image Detection (FCID-HIST) and Feature Encoding based Fake Colorized Image Detection (FCID-FE). Experimental results demonstrate that both proposed methods exhibit a decent performance against multiple state-of-the-art colorization approaches.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1801.02768</link><guid isPermaLink="false">https://papers.cool/arxiv/1801.02768</guid><pubDate>Tue, 09 Jan 2018 02:58:45 GMT</pubDate><author>Yuanfang Guo</author></item><item><title>Rank of Experts: Detection Network Ensemble</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1712.00185&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1712.00185&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Seung-Hwan Bae&lt;/p&gt;   &lt;p&gt;The recent advances of convolutional detectors show impressive performance improvement for large scale object detection. However, in general, the detection performance usually decreases as the object classes to be detected increases, and it is a practically challenging problem to train a dominant model for all classes due to the limitations of detection models and datasets. In most cases, therefore, there are distinct performance differences of the modern convolutional detectors for each object class detection. In this paper, in order to build an ensemble detector for large scale object detection, we present a conceptually simple but very effective class-wise ensemble detection which is named as Rank of Experts. We first decompose an intractable problem of finding the best detections for all object classes into small subproblems of finding the best ones for each object class. We then solve the detection problem by ranking detectors in order of the average precision rate for each class, and then aggregate the responses of the top ranked detectors (i.e. experts) for class-wise ensemble detection. The main benefit of our method is easy to implement and does not require any joint training of experts for ensemble. Based on the proposed Rank of Experts, we won the 2nd place in the ILSVRC 2017 object detection competition.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1712.00185</link><guid isPermaLink="false">https://papers.cool/arxiv/1712.00185</guid><pubDate>Fri, 01 Dec 2017 04:27:20 GMT</pubDate><author>Seung-Hwan Bae</author></item><item><title>Double balanced homodyne detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1711.03713&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1711.03713&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kouji Nakamura&lt;/p&gt;   &lt;p&gt;In the context of the readout scheme for gravitational-wave detectors, the &quot;double balanced homodyne detection&quot; proposed in [K.~Nakamura and M.-K.~Fujimoto, arXiv:1709.01697.] is discussed in detail. This double balanced homodyne detection enables us to measure the expectation values of the photon creation and annihilation operators. Although it has been said that the operator $\hat{b}_{\theta}:=\cos\theta\hat{b}_{1}+\sin\theta\hat{b}_{2}$ can be measured through the homodyne detection in literature, we first show that the expectation value of the operator $\hat{b}_{\theta}$ cannot be measured as the linear combination of the upper- and lower-sidebands from the output of the balanced homodyne detection. Here, the operators $\hat{b}_{1}$ and $\hat{b}_{2}$ are the amplitude and phase quadrature in the two-photon formulation, respectively. On the other hand, it is shown that the above double balanced homodyne detection enables us to measure the expectation value of the operator $\hat{b}_{\theta}$ if we can appropriately prepare the complex amplitude of the coherent state from the local oscillator. It is also shown that the interferometer set up of the eight-port homodyne detection realizes our idea of the double balanced homodyne detection. We also evaluate the noise-spectral density of the gravitational-wave detectors when our double balanced homodyne detection is applied as their readout scheme. Some requirements for the coherent state from the local oscillator to realize the double balanced homodyne detection are also discussed.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1711.03713</link><guid isPermaLink="false">https://papers.cool/arxiv/1711.03713</guid><pubDate>Fri, 10 Nov 2017 06:56:11 GMT</pubDate><author>Kouji Nakamura</author></item><item><title>FADO: A Deterministic Detection/Learning Algorithm</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1711.02361&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1711.02361&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Kristiaan Pelckmans&lt;/p&gt;   &lt;p&gt;This paper proposes and studies a detection technique for adversarial scenarios (dubbed deterministic detection). This technique provides an alternative detection methodology in case the usual stochastic methods are not applicable: this can be because the studied phenomenon does not follow a stochastic sampling scheme, samples are high-dimensional and subsequent multiple-testing corrections render results overly conservative, sample sizes are too low for asymptotic results (as e.g. the central limit theorem) to kick in, or one cannot allow for the small probability of failure inherent to stochastic approaches. This paper instead designs a method based on insights from machine learning and online learning theory: this detection algorithm - named Online FAult Detection (FADO) - comes with theoretical guarantees of its detection capabilities. A version of the margin is found to regulate the detection performance of FADO. A precise expression is derived for bounding the performance, and experimental results are presented assessing the influence of involved quantities. A case study of scene detection is used to illustrate the approach. The technology is closely related to the linear perceptron rule, inherits its computational attractiveness and flexibility towards various extensions.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1711.02361</link><guid isPermaLink="false">https://papers.cool/arxiv/1711.02361</guid><pubDate>Tue, 07 Nov 2017 09:57:44 GMT</pubDate><author>Kristiaan Pelckmans</author></item><item><title>Adversarial Occlusion-aware Face Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1709.05188&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1709.05188&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yujia Chen&lt;/p&gt;   &lt;p&gt;Occluded face detection is a challenging detection task due to the large appearance variations incurred by various real-world occlusions. This paper introduces an Adversarial Occlusion-aware Face Detector (AOFD) by simultaneously detecting occluded faces and segmenting occluded areas. Specifically, we employ an adversarial training strategy to generate occlusion-like face features that are difficult for a face detector to recognize. Occlusion mask is predicted simultaneously while detecting occluded faces and the occluded area is utilized as an auxiliary instead of being regarded as a hindrance. Moreover, the supervisory signals from the segmentation branch will reversely affect the features, aiding in detecting heavily-occluded faces accordingly. Consequently, AOFD is able to find the faces with few exposed facial landmarks with very high confidences and keeps high detection accuracy even for masked faces. Extensive experiments demonstrate that AOFD not only significantly outperforms state-of-the-art methods on the MAFA occluded face detection dataset, but also achieves competitive detection accuracy on benchmark dataset for general face detection such as FDDB.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1709.05188</link><guid isPermaLink="false">https://papers.cool/arxiv/1709.05188</guid><pubDate>Fri, 15 Sep 2017 13:22:22 GMT</pubDate><author>Yujia Chen</author></item><item><title>Blind Detection of Polar Codes</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1705.02111&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1705.02111&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Pascal Giard&lt;/p&gt;   &lt;p&gt;Polar codes were recently chosen to protect the control channel information in the next-generation mobile communication standard (5G) defined by the 3GPP. As a result, receivers will have to implement blind detection of polar coded frames in order to keep complexity, latency, and power consumption tractable. As a newly proposed class of block codes, the problem of polar-code blind detection has received very little attention. In this work, we propose a low-complexity blind-detection algorithm for polar-encoded frames. We base this algorithm on a novel detection metric with update rules that leverage the a priori knowledge of the frozen-bit locations, exploiting the inherent structures that these locations impose on a polar-encoded block of data. We show that the proposed detection metric allows to clearly distinguish polar-encoded frames from other types of data by considering the cumulative distribution functions of the detection metric, and the receiver operating characteristic. The presented results are tailored to the 5G standardization effort discussions, i.e., we consider a short low-rate polar code concatenated with a CRC.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1705.02111</link><guid isPermaLink="false">https://papers.cool/arxiv/1705.02111</guid><pubDate>Fri, 05 May 2017 07:43:52 GMT</pubDate><author>Pascal Giard</author></item><item><title>Randomized detection and detection capacity of multidetector networks</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1704.04600&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1704.04600&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ghurumuruhan Ganesan&lt;/p&gt;   &lt;p&gt;In this paper, we study the following detection problem. There are $n$ detectors randomly placed in the unit square $S = \left[-\frac{1}{2},\frac{1}{2}\right]^2$ assigned to detect the presence of a source located at the origin. Time is divided into slots of unit length and $D_i(t) \in \{0,1\}$ represents the (random) decision of the $i^{\rm th}$ detector in time slot $t$. The location of the source is unknown to the detectors and the goal is to design schemes that use the decisions $\{D_i(t)\}_{i,t}$ and detect the presence of the source in as short time as possible. We first determine the minimum achievable detection time $T_{cap}$ and show the existence of \emph{randomized} detection schemes that have detection times arbitrarily close to $T_{cap}$ for almost all configuration of detectors, provided the number of detectors $n$ is sufficiently large. We call such schemes as \emph{capacity achieving} and completely characterize all capacity achieving detection schemes.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1704.04600</link><guid isPermaLink="false">https://papers.cool/arxiv/1704.04600</guid><pubDate>Sat, 15 Apr 2017 07:32:16 GMT</pubDate><author>Ghurumuruhan Ganesan</author></item><item><title>Bridging Saliency Detection to Weakly Supervised Object Detection Based on Self-paced Curriculum Learning</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1703.01290&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1703.01290&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Dingwen Zhang&lt;/p&gt;   &lt;p&gt;Weakly-supervised object detection (WOD) is a challenging problems in computer vision. The key problem is to simultaneously infer the exact object locations in the training images and train the object detectors, given only the training images with weak image-level labels. Intuitively, by simulating the selective attention mechanism of human visual system, saliency detection technique can select attractive objects in scenes and thus is a potential way to provide useful priors for WOD. However, the way to adopt saliency detection in WOD is not trivial since the detected saliency region might be possibly highly ambiguous in complex cases. To this end, this paper first comprehensively analyzes the challenges in applying saliency detection to WOD. Then, we make one of the earliest efforts to bridge saliency detection to WOD via the self-paced curriculum learning, which can guide the learning procedure to gradually achieve faithful knowledge of multi-class objects from easy to hard. The experimental results demonstrate that the proposed approach can successfully bridge saliency detection and WOD tasks and achieve the state-of-the-art object detection results under the weak supervision.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1703.01290</link><guid isPermaLink="false">https://papers.cool/arxiv/1703.01290</guid><pubDate>Fri, 03 Mar 2017 18:55:10 GMT</pubDate><author>Dingwen Zhang</author></item><item><title>Assessing the impacts of time to detection distribution assumptions on detection probability estimation</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1612.00168&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1612.00168&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Adam Martin-Schwarze&lt;/p&gt;   &lt;p&gt;Abundance estimates from animal point-count surveys require accurate estimates of detection probabilities. The standard model for estimating detection from removal-sampled point-count surveys assumes that organisms at a survey site are detected at a constant rate; however, this assumption is often not justified. We consider a class of N-mixture models that allows for detection heterogeneity over time through a flexibly defined time-to-detection distribution (TTDD) and allows for fixed and random effects for both abundance and detection. Our model is thus a combination of survival time-to-event analysis with unknown-N, unknown-p abundance estimation. We specifically explore two-parameter families of TTDDs, e.g. gamma, that can additionally include a mixture component to model increased probability of detection in the initial observation period. We find that modeling a TTDD by using a two-parameter family is necessary when data have a chance of arising from a distribution of this nature. In addition, models with a mixture component can outperform non-mixture models even when the truth is non-mixture. Finally, we analyze an Overbird data set from the Chippewa National Forest using mixed effect models for both abundance and detection. We demonstrate that the effects of explanatory variables on abundance and detection are consistent across mixture TTDDs but that flexible TTDDs result in lower estimated probabilities of detection and therefore higher estimates of abundance.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1612.00168</link><guid isPermaLink="false">https://papers.cool/arxiv/1612.00168</guid><pubDate>Thu, 01 Dec 2016 08:04:07 GMT</pubDate><author>Adam Martin-Schwarze</author></item><item><title>Recurrent Neural Radio Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1611.00301&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1611.00301&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Timothy J O&#39;Shea&lt;/p&gt;   &lt;p&gt;We introduce a powerful recurrent neural network based method for novelty detection to the application of detecting radio anomalies. This approach holds promise in significantly increasing the ability of naive anomaly detection to detect small anomalies in highly complex complexity multi-user radio bands. We demonstrate the efficacy of this approach on a number of common real over the air radio communications bands of interest and quantify detection performance in terms of probability of detection an false alarm rates across a range of interference to band power ratios and compare to baseline methods.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1611.00301</link><guid isPermaLink="false">https://papers.cool/arxiv/1611.00301</guid><pubDate>Tue, 01 Nov 2016 17:17:26 GMT</pubDate><author>Timothy J O&#39;Shea</author></item><item><title>Optimal Inference for Distributed Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1605.05808&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1605.05808&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Earnest Akofor&lt;/p&gt;   &lt;p&gt;In distributed detection, there does not exist an automatic way of generating optimal decision strategies for non-affine decision functions. Consequently, in a detection problem based on a non-affine decision function, establishing optimality of a given decision strategy, such as a generalized likelihood ratio test, is often difficult or even impossible. In this thesis we develop a novel detection network optimization technique that can be used to determine necessary and sufficient conditions for optimality in distributed detection for which the underlying objective function is monotonic and convex in probabilistic decision strategies. Our developed approach leverages on basic concepts of optimization and statistical inference which are provided in sufficient detail. These basic concepts are combined to form the basis of an optimal inference technique for signal detection. We prove a central theorem that characterizes optimality in a variety of distributed detection architectures. We discuss three applications of this result in distributed signal detection. These applications include interactive distributed detection, optimal tandem fusion architecture, and distributed detection by acyclic graph networks. In the conclusion we indicate several future research directions, which include possible generalizations of our optimization method and new research problems arising from each of the three applications considered.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1605.05808</link><guid isPermaLink="false">https://papers.cool/arxiv/1605.05808</guid><pubDate>Thu, 19 May 2016 04:51:59 GMT</pubDate><author>Earnest Akofor</author></item><item><title>Detection under Privileged Information</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1603.09638&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1603.09638&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Z. Berkay Celik&lt;/p&gt;   &lt;p&gt;For well over a quarter century, detection systems have been driven by models learned from input features collected from real or simulated environments. An artifact (e.g., network event, potential malware sample, suspicious email) is deemed malicious or non-malicious based on its similarity to the learned model at runtime. However, the training of the models has been historically limited to only those features available at runtime. In this paper, we consider an alternate learning approach that trains models using &quot;privileged&quot; information--features available at training time but not at runtime--to improve the accuracy and resilience of detection systems. In particular, we adapt and extend recent advances in knowledge transfer, model influence, and distillation to enable the use of forensic or other data unavailable at runtime in a range of security domains. An empirical evaluation shows that privileged information increases precision and recall over a system with no privileged information: we observe up to 7.7% relative decrease in detection error for fast-flux bot detection, 8.6% for malware traffic detection, 7.3% for malware classification, and 16.9% for face recognition. We explore the limitations and applications of different privileged information techniques in detection systems. Such techniques provide a new means for detection systems to learn from data that would otherwise not be available at runtime.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1603.09638</link><guid isPermaLink="false">https://papers.cool/arxiv/1603.09638</guid><pubDate>Thu, 31 Mar 2016 15:28:45 GMT</pubDate><author>Z. Berkay Celik</author></item><item><title>Fast detection of multiple objects in traffic scenes with a common detection framework</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1510.03125&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1510.03125&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Qichang Hu&lt;/p&gt;   &lt;p&gt;Traffic scene perception (TSP) aims to real-time extract accurate on-road environment information, which in- volves three phases: detection of objects of interest, recognition of detected objects, and tracking of objects in motion. Since recognition and tracking often rely on the results from detection, the ability to detect objects of interest effectively plays a crucial role in TSP. In this paper, we focus on three important classes of objects: traffic signs, cars, and cyclists. We propose to detect all the three important objects in a single learning based detection framework. The proposed framework consists of a dense feature extractor and detectors of three important classes. Once the dense features have been extracted, these features are shared with all detectors. The advantage of using one common framework is that the detection speed is much faster, since all dense features need only to be evaluated once in the testing phase. In contrast, most previous works have designed specific detectors using different features for each of these objects. To enhance the feature robustness to noises and image deformations, we introduce spatially pooled features as a part of aggregated channel features. In order to further improve the generalization performance, we propose an object subcategorization method as a means of capturing intra-class variation of objects. We experimentally demonstrate the effectiveness and efficiency of the proposed framework in three detection applications: traffic sign detection, car detection, and cyclist detection. The proposed framework achieves the competitive performance with state-of- the-art approaches on several benchmark datasets.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1510.03125</link><guid isPermaLink="false">https://papers.cool/arxiv/1510.03125</guid><pubDate>Mon, 12 Oct 2015 02:30:22 GMT</pubDate><author>Qichang Hu</author></item><item><title>Holistically-Nested Edge Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1504.06375&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1504.06375&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Saining Xie&lt;/p&gt;   &lt;p&gt;We develop a new edge detection algorithm that tackles two important issues in this long-standing vision problem: (1) holistic image training and prediction; and (2) multi-scale and multi-level feature learning. Our proposed method, holistically-nested edge detection (HED), performs image-to-image prediction by means of a deep learning model that leverages fully convolutional neural networks and deeply-supervised nets. HED automatically learns rich hierarchical representations (guided by deep supervision on side responses) that are important in order to approach the human ability resolve the challenging ambiguity in edge and object boundary detection. We significantly advance the state-of-the-art on the BSD500 dataset (ODS F-score of .782) and the NYU Depth dataset (ODS F-score of .746), and do so with an improved speed (0.4 second per image) that is orders of magnitude faster than some recent CNN-based edge detection algorithms.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1504.06375</link><guid isPermaLink="false">https://papers.cool/arxiv/1504.06375</guid><pubDate>Fri, 24 Apr 2015 02:12:15 GMT</pubDate><author>Saining Xie</author></item><item><title>Scaling up Copy Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1503.00309&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1503.00309&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xian Li&lt;/p&gt;   &lt;p&gt;Recent research shows that copying is prevalent for Deep-Web data and considering copying can significantly improve truth finding from conflicting values. However, existing copy detection techniques do not scale for large sizes and numbers of data sources, so truth finding can be slowed down by one to two orders of magnitude compared with the corresponding techniques that do not consider copying. In this paper, we study {\em how to improve scalability of copy detection on structured data}. Our algorithm builds an inverted index for each \emph{shared} value and processes the index entries in decreasing order of how much the shared value can contribute to the conclusion of copying. We show how we use the index to prune the data items we consider for each pair of sources, and to incrementally refine our results in iterative copy detection. We also apply a sampling strategy with which we are able to further reduce copy-detection time while still obtaining very similar results as on the whole data set. Experiments on various real data sets show that our algorithm can reduce the time for copy detection by two to three orders of magnitude; in other words, truth finding can benefit from copy detection with very little overhead.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1503.00309</link><guid isPermaLink="false">https://papers.cool/arxiv/1503.00309</guid><pubDate>Sun, 01 Mar 2015 17:00:29 GMT</pubDate><author>Xian Li</author></item><item><title>Status of Dark Matter Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1409.4590&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1409.4590&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xiao-Jun Bi&lt;/p&gt;   &lt;p&gt;The detection of dark matter has made great progresses in recent years. We give a brief review on the status and progress in dark matter detection, including the progresses in direct detection, collider detection at LHC and focus on the indirect detection. The results from PAMELA, ATIC, Fermi-LAT and relevant studies on these results are introduced. Then we give the progress on indirect detection of gamma rays from Fermi-LAT and ground based Cerenkov telescopes. Finally the detection of neutrinos and constraints on the nature of dark matter are reviewed briefly.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1409.4590</link><guid isPermaLink="false">https://papers.cool/arxiv/1409.4590</guid><pubDate>Tue, 16 Sep 2014 11:37:06 GMT</pubDate><author>Xiao-Jun Bi</author></item><item><title>Strongly Incremental Repair Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1408.6788&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1408.6788&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Julian Hough&lt;/p&gt;   &lt;p&gt;We present STIR (STrongly Incremental Repair detection), a system that detects speech repairs and edit terms on transcripts incrementally with minimal latency. STIR uses information-theoretic measures from n-gram models as its principal decision features in a pipeline of classifiers detecting the different stages of repairs. Results on the Switchboard disfluency tagged corpus show utterance-final accuracy on a par with state-of-the-art incremental repair detection methods, but with better incremental accuracy, faster time-to-detection and less computational overhead. We evaluate its performance using incremental metrics and propose new repair processing evaluation standards.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1408.6788</link><guid isPermaLink="false">https://papers.cool/arxiv/1408.6788</guid><pubDate>Thu, 28 Aug 2014 17:29:55 GMT</pubDate><author>Julian Hough</author></item><item><title>Hanle detection for optical clocks</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1404.4431&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1404.4431&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Xiaogang Zhang&lt;/p&gt;   &lt;p&gt;Considering the strong inhomogeneous spatial polarization and intensity distribution of spontaneous decay fluorescence due to the Hanle effect, we propose and demonstrate a universe Hanle detection configuration of electron-shelving method for optical clocks. Experimental results from Ca atomic beam optical frequency standard with 423 nm electron-shelving method show that a designed Hanle detection geometry with optimized magnetic field direction, detection laser beam propagation and polarization direction, and detector position can improve the fluorescence collection rate by more than one order of magnitude comparing with that of inefficient geometry. With the fixed 423 nm fluorescence, the improved 657 nm optical frequency standard signal intensity is presented. And the potential application of the Hanle detection geometry designed for facilitating the fluorescence collection for optical lattice clock with a limited solid angle of the fluorescence collection has been discussed. This Hanle detection configuration is also effective for ion detection in ion optical clock and quantum information experiments. Besides, a cylinder fluorescence collection structure is designed to increase the solid angle of the fluorescence collection in Ca atomic beam optical frequency standard.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1404.4431</link><guid isPermaLink="false">https://papers.cool/arxiv/1404.4431</guid><pubDate>Thu, 17 Apr 2014 06:49:39 GMT</pubDate><author>Xiaogang Zhang</author></item><item><title>Network Traffic Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1402.0856&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1402.0856&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Hong Huang&lt;/p&gt;   &lt;p&gt;This paper presents a tutorial for network anomaly detection, focusing on non-signature-based approaches. Network traffic anomalies are unusual and significant changes in the traffic of a network. Networks play an important role in today&#39;s social and economic infrastructures. The security of the network becomes crucial, and network traffic anomaly detection constitutes an important part of network security. In this paper, we present three major approaches to non-signature-based network detection: PCA-based, sketch-based, and signal-analysis-based. In addition, we introduce a framework that subsumes the three approaches and a scheme for network anomaly extraction. We believe network anomaly detection will become more important in the future because of the increasing importance of network security.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1402.0856</link><guid isPermaLink="false">https://papers.cool/arxiv/1402.0856</guid><pubDate>Tue, 04 Feb 2014 20:38:34 GMT</pubDate><author>Hong Huang</author></item><item><title>Toward Supervised Anomaly Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1401.6424&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1401.6424&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Nico Goernitz&lt;/p&gt;   &lt;p&gt;Anomaly detection is being regarded as an unsupervised learning task as anomalies stem from adversarial or unlikely events with unknown distributions. However, the predictive performance of purely unsupervised anomaly detection often fails to match the required detection rates in many tasks and there exists a need for labeled data to guide the model generation. Our first contribution shows that classical semi-supervised approaches, originating from a supervised classifier, are inappropriate and hardly detect new and unknown anomalies. We argue that semi-supervised anomaly detection needs to ground on the unsupervised learning paradigm and devise a novel algorithm that meets this requirement. Although being intrinsically non-convex, we further show that the optimization problem has a convex equivalent under relatively mild assumptions. Additionally, we propose an active learning strategy to automatically filter candidates for labeling. In an empirical study on network intrusion detection data, we observe that the proposed learning methodology requires much less labeled data than the state-of-the-art, while achieving higher detection accuracies.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1401.6424</link><guid isPermaLink="false">https://papers.cool/arxiv/1401.6424</guid><pubDate>Thu, 23 Jan 2014 02:46:53 GMT</pubDate><author>Nico Goernitz</author></item><item><title>Experimental Detection of Quantum Channels</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1307.6005&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1307.6005&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; 1 and 2 Adeline Orieux&lt;/p&gt;   &lt;p&gt;We demonstrate experimentally the possibility of efficiently detecting properties of quantum channels and quantum gates. The optimal detection scheme is first achieved for non entanglement breaking channels of the depolarizing form and is based on the generation and detection of polarized entangled photons. We then demonstrate channel detection for non separable maps by considering the CNOT gate and employing two-photon hyperentangled states.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1307.6005</link><guid isPermaLink="false">https://papers.cool/arxiv/1307.6005</guid><pubDate>Tue, 23 Jul 2013 09:59:51 GMT</pubDate><author>1 and 2 Adeline Orieux</author></item><item><title>Network Detection Theory and Performance</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1303.5613&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1303.5613&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Steven T. Smith&lt;/p&gt;   &lt;p&gt;Network detection is an important capability in many areas of applied research in which data can be represented as a graph of entities and relationships. Oftentimes the object of interest is a relatively small subgraph in an enormous, potentially uninteresting background. This aspect characterizes network detection as a &quot;big data&quot; problem. Graph partitioning and network discovery have been major research areas over the last ten years, driven by interest in internet search, cyber security, social networks, and criminal or terrorist activities. The specific problem of network discovery is addressed as a special case of graph partitioning in which membership in a small subgraph of interest must be determined. Algebraic graph theory is used as the basis to analyze and compare different network detection methods. A new Bayesian network detection framework is introduced that partitions the graph based on prior information and direct observations. The new approach, called space-time threat propagation, is proved to maximize the probability of detection and is therefore optimum in the Neyman-Pearson sense. This optimality criterion is compared to spectral community detection approaches which divide the global graph into subsets or communities with optimal connectivity properties. We also explore a new generative stochastic model for covert networks and analyze using receiver operating characteristics the detection performance of both classes of optimal detection techniques.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1303.5613</link><guid isPermaLink="false">https://papers.cool/arxiv/1303.5613</guid><pubDate>Fri, 22 Mar 2013 13:34:28 GMT</pubDate><author>Steven T. Smith</author></item><item><title>Efficient Computer Network Anomaly Detection by Changepoint Detection Methods</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1212.1829&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1212.1829&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Alexander G. Tartakovsky&lt;/p&gt;   &lt;p&gt;We consider the problem of efficient on-line anomaly detection in computer network traffic. The problem is approached statistically, as that of sequential (quickest) changepoint detection. A multi-cyclic setting of quickest change detection is a natural fit for this problem. We propose a novel score-based multi-cyclic detection algorithm. The algorithm is based on the so-called Shiryaev-Roberts procedure. This procedure is as easy to employ in practice and as computationally inexpensive as the popular Cumulative Sum chart and the Exponentially Weighted Moving Average scheme. The likelihood ratio based Shiryaev-Roberts procedure has appealing optimality properties, particularly it is exactly optimal in a multi-cyclic setting geared to detect a change occurring at a far time horizon. It is therefore expected that an intrusion detection algorithm based on the Shiryaev-Roberts procedure will perform better than other detection schemes. This is confirmed experimentally for real traces. We also discuss the possibility of complementing our anomaly detection algorithm with a spectral-signature intrusion detection system with false alarm filtering and true attack confirmation capability, so as to obtain a synergistic system.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1212.1829</link><guid isPermaLink="false">https://papers.cool/arxiv/1212.1829</guid><pubDate>Sat, 08 Dec 2012 19:16:07 GMT</pubDate><author>Alexander G. Tartakovsky</author></item><item><title>Optimal Detection For Sparse Mixtures</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1211.2265&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1211.2265&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; T. Tony Cai&lt;/p&gt;   &lt;p&gt;Detection of sparse signals arises in a wide range of modern scientific studies. The focus so far has been mainly on Gaussian mixture models. In this paper, we consider the detection problem under a general sparse mixture model and obtain an explicit expression for the detection boundary. It is shown that the fundamental limits of detection is governed by the behavior of the log-likelihood ratio evaluated at an appropriate quantile of the null distribution. We also establish the adaptive optimality of the higher criticism procedure across all sparse mixtures satisfying certain mild regularity conditions. In particular, the general results obtained in this paper recover and extend in a unified manner the previously known results on sparse detection far beyond the conventional Gaussian model and other exponential families.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1211.2265</link><guid isPermaLink="false">https://papers.cool/arxiv/1211.2265</guid><pubDate>Fri, 09 Nov 2012 23:31:47 GMT</pubDate><author>T. Tony Cai</author></item><item><title>Detection and emergence</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1108.4279&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1108.4279&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; INFRES, LTCI Eric Bonabeau&lt;/p&gt;   &lt;p&gt;Two different conceptions of emergence are reconciled as two instances of the phenomenon of detection. In the process of comparing these two conceptions, we find that the notions of complexity and detection allow us to form a unified definition of emergence that clearly delineates the role of the observer.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1108.4279</link><guid isPermaLink="false">https://papers.cool/arxiv/1108.4279</guid><pubDate>Mon, 22 Aug 2011 11:30:49 GMT</pubDate><author>INFRES, LTCI Eric Bonabeau</author></item><item><title>Visual Concept Detection and Real Time Object Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1104.0582&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1104.0582&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Ran Tao&lt;/p&gt;   &lt;p&gt;Bag-of-words model is implemented and tried on 10-class visual concept detection problem. The experimental results show that &quot;DURF+ERT+SVM&quot; outperforms &quot;SIFT+ERT+SVM&quot; both in detection performance and computation efficiency. Besides, combining DURF and SIFT results in even better detection performance. Real-time object detection using SIFT and RANSAC is also tried on simple objects, e.g. drink can, and good result is achieved.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1104.0582</link><guid isPermaLink="false">https://papers.cool/arxiv/1104.0582</guid><pubDate>Mon, 04 Apr 2011 14:18:51 GMT</pubDate><author>Ran Tao</author></item><item><title>Detection boundary in sparse regression</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1009.1706&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1009.1706&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; LETI Yuri I. Ingster&lt;/p&gt;   &lt;p&gt;We study the problem of detection of a p-dimensional sparse vector of parameters in the linear regression model with Gaussian noise. We establish the detection boundary, i.e., the necessary and sufficient conditions for the possibility of successful detection as both the sample size n and the dimension p tend to the infinity. Testing procedures that achieve this boundary are also exhibited. Our results encompass the high-dimensional setting (p&amp;gt;&amp;gt; n). The main message is that, under some conditions, the detection boundary phenomenon that has been proved for the Gaussian sequence model, extends to high-dimensional linear regression. Finally, we establish the detection boundaries when the variance of the noise is unknown. Interestingly, the detection boundaries sometimes depend on the knowledge of the variance in a high-dimensional setting.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1009.1706</link><guid isPermaLink="false">https://papers.cool/arxiv/1009.1706</guid><pubDate>Thu, 09 Sep 2010 08:06:30 GMT</pubDate><author>LETI Yuri I. Ingster</author></item><item><title>On Optimal Deadlock Detection Scheduling</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1008.0451&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1008.0451&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Yibei Ling&lt;/p&gt;   &lt;p&gt;Deadlock detection scheduling is an important, yet often overlooked problem that can significantly affect the overall performance of deadlock handling. Excessive initiation of deadlock detection increases overall message usage, resulting in degraded system performance in the absence of deadlocks; while insufficient initiation of deadlock detection increases the deadlock persistence time, resulting in an increased deadlock resolution cost in the presence of deadlocks. The investigation of this performance tradeoff, however, is missing in the literature. This paper studies the impact of deadlock detection scheduling on the overall performance of deadlock handling. In particular, we show that there exists an optimal deadlock detection frequency that yields the minimum long-run mean average cost, which is determined by the message complexities of the deadlock detection and resolution algorithms being used, as well as the rate of deadlock formation, denoted as $\lambda$. For the best known deadlock detection and resolution algorithms, we show that the asymptotically optimal frequency of deadlock detection scheduling that minimizes the overall message overhead is ${\cal O}((\lambda n)^{1/3})$, when the total number $n$ of processes is sufficiently large. Furthermore, we show that in general fully distributed (uncoordinated) deadlock detection scheduling cannot be performed as efficiently as centralized (coordinated) deadlock detection scheduling.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1008.0451</link><guid isPermaLink="false">https://papers.cool/arxiv/1008.0451</guid><pubDate>Tue, 03 Aug 2010 03:46:56 GMT</pubDate><author>Yibei Ling</author></item><item><title>Features Based Text Similarity Detection</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1001.3487&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1001.3487&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; Chow Kok Kent&lt;/p&gt;   &lt;p&gt;As the Internet help us cross cultural border by providing different information, plagiarism issue is bound to arise. As a result, plagiarism detection becomes more demanding in overcoming this issue. Different plagiarism detection tools have been developed based on various detection techniques. Nowadays, fingerprint matching technique plays an important role in those detection tools. However, in handling some large content articles, there are some weaknesses in fingerprint matching technique especially in space and time consumption issue. In this paper, we propose a new approach to detect plagiarism which integrates the use of fingerprint matching technique with four key features to assist in the detection process. These proposed features are capable to choose the main point or key sentence in the articles to be compared. Those selected sentence will be undergo the fingerprint matching process in order to detect the similarity between the sentences. Hence, time and space usage for the comparison process is reduced without affecting the effectiveness of the plagiarism detection.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1001.3487</link><guid isPermaLink="false">https://papers.cool/arxiv/1001.3487</guid><pubDate>Wed, 20 Jan 2010 07:46:23 GMT</pubDate><author>Chow Kok Kent</author></item><item><title>Termination Detection of Local Computations</title><description>&lt;a href=&quot;https://papers.cool/arxiv/1001.2785&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/1001.2785&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; LIF Emmanuel Godard&lt;/p&gt;   &lt;p&gt;Contrary to the sequential world, the processes involved in a distributed system do not necessarily know when a computation is globally finished. This paper investigates the problem of the detection of the termination of local computations. We define four types of termination detection: no detection, detection of the local termination, detection by a distributed observer, detection of the global termination. We give a complete characterisation (except in the local termination detection case where a partial one is given) for each of this termination detection and show that they define a strict hierarchy. These results emphasise the difference between computability of a distributed task and termination detection. Furthermore, these characterisations encompass all standard criteria that are usually formulated : topological restriction (tree, rings, or triangu- lated networks ...), topological knowledge (size, diameter ...), and local knowledge to distinguish nodes (identities, sense of direction). These results are now presented as corollaries of generalising theorems. As a very special and important case, the techniques are also applied to the election problem. Though given in the model of local computations, these results can give qualitative insight for similar results in other standard models. The necessary conditions involve graphs covering and quasi-covering; the sufficient conditions (constructive local computations) are based upon an enumeration algorithm of Mazurkiewicz and a stable properties detection algorithm of Szymanski, Shi and Prywes.&lt;/p&gt; </description><link>https://papers.cool/arxiv/1001.2785</link><guid isPermaLink="false">https://papers.cool/arxiv/1001.2785</guid><pubDate>Mon, 18 Jan 2010 20:12:54 GMT</pubDate><author>LIF Emmanuel Godard</author></item><item><title>Single Atom Detection With Optical Cavities</title><description>&lt;a href=&quot;https://papers.cool/arxiv/0805.3854&quot;&gt;[Site]&lt;/a&gt;   &lt;a href=&quot;https://papers.cool/Detection/0805.3854&quot;&gt;[Kimi]&lt;/a&gt;   &lt;p&gt;&lt;b&gt;Authors:&lt;/b&gt; R. Poldy&lt;/p&gt;   &lt;p&gt;We present a thorough analysis of single atom detection using optical cavities. The large set of parameters that influence the signal-to-noise ratio for cavity detection is considered, with an emphasis on detunings, probe power, cavity finesse and photon detection schemes. Real device operating restrictions for single photon counting modules and standard photodiodes are included in our discussion, with heterodyne detection emerging as the clearly favourable technique, particularly for detuned detection at high power.&lt;/p&gt; </description><link>https://papers.cool/arxiv/0805.3854</link><guid isPermaLink="false">https://papers.cool/arxiv/0805.3854</guid><pubDate>Mon, 26 May 2008 00:54:53 GMT</pubDate><author>R. Poldy</author></item></channel></rss>